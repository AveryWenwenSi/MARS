pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 91
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f4b8629ec10>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  ./data/model/20220119_0521/pettingzoo_tennis_v2_nash_dqn_exploiter/2000_0
Arguments:  {'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'exploiter_update_itr': 3}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220119_0521/pettingzoo_tennis_v2_nash_dqn_exploiter/2000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220119_0521_exploit/pettingzoo_tennis_v2_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0521_exploit/pettingzoo_tennis_v2_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 216.0841s / 216.0841 s
first_0:                 episode reward: 70.0000,                 loss: nan
second_0:                 episode reward: -70.0000,                 loss: 0.0087
Episode: 21/10000 (0.2100%),                 avg. length: 4881.7,                last time consumption/overall running time: 4299.9307s / 4516.0148 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0061
Episode: 41/10000 (0.4100%),                 avg. length: 2939.4,                last time consumption/overall running time: 2644.2312s / 7160.2460 s
first_0:                 episode reward: -2.4000,                 loss: nan
second_0:                 episode reward: 2.4000,                 loss: 0.0046
Episode: 61/10000 (0.6100%),                 avg. length: 2304.1,                last time consumption/overall running time: 2065.6999s / 9225.9459 s
first_0:                 episode reward: -21.1500,                 loss: nan
second_0:                 episode reward: 21.1500,                 loss: 0.0052
Episode: 81/10000 (0.8100%),                 avg. length: 2043.0,                last time consumption/overall running time: 1854.7901s / 11080.7360 s
first_0:                 episode reward: -23.4000,                 loss: nan
second_0:                 episode reward: 23.4000,                 loss: 0.0051
Episode: 101/10000 (1.0100%),                 avg. length: 2162.15,                last time consumption/overall running time: 1970.2457s / 13050.9817 s
first_0:                 episode reward: -20.9500,                 loss: nan
second_0:                 episode reward: 20.9500,                 loss: 0.0038
Episode: 121/10000 (1.2100%),                 avg. length: 2021.95,                last time consumption/overall running time: 1837.8721s / 14888.8538 s
first_0:                 episode reward: -23.8000,                 loss: nan
second_0:                 episode reward: 23.8000,                 loss: 0.0037
Episode: 141/10000 (1.4100%),                 avg. length: 2027.8,                last time consumption/overall running time: 1828.1331s / 16716.9869 s
first_0:                 episode reward: -21.4500,                 loss: nan
second_0:                 episode reward: 21.4500,                 loss: 0.0039
Episode: 161/10000 (1.6100%),                 avg. length: 1910.0,                last time consumption/overall running time: 1711.8798s / 18428.8667 s
first_0:                 episode reward: -25.7000,                 loss: nan
second_0:                 episode reward: 25.7000,                 loss: 0.0034
Episode: 181/10000 (1.8100%),                 avg. length: 1956.55,                last time consumption/overall running time: 1763.9318s / 20192.7985 s
first_0:                 episode reward: -24.9500,                 loss: nan
second_0:                 episode reward: 24.9500,                 loss: 0.0031
Episode: 201/10000 (2.0100%),                 avg. length: 1915.85,                last time consumption/overall running time: 1729.5945s / 21922.3931 s
first_0:                 episode reward: -24.6000,                 loss: nan
second_0:                 episode reward: 24.6000,                 loss: 0.0032
Episode: 221/10000 (2.2100%),                 avg. length: 1804.2,                last time consumption/overall running time: 1624.2357s / 23546.6288 s
first_0:                 episode reward: -24.5000,                 loss: nan
second_0:                 episode reward: 24.5000,                 loss: 0.0030
Episode: 241/10000 (2.4100%),                 avg. length: 1762.0,                last time consumption/overall running time: 1601.7422s / 25148.3710 s
first_0:                 episode reward: -25.9000,                 loss: nan
second_0:                 episode reward: 25.9000,                 loss: 0.0028
Episode: 261/10000 (2.6100%),                 avg. length: 1948.2,                last time consumption/overall running time: 1743.1108s / 26891.4817 s
first_0:                 episode reward: -22.5500,                 loss: nan
second_0:                 episode reward: 22.5500,                 loss: 0.0030
Episode: 281/10000 (2.8100%),                 avg. length: 1849.6,                last time consumption/overall running time: 1663.3129s / 28554.7947 s
first_0:                 episode reward: -25.0000,                 loss: nan
second_0:                 episode reward: 25.0000,                 loss: 0.0032
Episode: 301/10000 (3.0100%),                 avg. length: 1919.85,                last time consumption/overall running time: 1738.3662s / 30293.1609 s
first_0:                 episode reward: -24.1500,                 loss: nan
second_0:                 episode reward: 24.1500,                 loss: 0.0031
Episode: 321/10000 (3.2100%),                 avg. length: 1793.2,                last time consumption/overall running time: 1622.1045s / 31915.2655 s
first_0:                 episode reward: -23.5000,                 loss: nan
second_0:                 episode reward: 23.5000,                 loss: 0.0029
Episode: 341/10000 (3.4100%),                 avg. length: 1896.65,                last time consumption/overall running time: 1717.8827s / 33633.1481 s
first_0:                 episode reward: -23.4500,                 loss: nan
second_0:                 episode reward: 23.4500,                 loss: 0.0026
Episode: 361/10000 (3.6100%),                 avg. length: 3613.4,                last time consumption/overall running time: 3254.8808s / 36888.0289 s
first_0:                 episode reward: 13.9000,                 loss: nan
second_0:                 episode reward: -13.9000,                 loss: 0.0052
Episode: 381/10000 (3.8100%),                 avg. length: 1778.55,                last time consumption/overall running time: 1608.5986s / 38496.6275 s
first_0:                 episode reward: -25.3500,                 loss: nan
second_0:                 episode reward: 25.3500,                 loss: 0.0057
Episode: 401/10000 (4.0100%),                 avg. length: 1891.75,                last time consumption/overall running time: 1707.7545s / 40204.3820 s
first_0:                 episode reward: -24.7500,                 loss: nan
second_0:                 episode reward: 24.7500,                 loss: 0.0042
Episode: 421/10000 (4.2100%),                 avg. length: 1770.15,                last time consumption/overall running time: 1621.6238s / 41826.0058 s
first_0:                 episode reward: -24.6500,                 loss: nan
second_0:                 episode reward: 24.6500,                 loss: 0.0028
Episode: 441/10000 (4.4100%),                 avg. length: 2827.2,                last time consumption/overall running time: 2558.1283s / 44384.1341 s
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.0043
Episode: 461/10000 (4.6100%),                 avg. length: 1761.2,                last time consumption/overall running time: 1590.4168s / 45974.5509 s
first_0:                 episode reward: -24.0500,                 loss: nan
second_0:                 episode reward: 24.0500,                 loss: 0.0050
Episode: 481/10000 (4.8100%),                 avg. length: 3216.35,                last time consumption/overall running time: 2935.0020s / 48909.5529 s
first_0:                 episode reward: 4.6000,                 loss: nan
second_0:                 episode reward: -4.6000,                 loss: 0.0051
Episode: 501/10000 (5.0100%),                 avg. length: 1788.05,                last time consumption/overall running time: 1616.7582s / 50526.3111 s
first_0:                 episode reward: -25.1000,                 loss: nan
second_0:                 episode reward: 25.1000,                 loss: 0.0052
Episode: 521/10000 (5.2100%),                 avg. length: 1894.25,                last time consumption/overall running time: 1692.4174s / 52218.7285 s
first_0:                 episode reward: -21.2000,                 loss: nan
second_0:                 episode reward: 21.2000,                 loss: 0.0049
Episode: 541/10000 (5.4100%),                 avg. length: 2133.75,                last time consumption/overall running time: 1952.8204s / 54171.5489 s
first_0:                 episode reward: -20.0500,                 loss: nan
second_0:                 episode reward: 20.0500,                 loss: 0.0043
Episode: 561/10000 (5.6100%),                 avg. length: 2150.65,                last time consumption/overall running time: 1949.6026s / 56121.1515 s
first_0:                 episode reward: -15.2000,                 loss: nan
second_0:                 episode reward: 15.2000,                 loss: 0.0031
Episode: 581/10000 (5.8100%),                 avg. length: 2798.2,                last time consumption/overall running time: 2507.6466s / 58628.7981 s
first_0:                 episode reward: -2.5000,                 loss: nan
second_0:                 episode reward: 2.5000,                 loss: 0.0046
Episode: 601/10000 (6.0100%),                 avg. length: 1879.7,                last time consumption/overall running time: 1707.3191s / 60336.1172 s
first_0:                 episode reward: -22.5000,                 loss: nan
second_0:                 episode reward: 22.5000,                 loss: 0.0055
Episode: 621/10000 (6.2100%),                 avg. length: 2103.75,                last time consumption/overall running time: 1908.8245s / 62244.9417 s
first_0:                 episode reward: -17.6000,                 loss: nan
second_0:                 episode reward: 17.6000,                 loss: 0.0050
Episode: 641/10000 (6.4100%),                 avg. length: 1848.5,                last time consumption/overall running time: 1687.1128s / 63932.0545 s
first_0:                 episode reward: -22.2500,                 loss: nan
second_0:                 episode reward: 22.2500,                 loss: 0.0032
Episode: 661/10000 (6.6100%),                 avg. length: 1937.15,                last time consumption/overall running time: 1753.4826s / 65685.5371 s
first_0:                 episode reward: -22.5000,                 loss: nan
second_0:                 episode reward: 22.5000,                 loss: 0.0038
Episode: 681/10000 (6.8100%),                 avg. length: 1946.4,                last time consumption/overall running time: 1732.0137s / 67417.5508 s
first_0:                 episode reward: -19.0500,                 loss: nan
second_0:                 episode reward: 19.0500,                 loss: 0.0028
Episode: 701/10000 (7.0100%),                 avg. length: 1994.3,                last time consumption/overall running time: 1829.6615s / 69247.2123 s
first_0:                 episode reward: -18.1500,                 loss: nan
second_0:                 episode reward: 18.1500,                 loss: 0.0027
Episode: 721/10000 (7.2100%),                 avg. length: 1887.45,                last time consumption/overall running time: 1717.2871s / 70964.4994 s
first_0:                 episode reward: -22.8000,                 loss: nan
second_0:                 episode reward: 22.8000,                 loss: 0.0030
Episode: 741/10000 (7.4100%),                 avg. length: 1892.9,                last time consumption/overall running time: 1708.5630s / 72673.0625 s
first_0:                 episode reward: -22.2000,                 loss: nan
second_0:                 episode reward: 22.2000,                 loss: 0.0029
Episode: 761/10000 (7.6100%),                 avg. length: 1889.1,                last time consumption/overall running time: 1717.3751s / 74390.4376 s
first_0:                 episode reward: -21.1500,                 loss: nan
second_0:                 episode reward: 21.1500,                 loss: 0.0030
Episode: 781/10000 (7.8100%),                 avg. length: 1829.3,                last time consumption/overall running time: 1667.6322s / 76058.0698 s
first_0:                 episode reward: -24.2500,                 loss: nan
second_0:                 episode reward: 24.2500,                 loss: 0.0029
Episode: 801/10000 (8.0100%),                 avg. length: 2130.9,                last time consumption/overall running time: 1928.5228s / 77986.5926 s
first_0:                 episode reward: -17.6500,                 loss: nan
second_0:                 episode reward: 17.6500,                 loss: 0.0030
Episode: 821/10000 (8.2100%),                 avg. length: 2789.45,                last time consumption/overall running time: 2544.1381s / 80530.7306 s
first_0:                 episode reward: -2.4000,                 loss: nan
second_0:                 episode reward: 2.4000,                 loss: 0.0051
Episode: 841/10000 (8.4100%),                 avg. length: 1894.25,                last time consumption/overall running time: 1733.1009s / 82263.8316 s
first_0:                 episode reward: -22.9500,                 loss: nan
second_0:                 episode reward: 22.9500,                 loss: 0.0054
Episode: 861/10000 (8.6100%),                 avg. length: 2191.75,                last time consumption/overall running time: 1994.7728s / 84258.6044 s
first_0:                 episode reward: -13.8500,                 loss: nan
second_0:                 episode reward: 13.8500,                 loss: 0.0044
Episode: 881/10000 (8.8100%),                 avg. length: 1977.2,                last time consumption/overall running time: 1774.0597s / 86032.6641 s
first_0:                 episode reward: -19.9500,                 loss: nan
second_0:                 episode reward: 19.9500,                 loss: 0.0039
Episode: 901/10000 (9.0100%),                 avg. length: 2000.35,                last time consumption/overall running time: 1788.3615s / 87821.0256 s
first_0:                 episode reward: -19.6000,                 loss: nan
second_0:                 episode reward: 19.6000,                 loss: 0.0039
Episode: 921/10000 (9.2100%),                 avg. length: 2269.5,                last time consumption/overall running time: 2026.3315s / 89847.3571 s
first_0:                 episode reward: -12.9500,                 loss: nan
second_0:                 episode reward: 12.9500,                 loss: 0.0035
Episode: 941/10000 (9.4100%),                 avg. length: 3081.4,                last time consumption/overall running time: 2787.3809s / 92634.7380 s
first_0:                 episode reward: 3.2500,                 loss: nan
second_0:                 episode reward: -3.2500,                 loss: 0.0051
Episode: 961/10000 (9.6100%),                 avg. length: 1834.3,                last time consumption/overall running time: 1668.4329s / 94303.1709 s
first_0:                 episode reward: -24.0000,                 loss: nan
second_0:                 episode reward: 24.0000,                 loss: 0.0055
Episode: 981/10000 (9.8100%),                 avg. length: 2082.7,                last time consumption/overall running time: 1871.9443s / 96175.1153 s
first_0:                 episode reward: -18.0000,                 loss: nan
second_0:                 episode reward: 18.0000,                 loss: 0.0045
Episode: 1001/10000 (10.0100%),                 avg. length: 1947.95,                last time consumption/overall running time: 1783.2432s / 97958.3585 s
first_0:                 episode reward: -20.5500,                 loss: nan
second_0:                 episode reward: 20.5500,                 loss: 0.0034
Episode: 1021/10000 (10.2100%),                 avg. length: 2603.75,                last time consumption/overall running time: 2378.3107s / 100336.6691 s
first_0:                 episode reward: -8.4000,                 loss: nan
second_0:                 episode reward: 8.4000,                 loss: 0.0038
Episode: 1041/10000 (10.4100%),                 avg. length: 1933.85,                last time consumption/overall running time: 1750.4975s / 102087.1666 s
first_0:                 episode reward: -21.8500,                 loss: nan
second_0:                 episode reward: 21.8500,                 loss: 0.0041
Episode: 1061/10000 (10.6100%),                 avg. length: 3337.8,                last time consumption/overall running time: 3014.1347s / 105101.3013 s
first_0:                 episode reward: 5.2000,                 loss: nan
second_0:                 episode reward: -5.2000,                 loss: 0.0048
Episode: 1081/10000 (10.8100%),                 avg. length: 1939.45,                last time consumption/overall running time: 1765.0373s / 106866.3386 s
first_0:                 episode reward: -22.3000,                 loss: nan
second_0:                 episode reward: 22.3000,                 loss: 0.0055
Episode: 1101/10000 (11.0100%),                 avg. length: 1890.75,                last time consumption/overall running time: 1704.2273s / 108570.5658 s
first_0:                 episode reward: -20.7500,                 loss: nan
second_0:                 episode reward: 20.7500,                 loss: 0.0043
Episode: 1121/10000 (11.2100%),                 avg. length: 3109.9,                last time consumption/overall running time: 2825.4409s / 111396.0067 s
first_0:                 episode reward: 6.3500,                 loss: nan
second_0:                 episode reward: -6.3500,                 loss: 0.0042
Episode: 1141/10000 (11.4100%),                 avg. length: 2290.6,                last time consumption/overall running time: 2087.2035s / 113483.2102 s
first_0:                 episode reward: -13.1000,                 loss: nan
second_0:                 episode reward: 13.1000,                 loss: 0.0058
Episode: 1161/10000 (11.6100%),                 avg. length: 2127.1,                last time consumption/overall running time: 1934.3197s / 115417.5299 s
first_0:                 episode reward: -16.2000,                 loss: nan
second_0:                 episode reward: 16.2000,                 loss: 0.0051
Episode: 1181/10000 (11.8100%),                 avg. length: 1972.85,                last time consumption/overall running time: 1763.0285s / 117180.5584 s
first_0:                 episode reward: -22.9500,                 loss: nan
second_0:                 episode reward: 22.9500,                 loss: 0.0035
Episode: 1201/10000 (12.0100%),                 avg. length: 1914.35,                last time consumption/overall running time: 1742.2559s / 118922.8142 s
first_0:                 episode reward: -19.7000,                 loss: nan
second_0:                 episode reward: 19.7000,                 loss: 0.0038
Episode: 1221/10000 (12.2100%),                 avg. length: 3052.5,                last time consumption/overall running time: 2770.5854s / 121693.3997 s
first_0:                 episode reward: 2.8500,                 loss: nan
second_0:                 episode reward: -2.8500,                 loss: 0.0035
Episode: 1241/10000 (12.4100%),                 avg. length: 2670.7,                last time consumption/overall running time: 2406.3009s / 124099.7006 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0071
Episode: 1261/10000 (12.6100%),                 avg. length: 2462.85,                last time consumption/overall running time: 2244.1372s / 126343.8378 s
first_0:                 episode reward: -11.7000,                 loss: nan
second_0:                 episode reward: 11.7000,                 loss: 0.0068
Episode: 1281/10000 (12.8100%),                 avg. length: 2334.95,                last time consumption/overall running time: 2138.6774s / 128482.5152 s
first_0:                 episode reward: -9.6000,                 loss: nan
second_0:                 episode reward: 9.6000,                 loss: 0.0044
Episode: 1301/10000 (13.0100%),                 avg. length: 1926.4,                last time consumption/overall running time: 1769.9385s / 130252.4537 s
first_0:                 episode reward: -20.9500,                 loss: nan
second_0:                 episode reward: 20.9500,                 loss: 0.0038
Episode: 1321/10000 (13.2100%),                 avg. length: 2152.35,                last time consumption/overall running time: 1971.5655s / 132224.0191 s
first_0:                 episode reward: -16.3000,                 loss: nan
second_0:                 episode reward: 16.3000,                 loss: 0.0039
Episode: 1341/10000 (13.4100%),                 avg. length: 3644.85,                last time consumption/overall running time: 3336.7220s / 135560.7411 s
first_0:                 episode reward: 15.6500,                 loss: nan
second_0:                 episode reward: -15.6500,                 loss: 0.0045
Episode: 1361/10000 (13.6100%),                 avg. length: 2231.6,                last time consumption/overall running time: 2037.9303s / 137598.6714 s
first_0:                 episode reward: -14.3000,                 loss: nan
second_0:                 episode reward: 14.3000,                 loss: 0.0065
Episode: 1381/10000 (13.8100%),                 avg. length: 2293.65,                last time consumption/overall running time: 2076.4200s / 139675.0914 s
first_0:                 episode reward: -15.3500,                 loss: nan
second_0:                 episode reward: 15.3500,                 loss: 0.0058
Episode: 1401/10000 (14.0100%),                 avg. length: 3159.6,                last time consumption/overall running time: 2862.5640s / 142537.6553 s
first_0:                 episode reward: 2.7000,                 loss: nan
second_0:                 episode reward: -2.7000,                 loss: 0.0048