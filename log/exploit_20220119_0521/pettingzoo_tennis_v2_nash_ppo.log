pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 91
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7ff5a7b63690>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  ./data/model/20220119_0521/pettingzoo_tennis_v2_nash_ppo/4000_0
Arguments:  {'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220119_0521/pettingzoo_tennis_v2_nash_ppo/4000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220119_0521_exploit/pettingzoo_tennis_v2_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0521_exploit/pettingzoo_tennis_v2_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 1690.0,                last time consumption/overall running time: 23.7975s / 23.7975 s
first_0:                 episode reward: 25.0000,                 loss: nan
second_0:                 episode reward: -25.0000,                 loss: 0.0047
Episode: 21/10000 (0.2100%),                 avg. length: 1875.55,                last time consumption/overall running time: 961.4033s / 985.2008 s
first_0:                 episode reward: 27.7500,                 loss: nan
second_0:                 episode reward: -27.7500,                 loss: 0.0032
Episode: 41/10000 (0.4100%),                 avg. length: 6047.8,                last time consumption/overall running time: 4065.5205s / 5050.7212 s
first_0:                 episode reward: 32.6000,                 loss: nan
second_0:                 episode reward: -32.6000,                 loss: 0.0054
Episode: 61/10000 (0.6100%),                 avg. length: 6977.55,                last time consumption/overall running time: 4754.8219s / 9805.5431 s
first_0:                 episode reward: 16.2500,                 loss: nan
second_0:                 episode reward: -16.2500,                 loss: 0.0063
Episode: 81/10000 (0.8100%),                 avg. length: 5006.85,                last time consumption/overall running time: 3423.6531s / 13229.1962 s
first_0:                 episode reward: -42.2000,                 loss: nan
second_0:                 episode reward: 42.2000,                 loss: 0.0063
Episode: 101/10000 (1.0100%),                 avg. length: 8811.7,                last time consumption/overall running time: 6013.0393s / 19242.2355 s
first_0:                 episode reward: -129.3500,                 loss: nan
second_0:                 episode reward: 129.3500,                 loss: 0.0080
Episode: 121/10000 (1.2100%),                 avg. length: 8102.65,                last time consumption/overall running time: 5503.2027s / 24745.4382 s
first_0:                 episode reward: -97.4000,                 loss: nan
second_0:                 episode reward: 97.4000,                 loss: 0.0084
Episode: 141/10000 (1.4100%),                 avg. length: 8487.5,                last time consumption/overall running time: 5784.3585s / 30529.7967 s
first_0:                 episode reward: -85.7000,                 loss: nan
second_0:                 episode reward: 85.7000,                 loss: 0.0084
Episode: 161/10000 (1.6100%),                 avg. length: 9327.5,                last time consumption/overall running time: 6334.3326s / 36864.1294 s
first_0:                 episode reward: -103.7500,                 loss: nan
second_0:                 episode reward: 103.7500,                 loss: 0.0082
Episode: 181/10000 (1.8100%),                 avg. length: 9596.4,                last time consumption/overall running time: 6509.3183s / 43373.4477 s
first_0:                 episode reward: -128.3500,                 loss: nan
second_0:                 episode reward: 128.3500,                 loss: 0.0082
Episode: 201/10000 (2.0100%),                 avg. length: 9341.15,                last time consumption/overall running time: 6346.2819s / 49719.7296 s
first_0:                 episode reward: -69.3000,                 loss: nan
second_0:                 episode reward: 69.3000,                 loss: 0.0079
Episode: 221/10000 (2.2100%),                 avg. length: 6664.2,                last time consumption/overall running time: 4535.3445s / 54255.0740 s
first_0:                 episode reward: -65.1000,                 loss: nan
second_0:                 episode reward: 65.1000,                 loss: 0.0072
Episode: 241/10000 (2.4100%),                 avg. length: 7127.8,                last time consumption/overall running time: 4847.8275s / 59102.9016 s
first_0:                 episode reward: -56.3000,                 loss: nan
second_0:                 episode reward: 56.3000,                 loss: 0.0070
Episode: 261/10000 (2.6100%),                 avg. length: 6272.35,                last time consumption/overall running time: 4274.2528s / 63377.1544 s
first_0:                 episode reward: -67.2000,                 loss: nan
second_0:                 episode reward: 67.2000,                 loss: 0.0070
Episode: 281/10000 (2.8100%),                 avg. length: 6544.7,                last time consumption/overall running time: 4478.7844s / 67855.9389 s
first_0:                 episode reward: -59.3500,                 loss: nan
second_0:                 episode reward: 59.3500,                 loss: 0.0070
Episode: 301/10000 (3.0100%),                 avg. length: 6282.8,                last time consumption/overall running time: 4279.4110s / 72135.3498 s
first_0:                 episode reward: -62.7000,                 loss: nan
second_0:                 episode reward: 62.7000,                 loss: 0.0074
Episode: 321/10000 (3.2100%),                 avg. length: 6729.6,                last time consumption/overall running time: 4583.8689s / 76719.2188 s
first_0:                 episode reward: -80.5500,                 loss: nan
second_0:                 episode reward: 80.5500,                 loss: 0.0072
Episode: 341/10000 (3.4100%),                 avg. length: 5964.35,                last time consumption/overall running time: 4052.8292s / 80772.0480 s
first_0:                 episode reward: -66.1000,                 loss: nan
second_0:                 episode reward: 66.1000,                 loss: 0.0072
Episode: 361/10000 (3.6100%),                 avg. length: 8752.7,                last time consumption/overall running time: 5979.9540s / 86752.0020 s
first_0:                 episode reward: -78.2000,                 loss: nan
second_0:                 episode reward: 78.2000,                 loss: 0.0079
Episode: 381/10000 (3.8100%),                 avg. length: 8420.9,                last time consumption/overall running time: 5716.0563s / 92468.0583 s
first_0:                 episode reward: -86.5000,                 loss: nan
second_0:                 episode reward: 86.5000,                 loss: 0.0080
Episode: 401/10000 (4.0100%),                 avg. length: 8847.95,                last time consumption/overall running time: 6024.5396s / 98492.5979 s
first_0:                 episode reward: -88.5000,                 loss: nan
second_0:                 episode reward: 88.5000,                 loss: 0.0080
Episode: 421/10000 (4.2100%),                 avg. length: 9721.6,                last time consumption/overall running time: 6635.7864s / 105128.3843 s
first_0:                 episode reward: -80.8000,                 loss: nan
second_0:                 episode reward: 80.8000,                 loss: 0.0086
Episode: 441/10000 (4.4100%),                 avg. length: 8295.85,                last time consumption/overall running time: 5641.5616s / 110769.9458 s
first_0:                 episode reward: -62.3500,                 loss: nan
second_0:                 episode reward: 62.3500,                 loss: 0.0088
Episode: 461/10000 (4.6100%),                 avg. length: 9828.45,                last time consumption/overall running time: 6714.3125s / 117484.2584 s
first_0:                 episode reward: -134.6000,                 loss: nan
second_0:                 episode reward: 134.6000,                 loss: 0.0083
Episode: 481/10000 (4.8100%),                 avg. length: 9114.7,                last time consumption/overall running time: 6179.1054s / 123663.3638 s
first_0:                 episode reward: -105.5000,                 loss: nan
second_0:                 episode reward: 105.5000,                 loss: 0.0086
Episode: 501/10000 (5.0100%),                 avg. length: 9846.95,                last time consumption/overall running time: 6683.6197s / 130346.9835 s
first_0:                 episode reward: -106.9000,                 loss: nan
second_0:                 episode reward: 106.9000,                 loss: 0.0087
Episode: 521/10000 (5.2100%),                 avg. length: 9367.6,                last time consumption/overall running time: 6391.7829s / 136738.7664 s
first_0:                 episode reward: -114.0000,                 loss: nan
second_0:                 episode reward: 114.0000,                 loss: 0.0089
Episode: 541/10000 (5.4100%),                 avg. length: 9960.5,                last time consumption/overall running time: 6761.2143s / 143499.9807 s
first_0:                 episode reward: -111.1000,                 loss: nan
second_0:                 episode reward: 111.1000,                 loss: 0.0085
Episode: 561/10000 (5.6100%),                 avg. length: 9449.55,                last time consumption/overall running time: 6421.6856s / 149921.6663 s
first_0:                 episode reward: -135.5500,                 loss: nan
second_0:                 episode reward: 135.5500,                 loss: 0.0083
Episode: 581/10000 (5.8100%),                 avg. length: 9186.8,                last time consumption/overall running time: 6235.9145s / 156157.5808 s
first_0:                 episode reward: -125.0000,                 loss: nan
second_0:                 episode reward: 125.0000,                 loss: 0.0086
Episode: 601/10000 (6.0100%),                 avg. length: 9865.05,                last time consumption/overall running time: 6687.2362s / 162844.8170 s
first_0:                 episode reward: -110.2500,                 loss: nan
second_0:                 episode reward: 110.2500,                 loss: 0.0088
Episode: 621/10000 (6.2100%),                 avg. length: 9200.3,                last time consumption/overall running time: 6224.0734s / 169068.8904 s
first_0:                 episode reward: -126.4000,                 loss: nan
second_0:                 episode reward: 126.4000,                 loss: 0.0083
Episode: 641/10000 (6.4100%),                 avg. length: 9211.9,                last time consumption/overall running time: 6244.4141s / 175313.3045 s
first_0:                 episode reward: -99.8000,                 loss: nan
second_0:                 episode reward: 99.8000,                 loss: 0.0085
Episode: 661/10000 (6.6100%),                 avg. length: 9822.6,                last time consumption/overall running time: 6688.4710s / 182001.7755 s
first_0:                 episode reward: -125.1000,                 loss: nan
second_0:                 episode reward: 125.1000,                 loss: 0.0088
Episode: 681/10000 (6.8100%),                 avg. length: 9511.25,                last time consumption/overall running time: 6480.3509s / 188482.1264 s
first_0:                 episode reward: -72.2500,                 loss: nan
second_0:                 episode reward: 72.2500,                 loss: 0.0092
Episode: 701/10000 (7.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 6795.0483s / 195277.1746 s
first_0:                 episode reward: -141.3500,                 loss: nan
second_0:                 episode reward: 141.3500,                 loss: 0.0090
Episode: 721/10000 (7.2100%),                 avg. length: 9164.35,                last time consumption/overall running time: 6243.5918s / 201520.7664 s
first_0:                 episode reward: -129.4500,                 loss: nan
second_0:                 episode reward: 129.4500,                 loss: 0.0090
Episode: 741/10000 (7.4100%),                 avg. length: 9667.85,                last time consumption/overall running time: 6575.8833s / 208096.6497 s
first_0:                 episode reward: -131.9500,                 loss: nan
second_0:                 episode reward: 131.9500,                 loss: 0.0085
Episode: 761/10000 (7.6100%),                 avg. length: 9871.45,                last time consumption/overall running time: 6724.0727s / 214820.7224 s
first_0:                 episode reward: -146.4500,                 loss: nan
second_0:                 episode reward: 146.4500,                 loss: 0.0092
Episode: 781/10000 (7.8100%),                 avg. length: 8762.45,                last time consumption/overall running time: 5988.9622s / 220809.6846 s
first_0:                 episode reward: -131.6000,                 loss: nan
second_0:                 episode reward: 131.6000,                 loss: 0.0089
Episode: 801/10000 (8.0100%),                 avg. length: 8873.2,                last time consumption/overall running time: 6072.4260s / 226882.1106 s
first_0:                 episode reward: -111.2500,                 loss: nan
second_0:                 episode reward: 111.2500,                 loss: 0.0082
Episode: 821/10000 (8.2100%),                 avg. length: 9262.55,                last time consumption/overall running time: 6307.6843s / 233189.7949 s
first_0:                 episode reward: -149.6000,                 loss: nan
second_0:                 episode reward: 149.6000,                 loss: 0.0091
Episode: 841/10000 (8.4100%),                 avg. length: 9102.4,                last time consumption/overall running time: 6208.5110s / 239398.3059 s
first_0:                 episode reward: -104.1500,                 loss: nan
second_0:                 episode reward: 104.1500,                 loss: 0.0086
Episode: 861/10000 (8.6100%),                 avg. length: 8370.7,                last time consumption/overall running time: 5684.3719s / 245082.6778 s
first_0:                 episode reward: -68.2500,                 loss: nan
second_0:                 episode reward: 68.2500,                 loss: 0.0121
Episode: 881/10000 (8.8100%),                 avg. length: 7916.25,                last time consumption/overall running time: 5379.1115s / 250461.7893 s
first_0:                 episode reward: 26.9500,                 loss: nan
second_0:                 episode reward: -26.9500,                 loss: 0.0170
Episode: 901/10000 (9.0100%),                 avg. length: 8131.7,                last time consumption/overall running time: 5547.2621s / 256009.0514 s
first_0:                 episode reward: -109.7000,                 loss: nan
second_0:                 episode reward: 109.7000,                 loss: 0.0075
Episode: 921/10000 (9.2100%),                 avg. length: 7878.4,                last time consumption/overall running time: 5370.2071s / 261379.2584 s
first_0:                 episode reward: -109.9000,                 loss: nan
second_0:                 episode reward: 109.9000,                 loss: 0.0099
Episode: 941/10000 (9.4100%),                 avg. length: 8543.4,                last time consumption/overall running time: 5793.6307s / 267172.8892 s
first_0:                 episode reward: -119.4000,                 loss: nan
second_0:                 episode reward: 119.4000,                 loss: 0.0085
Episode: 961/10000 (9.6100%),                 avg. length: 9105.55,                last time consumption/overall running time: 6227.7780s / 273400.6672 s
first_0:                 episode reward: -140.1500,                 loss: nan
second_0:                 episode reward: 140.1500,                 loss: 0.0090
Episode: 981/10000 (9.8100%),                 avg. length: 8446.8,                last time consumption/overall running time: 5763.6019s / 279164.2691 s
first_0:                 episode reward: -111.9000,                 loss: nan
second_0:                 episode reward: 111.9000,                 loss: 0.0088
Episode: 1001/10000 (10.0100%),                 avg. length: 7702.6,                last time consumption/overall running time: 5247.3581s / 284411.6273 s
first_0:                 episode reward: -119.5500,                 loss: nan
second_0:                 episode reward: 119.5500,                 loss: 0.0084
Episode: 1021/10000 (10.2100%),                 avg. length: 8594.65,                last time consumption/overall running time: 5859.9316s / 290271.5589 s
first_0:                 episode reward: -126.9500,                 loss: nan
second_0:                 episode reward: 126.9500,                 loss: 0.0083
Episode: 1041/10000 (10.4100%),                 avg. length: 6305.1,                last time consumption/overall running time: 4263.3694s / 294534.9282 s
first_0:                 episode reward: -42.3500,                 loss: nan
second_0:                 episode reward: 42.3500,                 loss: 0.0091
Episode: 1061/10000 (10.6100%),                 avg. length: 7338.25,                last time consumption/overall running time: 4982.1767s / 299517.1049 s
first_0:                 episode reward: -87.7000,                 loss: nan
second_0:                 episode reward: 87.7000,                 loss: 0.0071
Episode: 1081/10000 (10.8100%),                 avg. length: 8168.2,                last time consumption/overall running time: 5552.3468s / 305069.4518 s
first_0:                 episode reward: -119.1000,                 loss: nan
second_0:                 episode reward: 119.1000,                 loss: 0.0083
Episode: 1101/10000 (11.0100%),                 avg. length: 9586.9,                last time consumption/overall running time: 6572.9617s / 311642.4135 s
first_0:                 episode reward: -144.3000,                 loss: nan
second_0:                 episode reward: 144.3000,                 loss: 0.0090
Episode: 1121/10000 (11.2100%),                 avg. length: 8665.15,                last time consumption/overall running time: 5901.4364s / 317543.8499 s
first_0:                 episode reward: -126.5000,                 loss: nan
second_0:                 episode reward: 126.5000,                 loss: 0.0087
Episode: 1141/10000 (11.4100%),                 avg. length: 8233.65,                last time consumption/overall running time: 5598.4964s / 323142.3463 s
first_0:                 episode reward: -129.2500,                 loss: nan
second_0:                 episode reward: 129.2500,                 loss: 0.0087
Episode: 1161/10000 (11.6100%),                 avg. length: 7979.8,                last time consumption/overall running time: 5438.8829s / 328581.2292 s
first_0:                 episode reward: -118.2500,                 loss: nan
second_0:                 episode reward: 118.2500,                 loss: 0.0086
Episode: 1181/10000 (11.8100%),                 avg. length: 9104.05,                last time consumption/overall running time: 6192.9298s / 334774.1591 s
first_0:                 episode reward: -130.1000,                 loss: nan
second_0:                 episode reward: 130.1000,                 loss: 0.0083
Episode: 1201/10000 (12.0100%),                 avg. length: 9720.55,                last time consumption/overall running time: 6645.3378s / 341419.4969 s
first_0:                 episode reward: -154.6500,                 loss: nan
second_0:                 episode reward: 154.6500,                 loss: 0.0090
Episode: 1221/10000 (12.2100%),                 avg. length: 9562.55,                last time consumption/overall running time: 6526.6866s / 347946.1835 s
first_0:                 episode reward: -156.2500,                 loss: nan
second_0:                 episode reward: 156.2500,                 loss: 0.0089
Episode: 1241/10000 (12.4100%),                 avg. length: 8932.0,                last time consumption/overall running time: 6065.7839s / 354011.9673 s
first_0:                 episode reward: -139.1000,                 loss: nan
second_0:                 episode reward: 139.1000,                 loss: 0.0088
Episode: 1261/10000 (12.6100%),                 avg. length: 7861.8,                last time consumption/overall running time: 5351.0001s / 359362.9675 s
first_0:                 episode reward: -102.6500,                 loss: nan
second_0:                 episode reward: 102.6500,                 loss: 0.0087
Episode: 1281/10000 (12.8100%),                 avg. length: 7703.1,                last time consumption/overall running time: 5243.5267s / 364606.4941 s
first_0:                 episode reward: -72.4000,                 loss: nan
second_0:                 episode reward: 72.4000,                 loss: 0.0084
Episode: 1301/10000 (13.0100%),                 avg. length: 9293.25,                last time consumption/overall running time: 6363.4846s / 370969.9788 s
first_0:                 episode reward: -117.6500,                 loss: nan
second_0:                 episode reward: 117.6500,                 loss: 0.0086
Episode: 1321/10000 (13.2100%),                 avg. length: 7992.0,                last time consumption/overall running time: 5471.6661s / 376441.6449 s
first_0:                 episode reward: -95.8500,                 loss: nan
second_0:                 episode reward: 95.8500,                 loss: 0.0087
Episode: 1341/10000 (13.4100%),                 avg. length: 9161.95,                last time consumption/overall running time: 6238.3621s / 382680.0070 s
first_0:                 episode reward: -113.6500,                 loss: nan
second_0:                 episode reward: 113.6500,                 loss: 0.0086
Episode: 1361/10000 (13.6100%),                 avg. length: 9470.25,                last time consumption/overall running time: 6433.9572s / 389113.9642 s
first_0:                 episode reward: -99.9000,                 loss: nan
second_0:                 episode reward: 99.9000,                 loss: 0.0090
Episode: 1381/10000 (13.8100%),                 avg. length: 9386.05,                last time consumption/overall running time: 6387.2644s / 395501.2286 s
first_0:                 episode reward: -120.3500,                 loss: nan
second_0:                 episode reward: 120.3500,                 loss: 0.0088
Episode: 1401/10000 (14.0100%),                 avg. length: 9257.55,                last time consumption/overall running time: 6302.6937s / 401803.9223 s
first_0:                 episode reward: -147.8500,                 loss: nan
second_0:                 episode reward: 147.8500,                 loss: 0.0089
Episode: 1421/10000 (14.2100%),                 avg. length: 8774.1,                last time consumption/overall running time: 5985.5544s / 407789.4767 s
first_0:                 episode reward: -108.0500,                 loss: nan
second_0:                 episode reward: 108.0500,                 loss: 0.0087
Episode: 1441/10000 (14.4100%),                 avg. length: 9097.15,                last time consumption/overall running time: 6217.0038s / 414006.4804 s