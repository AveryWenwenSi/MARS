pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
random seed: 91
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f8f45702a58>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  ./data/model/20220119_0521/pettingzoo_pong_v2_nash_dqn_exploiter/6000_0
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'exploiter_update_itr': 3}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220119_0521/pettingzoo_pong_v2_nash_dqn_exploiter/6000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220119_0521_exploit/pettingzoo_pong_v2_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0521_exploit/pettingzoo_pong_v2_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 923.0,                last time consumption/overall running time: 68.9888s / 68.9888 s
first_0:                 episode reward: 20.0000,                 loss: nan
second_0:                 episode reward: -20.0000,                 loss: 0.0104
Episode: 21/10000 (0.2100%),                 avg. length: 1369.6,                last time consumption/overall running time: 461.5825s / 530.5713 s
first_0:                 episode reward: 13.4000,                 loss: nan
second_0:                 episode reward: -13.4000,                 loss: 0.0034
Episode: 41/10000 (0.4100%),                 avg. length: 1965.6,                last time consumption/overall running time: 686.9676s / 1217.5390 s
first_0:                 episode reward: 1.5000,                 loss: nan
second_0:                 episode reward: -1.5000,                 loss: 0.0081
Episode: 61/10000 (0.6100%),                 avg. length: 1892.0,                last time consumption/overall running time: 673.0890s / 1890.6280 s
first_0:                 episode reward: -12.4000,                 loss: nan
second_0:                 episode reward: 12.4000,                 loss: 0.0100
Episode: 81/10000 (0.8100%),                 avg. length: 1652.0,                last time consumption/overall running time: 595.3938s / 2486.0218 s
first_0:                 episode reward: -17.1500,                 loss: nan
second_0:                 episode reward: 17.1500,                 loss: 0.0072
Episode: 101/10000 (1.0100%),                 avg. length: 1656.85,                last time consumption/overall running time: 595.2031s / 3081.2249 s
first_0:                 episode reward: -17.9000,                 loss: nan
second_0:                 episode reward: 17.9000,                 loss: 0.0043
Episode: 121/10000 (1.2100%),                 avg. length: 1676.0,                last time consumption/overall running time: 603.1911s / 3684.4160 s
first_0:                 episode reward: -17.6000,                 loss: nan
second_0:                 episode reward: 17.6000,                 loss: 0.0051
Episode: 141/10000 (1.4100%),                 avg. length: 1696.9,                last time consumption/overall running time: 607.7940s / 4292.2100 s
first_0:                 episode reward: -17.0000,                 loss: nan
second_0:                 episode reward: 17.0000,                 loss: 0.0053
Episode: 161/10000 (1.6100%),                 avg. length: 1642.35,                last time consumption/overall running time: 593.0678s / 4885.2778 s
first_0:                 episode reward: -17.4500,                 loss: nan
second_0:                 episode reward: 17.4500,                 loss: 0.0048
Episode: 181/10000 (1.8100%),                 avg. length: 1634.7,                last time consumption/overall running time: 585.6491s / 5470.9269 s
first_0:                 episode reward: -17.8000,                 loss: nan
second_0:                 episode reward: 17.8000,                 loss: 0.0045
Episode: 201/10000 (2.0100%),                 avg. length: 1575.55,                last time consumption/overall running time: 570.6759s / 6041.6028 s
first_0:                 episode reward: -17.7500,                 loss: nan
second_0:                 episode reward: 17.7500,                 loss: 0.0050
Episode: 221/10000 (2.2100%),                 avg. length: 1677.35,                last time consumption/overall running time: 601.5046s / 6643.1074 s
first_0:                 episode reward: -16.7000,                 loss: nan
second_0:                 episode reward: 16.7000,                 loss: 0.0040
Episode: 241/10000 (2.4100%),                 avg. length: 1557.5,                last time consumption/overall running time: 556.3605s / 7199.4680 s
first_0:                 episode reward: -17.8000,                 loss: nan
second_0:                 episode reward: 17.8000,                 loss: 0.0046
Episode: 261/10000 (2.6100%),                 avg. length: 1575.65,                last time consumption/overall running time: 568.7911s / 7768.2591 s
first_0:                 episode reward: -17.7500,                 loss: nan
second_0:                 episode reward: 17.7500,                 loss: 0.0039
Episode: 281/10000 (2.8100%),                 avg. length: 1584.15,                last time consumption/overall running time: 569.1164s / 8337.3755 s
first_0:                 episode reward: -17.7500,                 loss: nan
second_0:                 episode reward: 17.7500,                 loss: 0.0041
Episode: 301/10000 (3.0100%),                 avg. length: 1557.8,                last time consumption/overall running time: 562.1248s / 8899.5003 s
first_0:                 episode reward: -17.3000,                 loss: nan
second_0:                 episode reward: 17.3000,                 loss: 0.0041
Episode: 321/10000 (3.2100%),                 avg. length: 1605.05,                last time consumption/overall running time: 577.6196s / 9477.1199 s
first_0:                 episode reward: -17.6000,                 loss: nan
second_0:                 episode reward: 17.6000,                 loss: 0.0041
Episode: 341/10000 (3.4100%),                 avg. length: 1596.5,                last time consumption/overall running time: 574.3706s / 10051.4905 s
first_0:                 episode reward: -17.9000,                 loss: nan
second_0:                 episode reward: 17.9000,                 loss: 0.0037
Episode: 361/10000 (3.6100%),                 avg. length: 1695.65,                last time consumption/overall running time: 573.0339s / 10624.5243 s
first_0:                 episode reward: -16.7000,                 loss: nan
second_0:                 episode reward: 16.7000,                 loss: 0.0042
Episode: 381/10000 (3.8100%),                 avg. length: 1645.5,                last time consumption/overall running time: 559.9365s / 11184.4608 s
first_0:                 episode reward: -17.3500,                 loss: nan
second_0:                 episode reward: 17.3500,                 loss: 0.0038
Episode: 401/10000 (4.0100%),                 avg. length: 1599.1,                last time consumption/overall running time: 542.6760s / 11727.1369 s
first_0:                 episode reward: -17.6000,                 loss: nan
second_0:                 episode reward: 17.6000,                 loss: 0.0042
Episode: 421/10000 (4.2100%),                 avg. length: 1659.8,                last time consumption/overall running time: 564.7204s / 12291.8572 s
first_0:                 episode reward: -17.3000,                 loss: nan
second_0:                 episode reward: 17.3000,                 loss: 0.0040
Episode: 441/10000 (4.4100%),                 avg. length: 1585.4,                last time consumption/overall running time: 536.3607s / 12828.2180 s
first_0:                 episode reward: -18.0500,                 loss: nan
second_0:                 episode reward: 18.0500,                 loss: 0.0035
Episode: 461/10000 (4.6100%),                 avg. length: 1484.85,                last time consumption/overall running time: 504.5644s / 13332.7824 s
first_0:                 episode reward: -18.9500,                 loss: nan
second_0:                 episode reward: 18.9500,                 loss: 0.0035
Episode: 481/10000 (4.8100%),                 avg. length: 1555.25,                last time consumption/overall running time: 530.5269s / 13863.3093 s
first_0:                 episode reward: -17.8000,                 loss: nan
second_0:                 episode reward: 17.8000,                 loss: 0.0035
Episode: 501/10000 (5.0100%),                 avg. length: 1574.35,                last time consumption/overall running time: 536.3973s / 14399.7066 s
first_0:                 episode reward: -17.6000,                 loss: nan
second_0:                 episode reward: 17.6000,                 loss: 0.0033
Episode: 521/10000 (5.2100%),                 avg. length: 1603.1,                last time consumption/overall running time: 544.9912s / 14944.6978 s
first_0:                 episode reward: -17.7500,                 loss: nan
second_0:                 episode reward: 17.7500,                 loss: 0.0036
Episode: 541/10000 (5.4100%),                 avg. length: 1558.4,                last time consumption/overall running time: 531.3710s / 15476.0688 s
first_0:                 episode reward: -18.5500,                 loss: nan
second_0:                 episode reward: 18.5500,                 loss: 0.0034
Episode: 561/10000 (5.6100%),                 avg. length: 1674.55,                last time consumption/overall running time: 571.8527s / 16047.9215 s
first_0:                 episode reward: -16.5000,                 loss: nan
second_0:                 episode reward: 16.5000,                 loss: 0.0035
Episode: 581/10000 (5.8100%),                 avg. length: 1565.25,                last time consumption/overall running time: 534.5854s / 16582.5069 s
first_0:                 episode reward: -18.3500,                 loss: nan
second_0:                 episode reward: 18.3500,                 loss: 0.0036
Episode: 601/10000 (6.0100%),                 avg. length: 1570.75,                last time consumption/overall running time: 532.2049s / 17114.7118 s
first_0:                 episode reward: -18.4000,                 loss: nan
second_0:                 episode reward: 18.4000,                 loss: 0.0034
Episode: 621/10000 (6.2100%),                 avg. length: 1593.1,                last time consumption/overall running time: 540.2984s / 17655.0102 s
first_0:                 episode reward: -17.9000,                 loss: nan
second_0:                 episode reward: 17.9000,                 loss: 0.0033
Episode: 641/10000 (6.4100%),                 avg. length: 1652.2,                last time consumption/overall running time: 561.7063s / 18216.7164 s
first_0:                 episode reward: -16.4500,                 loss: nan
second_0:                 episode reward: 16.4500,                 loss: 0.0031
Episode: 661/10000 (6.6100%),                 avg. length: 1650.65,                last time consumption/overall running time: 564.2236s / 18780.9400 s
first_0:                 episode reward: -17.0000,                 loss: nan
second_0:                 episode reward: 17.0000,                 loss: 0.0034
Episode: 681/10000 (6.8100%),                 avg. length: 1696.95,                last time consumption/overall running time: 580.4422s / 19361.3822 s
first_0:                 episode reward: -17.2500,                 loss: nan
second_0:                 episode reward: 17.2500,                 loss: 0.0040
Episode: 701/10000 (7.0100%),                 avg. length: 1668.75,                last time consumption/overall running time: 562.4190s / 19923.8012 s
first_0:                 episode reward: -17.7000,                 loss: nan
second_0:                 episode reward: 17.7000,                 loss: 0.0034
Episode: 721/10000 (7.2100%),                 avg. length: 1524.3,                last time consumption/overall running time: 518.1376s / 20441.9388 s
first_0:                 episode reward: -18.4000,                 loss: nan
second_0:                 episode reward: 18.4000,                 loss: 0.0030
Episode: 741/10000 (7.4100%),                 avg. length: 1692.25,                last time consumption/overall running time: 575.9611s / 21017.8999 s
first_0:                 episode reward: -17.6000,                 loss: nan
second_0:                 episode reward: 17.6000,                 loss: 0.0032
Episode: 761/10000 (7.6100%),                 avg. length: 1682.0,                last time consumption/overall running time: 571.7069s / 21589.6068 s
first_0:                 episode reward: -17.4000,                 loss: nan
second_0:                 episode reward: 17.4000,                 loss: 0.0031
Episode: 781/10000 (7.8100%),                 avg. length: 1572.15,                last time consumption/overall running time: 530.4097s / 22120.0164 s
first_0:                 episode reward: -18.4000,                 loss: nan
second_0:                 episode reward: 18.4000,                 loss: 0.0035
Episode: 801/10000 (8.0100%),                 avg. length: 1507.5,                last time consumption/overall running time: 518.7771s / 22638.7935 s
first_0:                 episode reward: -18.3000,                 loss: nan
second_0:                 episode reward: 18.3000,                 loss: 0.0034
Episode: 821/10000 (8.2100%),                 avg. length: 1636.95,                last time consumption/overall running time: 556.9412s / 23195.7347 s
first_0:                 episode reward: -17.0000,                 loss: nan
second_0:                 episode reward: 17.0000,                 loss: 0.0031
Episode: 841/10000 (8.4100%),                 avg. length: 1624.65,                last time consumption/overall running time: 548.1926s / 23743.9273 s
first_0:                 episode reward: -17.7000,                 loss: nan
second_0:                 episode reward: 17.7000,                 loss: 0.0032
Episode: 861/10000 (8.6100%),                 avg. length: 1521.15,                last time consumption/overall running time: 517.3229s / 24261.2502 s
first_0:                 episode reward: -17.9500,                 loss: nan
second_0:                 episode reward: 17.9500,                 loss: 0.0035
Episode: 881/10000 (8.8100%),                 avg. length: 1645.7,                last time consumption/overall running time: 560.2653s / 24821.5155 s
first_0:                 episode reward: -17.8500,                 loss: nan
second_0:                 episode reward: 17.8500,                 loss: 0.0032
Episode: 901/10000 (9.0100%),                 avg. length: 1509.85,                last time consumption/overall running time: 511.8843s / 25333.3999 s
first_0:                 episode reward: -18.1500,                 loss: nan
second_0:                 episode reward: 18.1500,                 loss: 0.0031
Episode: 921/10000 (9.2100%),                 avg. length: 1645.2,                last time consumption/overall running time: 560.1146s / 25893.5145 s
first_0:                 episode reward: -16.8500,                 loss: nan
second_0:                 episode reward: 16.8500,                 loss: 0.0034
Episode: 941/10000 (9.4100%),                 avg. length: 1517.0,                last time consumption/overall running time: 520.8779s / 26414.3924 s
first_0:                 episode reward: -18.4500,                 loss: nan
second_0:                 episode reward: 18.4500,                 loss: 0.0038
Episode: 961/10000 (9.6100%),                 avg. length: 1724.5,                last time consumption/overall running time: 570.0866s / 26984.4790 s
first_0:                 episode reward: -16.7000,                 loss: nan
second_0:                 episode reward: 16.7000,                 loss: 0.0033
Episode: 981/10000 (9.8100%),                 avg. length: 1634.6,                last time consumption/overall running time: 522.9960s / 27507.4750 s
first_0:                 episode reward: -17.0500,                 loss: nan
second_0:                 episode reward: 17.0500,                 loss: 0.0032
Episode: 1001/10000 (10.0100%),                 avg. length: 1614.75,                last time consumption/overall running time: 523.3311s / 28030.8061 s
first_0:                 episode reward: -16.6500,                 loss: nan
second_0:                 episode reward: 16.6500,                 loss: 0.0033
Episode: 1021/10000 (10.2100%),                 avg. length: 1650.6,                last time consumption/overall running time: 530.4020s / 28561.2081 s
first_0:                 episode reward: -17.2500,                 loss: nan
second_0:                 episode reward: 17.2500,                 loss: 0.0035
Episode: 1041/10000 (10.4100%),                 avg. length: 1633.2,                last time consumption/overall running time: 518.4592s / 29079.6673 s
first_0:                 episode reward: -18.1500,                 loss: nan
second_0:                 episode reward: 18.1500,                 loss: 0.0033
Episode: 1061/10000 (10.6100%),                 avg. length: 1640.5,                last time consumption/overall running time: 528.6935s / 29608.3608 s
first_0:                 episode reward: -17.2000,                 loss: nan
second_0:                 episode reward: 17.2000,                 loss: 0.0034
Episode: 1081/10000 (10.8100%),                 avg. length: 1538.7,                last time consumption/overall running time: 489.5204s / 30097.8812 s
first_0:                 episode reward: -18.1500,                 loss: nan
second_0:                 episode reward: 18.1500,                 loss: 0.0035
Episode: 1101/10000 (11.0100%),                 avg. length: 1591.45,                last time consumption/overall running time: 512.5174s / 30610.3986 s
first_0:                 episode reward: -17.9500,                 loss: nan
second_0:                 episode reward: 17.9500,                 loss: 0.0033
Episode: 1121/10000 (11.2100%),                 avg. length: 1607.2,                last time consumption/overall running time: 510.5735s / 31120.9722 s
first_0:                 episode reward: -17.0500,                 loss: nan
second_0:                 episode reward: 17.0500,                 loss: 0.0031
Episode: 1141/10000 (11.4100%),                 avg. length: 1604.45,                last time consumption/overall running time: 512.5286s / 31633.5008 s
first_0:                 episode reward: -17.8000,                 loss: nan
second_0:                 episode reward: 17.8000,                 loss: 0.0034
Episode: 1161/10000 (11.6100%),                 avg. length: 1558.45,                last time consumption/overall running time: 496.4975s / 32129.9983 s
first_0:                 episode reward: -17.6000,                 loss: nan
second_0:                 episode reward: 17.6000,                 loss: 0.0033
Episode: 1181/10000 (11.8100%),                 avg. length: 1600.55,                last time consumption/overall running time: 511.6607s / 32641.6589 s
first_0:                 episode reward: -17.8500,                 loss: nan
second_0:                 episode reward: 17.8500,                 loss: 0.0033
Episode: 1201/10000 (12.0100%),                 avg. length: 1571.9,                last time consumption/overall running time: 500.3513s / 33142.0102 s
first_0:                 episode reward: -17.5500,                 loss: nan
second_0:                 episode reward: 17.5500,                 loss: 0.0035
Episode: 1221/10000 (12.2100%),                 avg. length: 1682.75,                last time consumption/overall running time: 530.6391s / 33672.6493 s
first_0:                 episode reward: -16.6000,                 loss: nan
second_0:                 episode reward: 16.6000,                 loss: 0.0033
Episode: 1241/10000 (12.4100%),                 avg. length: 1702.5,                last time consumption/overall running time: 542.5606s / 34215.2100 s
first_0:                 episode reward: -16.3000,                 loss: nan
second_0:                 episode reward: 16.3000,                 loss: 0.0034
Episode: 1261/10000 (12.6100%),                 avg. length: 1618.45,                last time consumption/overall running time: 516.5506s / 34731.7605 s
first_0:                 episode reward: -17.6000,                 loss: nan
second_0:                 episode reward: 17.6000,                 loss: 0.0039
Episode: 1281/10000 (12.8100%),                 avg. length: 1590.4,                last time consumption/overall running time: 507.4245s / 35239.1850 s
first_0:                 episode reward: -17.6000,                 loss: nan
second_0:                 episode reward: 17.6000,                 loss: 0.0037
Episode: 1301/10000 (13.0100%),                 avg. length: 1582.75,                last time consumption/overall running time: 499.4265s / 35738.6115 s
first_0:                 episode reward: -17.6500,                 loss: nan
second_0:                 episode reward: 17.6500,                 loss: 0.0037
Episode: 1321/10000 (13.2100%),                 avg. length: 1657.9,                last time consumption/overall running time: 523.8822s / 36262.4937 s
first_0:                 episode reward: -17.3500,                 loss: nan
second_0:                 episode reward: 17.3500,                 loss: 0.0032
Episode: 1341/10000 (13.4100%),                 avg. length: 1568.9,                last time consumption/overall running time: 494.7671s / 36757.2608 s
first_0:                 episode reward: -17.9000,                 loss: nan
second_0:                 episode reward: 17.9000,                 loss: 0.0033
Episode: 1361/10000 (13.6100%),                 avg. length: 1512.8,                last time consumption/overall running time: 479.9177s / 37237.1784 s
first_0:                 episode reward: -18.2000,                 loss: nan
second_0:                 episode reward: 18.2000,                 loss: 0.0031
Episode: 1381/10000 (13.8100%),                 avg. length: 1598.1,                last time consumption/overall running time: 507.9157s / 37745.0941 s
first_0:                 episode reward: -17.7500,                 loss: nan
second_0:                 episode reward: 17.7500,                 loss: 0.0031
Episode: 1401/10000 (14.0100%),                 avg. length: 1666.35,                last time consumption/overall running time: 525.7278s / 38270.8219 s
first_0:                 episode reward: -16.5000,                 loss: nan
second_0:                 episode reward: 16.5000,                 loss: 0.0033