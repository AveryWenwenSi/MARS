pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
random seed: 57
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f7c19265358>
No agent are not learnable.
{'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': True, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'eta': 0.1}, 'add_components': {'replay_buffer': <AutoProxy[replay_buffer] object, typeid 'replay_buffer' at 0x7f7c19268f60>, 'reservoir_buffer': <AutoProxy[reservoir_buffer] object, typeid 'reservoir_buffer' at 0x7f7c19b4c668>}}
pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
random seed: 42
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': True, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'eta': 0.1}, 'add_components': {'replay_buffer': <AutoProxy[replay_buffer] object, typeid 'replay_buffer' at 0x7ff5aeddcc18>, 'reservoir_buffer': <AutoProxy[reservoir_buffer] object, typeid 'reservoir_buffer' at 0x7ff5ae486b70>}}
Save models to : /home/zihan/research/MARS/data/model/0/pettingzoo_pong_v2_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/0/pettingzoo_pong_v2_nfsp.
Process ID: 0, episode: 20/10000 (0.2000%),                     avg. length: 1194.0,                    last time consumption/overall running time: 111.5408s / 111.5408 s
first_0:                     episode reward: 10.9000
second_0:                     episode reward: -10.9000
Process ID: 0, episode: 40/10000 (0.4000%),                     avg. length: 1086.8,                    last time consumption/overall running time: 120.4610s / 232.0019 s
first_0:                     episode reward: 11.2000
second_0:                     episode reward: -11.2000
Process ID: 0, episode: 60/10000 (0.6000%),                     avg. length: 1323.05,                    last time consumption/overall running time: 157.1817s / 389.1836 s
first_0:                     episode reward: 3.3000
second_0:                     episode reward: -3.3000
Process ID: 0, episode: 80/10000 (0.8000%),                     avg. length: 1207.55,                    last time consumption/overall running time: 148.1746s / 537.3581 s
first_0:                     episode reward: -4.4500
second_0:                     episode reward: 4.4500
Process ID: 0, episode: 100/10000 (1.0000%),                     avg. length: 1225.05,                    last time consumption/overall running time: 152.1569s / 689.5150 s
first_0:                     episode reward: -5.0000
second_0:                     episode reward: 5.0000
Process ID: 0, episode: 120/10000 (1.2000%),                     avg. length: 1141.65,                    last time consumption/overall running time: 143.7504s / 833.2654 s
first_0:                     episode reward: -2.3500
second_0:                     episode reward: 2.3500
Process ID: 0, episode: 140/10000 (1.4000%),                     avg. length: 1321.8,                    last time consumption/overall running time: 167.7508s / 1001.0162 s
first_0:                     episode reward: -9.2500
second_0:                     episode reward: 9.2500
Process ID: 0, episode: 160/10000 (1.6000%),                     avg. length: 1178.45,                    last time consumption/overall running time: 150.3924s / 1151.4087 s
first_0:                     episode reward: -5.1500
second_0:                     episode reward: 5.1500
Process ID: 0, episode: 180/10000 (1.8000%),                     avg. length: 1083.05,                    last time consumption/overall running time: 138.6730s / 1290.0816 s
first_0:                     episode reward: 2.1500
second_0:                     episode reward: -2.1500
Process ID: 0, episode: 200/10000 (2.0000%),                     avg. length: 886.0,                    last time consumption/overall running time: 113.8109s / 1403.8926 s
first_0:                     episode reward: 18.8000
second_0:                     episode reward: -18.8000
Process ID: 0, episode: 220/10000 (2.2000%),                     avg. length: 1571.3,                    last time consumption/overall running time: 201.1206s / 1605.0132 s
first_0:                     episode reward: -4.3500
second_0:                     episode reward: 4.3500
Process ID: 0, episode: 240/10000 (2.4000%),                     avg. length: 990.95,                    last time consumption/overall running time: 126.9663s / 1731.9795 s
first_0:                     episode reward: 11.3500
second_0:                     episode reward: -11.3500
Process ID: 0, episode: 260/10000 (2.6000%),                     avg. length: 1237.35,                    last time consumption/overall running time: 159.0733s / 1891.0528 s
first_0:                     episode reward: 5.1500
second_0:                     episode reward: -5.1500
Process ID: 0, episode: 280/10000 (2.8000%),                     avg. length: 1027.9,                    last time consumption/overall running time: 132.1528s / 2023.2056 s
first_0:                     episode reward: 1.5000
second_0:                     episode reward: -1.5000
Process ID: 0, episode: 300/10000 (3.0000%),                     avg. length: 1130.15,                    last time consumption/overall running time: 145.6983s / 2168.9039 s
first_0:                     episode reward: 1.6500
second_0:                     episode reward: -1.6500
Process ID: 0, episode: 320/10000 (3.2000%),                     avg. length: 1174.5,                    last time consumption/overall running time: 151.0890s / 2319.9929 s
first_0:                     episode reward: -3.3500
second_0:                     episode reward: 3.3500
Process ID: 0, episode: 340/10000 (3.4000%),                     avg. length: 1218.7,                    last time consumption/overall running time: 156.5488s / 2476.5417 s
first_0:                     episode reward: -6.1500
second_0:                     episode reward: 6.1500
Process ID: 0, episode: 360/10000 (3.6000%),                     avg. length: 1086.0,                    last time consumption/overall running time: 138.8712s / 2615.4129 s
first_0:                     episode reward: 8.7500
second_0:                     episode reward: -8.7500
Process ID: 0, episode: 380/10000 (3.8000%),                     avg. length: 1328.95,                    last time consumption/overall running time: 171.7770s / 2787.1900 s
first_0:                     episode reward: -5.7500
second_0:                     episode reward: 5.7500
Process ID: 0, episode: 400/10000 (4.0000%),                     avg. length: 1276.0,                    last time consumption/overall running time: 163.3708s / 2950.5607 s
first_0:                     episode reward: 0.0000
second_0:                     episode reward: 0.0000
Process ID: 0, episode: 420/10000 (4.2000%),                     avg. length: 1064.35,                    last time consumption/overall running time: 136.7343s / 3087.2950 s
first_0:                     episode reward: 6.8500
second_0:                     episode reward: -6.8500
Process ID: 0, episode: 440/10000 (4.4000%),                     avg. length: 1111.9,                    last time consumption/overall running time: 143.9068s / 3231.2018 s
first_0:                     episode reward: 10.5500
second_0:                     episode reward: -10.5500
Process ID: 0, episode: 460/10000 (4.6000%),                     avg. length: 1093.45,                    last time consumption/overall running time: 141.4789s / 3372.6808 s
first_0:                     episode reward: 13.6000
second_0:                     episode reward: -13.6000
Process ID: 0, episode: 480/10000 (4.8000%),                     avg. length: 1226.45,                    last time consumption/overall running time: 157.6616s / 3530.3424 spygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
random seed: 89
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': True, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'eta': 0.1}, 'add_components': {'replay_buffer': <AutoProxy[replay_buffer] object, typeid 'replay_buffer' at 0x7ff5aeddcc18>, 'reservoir_buffer': <AutoProxy[reservoir_buffer] object, typeid 'reservoir_buffer' at 0x7ff5ae486b70>}}
Save models to : /home/zihan/research/MARS/data/model/1/pettingzoo_pong_v2_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/1/pettingzoo_pong_v2_nfsp.
Process ID: 1, episode: 20/10000 (0.2000%),                     avg. length: 1208.2,                    last time consumption/overall running time: 106.0872s / 106.0872 s
first_0:                     episode reward: 9.4000
second_0:                     episode reward: -9.4000
Process ID: 1, episode: 40/10000 (0.4000%),                     avg. length: 1022.65,                    last time consumption/overall running time: 113.4922s / 219.5793 s
first_0:                     episode reward: 12.2500
second_0:                     episode reward: -12.2500
Process ID: 1, episode: 60/10000 (0.6000%),                     avg. length: 1269.65,                    last time consumption/overall running time: 150.3998s / 369.9791 s
first_0:                     episode reward: 4.8500
second_0:                     episode reward: -4.8500
Process ID: 1, episode: 80/10000 (0.8000%),                     avg. length: 1282.3,                    last time consumption/overall running time: 156.6236s / 526.6027 s
first_0:                     episode reward: -3.9000
second_0:                     episode reward: 3.9000
Process ID: 1, episode: 100/10000 (1.0000%),                     avg. length: 1193.95,                    last time consumption/overall running time: 147.6208s / 674.2235 s
first_0:                     episode reward: -7.9500
second_0:                     episode reward: 7.9500
Process ID: 1, episode: 120/10000 (1.2000%),                     avg. length: 1277.55,                    last time consumption/overall running time: 160.2067s / 834.4302 s
first_0:                     episode reward: -4.7000
second_0:                     episode reward: 4.7000
Process ID: 1, episode: 140/10000 (1.4000%),                     avg. length: 1329.9,                    last time consumption/overall running time: 168.9063s / 1003.3366 s
first_0:                     episode reward: -3.9500
second_0:                     episode reward: 3.9500
Process ID: 1, episode: 160/10000 (1.6000%),                     avg. length: 1090.35,                    last time consumption/overall running time: 138.8552s / 1142.1918 s
first_0:                     episode reward: 0.2500
second_0:                     episode reward: -0.2500
Process ID: 1, episode: 180/10000 (1.8000%),                     avg. length: 1058.65,                    last time consumption/overall running time: 134.7432s / 1276.9350 s
first_0:                     episode reward: 2.5500
second_0:                     episode reward: -2.5500
Process ID: 1, episode: 200/10000 (2.0000%),                     avg. length: 948.25,                    last time consumption/overall running time: 121.4613s / 1398.3963 s
first_0:                     episode reward: 13.9500
second_0:                     episode reward: -13.9500
Process ID: 1, episode: 220/10000 (2.2000%),                     avg. length: 1379.1,                    last time consumption/overall running time: 175.0720s / 1573.4683 s
first_0:                     episode reward: -1.8500
second_0:                     episode reward: 1.8500
Process ID: 1, episode: 240/10000 (2.4000%),                     avg. length: 1151.8,                    last time consumption/overall running time: 147.1038s / 1720.5721 s
first_0:                     episode reward: 10.5000
second_0:                     episode reward: -10.5000
Process ID: 1, episode: 260/10000 (2.6000%),                     avg. length: 1311.8,                    last time consumption/overall running time: 167.7414s / 1888.3135 s
first_0:                     episode reward: 6.9000
second_0:                     episode reward: -6.9000
Process ID: 1, episode: 280/10000 (2.8000%),                     avg. length: 1183.6,                    last time consumption/overall running time: 151.6180s / 2039.9315 s
first_0:                     episode reward: 1.0500
second_0:                     episode reward: -1.0500
Process ID: 1, episode: 300/10000 (3.0000%),                     avg. length: 1378.15,                    last time consumption/overall running time: 176.1822s / 2216.1137 s
first_0:                     episode reward: 0.7000
second_0:                     episode reward: -0.7000
Process ID: 1, episode: 320/10000 (3.2000%),                     avg. length: 1255.35,                    last time consumption/overall running time: 160.9972s / 2377.1108 s
first_0:                     episode reward: -3.7500
second_0:                     episode reward: 3.7500
Process ID: 1, episode: 340/10000 (3.4000%),                     avg. length: 1123.7,                    last time consumption/overall running time: 143.1820s / 2520.2928 s
first_0:                     episode reward: -2.1500
second_0:                     episode reward: 2.1500
Process ID: 1, episode: 360/10000 (3.6000%),                     avg. length: 1274.2,                    last time consumption/overall running time: 162.8475s / 2683.1403 s
first_0:                     episode reward: 0.1500
second_0:                     episode reward: -0.1500
Process ID: 1, episode: 380/10000 (3.8000%),                     avg. length: 1206.25,                    last time consumption/overall running time: 154.7822s / 2837.9225 s
first_0:                     episode reward: 0.1000
second_0:                     episode reward: -0.1000
Process ID: 1, episode: 400/10000 (4.0000%),                     avg. length: 1219.45,                    last time consumption/overall running time: 156.0514s / 2993.9740 s
first_0:                     episode reward: 2.6500
second_0:                     episode reward: -2.6500
Process ID: 1, episode: 420/10000 (4.2000%),                     avg. length: 1241.5,                    last time consumption/overall running time: 158.8585s / 3152.8325 s
first_0:                     episode reward: 3.8500
second_0:                     episode reward: -3.8500
Process ID: 1, episode: 440/10000 (4.4000%),                     avg. length: 1232.05,                    last time consumption/overall running time: 158.8396s / 3311.6720 s
first_0:                     episode reward: 9.4000
second_0:                     episode reward: -9.4000
Process ID: 1, episode: 460/10000 (4.6000%),                     avg. length: 1198.5,                    last time consumption/overall running time: 153.8817s / 3465.5537 s
first_0:                     episode reward: 7.7500
second_0:                     episode reward: -7.7500
Process ID: 1, episode: 480/10000 (4.8000%),                     avg. length: 1292.85,                    last time consumption/overall running time: 166.0439s / 3631.5976 s