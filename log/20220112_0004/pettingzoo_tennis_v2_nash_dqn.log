pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 42
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f0edaddaf98>
No agent are not learnable.
{'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': True, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'add_components': {'replay_buffer': <AutoProxy[replay_buffer] object, typeid 'replay_buffer' at 0x7f0edb6dd5c0>}}
pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 46
Arguments:  {'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': True, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'add_components': {'replay_buffer': <AutoProxy[replay_buffer] object, typeid 'replay_buffer' at 0x7fb389996cf8>}}
Save models to : /home/zihan/research/MARS/data/model/1/pettingzoo_tennis_v2_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/1/pettingzoo_tennis_v2_nash_dqn.
Process ID: 1, episode: 20/10000 (0.2000%),                     avg. length: 9620.6,                    last time consumption/overall running time: 1284.9022s / 1284.9022 s
first_0:                     episode reward: 1.5000
second_0:                     episode reward: -1.5000
Process ID: 1, episode: 40/10000 (0.4000%),                     avg. length: 9999.0,                    last time consumption/overall running time: 1495.2143s / 2780.1164 s
first_0:                     episode reward: 1.6500
second_0:                     episode reward: -1.6500
Process ID: 1, episode: 60/10000 (0.6000%),                     avg. length: 9378.4,                    last time consumption/overall running time: 1397.5436s / 4177.6600 s
first_0:                     episode reward: 8.9000
second_0:                     episode reward: -8.9000
Process ID: 1, episode: 80/10000 (0.8000%),                     avg. length: 9017.65,                    last time consumption/overall running time: 1337.4937s / 5515.1536 s
first_0:                     episode reward: 3.6500
second_0:                     episode reward: -3.6500
Process ID: 1, episode: 100/10000 (1.0000%),                     avg. length: 9600.8,                    last time consumption/overall running time: 1423.6044s / 6938.7580 s
first_0:                     episode reward: 4.7500
second_0:                     episode reward: -4.7500
Process ID: 1, episode: 120/10000 (1.2000%),                     avg. length: 8897.45,                    last time consumption/overall running time: 1322.7047s / 8261.4627 s
first_0:                     episode reward: 2.4500
second_0:                     episode reward: -2.4500
Process ID: 1, episode: 140/10000 (1.4000%),                     avg. length: 9816.95,                    last time consumption/overall running time: 1493.2293s / 9754.6920 s
first_0:                     episode reward: 3.9500
second_0:                     episode reward: -3.9500
Process ID: 1, episode: 160/10000 (1.6000%),                     avg. length: 8570.5,                    last time consumption/overall running time: 1320.9739s / 11075.6659 s
first_0:                     episode reward: -0.8500
second_0:                     episode reward: 0.8500
Process ID: 1, episode: 180/10000 (1.8000%),                     avg. length: 9679.05,                    last time consumption/overall running time: 1479.8458s / 12555.5117 s
first_0:                     episode reward: -0.5000
second_0:                     episode reward: 0.5000
Process ID: 1, episode: 200/10000 (2.0000%),                     avg. length: 9657.8,                    last time consumption/overall running time: 1482.1790s / 14037.6907 s
first_0:                     episode reward: -0.4500
second_0:                     episode reward: 0.4500
Process ID: 1, episode: 220/10000 (2.2000%),                     avg. length: 8896.2,                    last time consumption/overall running time: 1366.6012s / 15404.2919 s
first_0:                     episode reward: 2.0500
second_0:                     episode reward: -2.0500
Process ID: 1, episode: 240/10000 (2.4000%),                     avg. length: 8843.8,                    last time consumption/overall running time: 1356.1900s / 16760.4820 s
first_0:                     episode reward: 6.6000
second_0:                     episode reward: -6.6000
Process ID: 1, episode: 260/10000 (2.6000%),                     avg. length: 8101.45,                    last time consumption/overall running time: 1233.8313s / 17994.3133 s
first_0:                     episode reward: 5.3000
second_0:                     episode reward: -5.3000
Process ID: 1, episode: 280/10000 (2.8000%),                     avg. length: 8541.55,                    last time consumption/overall running time: 1312.5875s / 19306.9008 s
first_0:                     episode reward: 3.5500
second_0:                     episode reward: -3.5500
Process ID: 1, episode: 300/10000 (3.0000%),                     avg. length: 7591.55,                    last time consumption/overall running time: 1176.4376s / 20483.3384 s
first_0:                     episode reward: 4.2000
second_0:                     episode reward: -4.2000
Process ID: 1, episode: 320/10000 (3.2000%),                     avg. length: 6801.45,                    last time consumption/overall running time: 1052.7535s / 21536.0919 s
first_0:                     episode reward: 3.6500
second_0:                     episode reward: -3.6500
Process ID: 1, episode: 340/10000 (3.4000%),                     avg. length: 6280.5,                    last time consumption/overall running time: 978.8152s / 22514.9071 s
first_0:                     episode reward: 5.6500
second_0:                     episode reward: -5.6500
Process ID: 1, episode: 360/10000 (3.6000%),                     avg. length: 5824.7,                    last time consumption/overall running time: 896.5527s / 23411.4598 s
first_0:                     episode reward: 5.8000
second_0:                     episode reward: -5.8000
Process ID: 1, episode: 380/10000 (3.8000%),                     avg. length: 7373.7,                    last time consumption/overall running time: 1135.4360s / 24546.8958 s
first_0:                     episode reward: 0.1500
second_0:                     episode reward: -0.1500
Process ID: 1, episode: 400/10000 (4.0000%),                     avg. length: 5128.95,                    last time consumption/overall running time: 778.8091s / 25325.7049 s
first_0:                     episode reward: 4.0000
second_0:                     episode reward: -4.0000
Process ID: 1, episode: 420/10000 (4.2000%),                     avg. length: 4850.8,                    last time consumption/overall running time: 745.1177s / 26070.8226 s
first_0:                     episode reward: 4.8000
second_0:                     episode reward: -4.8000
Process ID: 1, episode: 440/10000 (4.4000%),                     avg. length: 5192.45,                    last time consumption/overall running time: 801.7736s / 26872.5963 s
first_0:                     episode reward: 7.3000
second_0:                     episode reward: -7.3000
Process ID: 1, episode: 460/10000 (4.6000%),                     avg. length: 4639.75,                    last time consumption/overall running time: 723.3820s / 27595.9783 s
first_0:                     episode reward: 8.2000
second_0:                     episode reward: -8.2000
Process ID: 1, episode: 480/10000 (4.8000%),                     avg. length: 4867.05,                    last time consumption/overall running time: 751.7525s / 28347.7308 s
first_0:                     episode reward: 3.9500pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 83
Arguments:  {'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': True, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'add_components': {'replay_buffer': <AutoProxy[replay_buffer] object, typeid 'replay_buffer' at 0x7fb389996cf8>}}
Save models to : /home/zihan/research/MARS/data/model/0/pettingzoo_tennis_v2_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/0/pettingzoo_tennis_v2_nash_dqn.
Process ID: 0, episode: 20/10000 (0.2000%),                     avg. length: 9999.0,                    last time consumption/overall running time: 1339.7049s / 1339.7049 s
first_0:                     episode reward: -3.1500
second_0:                     episode reward: 3.1500
Process ID: 0, episode: 40/10000 (0.4000%),                     avg. length: 9619.35,                    last time consumption/overall running time: 1438.2052s / 2777.9101 s
first_0:                     episode reward: 1.4000
second_0:                     episode reward: -1.4000
Process ID: 0, episode: 60/10000 (0.6000%),                     avg. length: 9999.0,                    last time consumption/overall running time: 1501.6443s / 4279.5545 s
first_0:                     episode reward: 1.7500
second_0:                     episode reward: -1.7500
Process ID: 0, episode: 80/10000 (0.8000%),                     avg. length: 9999.0,                    last time consumption/overall running time: 1504.6727s / 5784.2272 s
first_0:                     episode reward: 0.3000
second_0:                     episode reward: -0.3000
Process ID: 0, episode: 100/10000 (1.0000%),                     avg. length: 9094.6,                    last time consumption/overall running time: 1373.3579s / 7157.5851 s
first_0:                     episode reward: -0.8000
second_0:                     episode reward: 0.8000
Process ID: 0, episode: 120/10000 (1.2000%),                     avg. length: 9648.05,                    last time consumption/overall running time: 1454.1372s / 8611.7223 s
first_0:                     episode reward: 0.3500
second_0:                     episode reward: -0.3500
Process ID: 0, episode: 140/10000 (1.4000%),                     avg. length: 8880.4,                    last time consumption/overall running time: 1393.0949s / 10004.8172 s
first_0:                     episode reward: 2.7500
second_0:                     episode reward: -2.7500
Process ID: 0, episode: 160/10000 (1.6000%),                     avg. length: 9252.1,                    last time consumption/overall running time: 1466.4037s / 11471.2209 s
first_0:                     episode reward: 4.5000
second_0:                     episode reward: -4.5000
Process ID: 0, episode: 180/10000 (1.8000%),                     avg. length: 8870.05,                    last time consumption/overall running time: 1400.1038s / 12871.3247 s
first_0:                     episode reward: 5.0000
second_0:                     episode reward: -5.0000
Process ID: 0, episode: 200/10000 (2.0000%),                     avg. length: 9952.6,                    last time consumption/overall running time: 1581.6632s / 14452.9879 s
first_0:                     episode reward: -2.9000
second_0:                     episode reward: 2.9000
Process ID: 0, episode: 220/10000 (2.2000%),                     avg. length: 8876.45,                    last time consumption/overall running time: 1403.2475s / 15856.2354 s
first_0:                     episode reward: 4.8000
second_0:                     episode reward: -4.8000
Process ID: 0, episode: 240/10000 (2.4000%),                     avg. length: 8393.05,                    last time consumption/overall running time: 1322.0437s / 17178.2792 s
first_0:                     episode reward: 0.2500
second_0:                     episode reward: -0.2500
Process ID: 0, episode: 260/10000 (2.6000%),                     avg. length: 8869.15,                    last time consumption/overall running time: 1392.6337s / 18570.9128 s
first_0:                     episode reward: 4.8000
second_0:                     episode reward: -4.8000
Process ID: 0, episode: 280/10000 (2.8000%),                     avg. length: 9649.9,                    last time consumption/overall running time: 1528.4266s / 20099.3394 s
first_0:                     episode reward: 3.0000
second_0:                     episode reward: -3.0000
Process ID: 0, episode: 300/10000 (3.0000%),                     avg. length: 7572.7,                    last time consumption/overall running time: 1204.5804s / 21303.9198 s
first_0:                     episode reward: 0.6000
second_0:                     episode reward: -0.6000
Process ID: 0, episode: 320/10000 (3.2000%),                     avg. length: 7049.8,                    last time consumption/overall running time: 1115.1778s / 22419.0976 s
first_0:                     episode reward: 6.4000
second_0:                     episode reward: -6.4000
Process ID: 0, episode: 340/10000 (3.4000%),                     avg. length: 4741.85,                    last time consumption/overall running time: 747.3645s / 23166.4621 s
first_0:                     episode reward: 6.2000
second_0:                     episode reward: -6.2000
Process ID: 0, episode: 360/10000 (3.6000%),                     avg. length: 8044.2,                    last time consumption/overall running time: 1267.0697s / 24433.5318 s
first_0:                     episode reward: 1.2500
second_0:                     episode reward: -1.2500
Process ID: 0, episode: 380/10000 (3.8000%),                     avg. length: 5137.15,                    last time consumption/overall running time: 787.9949s / 25221.5267 s
first_0:                     episode reward: 5.9000
second_0:                     episode reward: -5.9000
Process ID: 0, episode: 400/10000 (4.0000%),                     avg. length: 6006.25,                    last time consumption/overall running time: 933.4842s / 26155.0109 s
first_0:                     episode reward: 6.8500
second_0:                     episode reward: -6.8500
Process ID: 0, episode: 420/10000 (4.2000%),                     avg. length: 4669.2,                    last time consumption/overall running time: 730.2067s / 26885.2176 s
first_0:                     episode reward: 4.3500
second_0:                     episode reward: -4.3500
Process ID: 0, episode: 440/10000 (4.4000%),                     avg. length: 4262.4,                    last time consumption/overall running time: 670.0092s / 27555.2268 s
first_0:                     episode reward: 9.3000
second_0:                     episode reward: -9.3000
Process ID: 0, episode: 460/10000 (4.6000%),                     avg. length: 4110.8,                    last time consumption/overall running time: 644.7454s / 28199.9722 s
first_0:                     episode reward: 5.1000
second_0:                     episode reward: -5.1000
Process ID: 0, episode: 480/10000 (4.8000%),                     avg. length: 5234.2,                    last time consumption/overall running time: 820.3024s / 29020.2746 s
first_0:                     episode reward: 1.1500
second_0:                     episode reward: -3.9500
Process ID: 1, episode: 500/10000 (5.0000%),                     avg. length: 4808.8,                    last time consumption/overall running time: 742.2005s / 29089.9313 s
first_0:                     episode reward: 5.0000
second_0:                     episode reward: -5.0000
Process ID: 1, episode: 520/10000 (5.2000%),                     avg. length: 5270.45,                    last time consumption/overall running time: 818.3811s / 29908.3124 s
first_0:                     episode reward: -0.1500
second_0:                     episode reward: 0.1500
Process ID: 1, episode: 540/10000 (5.4000%),                     avg. length: 4477.15,                    last time consumption/overall running time: 690.2365s / 30598.5489 s
first_0:                     episode reward: 2.5000
second_0:                     episode reward: -2.5000
Process ID: 1, episode: 560/10000 (5.6000%),                     avg. length: 4339.25,                    last time consumption/overall running time: 670.2400s / 31268.7889 s
first_0:                     episode reward: 5.8000
second_0:                     episode reward: -5.8000
Process ID: 1, episode: 580/10000 (5.8000%),                     avg. length: 4665.15,                    last time consumption/overall running time: 720.8421s / 31989.6309 s
first_0:                     episode reward: 5.3500
second_0:                     episode reward: -5.3500
Process ID: 1, episode: 600/10000 (6.0000%),                     avg. length: 4924.45,                    last time consumption/overall running time: 760.9362s / 32750.5671 s
first_0:                     episode reward: 1.6500
second_0:                     episode reward: -1.6500
Process ID: 1, episode: 620/10000 (6.2000%),                     avg. length: 6163.9,                    last time consumption/overall running time: 957.7557s / 33708.3228 s
first_0:                     episode reward: -2.7000
second_0:                     episode reward: 2.7000
Process ID: 1, episode: 640/10000 (6.4000%),                     avg. length: 5177.6,                    last time consumption/overall running time: 801.6574s / 34509.9802 s
first_0:                     episode reward: 6.3000
second_0:                     episode reward: -6.3000
Process ID: 1, episode: 660/10000 (6.6000%),                     avg. length: 4942.5,                    last time consumption/overall running time: 773.3335s / 35283.3138 s
first_0:                     episode reward: 1.5000
second_0:                     episode reward: -1.5000
Process ID: 1, episode: 680/10000 (6.8000%),                     avg. length: 5748.6,                    last time consumption/overall running time: 896.0305s / 36179.3443 s
first_0:                     episode reward: 3.2000
second_0:                     episode reward: -3.2000
Process ID: 1, episode: 700/10000 (7.0000%),                     avg. length: 5602.3,                    last time consumption/overall running time: 877.3325s / 37056.6768 s
first_0:                     episode reward: -0.7000
second_0:                     episode reward: 0.7000
Process ID: 1, episode: 720/10000 (7.2000%),                     avg. length: 5417.0,                    last time consumption/overall running time: 845.6990s / 37902.3758 s
first_0:                     episode reward: 3.7000
second_0:                     episode reward: -3.7000
Process ID: 1, episode: 740/10000 (7.4000%),                     avg. length: 5814.9,                    last time consumption/overall running time: 903.6434s / 38806.0191 s
first_0:                     episode reward: 1.1000
second_0:                     episode reward: -1.1000
Process ID: 1, episode: 760/10000 (7.6000%),                     avg. length: 5202.5,                    last time consumption/overall running time: 806.2887s / 39612.3078 s
first_0:                     episode reward: -1.6000
second_0:                     episode reward: 1.6000
Process ID: 1, episode: 780/10000 (7.8000%),                     avg. length: 5654.15,                    last time consumption/overall running time: 882.7308s / 40495.0386 s
first_0:                     episode reward: 2.1000
second_0:                     episode reward: -2.1000
Process ID: 1, episode: 800/10000 (8.0000%),                     avg. length: 5603.4,                    last time consumption/overall running time: 879.3916s / 41374.4302 s
first_0:                     episode reward: 3.4500
second_0:                     episode reward: -3.4500
Process ID: 1, episode: 820/10000 (8.2000%),                     avg. length: 5544.85,                    last time consumption/overall running time: 863.1220s / 42237.5521 s
first_0:                     episode reward: -3.9000
second_0:                     episode reward: 3.9000
Process ID: 1, episode: 840/10000 (8.4000%),                     avg. length: 5531.85,                    last time consumption/overall running time: 863.9405s / 43101.4927 s
first_0:                     episode reward: -1.3000
second_0:                     episode reward: 1.3000
Process ID: 1, episode: 860/10000 (8.6000%),                     avg. length: 5491.85,                    last time consumption/overall running time: 848.0669s / 43949.5596 s
first_0:                     episode reward: -0.8000
second_0:                     episode reward: 0.8000
Process ID: 1, episode: 880/10000 (8.8000%),                     avg. length: 6369.6,                    last time consumption/overall running time: 982.0175s / 44931.5771 s
first_0:                     episode reward: 0.5500
second_0:                     episode reward: -0.5500
Process ID: 1, episode: 900/10000 (9.0000%),                     avg. length: 5220.35,                    last time consumption/overall running time: 802.7756s / 45734.3527 s
first_0:                     episode reward: -4.9000
second_0:                     episode reward: 4.9000
Process ID: 1, episode: 920/10000 (9.2000%),                     avg. length: 5584.25,                    last time consumption/overall running time: 868.9734s / 46603.3261 s
first_0:                     episode reward: -2.1000
second_0:                     episode reward: 2.1000
Process ID: 1, episode: 940/10000 (9.4000%),                     avg. length: 6252.05,                    last time consumption/overall running time: 976.2864s / 47579.6125 s
first_0:                     episode reward: -1.4500
second_0:                     episode reward: 1.4500
Process ID: 1, episode: 960/10000 (9.6000%),                     avg. length: 5416.2,                    last time consumption/overall running time: 824.6675s / 48404.2800 s
first_0:                     episode reward: -1.7000
second_0:                     episode reward: 1.7000
Process ID: 1, episode: 980/10000 (9.8000%),                     avg. length: 6283.25,                    last time consumption/overall running time: 955.7083s / 49359.9883 s
first_0:                     episode reward: -1.9000
second_0:                     episode reward: 1.9000
Process ID: 1, episode: 1000/10000 (10.0000%),                     avg. length: 5756.95,                    last time consumption/overall running time: 879.0230s / 50239.0112 s
first_0:                     episode reward: 3.5500
second_0:                     episode reward: -3.5500
Process ID: 1, episode: 1020/10000 (10.2000%),                     avg. length: 5780.5,                    last time consumption/overall running time: 881.1884s / 51120.1996 s
first_0:                     episode reward: -0.3500
second_0:                     episode reward: 0.3500
Process ID: 1, episode: 1040/10000 (10.4000%),                     avg. length: 5384.75,                    last time consumption/overall running time: 825.5693s / 51945.7689 s
first_0:                     episode reward: 0.9000
second_0:                     episode reward: -0.9000
Process ID: 1, episode: 1060/10000 (10.6000%),                     avg. length: 6356.2,                    last time consumption/overall running time: 970.0976s / 52915.8665 s
first_0:                     episode reward: -0.9500
second_0:                     episode reward: 0.9500
second_0:                     episode reward: -1.1500
Process ID: 0, episode: 500/10000 (5.0000%),                     avg. length: 5233.15,                    last time consumption/overall running time: 827.9510s / 29848.2255 s
first_0:                     episode reward: 3.8500
second_0:                     episode reward: -3.8500
Process ID: 0, episode: 520/10000 (5.2000%),                     avg. length: 5626.8,                    last time consumption/overall running time: 890.7834s / 30739.0090 s
first_0:                     episode reward: 6.4500
second_0:                     episode reward: -6.4500
Process ID: 0, episode: 540/10000 (5.4000%),                     avg. length: 5068.05,                    last time consumption/overall running time: 795.8703s / 31534.8793 s
first_0:                     episode reward: 3.4500
second_0:                     episode reward: -3.4500
Process ID: 0, episode: 560/10000 (5.6000%),                     avg. length: 4772.65,                    last time consumption/overall running time: 753.9615s / 32288.8409 s
first_0:                     episode reward: 1.0000
second_0:                     episode reward: -1.0000
Process ID: 0, episode: 580/10000 (5.8000%),                     avg. length: 4368.8,                    last time consumption/overall running time: 691.4271s / 32980.2680 s
first_0:                     episode reward: 1.2500
second_0:                     episode reward: -1.2500
Process ID: 0, episode: 600/10000 (6.0000%),                     avg. length: 4086.8,                    last time consumption/overall running time: 645.5280s / 33625.7960 s
first_0:                     episode reward: 3.2000
second_0:                     episode reward: -3.2000
Process ID: 0, episode: 620/10000 (6.2000%),                     avg. length: 6123.05,                    last time consumption/overall running time: 959.0184s / 34584.8144 s
first_0:                     episode reward: 0.8000
second_0:                     episode reward: -0.8000
Process ID: 0, episode: 640/10000 (6.4000%),                     avg. length: 5640.5,                    last time consumption/overall running time: 888.4176s / 35473.2320 s
first_0:                     episode reward: -1.2500
second_0:                     episode reward: 1.2500
Process ID: 0, episode: 660/10000 (6.6000%),                     avg. length: 5349.55,                    last time consumption/overall running time: 838.0900s / 36311.3220 s
first_0:                     episode reward: 1.1500
second_0:                     episode reward: -1.1500
Process ID: 0, episode: 680/10000 (6.8000%),                     avg. length: 6115.75,                    last time consumption/overall running time: 971.2938s / 37282.6158 s
first_0:                     episode reward: -1.3500
second_0:                     episode reward: 1.3500
Process ID: 0, episode: 700/10000 (7.0000%),                     avg. length: 5084.25,                    last time consumption/overall running time: 806.8532s / 38089.4690 s
first_0:                     episode reward: 3.6500
second_0:                     episode reward: -3.6500
Process ID: 0, episode: 720/10000 (7.2000%),                     avg. length: 5318.65,                    last time consumption/overall running time: 833.4770s / 38922.9461 s
first_0:                     episode reward: 4.0500
second_0:                     episode reward: -4.0500
Process ID: 0, episode: 740/10000 (7.4000%),                     avg. length: 5691.3,                    last time consumption/overall running time: 891.9993s / 39814.9453 s
first_0:                     episode reward: 0.5000
second_0:                     episode reward: -0.5000
Process ID: 0, episode: 760/10000 (7.6000%),                     avg. length: 6237.15,                    last time consumption/overall running time: 976.7427s / 40791.6880 s
first_0:                     episode reward: 0.3500
second_0:                     episode reward: -0.3500
Process ID: 0, episode: 780/10000 (7.8000%),                     avg. length: 6599.25,                    last time consumption/overall running time: 1047.9066s / 41839.5946 s
first_0:                     episode reward: -0.5000
second_0:                     episode reward: 0.5000
Process ID: 0, episode: 800/10000 (8.0000%),                     avg. length: 6169.8,                    last time consumption/overall running time: 976.3690s / 42815.9636 s
first_0:                     episode reward: -2.3500
second_0:                     episode reward: 2.3500
Process ID: 0, episode: 820/10000 (8.2000%),                     avg. length: 6684.75,                    last time consumption/overall running time: 1049.5689s / 43865.5324 s
first_0:                     episode reward: 2.6500
second_0:                     episode reward: -2.6500
Process ID: 0, episode: 840/10000 (8.4000%),                     avg. length: 6416.6,                    last time consumption/overall running time: 995.3396s / 44860.8720 s
first_0:                     episode reward: 0.4500
second_0:                     episode reward: -0.4500
Process ID: 0, episode: 860/10000 (8.6000%),                     avg. length: 5709.1,                    last time consumption/overall running time: 893.9202s / 45754.7923 s
first_0:                     episode reward: -2.7500
second_0:                     episode reward: 2.7500
Process ID: 0, episode: 880/10000 (8.8000%),                     avg. length: 5865.9,                    last time consumption/overall running time: 918.7028s / 46673.4950 s
first_0:                     episode reward: 2.6500
second_0:                     episode reward: -2.6500
Process ID: 0, episode: 900/10000 (9.0000%),                     avg. length: 5804.45,                    last time consumption/overall running time: 914.9734s / 47588.4684 s
first_0:                     episode reward: -1.0000
second_0:                     episode reward: 1.0000
Process ID: 0, episode: 920/10000 (9.2000%),                     avg. length: 5907.75,                    last time consumption/overall running time: 918.8593s / 48507.3277 s
first_0:                     episode reward: -4.5000
second_0:                     episode reward: 4.5000
Process ID: 0, episode: 940/10000 (9.4000%),                     avg. length: 5942.45,                    last time consumption/overall running time: 916.4224s / 49423.7500 s
first_0:                     episode reward: 0.2000
second_0:                     episode reward: -0.2000
Process ID: 0, episode: 960/10000 (9.6000%),                     avg. length: 5429.4,                    last time consumption/overall running time: 838.8079s / 50262.5579 s
first_0:                     episode reward: 0.0000
second_0:                     episode reward: 0.0000
Process ID: 0, episode: 980/10000 (9.8000%),                     avg. length: 5744.7,                    last time consumption/overall running time: 891.9950s / 51154.5529 s
first_0:                     episode reward: 2.6000
second_0:                     episode reward: -2.6000
Process ID: 0, episode: 1000/10000 (10.0000%),                     avg. length: 5632.5,                    last time consumption/overall running time: 878.4023s / 52032.9552 s
first_0:                     episode reward: 1.6500
second_0:                     episode reward: -1.6500
Process ID: 0, episode: 1020/10000 (10.2000%),                     avg. length: 6390.3,                    last time consumption/overall running time: 988.5765s / 53021.5317 s
first_0:                     episode reward: -0.3500
second_0:                     episode reward: 0.3500
Process ID: 0, episode: 1040/10000 (10.4000%),                     avg. length: 5200.15,                    last time consumption/overall running time: 815.6183s / 53837.1500 s
first_0:                     episode reward: -1.7000
second_0:                     episode reward: 1.7000
Process ID: 0, episode: 1060/10000 (10.6000%),                     avg. length: 6345.05,                    last time consumption/overall running time: 1000.0787s / 54837.2287 s
first_0:                     episode reward: 0.0000
second_0:                     episode reward: 0.0000