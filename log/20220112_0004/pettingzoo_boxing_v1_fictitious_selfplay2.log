pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 40
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f5479be6c88>
Agents No. [1] (index starting from 0) are not learnable.
{'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': True, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 60, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'add_components': {'replay_buffer': <AutoProxy[replay_buffer] object, typeid 'replay_buffer' at 0x7f5479c43cf8>}}
pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 50
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': True, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 60, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'add_components': {'replay_buffer': <AutoProxy[replay_buffer] object, typeid 'replay_buffer' at 0x7f33c1c51320>}}
Save models to : /home/zihan/research/MARS/data/model/0/pettingzoo_boxing_v1_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/0/pettingzoo_boxing_v1_fictitious_selfplay2.
Process ID: 0, episode: 20/10000 (0.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 189.6618s / 189.6618 s
first_0:                     episode reward: 2.7500
second_0:                     episode reward: -2.7500
Process ID: 0, episode: 40/10000 (0.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 211.5211s / 401.1830 s
first_0:                     episode reward: 5.4000
second_0:                     episode reward: -5.4000
Process ID: 0, episode: 60/10000 (0.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 217.1373s / 618.3203 s
first_0:                     episode reward: 1.7000
second_0:                     episode reward: -1.7000
Process ID: 0, episode: 80/10000 (0.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 218.8502s / 837.1705 s
first_0:                     episode reward: 2.1500
second_0:                     episode reward: -2.1500
Process ID: 0, episode: 100/10000 (1.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 219.6908s / 1056.8613 s
first_0:                     episode reward: 0.8000
second_0:                     episode reward: -0.8000
Process ID: 0, episode: 120/10000 (1.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 220.8376s / 1277.6990 s
first_0:                     episode reward: 0.8000
second_0:                     episode reward: -0.8000
Process ID: 0, episode: 140/10000 (1.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 220.5273s / 1498.2262 s
first_0:                     episode reward: 1.9500
second_0:                     episode reward: -1.9500
Process ID: 0, episode: 160/10000 (1.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 220.2867s / 1718.5130 s
first_0:                     episode reward: 6.1000
second_0:                     episode reward: -6.1000
Process ID: 0, episode: 180/10000 (1.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 221.1482s / 1939.6612 s
first_0:                     episode reward: 3.2000
second_0:                     episode reward: -3.2000
Process ID: 0, episode: 200/10000 (2.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 221.1905s / 2160.8517 s
first_0:                     episode reward: 0.1000
second_0:                     episode reward: -0.1000
Process ID: 0, episode: 220/10000 (2.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 221.5175s / 2382.3692 s
first_0:                     episode reward: 5.9000
second_0:                     episode reward: -5.9000
Process ID: 0, episode: 240/10000 (2.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 220.8871s / 2603.2563 s
first_0:                     episode reward: 3.4500
second_0:                     episode reward: -3.4500
Process ID: 0, episode: 260/10000 (2.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 220.3185s / 2823.5749 s
first_0:                     episode reward: 5.5500
second_0:                     episode reward: -5.5500
Process ID: 0, episode: 280/10000 (2.8000%),                     avg. length: 1772.7,                    last time consumption/overall running time: 217.6090s / 3041.1839 s
first_0:                     episode reward: 15.4500
second_0:                     episode reward: -15.4500
Process ID: 0, episode: 300/10000 (3.0000%),                     avg. length: 1757.45,                    last time consumption/overall running time: 215.8504s / 3257.0343 s
first_0:                     episode reward: 14.6500
second_0:                     episode reward: -14.6500
Process ID: 0, episode: 320/10000 (3.2000%),                     avg. length: 1516.2,                    last time consumption/overall running time: 185.9388s / 3442.9731 s
first_0:                     episode reward: 50.5500
second_0:                     episode reward: -50.5500
Process ID: 0, episode: 340/10000 (3.4000%),                     avg. length: 1453.3,                    last time consumption/overall running time: 179.2042s / 3622.1773 s
first_0:                     episode reward: 63.3000
second_0:                     episode reward: -63.3000
Process ID: 0, episode: 360/10000 (3.6000%),                     avg. length: 945.35,                    last time consumption/overall running time: 115.9105s / 3738.0878 s
first_0:                     episode reward: 91.8500
second_0:                     episode reward: -91.8500
Process ID: 0, episode: 380/10000 (3.8000%),                     avg. length: 1274.55,                    last time consumption/overall running time: 156.8151s / 3894.9029 s
first_0:                     episode reward: 68.9000
second_0:                     episode reward: -68.9000
Process ID: 0, episode: 400/10000 (4.0000%),                     avg. length: 921.3,                    last time consumption/overall running time: 112.8723s / 4007.7752 s
first_0:                     episode reward: 92.4500
second_0:                     episode reward: -92.4500
Process ID: 0, episode: 420/10000 (4.2000%),                     avg. length: 908.5,                    last time consumption/overall running time: 112.1783s / 4119.9535 s
first_0:                     episode reward: 84.4000
second_0:                     episode reward: -84.4000
Process ID: 0, episode: 440/10000 (4.4000%),                     avg. length: 909.95,                    last time consumption/overall running time: 112.5874s / 4232.5409 s
first_0:                     episode reward: 88.0000
second_0:                     episode reward: -88.0000
Process ID: 0, episode: 460/10000 (4.6000%),                     avg. length: 651.35,                    last time consumption/overall running time: 80.3203s / 4312.8611 s
first_0:                     episode reward: 91.6500
second_0:                     episode reward: -91.6500
Process ID: 0, episode: 480/10000 (4.8000%),                     avg. length: 461.9,                    last time consumption/overall running time: 57.1510s / 4370.0121 spygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 71
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': True, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 60, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'add_components': {'replay_buffer': <AutoProxy[replay_buffer] object, typeid 'replay_buffer' at 0x7f33c1c51320>}}
Save models to : /home/zihan/research/MARS/data/model/1/pettingzoo_boxing_v1_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/1/pettingzoo_boxing_v1_fictitious_selfplay2.
Process ID: 1, episode: 20/10000 (0.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 188.6862s / 188.6862 s
first_0:                     episode reward: 1.5000
second_0:                     episode reward: -1.5000
Process ID: 1, episode: 40/10000 (0.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 211.2083s / 399.8945 s
first_0:                     episode reward: 6.6000
second_0:                     episode reward: -6.6000
Process ID: 1, episode: 60/10000 (0.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 216.0370s / 615.9315 s
first_0:                     episode reward: 1.1000
second_0:                     episode reward: -1.1000
Process ID: 1, episode: 80/10000 (0.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 217.9546s / 833.8861 s
first_0:                     episode reward: 2.4500
second_0:                     episode reward: -2.4500
Process ID: 1, episode: 100/10000 (1.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 218.8991s / 1052.7852 s
first_0:                     episode reward: 0.7500
second_0:                     episode reward: -0.7500
Process ID: 1, episode: 120/10000 (1.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 219.3363s / 1272.1215 s
first_0:                     episode reward: 2.2000
second_0:                     episode reward: -2.2000
Process ID: 1, episode: 140/10000 (1.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 218.7999s / 1490.9214 s
first_0:                     episode reward: 2.4000
second_0:                     episode reward: -2.4000
Process ID: 1, episode: 160/10000 (1.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 218.4329s / 1709.3543 s
first_0:                     episode reward: 7.7500
second_0:                     episode reward: -7.7500
Process ID: 1, episode: 180/10000 (1.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 219.9231s / 1929.2774 s
first_0:                     episode reward: 6.9500
second_0:                     episode reward: -6.9500
Process ID: 1, episode: 200/10000 (2.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 218.7325s / 2148.0099 s
first_0:                     episode reward: 1.1000
second_0:                     episode reward: -1.1000
Process ID: 1, episode: 220/10000 (2.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 220.0892s / 2368.0992 s
first_0:                     episode reward: 2.0500
second_0:                     episode reward: -2.0500
Process ID: 1, episode: 240/10000 (2.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 219.0902s / 2587.1893 s
first_0:                     episode reward: 7.3000
second_0:                     episode reward: -7.3000
Process ID: 1, episode: 260/10000 (2.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 219.4200s / 2806.6093 s
first_0:                     episode reward: 1.1500
second_0:                     episode reward: -1.1500
Process ID: 1, episode: 280/10000 (2.8000%),                     avg. length: 1765.05,                    last time consumption/overall running time: 216.2204s / 3022.8297 s
first_0:                     episode reward: 11.2000
second_0:                     episode reward: -11.2000
Process ID: 1, episode: 300/10000 (3.0000%),                     avg. length: 1750.6,                    last time consumption/overall running time: 214.0619s / 3236.8916 s
first_0:                     episode reward: 25.3000
second_0:                     episode reward: -25.3000
Process ID: 1, episode: 320/10000 (3.2000%),                     avg. length: 1654.05,                    last time consumption/overall running time: 201.7190s / 3438.6107 s
first_0:                     episode reward: 61.8500
second_0:                     episode reward: -61.8500
Process ID: 1, episode: 340/10000 (3.4000%),                     avg. length: 1309.7,                    last time consumption/overall running time: 159.8230s / 3598.4336 s
first_0:                     episode reward: 76.7000
second_0:                     episode reward: -76.7000
Process ID: 1, episode: 360/10000 (3.6000%),                     avg. length: 1073.5,                    last time consumption/overall running time: 130.6168s / 3729.0504 s
first_0:                     episode reward: 77.1500
second_0:                     episode reward: -77.1500
Process ID: 1, episode: 380/10000 (3.8000%),                     avg. length: 1350.25,                    last time consumption/overall running time: 165.3749s / 3894.4254 s
first_0:                     episode reward: 65.2000
second_0:                     episode reward: -65.2000
Process ID: 1, episode: 400/10000 (4.0000%),                     avg. length: 952.5,                    last time consumption/overall running time: 115.8299s / 4010.2553 s
first_0:                     episode reward: 81.8500
second_0:                     episode reward: -81.8500
Process ID: 1, episode: 420/10000 (4.2000%),                     avg. length: 898.45,                    last time consumption/overall running time: 109.1630s / 4119.4183 s
first_0:                     episode reward: 80.6500
second_0:                     episode reward: -80.6500
Process ID: 1, episode: 440/10000 (4.4000%),                     avg. length: 776.15,                    last time consumption/overall running time: 95.0663s / 4214.4846 s
first_0:                     episode reward: 94.4000
second_0:                     episode reward: -94.4000
Process ID: 1, episode: 460/10000 (4.6000%),                     avg. length: 825.55,                    last time consumption/overall running time: 100.6531s / 4315.1376 s
first_0:                     episode reward: 89.1500
second_0:                     episode reward: -89.1500
Process ID: 1, episode: 480/10000 (4.8000%),                     avg. length: 485.5,                    last time consumption/overall running time: 59.5084s / 4374.6461 s
first_0:                     episode reward: 94.2500
second_0:                     episode reward: -94.2500
Process ID: 0, episode: 500/10000 (5.0000%),                     avg. length: 421.5,                    last time consumption/overall running time: 51.9764s / 4421.9885 s
first_0:                     episode reward: 99.2500
second_0:                     episode reward: -99.2500
Process ID: 0, episode: 520/10000 (5.2000%),                     avg. length: 639.5,                    last time consumption/overall running time: 78.2984s / 4500.2869 s
first_0:                     episode reward: 84.6000
second_0:                     episode reward: -84.6000
Process ID: 0, episode: 540/10000 (5.4000%),                     avg. length: 490.9,                    last time consumption/overall running time: 60.6916s / 4560.9784 s
first_0:                     episode reward: 94.7500
second_0:                     episode reward: -94.7500
Process ID: 0, episode: 560/10000 (5.6000%),                     avg. length: 455.05,                    last time consumption/overall running time: 55.6456s / 4616.6240 s
first_0:                     episode reward: 94.8000
second_0:                     episode reward: -94.8000
Process ID: 0, episode: 580/10000 (5.8000%),                     avg. length: 387.05,                    last time consumption/overall running time: 48.0371s / 4664.6611 s
first_0:                     episode reward: 99.7500
second_0:                     episode reward: -99.7500
Process ID: 0, episode: 600/10000 (6.0000%),                     avg. length: 886.85,                    last time consumption/overall running time: 108.5536s / 4773.2147 s
first_0:                     episode reward: 69.2000
second_0:                     episode reward: -69.2000
Process ID: 0, episode: 620/10000 (6.2000%),                     avg. length: 484.5,                    last time consumption/overall running time: 59.6318s / 4832.8465 s
first_0:                     episode reward: 99.6000
second_0:                     episode reward: -99.6000
Process ID: 0, episode: 640/10000 (6.4000%),                     avg. length: 412.2,                    last time consumption/overall running time: 50.8839s / 4883.7304 s
first_0:                     episode reward: 99.7000
second_0:                     episode reward: -99.7000
Process ID: 0, episode: 660/10000 (6.6000%),                     avg. length: 340.15,                    last time consumption/overall running time: 42.2176s / 4925.9480 s
first_0:                     episode reward: 99.7000
second_0:                     episode reward: -99.7000
Process ID: 0, episode: 680/10000 (6.8000%),                     avg. length: 633.0,                    last time consumption/overall running time: 78.3210s / 5004.2691 s
first_0:                     episode reward: 94.8500
second_0:                     episode reward: -94.8500
Process ID: 0, episode: 700/10000 (7.0000%),                     avg. length: 488.6,                    last time consumption/overall running time: 60.2638s / 5064.5329 s
first_0:                     episode reward: 99.8000
second_0:                     episode reward: -99.8000
Process ID: 0, episode: 720/10000 (7.2000%),                     avg. length: 380.45,                    last time consumption/overall running time: 47.1356s / 5111.6685 s
first_0:                     episode reward: 99.9500
second_0:                     episode reward: -99.9500
Process ID: 0, episode: 740/10000 (7.4000%),                     avg. length: 320.3,                    last time consumption/overall running time: 39.4360s / 5151.1045 s
first_0:                     episode reward: 99.9000
second_0:                     episode reward: -99.9000
Process ID: 0, episode: 760/10000 (7.6000%),                     avg. length: 323.0,                    last time consumption/overall running time: 39.9969s / 5191.1014 s
first_0:                     episode reward: 99.8000
second_0:                     episode reward: -99.8000
Process ID: 0, episode: 780/10000 (7.8000%),                     avg. length: 362.7,                    last time consumption/overall running time: 45.1436s / 5236.2450 s
first_0:                     episode reward: 100.0000
second_0:                     episode reward: -100.0000
Process ID: 0, episode: 800/10000 (8.0000%),                     avg. length: 302.85,                    last time consumption/overall running time: 37.1568s / 5273.4018 s
first_0:                     episode reward: 99.9000
second_0:                     episode reward: -99.9000
Process ID: 0, episode: 820/10000 (8.2000%),                     avg. length: 297.5,                    last time consumption/overall running time: 36.8298s / 5310.2316 s
first_0:                     episode reward: 99.9000
second_0:                     episode reward: -99.9000
Process ID: 0, episode: 840/10000 (8.4000%),                     avg. length: 347.85,                    last time consumption/overall running time: 43.1173s / 5353.3489 s
first_0:                     episode reward: 99.8000
second_0:                     episode reward: -99.8000
Process ID: 0, episode: 860/10000 (8.6000%),                     avg. length: 399.65,                    last time consumption/overall running time: 49.7658s / 5403.1147 s
first_0:                     episode reward: 99.7500
second_0:                     episode reward: -99.7500
Process ID: 0, episode: 880/10000 (8.8000%),                     avg. length: 391.8,                    last time consumption/overall running time: 48.3406s / 5451.4553 s
first_0:                     episode reward: 99.8000
second_0:                     episode reward: -99.8000
Process ID: 0, episode: 900/10000 (9.0000%),                     avg. length: 321.75,                    last time consumption/overall running time: 39.8110s / 5491.2663 s
first_0:                     episode reward: 99.9000
second_0:                     episode reward: -99.9000
Process ID: 0, episode: 920/10000 (9.2000%),                     avg. length: 343.45,                    last time consumption/overall running time: 42.7599s / 5534.0262 s
first_0:                     episode reward: 100.0000
second_0:                     episode reward: -100.0000
Process ID: 0, episode: 940/10000 (9.4000%),                     avg. length: 349.85,                    last time consumption/overall running time: 43.4839s / 5577.5101 s
first_0:                     episode reward: 99.9000
second_0:                     episode reward: -99.9000
Process ID: 0, episode: 960/10000 (9.6000%),                     avg. length: 320.0,                    last time consumption/overall running time: 39.5353s / 5617.0454 s
first_0:                     episode reward: 100.0000
second_0:                     episode reward: -100.0000
Process ID: 0, episode: 980/10000 (9.8000%),                     avg. length: 353.45,                    last time consumption/overall running time: 43.6164s / 5660.6618 s
first_0:                     episode reward: 99.7000
second_0:                     episode reward: -99.7000
Process ID: 0, episode: 1000/10000 (10.0000%),                     avg. length: 339.85,                    last time consumption/overall running time: 41.9626s / 5702.6244 s
first_0:                     episode reward: 100.0000
second_0:                     episode reward: -100.0000
Process ID: 0, episode: 1020/10000 (10.2000%),                     avg. length: 371.6,                    last time consumption/overall running time: 46.0157s / 5748.6401 s
first_0:                     episode reward: 99.7000
second_0:                     episode reward: -99.7000
Process ID: 0, episode: 1040/10000 (10.4000%),                     avg. length: 294.05,                    last time consumption/overall running time: 36.5510s / 5785.1911 s
first_0:                     episode reward: 100.0000
second_0:                     episode reward: -100.0000
Process ID: 0, episode: 1060/10000 (10.6000%),                     avg. length: 500.35,                    last time consumption/overall running time: 61.8893s / 5847.0804 s
first_0:                     episode reward: 95.0000
second_0:                     episode reward: -95.0000
first_0:                     episode reward: 94.1000
second_0:                     episode reward: -94.1000
Process ID: 1, episode: 500/10000 (5.0000%),                     avg. length: 459.4,                    last time consumption/overall running time: 56.0640s / 4430.7100 s
first_0:                     episode reward: 99.6500
second_0:                     episode reward: -99.6500
Process ID: 1, episode: 520/10000 (5.2000%),                     avg. length: 656.1,                    last time consumption/overall running time: 80.3965s / 4511.1065 s
first_0:                     episode reward: 84.8500
second_0:                     episode reward: -84.8500
Process ID: 1, episode: 540/10000 (5.4000%),                     avg. length: 443.0,                    last time consumption/overall running time: 54.6364s / 4565.7429 s
first_0:                     episode reward: 94.8000
second_0:                     episode reward: -94.8000
Process ID: 1, episode: 560/10000 (5.6000%),                     avg. length: 469.7,                    last time consumption/overall running time: 57.4790s / 4623.2220 s
first_0:                     episode reward: 94.9500
second_0:                     episode reward: -94.9500
Process ID: 1, episode: 580/10000 (5.8000%),                     avg. length: 658.55,                    last time consumption/overall running time: 80.8193s / 4704.0413 s
first_0:                     episode reward: 89.8500
second_0:                     episode reward: -89.8500
Process ID: 1, episode: 600/10000 (6.0000%),                     avg. length: 795.95,                    last time consumption/overall running time: 97.4651s / 4801.5064 s
first_0:                     episode reward: 79.7000
second_0:                     episode reward: -79.7000
Process ID: 1, episode: 620/10000 (6.2000%),                     avg. length: 607.65,                    last time consumption/overall running time: 74.7105s / 4876.2170 s
first_0:                     episode reward: 89.5000
second_0:                     episode reward: -89.5000
Process ID: 1, episode: 640/10000 (6.4000%),                     avg. length: 521.85,                    last time consumption/overall running time: 64.3052s / 4940.5222 s
first_0:                     episode reward: 96.9000
second_0:                     episode reward: -96.9000
Process ID: 1, episode: 660/10000 (6.6000%),                     avg. length: 606.45,                    last time consumption/overall running time: 75.1858s / 5015.7079 s
first_0:                     episode reward: 99.6000
second_0:                     episode reward: -99.6000
Process ID: 1, episode: 680/10000 (6.8000%),                     avg. length: 478.7,                    last time consumption/overall running time: 59.1115s / 5074.8194 s
first_0:                     episode reward: 99.9000
second_0:                     episode reward: -99.9000
Process ID: 1, episode: 700/10000 (7.0000%),                     avg. length: 361.35,                    last time consumption/overall running time: 44.4158s / 5119.2352 s
first_0:                     episode reward: 99.8000
second_0:                     episode reward: -99.8000
Process ID: 1, episode: 720/10000 (7.2000%),                     avg. length: 273.95,                    last time consumption/overall running time: 33.5368s / 5152.7720 s
first_0:                     episode reward: 99.9000
second_0:                     episode reward: -99.9000
Process ID: 1, episode: 740/10000 (7.4000%),                     avg. length: 334.9,                    last time consumption/overall running time: 41.1237s / 5193.8957 s
first_0:                     episode reward: 99.7000
second_0:                     episode reward: -99.7000
Process ID: 1, episode: 760/10000 (7.6000%),                     avg. length: 329.75,                    last time consumption/overall running time: 40.8742s / 5234.7699 s
first_0:                     episode reward: 99.7000
second_0:                     episode reward: -99.7000
Process ID: 1, episode: 780/10000 (7.8000%),                     avg. length: 281.05,                    last time consumption/overall running time: 34.5614s / 5269.3313 s
first_0:                     episode reward: 99.6500
second_0:                     episode reward: -99.6500
Process ID: 1, episode: 800/10000 (8.0000%),                     avg. length: 265.3,                    last time consumption/overall running time: 32.7693s / 5302.1006 s
first_0:                     episode reward: 100.0000
second_0:                     episode reward: -100.0000
Process ID: 1, episode: 820/10000 (8.2000%),                     avg. length: 302.65,                    last time consumption/overall running time: 37.0360s / 5339.1367 s
first_0:                     episode reward: 100.0000
second_0:                     episode reward: -100.0000
Process ID: 1, episode: 840/10000 (8.4000%),                     avg. length: 369.85,                    last time consumption/overall running time: 45.5385s / 5384.6751 s
first_0:                     episode reward: 100.0000
second_0:                     episode reward: -100.0000
Process ID: 1, episode: 860/10000 (8.6000%),                     avg. length: 432.35,                    last time consumption/overall running time: 53.1195s / 5437.7946 s
first_0:                     episode reward: 99.8000
second_0:                     episode reward: -99.8000
Process ID: 1, episode: 880/10000 (8.8000%),                     avg. length: 312.95,                    last time consumption/overall running time: 38.5432s / 5476.3379 s
first_0:                     episode reward: 100.0000
second_0:                     episode reward: -100.0000
Process ID: 1, episode: 900/10000 (9.0000%),                     avg. length: 352.6,                    last time consumption/overall running time: 43.4070s / 5519.7449 s
first_0:                     episode reward: 100.0000
second_0:                     episode reward: -100.0000
Process ID: 1, episode: 920/10000 (9.2000%),                     avg. length: 271.9,                    last time consumption/overall running time: 33.4093s / 5553.1542 s
first_0:                     episode reward: 99.6000
second_0:                     episode reward: -99.6000
Process ID: 1, episode: 940/10000 (9.4000%),                     avg. length: 369.25,                    last time consumption/overall running time: 45.5110s / 5598.6652 s
first_0:                     episode reward: 99.9000
second_0:                     episode reward: -99.9000
Process ID: 1, episode: 960/10000 (9.6000%),                     avg. length: 339.8,                    last time consumption/overall running time: 41.7950s / 5640.4602 s
first_0:                     episode reward: 99.9000
second_0:                     episode reward: -99.9000
Process ID: 1, episode: 980/10000 (9.8000%),                     avg. length: 369.3,                    last time consumption/overall running time: 45.5539s / 5686.0141 s
first_0:                     episode reward: 99.8000
second_0:                     episode reward: -99.8000
Process ID: 1, episode: 1000/10000 (10.0000%),                     avg. length: 371.65,                    last time consumption/overall running time: 45.8695s / 5731.8836 s
first_0:                     episode reward: 99.8000
second_0:                     episode reward: -99.8000
Process ID: 1, episode: 1020/10000 (10.2000%),                     avg. length: 335.2,                    last time consumption/overall running time: 41.4060s / 5773.2895 s
first_0:                     episode reward: 99.9000
second_0:                     episode reward: -99.9000
Process ID: 1, episode: 1040/10000 (10.4000%),                     avg. length: 362.45,                    last time consumption/overall running time: 44.8735s / 5818.1630 s
first_0:                     episode reward: 99.9500
second_0:                     episode reward: -99.9500
Process ID: 1, episode: 1060/10000 (10.6000%),                     avg. length: 361.9,                    last time consumption/overall running time: 44.7356s / 5862.8986 s
first_0:                     episode reward: 98.2000
second_0:                     episode reward: -98.2000