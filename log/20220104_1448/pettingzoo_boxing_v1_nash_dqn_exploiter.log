pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 29
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f53bd571710>
No agent are not learnable.
{'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'exploiter_update_itr': 1}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'multiprocess': True}
pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
<mars.rl.agents.multiagent.MultiAgent object at 0x7f5e8d567490>
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 9
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'exploiter_update_itr': 1}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'multiprocess': True}
Save models to : /home/zihan/research/MARS/data/model/0/pettingzoo_boxing_v1_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/0/pettingzoo_boxing_v1_nash_dqn_exploiter.
Process ID: 0, episode: 20/10000 (0.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 296.6733s / 296.6733 s
first_0:                     episode reward: 2.2500
second_0:                     episode reward: -2.2500
Process ID: 0, episode: 40/10000 (0.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 451.9657s / 748.6390 s
first_0:                     episode reward: 7.0500
second_0:                     episode reward: -7.0500
Process ID: 0, episode: 60/10000 (0.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 499.0239s / 1247.6629 s
first_0:                     episode reward: 13.7000
second_0:                     episode reward: -13.7000
Process ID: 0, episode: 80/10000 (0.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 499.9403s / 1747.6032 s
first_0:                     episode reward: 12.3500
second_0:                     episode reward: -12.3500
Process ID: 0, episode: 100/10000 (1.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 508.0441s / 2255.6473 s
first_0:                     episode reward: 12.7500
second_0:                     episode reward: -12.7500
Process ID: 0, episode: 120/10000 (1.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.5611s / 2763.2084 s
first_0:                     episode reward: 11.7500
second_0:                     episode reward: -11.7500
Process ID: 0, episode: 140/10000 (1.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 506.7754s / 3269.9839 s
first_0:                     episode reward: 7.7500
second_0:                     episode reward: -7.7500
Process ID: 0, episode: 160/10000 (1.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 505.6999s / 3775.6837 s
first_0:                     episode reward: 11.1500
second_0:                     episode reward: -11.1500
Process ID: 0, episode: 180/10000 (1.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 506.0568s / 4281.7405 s
first_0:                     episode reward: 7.0500
second_0:                     episode reward: -7.0500
Process ID: 0, episode: 200/10000 (2.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.4904s / 4791.2309 s
first_0:                     episode reward: 4.4500
second_0:                     episode reward: -4.4500
Process ID: 0, episode: 220/10000 (2.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 506.2282s / 5297.4591 s
first_0:                     episode reward: 8.4500
second_0:                     episode reward: -8.4500
Process ID: 0, episode: 240/10000 (2.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.1368s / 5804.5960 s
first_0:                     episode reward: 15.0000
second_0:                     episode reward: -15.0000
Process ID: 0, episode: 260/10000 (2.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 505.9710s / 6310.5670 s
first_0:                     episode reward: 10.0000
second_0:                     episode reward: -10.0000
Process ID: 0, episode: 280/10000 (2.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 508.5916s / 6819.1586 s
first_0:                     episode reward: 10.3500
second_0:                     episode reward: -10.3500
Process ID: 0, episode: 300/10000 (3.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.3959s / 7328.5545 s
first_0:                     episode reward: 15.1000
second_0:                     episode reward: -15.1000
Process ID: 0, episode: 320/10000 (3.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 506.3855s / 7834.9400 s
first_0:                     episode reward: 7.0500
second_0:                     episode reward: -7.0500
Process ID: 0, episode: 340/10000 (3.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 505.3402s / 8340.2802 s
first_0:                     episode reward: 11.2000
second_0:                     episode reward: -11.2000
Process ID: 0, episode: 360/10000 (3.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 508.8774s / 8849.1576 s
first_0:                     episode reward: 5.4500
second_0:                     episode reward: -5.4500
Process ID: 0, episode: 380/10000 (3.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 511.1349s / 9360.2925 s
first_0:                     episode reward: 8.4000
second_0:                     episode reward: -8.4000
Process ID: 0, episode: 400/10000 (4.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 514.9716s / 9875.2641 s
first_0:                     episode reward: 11.3000
second_0:                     episode reward: -11.3000
Process ID: 0, episode: 420/10000 (4.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 508.4538s / 10383.7178 s
first_0:                     episode reward: 10.8500
second_0:                     episode reward: -10.8500
Process ID: 0, episode: 440/10000 (4.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 510.0198s / 10893.7377 s
first_0:                     episode reward: 17.7000
second_0:                     episode reward: -17.7000
Process ID: 0, episode: 460/10000 (4.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.8657s / 11403.6034 s
first_0:                     episode reward: 8.2000
second_0:                     episode reward: -8.2000
Process ID: 0, episode: 480/10000 (4.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.3414s / 11910.9448 s
first_0:                     episode reward: 7.0000pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
<mars.rl.agents.multiagent.MultiAgent object at 0x7f5e8d569450>
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 37
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'exploiter_update_itr': 1}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'multiprocess': True}
Save models to : /home/zihan/research/MARS/data/model/1/pettingzoo_boxing_v1_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/1/pettingzoo_boxing_v1_nash_dqn_exploiter.
Process ID: 1, episode: 20/10000 (0.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 295.3539s / 295.3539 s
first_0:                     episode reward: 4.0500
second_0:                     episode reward: -4.0500
Process ID: 1, episode: 40/10000 (0.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 457.1867s / 752.5406 s
first_0:                     episode reward: 8.0500
second_0:                     episode reward: -8.0500
Process ID: 1, episode: 60/10000 (0.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 496.8671s / 1249.4077 s
first_0:                     episode reward: 14.3000
second_0:                     episode reward: -14.3000
Process ID: 1, episode: 80/10000 (0.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 499.1619s / 1748.5696 s
first_0:                     episode reward: 9.5500
second_0:                     episode reward: -9.5500
Process ID: 1, episode: 100/10000 (1.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 508.5914s / 2257.1610 s
first_0:                     episode reward: 11.7000
second_0:                     episode reward: -11.7000
Process ID: 1, episode: 120/10000 (1.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.2764s / 2764.4374 s
first_0:                     episode reward: 12.8500
second_0:                     episode reward: -12.8500
Process ID: 1, episode: 140/10000 (1.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 511.3190s / 3275.7564 s
first_0:                     episode reward: 7.2500
second_0:                     episode reward: -7.2500
Process ID: 1, episode: 160/10000 (1.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.1069s / 3782.8633 s
first_0:                     episode reward: 10.9500
second_0:                     episode reward: -10.9500
Process ID: 1, episode: 180/10000 (1.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.4655s / 4292.3288 s
first_0:                     episode reward: 10.3000
second_0:                     episode reward: -10.3000
Process ID: 1, episode: 200/10000 (2.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.8650s / 4802.1938 s
first_0:                     episode reward: 10.8500
second_0:                     episode reward: -10.8500
Process ID: 1, episode: 220/10000 (2.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.9366s / 5312.1304 s
first_0:                     episode reward: 8.2500
second_0:                     episode reward: -8.2500
Process ID: 1, episode: 240/10000 (2.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 503.1638s / 5815.2942 s
first_0:                     episode reward: 10.8000
second_0:                     episode reward: -10.8000
Process ID: 1, episode: 260/10000 (2.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 504.9999s / 6320.2941 s
first_0:                     episode reward: 10.2000
second_0:                     episode reward: -10.2000
Process ID: 1, episode: 280/10000 (2.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 503.9273s / 6824.2214 s
first_0:                     episode reward: 17.2000
second_0:                     episode reward: -17.2000
Process ID: 1, episode: 300/10000 (3.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 505.8898s / 7330.1112 s
first_0:                     episode reward: 12.0500
second_0:                     episode reward: -12.0500
Process ID: 1, episode: 320/10000 (3.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.0109s / 7839.1221 s
first_0:                     episode reward: 7.2500
second_0:                     episode reward: -7.2500
Process ID: 1, episode: 340/10000 (3.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 506.4567s / 8345.5788 s
first_0:                     episode reward: 11.4000
second_0:                     episode reward: -11.4000
Process ID: 1, episode: 360/10000 (3.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.7185s / 8855.2974 s
first_0:                     episode reward: 12.7500
second_0:                     episode reward: -12.7500
Process ID: 1, episode: 380/10000 (3.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 513.1738s / 9368.4712 s
first_0:                     episode reward: 9.8500
second_0:                     episode reward: -9.8500
Process ID: 1, episode: 400/10000 (4.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 514.6502s / 9883.1214 s
first_0:                     episode reward: 8.9000
second_0:                     episode reward: -8.9000
Process ID: 1, episode: 420/10000 (4.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 515.4994s / 10398.6208 s
first_0:                     episode reward: 6.6500
second_0:                     episode reward: -6.6500
Process ID: 1, episode: 440/10000 (4.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 511.7474s / 10910.3682 s
first_0:                     episode reward: 10.9000
second_0:                     episode reward: -10.9000
Process ID: 1, episode: 460/10000 (4.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 508.5820s / 11418.9502 s
first_0:                     episode reward: 8.2500
second_0:                     episode reward: -8.2500
Process ID: 1, episode: 480/10000 (4.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 514.1161s / 11933.0663 s
first_0:                     episode reward: 13.3500
second_0:                     episode reward: -7.0000
Process ID: 0, episode: 500/10000 (5.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 508.0585s / 12419.0034 s
first_0:                     episode reward: 10.2000
second_0:                     episode reward: -10.2000
Process ID: 0, episode: 520/10000 (5.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.2527s / 12928.2561 s
first_0:                     episode reward: 7.8000
second_0:                     episode reward: -7.8000
Process ID: 0, episode: 540/10000 (5.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.6957s / 13435.9518 s
first_0:                     episode reward: 9.8000
second_0:                     episode reward: -9.8000
Process ID: 0, episode: 560/10000 (5.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.9024s / 13945.8542 s
first_0:                     episode reward: 14.0500
second_0:                     episode reward: -14.0500
Process ID: 0, episode: 580/10000 (5.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.6600s / 14455.5142 s
first_0:                     episode reward: 7.2500
second_0:                     episode reward: -7.2500
Process ID: 0, episode: 600/10000 (6.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 513.2445s / 14968.7587 s
first_0:                     episode reward: 15.2500
second_0:                     episode reward: -15.2500
Process ID: 0, episode: 620/10000 (6.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 514.9521s / 15483.7108 s
first_0:                     episode reward: 5.8000
second_0:                     episode reward: -5.8000
Process ID: 0, episode: 640/10000 (6.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 512.6588s / 15996.3696 s
first_0:                     episode reward: 9.9500
second_0:                     episode reward: -9.9500
Process ID: 0, episode: 660/10000 (6.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.8619s / 16506.2316 s
first_0:                     episode reward: 6.7000
second_0:                     episode reward: -6.7000
Process ID: 0, episode: 680/10000 (6.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.3838s / 17015.6154 s
first_0:                     episode reward: 10.9000
second_0:                     episode reward: -10.9000
Process ID: 0, episode: 700/10000 (7.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 510.1447s / 17525.7601 s
first_0:                     episode reward: 10.5500
second_0:                     episode reward: -10.5500
Process ID: 0, episode: 720/10000 (7.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.8124s / 18035.5725 s
first_0:                     episode reward: 12.3000
second_0:                     episode reward: -12.3000
Process ID: 0, episode: 740/10000 (7.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 513.6411s / 18549.2137 s
first_0:                     episode reward: 3.6500
second_0:                     episode reward: -3.6500
Process ID: 0, episode: 760/10000 (7.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 511.1200s / 19060.3337 s
first_0:                     episode reward: 7.6000
second_0:                     episode reward: -7.6000
Process ID: 0, episode: 780/10000 (7.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.7712s / 19568.1049 s
first_0:                     episode reward: 12.8000
second_0:                     episode reward: -12.8000
Process ID: 0, episode: 800/10000 (8.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 511.2971s / 20079.4020 s
first_0:                     episode reward: 8.8500
second_0:                     episode reward: -8.8500
Process ID: 0, episode: 820/10000 (8.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 514.6619s / 20594.0639 s
first_0:                     episode reward: 11.6000
second_0:                     episode reward: -11.6000
Process ID: 0, episode: 840/10000 (8.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 511.2421s / 21105.3060 s
first_0:                     episode reward: 7.1500
second_0:                     episode reward: -7.1500
Process ID: 0, episode: 860/10000 (8.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 510.3842s / 21615.6902 s
first_0:                     episode reward: 8.9500
second_0:                     episode reward: -8.9500
Process ID: 0, episode: 880/10000 (8.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.8790s / 22125.5692 s
first_0:                     episode reward: 9.2000
second_0:                     episode reward: -9.2000
Process ID: 0, episode: 900/10000 (9.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 510.9378s / 22636.5070 s
first_0:                     episode reward: 8.5500
second_0:                     episode reward: -8.5500
Process ID: 0, episode: 920/10000 (9.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 510.5339s / 23147.0409 s
first_0:                     episode reward: 14.4000
second_0:                     episode reward: -14.4000
Process ID: 0, episode: 940/10000 (9.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.2785s / 23654.3194 s
first_0:                     episode reward: 8.1000
second_0:                     episode reward: -8.1000
Process ID: 0, episode: 960/10000 (9.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 511.1627s / 24165.4821 s
first_0:                     episode reward: 11.9500
second_0:                     episode reward: -11.9500
Process ID: 0, episode: 980/10000 (9.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 510.3609s / 24675.8430 s
first_0:                     episode reward: 14.4500
second_0:                     episode reward: -14.4500
Process ID: 0, episode: 1000/10000 (10.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 513.7923s / 25189.6353 s
first_0:                     episode reward: 7.3000
second_0:                     episode reward: -7.3000
Process ID: 0, episode: 1020/10000 (10.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 511.8382s / 25701.4735 s
first_0:                     episode reward: 9.6000
second_0:                     episode reward: -9.6000
Process ID: 0, episode: 1040/10000 (10.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.2205s / 26210.6940 s
first_0:                     episode reward: 5.5500
second_0:                     episode reward: -5.5500
Process ID: 0, episode: 1060/10000 (10.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.0761s / 26719.7701 s
first_0:                     episode reward: 11.1000
second_0:                     episode reward: -11.1000
second_0:                     episode reward: -13.3500
Process ID: 1, episode: 500/10000 (5.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 510.5537s / 12443.6199 s
first_0:                     episode reward: 9.7500
second_0:                     episode reward: -9.7500
Process ID: 1, episode: 520/10000 (5.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.5793s / 12951.1992 s
first_0:                     episode reward: 10.8000
second_0:                     episode reward: -10.8000
Process ID: 1, episode: 540/10000 (5.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 512.0233s / 13463.2226 s
first_0:                     episode reward: 11.6000
second_0:                     episode reward: -11.6000
Process ID: 1, episode: 560/10000 (5.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 515.6531s / 13978.8757 s
first_0:                     episode reward: 14.0500
second_0:                     episode reward: -14.0500
Process ID: 1, episode: 580/10000 (5.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 511.2734s / 14490.1491 s
first_0:                     episode reward: 13.7500
second_0:                     episode reward: -13.7500
Process ID: 1, episode: 600/10000 (6.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 508.7725s / 14998.9216 s
first_0:                     episode reward: 12.7000
second_0:                     episode reward: -12.7000
Process ID: 1, episode: 620/10000 (6.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.3128s / 15506.2344 s
first_0:                     episode reward: 10.1000
second_0:                     episode reward: -10.1000
Process ID: 1, episode: 640/10000 (6.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 515.4444s / 16021.6788 s
first_0:                     episode reward: 10.1500
second_0:                     episode reward: -10.1500
Process ID: 1, episode: 660/10000 (6.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 508.6820s / 16530.3607 s
first_0:                     episode reward: 8.4000
second_0:                     episode reward: -8.4000
Process ID: 1, episode: 680/10000 (6.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.0628s / 17039.4235 s
first_0:                     episode reward: 8.9000
second_0:                     episode reward: -8.9000
Process ID: 1, episode: 700/10000 (7.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 506.9727s / 17546.3962 s
first_0:                     episode reward: 8.4000
second_0:                     episode reward: -8.4000
Process ID: 1, episode: 720/10000 (7.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.5994s / 18053.9955 s
first_0:                     episode reward: 11.8500
second_0:                     episode reward: -11.8500
Process ID: 1, episode: 740/10000 (7.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 510.9819s / 18564.9774 s
first_0:                     episode reward: 9.3000
second_0:                     episode reward: -9.3000
Process ID: 1, episode: 760/10000 (7.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 510.4078s / 19075.3853 s
first_0:                     episode reward: 11.2500
second_0:                     episode reward: -11.2500
Process ID: 1, episode: 780/10000 (7.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 503.8802s / 19579.2655 s
first_0:                     episode reward: 11.9000
second_0:                     episode reward: -11.9000
Process ID: 1, episode: 800/10000 (8.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 513.2187s / 20092.4842 s
first_0:                     episode reward: 10.8500
second_0:                     episode reward: -10.8500
Process ID: 1, episode: 820/10000 (8.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 511.7736s / 20604.2578 s
first_0:                     episode reward: 16.8500
second_0:                     episode reward: -16.8500
Process ID: 1, episode: 840/10000 (8.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 510.7817s / 21115.0395 s
first_0:                     episode reward: 8.7500
second_0:                     episode reward: -8.7500
Process ID: 1, episode: 860/10000 (8.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.5141s / 21622.5535 s
first_0:                     episode reward: 16.6500
second_0:                     episode reward: -16.6500
Process ID: 1, episode: 880/10000 (8.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 513.3576s / 22135.9111 s
first_0:                     episode reward: 12.4500
second_0:                     episode reward: -12.4500
Process ID: 1, episode: 900/10000 (9.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 505.7180s / 22641.6292 s
first_0:                     episode reward: 9.1000
second_0:                     episode reward: -9.1000
Process ID: 1, episode: 920/10000 (9.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 512.4625s / 23154.0916 s
first_0:                     episode reward: 8.6500
second_0:                     episode reward: -8.6500
Process ID: 1, episode: 940/10000 (9.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.8218s / 23661.9134 s
first_0:                     episode reward: 13.3000
second_0:                     episode reward: -13.3000
Process ID: 1, episode: 960/10000 (9.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 513.6743s / 24175.5877 s
first_0:                     episode reward: 5.0500
second_0:                     episode reward: -5.0500
Process ID: 1, episode: 980/10000 (9.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.3955s / 24682.9832 s
first_0:                     episode reward: 11.4000
second_0:                     episode reward: -11.4000
Process ID: 1, episode: 1000/10000 (10.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 506.1187s / 25189.1019 s
first_0:                     episode reward: 9.0500
second_0:                     episode reward: -9.0500
Process ID: 1, episode: 1020/10000 (10.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.9992s / 25699.1011 s
first_0:                     episode reward: 11.2000
second_0:                     episode reward: -11.2000
Process ID: 1, episode: 1040/10000 (10.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 510.1652s / 26209.2663 s
first_0:                     episode reward: 12.8000
second_0:                     episode reward: -12.8000
Process ID: 1, episode: 1060/10000 (10.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 510.8343s / 26720.1006 s
first_0:                     episode reward: 10.4500
second_0:                     episode reward: -10.4500