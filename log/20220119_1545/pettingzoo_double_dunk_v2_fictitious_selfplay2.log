pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
double_dunk_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'double_dunk_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 50, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
Save models to : /home/zihan/research/MARS/data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 235.9537s / 235.9537 s
env0_first_0:                 episode reward: 331.0000,                 loss: 0.0162
env0_second_0:                 episode reward: -331.0000,                 loss: nan
env1_first_0:                 episode reward: 331.0000,                 loss: nan
env1_second_0:                 episode reward: -331.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 5288.0908s / 5524.0445 s
env0_first_0:                 episode reward: 327.2000,                 loss: 0.0165
env0_second_0:                 episode reward: -327.2000,                 loss: nan
env1_first_0:                 episode reward: 327.9500,                 loss: nan
env1_second_0:                 episode reward: -327.9500,                 loss: nan
Score delta: 654.0, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/21_0.
Episode: 41/10000 (0.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 5307.8560s / 10831.9005 s
env0_first_0:                 episode reward: -327.3000,                 loss: nan
env0_second_0:                 episode reward: 327.3000,                 loss: 1.0219
env1_first_0:                 episode reward: -327.5500,                 loss: nan
env1_second_0:                 episode reward: 327.5500,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 5318.6759s / 16150.5764 s
env0_first_0:                 episode reward: 165.5500,                 loss: 0.0147
env0_second_0:                 episode reward: -165.5500,                 loss: 2.3365
env1_first_0:                 episode reward: 180.4500,                 loss: nan
env1_second_0:                 episode reward: -180.4500,                 loss: nan
Score delta: 654.4, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/42_1.
Episode: 81/10000 (0.8100%),                 avg. length: 9628.2,                last time consumption/overall running time: 5122.0535s / 21272.6299 s
env0_first_0:                 episode reward: -165.3500,                 loss: 0.0145
env0_second_0:                 episode reward: 165.3500,                 loss: 21.6797
env1_first_0:                 episode reward: -166.7500,                 loss: nan
env1_second_0:                 episode reward: 166.7500,                 loss: nan
Score delta: 474.4, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/63_0.
Episode: 101/10000 (1.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 5319.3777s / 26592.0076 s
env0_first_0:                 episode reward: 120.5000,                 loss: 0.0114
env0_second_0:                 episode reward: -120.5000,                 loss: 9.3386
env1_first_0:                 episode reward: 118.7000,                 loss: nan
env1_second_0:                 episode reward: -118.7000,                 loss: nan
Score delta: 473.6, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/84_1.
Episode: 121/10000 (1.2100%),                 avg. length: 9836.05,                last time consumption/overall running time: 5232.7456s / 31824.7532 s
env0_first_0:                 episode reward: -197.5500,                 loss: 0.0103
env0_second_0:                 episode reward: 197.5500,                 loss: 29.2553
env1_first_0:                 episode reward: -195.2000,                 loss: nan
env1_second_0:                 episode reward: 195.2000,                 loss: nan
Score delta: 294.2, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/105_0.
Episode: 141/10000 (1.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 5318.7972s / 37143.5505 s
env0_first_0:                 episode reward: 119.4500,                 loss: 0.0151
env0_second_0:                 episode reward: -119.4500,                 loss: 8.3165
env1_first_0:                 episode reward: 112.5500,                 loss: nan
env1_second_0:                 episode reward: -112.5500,                 loss: nan
Score delta: 639.6, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/126_1.
Episode: 161/10000 (1.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 5317.0279s / 42460.5783 s
env0_first_0:                 episode reward: -113.8500,                 loss: 0.0114
env0_second_0:                 episode reward: 113.8500,                 loss: 3.3702
env1_first_0:                 episode reward: -98.5000,                 loss: nan
env1_second_0:                 episode reward: 98.5000,                 loss: nan
Score delta: 495.2, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/147_0.
Episode: 181/10000 (1.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 5316.8537s / 47777.4320 s
env0_first_0:                 episode reward: 22.5500,                 loss: 0.0128
env0_second_0:                 episode reward: -22.5500,                 loss: 1.0100
env1_first_0:                 episode reward: 66.2500,                 loss: nan
env1_second_0:                 episode reward: -66.2500,                 loss: nan
Score delta: 604.8, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/168_1.
Episode: 201/10000 (2.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 5318.9550s / 53096.3870 s
env0_first_0:                 episode reward: -57.2500,                 loss: 0.0148
env0_second_0:                 episode reward: 57.2500,                 loss: 26.8764
env1_first_0:                 episode reward: -57.8500,                 loss: nan
env1_second_0:                 episode reward: 57.8500,                 loss: nan
Score delta: 564.0, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/189_0.
Episode: 221/10000 (2.2100%),                 avg. length: 9782.55,                last time consumption/overall running time: 5208.3623s / 58304.7493 s
env0_first_0:                 episode reward: 11.0000,                 loss: 0.0130
env0_second_0:                 episode reward: -11.0000,                 loss: 3.5526
env1_first_0:                 episode reward: 8.7000,                 loss: nan
env1_second_0:                 episode reward: -8.7000,                 loss: nan
Score delta: 642.0, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/210_1.
Episode: 241/10000 (2.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 5315.8497s / 63620.5989 s
env0_first_0:                 episode reward: -15.7000,                 loss: 0.0136
env0_second_0:                 episode reward: 15.7000,                 loss: 38.5071
env1_first_0:                 episode reward: -34.8000,                 loss: nan
env1_second_0:                 episode reward: 34.8000,                 loss: nan
Score delta: 548.8, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/231_0.
Episode: 261/10000 (2.6100%),                 avg. length: 9858.4,                last time consumption/overall running time: 5236.6904s / 68857.2893 s
env0_first_0:                 episode reward: -24.3000,                 loss: 0.0138
env0_second_0:                 episode reward: 24.3000,                 loss: 65.9997
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Score delta: 532.2, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/252_1.
Episode: 281/10000 (2.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 5311.7229s / 74169.0122 s
env0_first_0:                 episode reward: 46.3500,                 loss: 0.0148
env0_second_0:                 episode reward: -46.3500,                 loss: 34.2210
env1_first_0:                 episode reward: 46.6000,                 loss: nan
env1_second_0:                 episode reward: -46.6000,                 loss: nan
Score delta: 579.4, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/273_0.
Episode: 301/10000 (3.0100%),                 avg. length: 9798.3,                last time consumption/overall running time: 5203.5116s / 79372.5238 s
env0_first_0:                 episode reward: -109.5500,                 loss: 0.0121
env0_second_0:                 episode reward: 109.5500,                 loss: 2.0511
env1_first_0:                 episode reward: -113.1500,                 loss: nan
env1_second_0:                 episode reward: 113.1500,                 loss: nan
Score delta: 566.2, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/294_1.
Episode: 321/10000 (3.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 5306.6324s / 84679.1562 s
env0_first_0:                 episode reward: 97.7000,                 loss: 0.0142
env0_second_0:                 episode reward: -97.7000,                 loss: 1.1885
env1_first_0:                 episode reward: 70.1000,                 loss: nan
env1_second_0:                 episode reward: -70.1000,                 loss: nan
Score delta: 503.8, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/315_0.
Episode: 341/10000 (3.4100%),                 avg. length: 9996.5,                last time consumption/overall running time: 5306.6217s / 89985.7780 s
env0_first_0:                 episode reward: -142.7500,                 loss: 0.0162
env0_second_0:                 episode reward: 142.7500,                 loss: 2.0414
env1_first_0:                 episode reward: -125.6000,                 loss: nan
env1_second_0:                 episode reward: 125.6000,                 loss: nan
Score delta: 606.2, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/336_1.
Episode: 361/10000 (3.6100%),                 avg. length: 9729.6,                last time consumption/overall running time: 5168.3236s / 95154.1016 s
env0_first_0:                 episode reward: 212.5500,                 loss: 0.0145
env0_second_0:                 episode reward: -212.5500,                 loss: 94.8359
env1_first_0:                 episode reward: 181.3000,                 loss: nan
env1_second_0:                 episode reward: -181.3000,                 loss: nan
Score delta: 579.0, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/357_0.
Episode: 381/10000 (3.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 5309.4543s / 100463.5559 s
env0_first_0:                 episode reward: -218.5500,                 loss: 0.0126
env0_second_0:                 episode reward: 218.5500,                 loss: 20.7419
env1_first_0:                 episode reward: -202.0500,                 loss: nan
env1_second_0:                 episode reward: 202.0500,                 loss: nan
Score delta: 607.6, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/378_1.
Episode: 401/10000 (4.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 5308.0146s / 105771.5704 s
env0_first_0:                 episode reward: 219.0500,                 loss: 0.0142
env0_second_0:                 episode reward: -219.0500,                 loss: 32.9957
env1_first_0:                 episode reward: 201.2000,                 loss: nan
env1_second_0:                 episode reward: -201.2000,                 loss: nan
Score delta: 553.8, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/399_0.
Episode: 421/10000 (4.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 5047.6533s / 110819.2238 s
env0_first_0:                 episode reward: -276.3000,                 loss: 0.0147
env0_second_0:                 episode reward: 276.3000,                 loss: 7.8964
env1_first_0:                 episode reward: -267.5000,                 loss: nan
env1_second_0:                 episode reward: 267.5000,                 loss: nan
Score delta: 593.6, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/420_1.
Episode: 441/10000 (4.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4840.4485s / 115659.6723 s
env0_first_0:                 episode reward: 305.5000,                 loss: 0.0160
env0_second_0:                 episode reward: -305.5000,                 loss: nan
env1_first_0:                 episode reward: 307.7000,                 loss: nan
env1_second_0:                 episode reward: -307.7000,                 loss: nan
Score delta: 578.2, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/441_0.
Episode: 461/10000 (4.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4653.6973s / 120313.3697 s
env0_first_0:                 episode reward: -321.4500,                 loss: nan
env0_second_0:                 episode reward: 321.4500,                 loss: 4.3487
env1_first_0:                 episode reward: -313.2500,                 loss: nan
env1_second_0:                 episode reward: 313.2500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4512.4097s / 124825.7794 s
env0_first_0:                 episode reward: 216.3500,                 loss: 0.0139
env0_second_0:                 episode reward: -216.3500,                 loss: 3.3405
env1_first_0:                 episode reward: 229.4000,                 loss: nan
env1_second_0:                 episode reward: -229.4000,                 loss: nan
Score delta: 639.4, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/462_1.
Episode: 501/10000 (5.0100%),                 avg. length: 9916.1,                last time consumption/overall running time: 4295.6736s / 129121.4529 s
env0_first_0:                 episode reward: -231.8500,                 loss: 0.0146
env0_second_0:                 episode reward: 231.8500,                 loss: 9.7494
env1_first_0:                 episode reward: -229.2500,                 loss: nan
env1_second_0:                 episode reward: 229.2500,                 loss: nan
Score delta: 476.2, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/483_0.
Episode: 521/10000 (5.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4331.0083s / 133452.4612 s
env0_first_0:                 episode reward: 199.9500,                 loss: 0.0151
env0_second_0:                 episode reward: -199.9500,                 loss: 31.1485
env1_first_0:                 episode reward: 198.3500,                 loss: nan
env1_second_0:                 episode reward: -198.3500,                 loss: nan
Score delta: 487.6, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/504_1.
Episode: 541/10000 (5.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4330.7293s / 137783.1905 s
env0_first_0:                 episode reward: -205.0000,                 loss: 0.0164
env0_second_0:                 episode reward: 205.0000,                 loss: 0.1516
env1_first_0:                 episode reward: -208.3500,                 loss: nan
env1_second_0:                 episode reward: 208.3500,                 loss: nan
Score delta: 447.6, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/525_0.
Episode: 561/10000 (5.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4326.8072s / 142109.9977 s
env0_first_0:                 episode reward: 160.5500,                 loss: 0.0151
env0_second_0:                 episode reward: -160.5500,                 loss: 0.0591
env1_first_0:                 episode reward: 148.3500,                 loss: nan
env1_second_0:                 episode reward: -148.3500,                 loss: nan
Score delta: 625.4, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/546_1.
Episode: 581/10000 (5.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4324.9341s / 146434.9319 s
env0_first_0:                 episode reward: -133.6000,                 loss: 0.0160
env0_second_0:                 episode reward: 133.6000,                 loss: 30.3082
env1_first_0:                 episode reward: -128.8500,                 loss: nan
env1_second_0:                 episode reward: 128.8500,                 loss: nan
Score delta: 617.8, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/567_0.
Episode: 601/10000 (6.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4324.2454s / 150759.1773 s
env0_first_0:                 episode reward: 92.6000,                 loss: 0.0163
env0_second_0:                 episode reward: -92.6000,                 loss: 88.7827
env1_first_0:                 episode reward: 91.5500,                 loss: nan
env1_second_0:                 episode reward: -91.5500,                 loss: nan
Score delta: 617.8, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/588_1.
Episode: 621/10000 (6.2100%),                 avg. length: 9721.75,                last time consumption/overall running time: 4197.7682s / 154956.9455 s
env0_first_0:                 episode reward: -65.5000,                 loss: 0.0141
env0_second_0:                 episode reward: 65.5000,                 loss: 109.2188
env1_first_0:                 episode reward: -79.0500,                 loss: nan
env1_second_0:                 episode reward: 79.0500,                 loss: nan
Score delta: 567.6, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/609_0.
Episode: 641/10000 (6.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4307.9411s / 159264.8866 s
env0_first_0:                 episode reward: 21.8500,                 loss: 0.0155
env0_second_0:                 episode reward: -21.8500,                 loss: 90.9503
env1_first_0:                 episode reward: 24.1000,                 loss: nan
env1_second_0:                 episode reward: -24.1000,                 loss: nan
Score delta: 632.2, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/630_1.
Episode: 661/10000 (6.6100%),                 avg. length: 9961.65,                last time consumption/overall running time: 4282.9202s / 163547.8068 s
env0_first_0:                 episode reward: -52.8000,                 loss: 0.0120
env0_second_0:                 episode reward: 52.8000,                 loss: 0.0780
env1_first_0:                 episode reward: -32.6000,                 loss: nan
env1_second_0:                 episode reward: 32.6000,                 loss: nan
Score delta: 410.6, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/651_0.
Episode: 681/10000 (6.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4288.4050s / 167836.2118 s
env0_first_0:                 episode reward: -32.2000,                 loss: 0.0146
env0_second_0:                 episode reward: 32.2000,                 loss: 0.0280
env1_first_0:                 episode reward: -74.6000,                 loss: nan
env1_second_0:                 episode reward: 74.6000,                 loss: nan
Score delta: 623.2, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/672_1.
Episode: 701/10000 (7.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4290.2263s / 172126.4381 s
env0_first_0:                 episode reward: 57.7500,                 loss: 0.0150
env0_second_0:                 episode reward: -57.7500,                 loss: 13.3734
env1_first_0:                 episode reward: 41.6500,                 loss: nan
env1_second_0:                 episode reward: -41.6500,                 loss: nan
Score delta: 614.6, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/693_0.
Episode: 721/10000 (7.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4289.3329s / 176415.7711 s
env0_first_0:                 episode reward: -95.7000,                 loss: 0.0151
env0_second_0:                 episode reward: 95.7000,                 loss: 40.5406
env1_first_0:                 episode reward: -89.0000,                 loss: nan
env1_second_0:                 episode reward: 89.0000,                 loss: nan
Score delta: 633.4, save the model to .//data/model/20220119_1545/pettingzoo_double_dunk_v2_fictitious_selfplay2/714_1.
Episode: 741/10000 (7.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4046.6383s / 180462.4093 s
env0_first_0:                 episode reward: 88.1000,                 loss: 0.0149
env0_second_0:                 episode reward: -88.1000,                 loss: 73.5824