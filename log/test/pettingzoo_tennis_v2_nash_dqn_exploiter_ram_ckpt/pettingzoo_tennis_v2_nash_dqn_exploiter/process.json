{"episode_reward": {"env0_first_0": [3.0], "env0_second_0": [-3.0], "env1_first_0": [-4.0], "env1_second_0": [4.0]}, "loss": {"env0_first_0": [0.018385374681884517], "env0_second_0": [0.018111922636710603], "env1_first_0": [NaN], "env1_second_0": [NaN]}, "episode_length": [9999]}