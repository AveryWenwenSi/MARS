{"episode_reward": {"env0_first_0": [-8.0], "env0_second_0": [8.0], "env1_first_0": [-4.0], "env1_second_0": [4.0]}, "loss": {"env0_first_0": [0.012412042752805783], "env0_second_0": [0.011714474913132171], "env1_first_0": [NaN], "env1_second_0": [NaN]}, "episode_length": [1784]}