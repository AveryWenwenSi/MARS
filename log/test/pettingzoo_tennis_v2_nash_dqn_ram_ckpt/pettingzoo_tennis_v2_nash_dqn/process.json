{"episode_reward": {"env0_first_0": [-8.0], "env0_second_0": [8.0], "env1_first_0": [4.0], "env1_second_0": [-4.0]}, "loss": {"env0_first_0": [0.018610015395155992], "env0_second_0": [0.018934737281564397], "env1_first_0": [NaN], "env1_second_0": [NaN]}, "episode_length": [9999]}