pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 30, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
Save models to : /home/zihan/research/MARS/data/model/20220119_0526/pettingzoo_pong_v2_nxdo2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0526/pettingzoo_pong_v2_nxdo2.
pong_v2 pettingzoo
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
random seed: 11
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Episode: 1/10000 (0.0100%),                 avg. length: 1226.0,                last time consumption/overall running time: 27.2510s / 27.2510 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.0103
env0_second_0:                 episode reward: 13.0000,                 loss: nan
env1_first_0:                 episode reward: 9.0000,                 loss: nan
env1_second_0:                 episode reward: -9.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 979.25,                last time consumption/overall running time: 406.2569s / 433.5079 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.0021
env0_second_0:                 episode reward: -3.1500,                 loss: nan
env1_first_0:                 episode reward: 4.2500,                 loss: nan
env1_second_0:                 episode reward: -4.2500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 897.1,                last time consumption/overall running time: 380.6903s / 814.1982 s
env0_first_0:                 episode reward: 12.3500,                 loss: 0.0017
env0_second_0:                 episode reward: -12.3500,                 loss: 0.0051
env1_first_0:                 episode reward: 14.0500,                 loss: nan
env1_second_0:                 episode reward: -14.0500,                 loss: nan
Score delta: 33.8, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/33_0.
Episode: 61/10000 (0.6100%),                 avg. length: 1120.1,                last time consumption/overall running time: 484.1044s / 1298.3026 s
env0_first_0:                 episode reward: 8.8000,                 loss: nan
env0_second_0:                 episode reward: -8.8000,                 loss: 0.0030
env1_first_0:                 episode reward: 6.7000,                 loss: nan
env1_second_0:                 episode reward: -6.7000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1275.3,                last time consumption/overall running time: 575.2971s / 1873.5997 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.0022
env0_second_0:                 episode reward: 12.6500,                 loss: 0.0080
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Score delta: 32.0, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/79_1.
Episode: 101/10000 (1.0100%),                 avg. length: 1500.6,                last time consumption/overall running time: 664.7181s / 2538.3178 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0073
env0_second_0:                 episode reward: 3.9500,                 loss: nan
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 1356.4,                last time consumption/overall running time: 600.9813s / 3139.2991 s
env0_first_0:                 episode reward: 11.9000,                 loss: 0.0123
env0_second_0:                 episode reward: -11.9000,                 loss: nan
env1_first_0:                 episode reward: 11.2000,                 loss: nan
env1_second_0:                 episode reward: -11.2000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 1228.6,                last time consumption/overall running time: 544.7404s / 3684.0395 s
env0_first_0:                 episode reward: 12.5000,                 loss: 0.0124
env0_second_0:                 episode reward: -12.5000,                 loss: nan
env1_first_0:                 episode reward: 14.8500,                 loss: nan
env1_second_0:                 episode reward: -14.8500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 1456.35,                last time consumption/overall running time: 676.4317s / 4360.4713 s
env0_first_0:                 episode reward: 4.4000,                 loss: 0.0106
env0_second_0:                 episode reward: -4.4000,                 loss: 0.0122
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
Score delta: 30.4, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/151_0.
Episode: 181/10000 (1.8100%),                 avg. length: 1435.15,                last time consumption/overall running time: 1043.8039s / 5404.2751 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.0114
env0_second_0:                 episode reward: 10.2000,                 loss: 0.0109
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Score delta: 33.0, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/180_1.
Episode: 201/10000 (2.0100%),                 avg. length: 1227.95,                last time consumption/overall running time: 607.4188s / 6011.6939 s
env0_first_0:                 episode reward: 15.4000,                 loss: 0.0118
env0_second_0:                 episode reward: -15.4000,                 loss: nan
env1_first_0:                 episode reward: 12.2000,                 loss: nan
env1_second_0:                 episode reward: -12.2000,                 loss: nan
Score delta: 35.0, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/201_0.
Episode: 221/10000 (2.2100%),                 avg. length: 1609.6,                last time consumption/overall running time: 713.6818s / 6725.3757 s
env0_first_0:                 episode reward: -11.4000,                 loss: nan
env0_second_0:                 episode reward: 11.4000,                 loss: 0.0142
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 1276.9,                last time consumption/overall running time: 985.4990s / 7710.8746 s
env0_first_0:                 episode reward: 11.9500,                 loss: 0.0115
env0_second_0:                 episode reward: -11.9500,                 loss: 0.0104
env1_first_0:                 episode reward: 12.1000,                 loss: nan
env1_second_0:                 episode reward: -12.1000,                 loss: nan
Score delta: 30.4, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/223_1.
Episode: 261/10000 (2.6100%),                 avg. length: 1354.0,                last time consumption/overall running time: 735.7017s / 8446.5763 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0091
env0_second_0:                 episode reward: 2.4500,                 loss: 0.0135
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Score delta: 33.0, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/247_0.
Episode: 281/10000 (2.8100%),                 avg. length: 1221.3,                last time consumption/overall running time: 846.7326s / 9293.3090 s
env0_first_0:                 episode reward: -6.8500,                 loss: 0.0120
env0_second_0:                 episode reward: 6.8500,                 loss: 0.0105
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
Score delta: 32.2, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/274_1.
Episode: 301/10000 (3.0100%),                 avg. length: 1381.85,                last time consumption/overall running time: 928.6870s / 10221.9960 s
env0_first_0:                 episode reward: 10.4500,                 loss: 0.0098
env0_second_0:                 episode reward: -10.4500,                 loss: 0.0133
env1_first_0:                 episode reward: 10.8500,                 loss: nan
env1_second_0:                 episode reward: -10.8500,                 loss: nan
Score delta: 33.2, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/295_0.
Episode: 321/10000 (3.2100%),                 avg. length: 1322.95,                last time consumption/overall running time: 587.8095s / 10809.8055 s
env0_first_0:                 episode reward: -12.3500,                 loss: nan
env0_second_0:                 episode reward: 12.3500,                 loss: 0.0108
env1_first_0:                 episode reward: -16.4500,                 loss: nan
env1_second_0:                 episode reward: 16.4500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 1325.75,                last time consumption/overall running time: 1047.2182s / 11857.0237 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0063
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0070
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Score delta: 31.8, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/327_1.
Episode: 361/10000 (3.6100%),                 avg. length: 1914.4,                last time consumption/overall running time: 845.3460s / 12702.3697 s
env0_first_0:                 episode reward: 9.2000,                 loss: 0.0090
env0_second_0:                 episode reward: -9.2000,                 loss: nan
env1_first_0:                 episode reward: 10.2500,                 loss: nan
env1_second_0:                 episode reward: -10.2500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 1665.75,                last time consumption/overall running time: 1294.9512s / 13997.3209 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0102
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0065
env1_first_0:                 episode reward: -4.9000,                 loss: nan
env1_second_0:                 episode reward: 4.9000,                 loss: nan
Score delta: 35.2, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/368_0.
Episode: 401/10000 (4.0100%),                 avg. length: 2790.1,                last time consumption/overall running time: 1505.0293s / 15502.3502 s
env0_first_0:                 episode reward: 20.2000,                 loss: 0.0096
env0_second_0:                 episode reward: -20.2000,                 loss: 0.0066
env1_first_0:                 episode reward: 13.0500,                 loss: nan
env1_second_0:                 episode reward: -13.0500,                 loss: nan
Score delta: 32.4, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/389_1.
Episode: 421/10000 (4.2100%),                 avg. length: 2591.5,                last time consumption/overall running time: 1677.9460s / 17180.2962 s
env0_first_0:                 episode reward: 28.9500,                 loss: 0.0121
env0_second_0:                 episode reward: -28.9500,                 loss: 0.0071
env1_first_0:                 episode reward: 30.4000,                 loss: nan
env1_second_0:                 episode reward: -30.4000,                 loss: nan
Score delta: 194.8, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/410_0.
Episode: 441/10000 (4.4100%),                 avg. length: 1598.0,                last time consumption/overall running time: 1926.5178s / 19106.8140 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.0125
env0_second_0:                 episode reward: 7.3500,                 loss: 0.0064
env1_first_0:                 episode reward: -6.5500,                 loss: nan
env1_second_0:                 episode reward: 6.5500,                 loss: nan
Score delta: 43.2, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/431_1.
Episode: 461/10000 (4.6100%),                 avg. length: 2259.85,                last time consumption/overall running time: 1640.3076s / 20747.1216 s
env0_first_0:                 episode reward: 11.0000,                 loss: 0.0105
env0_second_0:                 episode reward: -11.0000,                 loss: 0.0128
env1_first_0:                 episode reward: 16.6000,                 loss: nan
env1_second_0:                 episode reward: -16.6000,                 loss: nan
Score delta: 32.6, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/456_0.
Episode: 481/10000 (4.8100%),                 avg. length: 2229.9,                last time consumption/overall running time: 981.2300s / 21728.3516 s
env0_first_0:                 episode reward: -6.8000,                 loss: nan
env0_second_0:                 episode reward: 6.8000,                 loss: 0.0095
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 1582.5,                last time consumption/overall running time: 2303.1501s / 24031.5017 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.0105
env0_second_0:                 episode reward: 10.0000,                 loss: 0.0061
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Score delta: 30.8, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/497_1.
Episode: 521/10000 (5.2100%),                 avg. length: 1550.5,                last time consumption/overall running time: 688.5910s / 24720.0927 s
env0_first_0:                 episode reward: 8.7500,                 loss: 0.0104
env0_second_0:                 episode reward: -8.7500,                 loss: nan
env1_first_0:                 episode reward: 9.8000,                 loss: nan
env1_second_0:                 episode reward: -9.8000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 1916.05,                last time consumption/overall running time: 2243.4018s / 26963.4945 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0095
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0130
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Score delta: 33.0, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/523_0.
Episode: 561/10000 (5.6100%),                 avg. length: 1413.95,                last time consumption/overall running time: 2422.0729s / 29385.5674 s
env0_first_0:                 episode reward: -5.5500,                 loss: 0.0141
env0_second_0:                 episode reward: 5.5500,                 loss: 0.0069
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
Score delta: 32.0, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/552_1.
Episode: 581/10000 (5.8100%),                 avg. length: 1669.95,                last time consumption/overall running time: 734.6511s / 30120.2186 s
env0_first_0:                 episode reward: 8.8500,                 loss: 0.0115
env0_second_0:                 episode reward: -8.8500,                 loss: nan
env1_first_0:                 episode reward: 7.5000,                 loss: nan
env1_second_0:                 episode reward: -7.5000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 2069.05,                last time consumption/overall running time: 1649.0117s / 31769.2303 s
env0_first_0:                 episode reward: 3.2500,                 loss: 0.0105
env0_second_0:                 episode reward: -3.2500,                 loss: 0.0138
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Score delta: 43.6, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/583_0.
Episode: 621/10000 (6.2100%),                 avg. length: 1517.0,                last time consumption/overall running time: 667.8868s / 32437.1171 s
env0_first_0:                 episode reward: -13.5500,                 loss: nan
env0_second_0:                 episode reward: 13.5500,                 loss: 0.0059
env1_first_0:                 episode reward: -15.0000,                 loss: nan
env1_second_0:                 episode reward: 15.0000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 2130.4,                last time consumption/overall running time: 2017.3151s / 34454.4322 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.0091
env0_second_0:                 episode reward: 8.4500,                 loss: 0.0062
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Score delta: 31.2, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/623_1.
Episode: 661/10000 (6.6100%),                 avg. length: 1870.3,                last time consumption/overall running time: 1744.5976s / 36199.0299 s
env0_first_0:                 episode reward: -5.6500,                 loss: 0.0087
env0_second_0:                 episode reward: 5.6500,                 loss: 0.0144
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Score delta: 33.0, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/652_0.
Episode: 681/10000 (6.8100%),                 avg. length: 1726.6,                last time consumption/overall running time: 3358.7170s / 39557.7469 s
env0_first_0:                 episode reward: -9.7000,                 loss: 0.0077
env0_second_0:                 episode reward: 9.7000,                 loss: 0.0116
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Score delta: 62.2, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/673_1.
Episode: 701/10000 (7.0100%),                 avg. length: 1439.25,                last time consumption/overall running time: 2666.8849s / 42224.6318 s
env0_first_0:                 episode reward: 7.6500,                 loss: 0.0077
env0_second_0:                 episode reward: -7.6500,                 loss: 0.0167
env1_first_0:                 episode reward: 9.7000,                 loss: nan
env1_second_0:                 episode reward: -9.7000,                 loss: nan
Score delta: 30.4, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/694_0.
Episode: 721/10000 (7.2100%),                 avg. length: 2243.8,                last time consumption/overall running time: 3505.4331s / 45730.0649 s
env0_first_0:                 episode reward: -16.7500,                 loss: 0.0071
env0_second_0:                 episode reward: 16.7500,                 loss: 0.0116
env1_first_0:                 episode reward: -22.5000,                 loss: nan
env1_second_0:                 episode reward: 22.5000,                 loss: nan
Score delta: 51.2, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/715_1.
Episode: 741/10000 (7.4100%),                 avg. length: 1185.75,                last time consumption/overall running time: 624.8377s / 46354.9026 s
env0_first_0:                 episode reward: 13.6000,                 loss: 0.0083
env0_second_0:                 episode reward: -13.6000,                 loss: nan
env1_first_0:                 episode reward: 11.6000,                 loss: nan
env1_second_0:                 episode reward: -11.6000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 1318.1,                last time consumption/overall running time: 1808.3422s / 48163.2448 s
env0_first_0:                 episode reward: 5.5000,                 loss: 0.0081
env0_second_0:                 episode reward: -5.5000,                 loss: 0.0173
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
Score delta: 31.0, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/751_0.
Episode: 781/10000 (7.8100%),                 avg. length: 1477.15,                last time consumption/overall running time: 3375.3350s / 51538.5798 s
env0_first_0:                 episode reward: -15.3000,                 loss: 0.0090
env0_second_0:                 episode reward: 15.3000,                 loss: 0.0128
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Score delta: 31.2, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/773_1.
Episode: 801/10000 (8.0100%),                 avg. length: 1345.95,                last time consumption/overall running time: 708.8312s / 52247.4110 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.0090
env0_second_0:                 episode reward: 6.3000,                 loss: nan
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 1541.9,                last time consumption/overall running time: 807.4194s / 53054.8303 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0096
env0_second_0:                 episode reward: 3.6500,                 loss: nan
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 2344.95,                last time consumption/overall running time: 1224.3307s / 54279.1611 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.0119
env0_second_0:                 episode reward: 5.2500,                 loss: nan
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 2228.25,                last time consumption/overall running time: 1166.2846s / 55445.4457 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.0095
env0_second_0:                 episode reward: -2.4000,                 loss: nan
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 2060.4,                last time consumption/overall running time: 1069.1466s / 56514.5923 s
env0_first_0:                 episode reward: 6.6500,                 loss: 0.0083
env0_second_0:                 episode reward: -6.6500,                 loss: nan
env1_first_0:                 episode reward: 5.4000,                 loss: nan
env1_second_0:                 episode reward: -5.4000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 2386.5,                last time consumption/overall running time: 1242.5633s / 57757.1556 s
env0_first_0:                 episode reward: 4.9000,                 loss: 0.0076
env0_second_0:                 episode reward: -4.9000,                 loss: nan
env1_first_0:                 episode reward: 5.3500,                 loss: nan
env1_second_0:                 episode reward: -5.3500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 1997.8,                last time consumption/overall running time: 1034.0870s / 58791.2426 s
env0_first_0:                 episode reward: 8.4000,                 loss: 0.0075
env0_second_0:                 episode reward: -8.4000,                 loss: nan
env1_first_0:                 episode reward: 7.8500,                 loss: nan
env1_second_0:                 episode reward: -7.8500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 1653.7,                last time consumption/overall running time: 853.0249s / 59644.2675 s
env0_first_0:                 episode reward: 12.5000,                 loss: 0.0073
env0_second_0:                 episode reward: -12.5000,                 loss: nan
env1_first_0:                 episode reward: 12.1500,                 loss: nan
env1_second_0:                 episode reward: -12.1500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 1377.9,                last time consumption/overall running time: 706.1594s / 60350.4269 s
env0_first_0:                 episode reward: 12.8500,                 loss: 0.0086
env0_second_0:                 episode reward: -12.8500,                 loss: nan
env1_first_0:                 episode reward: 12.6000,                 loss: nan
env1_second_0:                 episode reward: -12.6000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 1935.15,                last time consumption/overall running time: 1013.7462s / 61364.1731 s
env0_first_0:                 episode reward: 8.5000,                 loss: 0.0080
env0_second_0:                 episode reward: -8.5000,                 loss: nan
env1_first_0:                 episode reward: 9.3500,                 loss: nan
env1_second_0:                 episode reward: -9.3500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 2051.1,                last time consumption/overall running time: 1065.0720s / 62429.2450 s
env0_first_0:                 episode reward: 6.4500,                 loss: 0.0079
env0_second_0:                 episode reward: -6.4500,                 loss: nan
env1_first_0:                 episode reward: 5.7500,                 loss: nan
env1_second_0:                 episode reward: -5.7500,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 1788.75,                last time consumption/overall running time: 938.6669s / 63367.9119 s
env0_first_0:                 episode reward: 7.7500,                 loss: 0.0082
env0_second_0:                 episode reward: -7.7500,                 loss: nan
env1_first_0:                 episode reward: 8.3000,                 loss: nan
env1_second_0:                 episode reward: -8.3000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 1720.65,                last time consumption/overall running time: 2352.8374s / 65720.7493 s
env0_first_0:                 episode reward: 8.3500,                 loss: 0.0097
env0_second_0:                 episode reward: -8.3500,                 loss: 0.0155
env1_first_0:                 episode reward: 10.3000,                 loss: nan
env1_second_0:                 episode reward: -10.3000,                 loss: nan
Score delta: 31.0, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/1030_0.
Episode: 1061/10000 (10.6100%),                 avg. length: 3312.8,                last time consumption/overall running time: 2909.4070s / 68630.1563 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0109
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0095
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Score delta: 123.2, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/1051_1.
Episode: 1081/10000 (10.8100%),                 avg. length: 5889.2,                last time consumption/overall running time: 4123.5922s / 72753.7485 s
env0_first_0:                 episode reward: 60.0500,                 loss: 0.0138
env0_second_0:                 episode reward: -60.0500,                 loss: 0.0119
env1_first_0:                 episode reward: 53.4500,                 loss: nan
env1_second_0:                 episode reward: -53.4500,                 loss: nan
Score delta: 339.8, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/1072_0.
Episode: 1101/10000 (11.0100%),                 avg. length: 2300.2,                last time consumption/overall running time: 2479.5813s / 75233.3298 s
env0_first_0:                 episode reward: -22.8500,                 loss: 0.0138
env0_second_0:                 episode reward: 22.8500,                 loss: 0.0104
env1_first_0:                 episode reward: -23.1000,                 loss: nan
env1_second_0:                 episode reward: 23.1000,                 loss: nan
Score delta: 79.4, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/1093_1.
Episode: 1121/10000 (11.2100%),                 avg. length: 2358.05,                last time consumption/overall running time: 1241.9768s / 76475.3066 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 2268.95,                last time consumption/overall running time: 1186.8516s / 77662.1583 s
env0_first_0:                 episode reward: 4.1500,                 loss: 0.0081
env0_second_0:                 episode reward: -4.1500,                 loss: nan
env1_first_0:                 episode reward: 5.5000,                 loss: nan
env1_second_0:                 episode reward: -5.5000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 2590.2,                last time consumption/overall running time: 1352.2233s / 79014.3816 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0072
env0_second_0:                 episode reward: -0.9500,                 loss: nan
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 2127.6,                last time consumption/overall running time: 1110.0271s / 80124.4087 s
env0_first_0:                 episode reward: 8.7500,                 loss: 0.0086
env0_second_0:                 episode reward: -8.7500,                 loss: nan
env1_first_0:                 episode reward: 7.6000,                 loss: nan
env1_second_0:                 episode reward: -7.6000,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 1823.8,                last time consumption/overall running time: 956.6510s / 81081.0597 s
env0_first_0:                 episode reward: 9.6500,                 loss: 0.0104
env0_second_0:                 episode reward: -9.6500,                 loss: nan
env1_first_0:                 episode reward: 11.7000,                 loss: nan
env1_second_0:                 episode reward: -11.7000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 1757.15,                last time consumption/overall running time: 911.3685s / 81992.4282 s
env0_first_0:                 episode reward: 9.6500,                 loss: 0.0121
env0_second_0:                 episode reward: -9.6500,                 loss: nan
env1_first_0:                 episode reward: 10.5500,                 loss: nan
env1_second_0:                 episode reward: -10.5500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 2070.5,                last time consumption/overall running time: 1084.2265s / 83076.6546 s
env0_first_0:                 episode reward: 8.1500,                 loss: 0.0117
env0_second_0:                 episode reward: -8.1500,                 loss: nan
env1_first_0:                 episode reward: 12.1500,                 loss: nan
env1_second_0:                 episode reward: -12.1500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 1947.3,                last time consumption/overall running time: 1011.4783s / 84088.1330 s
env0_first_0:                 episode reward: 5.3000,                 loss: 0.0108
env0_second_0:                 episode reward: -5.3000,                 loss: nan
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 1913.45,                last time consumption/overall running time: 2462.7954s / 86550.9284 s
env0_first_0:                 episode reward: -27.4000,                 loss: 0.0108
env0_second_0:                 episode reward: 27.4000,                 loss: 0.0094
env1_first_0:                 episode reward: -21.8500,                 loss: nan
env1_second_0:                 episode reward: 21.8500,                 loss: nan
Score delta: 30.2, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/1264_0.
Episode: 1301/10000 (13.0100%),                 avg. length: 1830.95,                last time consumption/overall running time: 4585.8633s / 91136.7917 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.0056
env0_second_0:                 episode reward: 7.2500,                 loss: 0.0087
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Score delta: 35.6, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/1285_1.
Episode: 1321/10000 (13.2100%),                 avg. length: 2027.95,                last time consumption/overall running time: 1059.5225s / 92196.3142 s
env0_first_0:                 episode reward: 8.4500,                 loss: 0.0079
env0_second_0:                 episode reward: -8.4500,                 loss: nan
env1_first_0:                 episode reward: 5.6500,                 loss: nan
env1_second_0:                 episode reward: -5.6500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 2054.3,                last time consumption/overall running time: 1075.4299s / 93271.7441 s
env0_first_0:                 episode reward: 8.1000,                 loss: 0.0095
env0_second_0:                 episode reward: -8.1000,                 loss: nan
env1_first_0:                 episode reward: 7.8000,                 loss: nan
env1_second_0:                 episode reward: -7.8000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 1823.35,                last time consumption/overall running time: 965.4895s / 94237.2336 s
env0_first_0:                 episode reward: 11.4500,                 loss: 0.0071
env0_second_0:                 episode reward: -11.4500,                 loss: nan
env1_first_0:                 episode reward: 10.7500,                 loss: nan
env1_second_0:                 episode reward: -10.7500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 1679.55,                last time consumption/overall running time: 2477.2670s / 96714.5006 s
env0_first_0:                 episode reward: 6.1500,                 loss: 0.0064
env0_second_0:                 episode reward: -6.1500,                 loss: 0.0151
env1_first_0:                 episode reward: 5.4000,                 loss: nan
env1_second_0:                 episode reward: -5.4000,                 loss: nan
Score delta: 31.0, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/1367_0.
Episode: 1401/10000 (14.0100%),                 avg. length: 1827.7,                last time consumption/overall running time: 943.2488s / 97657.7494 s
env0_first_0:                 episode reward: -9.8500,                 loss: nan
env0_second_0:                 episode reward: 9.8500,                 loss: 0.0093
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 1787.45,                last time consumption/overall running time: 4587.8240s / 102245.5734 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0095
env0_second_0:                 episode reward: 7.0500,                 loss: 0.0061
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Score delta: 35.2, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/1412_1.
Episode: 1441/10000 (14.4100%),                 avg. length: 2330.3,                last time consumption/overall running time: 1228.4371s / 103474.0105 s
env0_first_0:                 episode reward: 3.4000,                 loss: 0.0074
env0_second_0:                 episode reward: -3.4000,                 loss: nan
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 2628.4,                last time consumption/overall running time: 1351.3343s / 104825.3448 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.0061
env0_second_0:                 episode reward: -3.3000,                 loss: nan
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 2476.8,                last time consumption/overall running time: 1293.1796s / 106118.5244 s
env0_first_0:                 episode reward: 7.7500,                 loss: 0.0068
env0_second_0:                 episode reward: -7.7500,                 loss: nan
env1_first_0:                 episode reward: 5.7500,                 loss: nan
env1_second_0:                 episode reward: -5.7500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 2271.9,                last time consumption/overall running time: 1178.2623s / 107296.7868 s
env0_first_0:                 episode reward: 7.9000,                 loss: 0.0077
env0_second_0:                 episode reward: -7.9000,                 loss: nan
env1_first_0:                 episode reward: 9.0000,                 loss: nan
env1_second_0:                 episode reward: -9.0000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 1923.35,                last time consumption/overall running time: 1004.1658s / 108300.9526 s
env0_first_0:                 episode reward: 8.1000,                 loss: 0.0071
env0_second_0:                 episode reward: -8.1000,                 loss: nan
env1_first_0:                 episode reward: 7.9000,                 loss: nan
env1_second_0:                 episode reward: -7.9000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 2157.4,                last time consumption/overall running time: 1131.8735s / 109432.8261 s
env0_first_0:                 episode reward: 10.1500,                 loss: 0.0068
env0_second_0:                 episode reward: -10.1500,                 loss: nan
env1_first_0:                 episode reward: 8.5500,                 loss: nan
env1_second_0:                 episode reward: -8.5500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 2480.05,                last time consumption/overall running time: 1293.7685s / 110726.5946 s
env0_first_0:                 episode reward: 6.2500,                 loss: 0.0083
env0_second_0:                 episode reward: -6.2500,                 loss: nan
env1_first_0:                 episode reward: 5.4500,                 loss: nan
env1_second_0:                 episode reward: -5.4500,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 1682.6,                last time consumption/overall running time: 870.0491s / 111596.6437 s
env0_first_0:                 episode reward: 10.5000,                 loss: 0.0080
env0_second_0:                 episode reward: -10.5000,                 loss: nan
env1_first_0:                 episode reward: 10.0500,                 loss: nan
env1_second_0:                 episode reward: -10.0500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 1922.85,                last time consumption/overall running time: 1001.1114s / 112597.7551 s
env0_first_0:                 episode reward: 10.9500,                 loss: 0.0084
env0_second_0:                 episode reward: -10.9500,                 loss: nan
env1_first_0:                 episode reward: 11.4000,                 loss: nan
env1_second_0:                 episode reward: -11.4000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 1784.25,                last time consumption/overall running time: 928.5788s / 113526.3339 s
env0_first_0:                 episode reward: 11.7500,                 loss: 0.0082
env0_second_0:                 episode reward: -11.7500,                 loss: nan
env1_first_0:                 episode reward: 12.7000,                 loss: nan
env1_second_0:                 episode reward: -12.7000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 1756.65,                last time consumption/overall running time: 922.8052s / 114449.1392 s
env0_first_0:                 episode reward: 12.0000,                 loss: 0.0081
env0_second_0:                 episode reward: -12.0000,                 loss: nan
env1_first_0:                 episode reward: 11.7500,                 loss: nan
env1_second_0:                 episode reward: -11.7500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 2091.25,                last time consumption/overall running time: 1104.6226s / 115553.7618 s
env0_first_0:                 episode reward: 10.6000,                 loss: 0.0098
env0_second_0:                 episode reward: -10.6000,                 loss: nan
env1_first_0:                 episode reward: 10.6000,                 loss: nan
env1_second_0:                 episode reward: -10.6000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 1563.85,                last time consumption/overall running time: 819.6117s / 116373.3734 s
env0_first_0:                 episode reward: 12.4500,                 loss: 0.0091
env0_second_0:                 episode reward: -12.4500,                 loss: nan
env1_first_0:                 episode reward: 12.7000,                 loss: nan
env1_second_0:                 episode reward: -12.7000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 1967.05,                last time consumption/overall running time: 1022.9981s / 117396.3715 s
env0_first_0:                 episode reward: 11.7500,                 loss: 0.0093
env0_second_0:                 episode reward: -11.7500,                 loss: nan
env1_first_0:                 episode reward: 9.7500,                 loss: nan
env1_second_0:                 episode reward: -9.7500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 3246.3,                last time consumption/overall running time: 2931.4750s / 120327.8465 s
env0_first_0:                 episode reward: -28.3000,                 loss: 0.0095
env0_second_0:                 episode reward: 28.3000,                 loss: 0.0092
env1_first_0:                 episode reward: -32.6500,                 loss: nan
env1_second_0:                 episode reward: 32.6500,                 loss: nan
Score delta: 31.0, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/1702_0.
Episode: 1741/10000 (17.4100%),                 avg. length: 2513.0,                last time consumption/overall running time: 5620.5549s / 125948.4014 s
env0_first_0:                 episode reward: 8.5000,                 loss: 0.0090
env0_second_0:                 episode reward: -8.5000,                 loss: 0.0095
env1_first_0:                 episode reward: 7.4000,                 loss: nan
env1_second_0:                 episode reward: -7.4000,                 loss: nan
Score delta: 117.8, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/1723_1.
Episode: 1761/10000 (17.6100%),                 avg. length: 2129.1,                last time consumption/overall running time: 2529.3370s / 128477.7384 s
env0_first_0:                 episode reward: 14.4500,                 loss: 0.0075
env0_second_0:                 episode reward: -14.4500,                 loss: 0.0135
env1_first_0:                 episode reward: 12.6000,                 loss: nan
env1_second_0:                 episode reward: -12.6000,                 loss: nan
Score delta: 31.0, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/1760_0.
Episode: 1781/10000 (17.8100%),                 avg. length: 3068.45,                last time consumption/overall running time: 5708.4185s / 134186.1569 s
env0_first_0:                 episode reward: -23.9000,                 loss: nan
env0_second_0:                 episode reward: 23.9000,                 loss: 0.0083
env1_first_0:                 episode reward: -23.2000,                 loss: nan
env1_second_0:                 episode reward: 23.2000,                 loss: nan
Score delta: 61.4, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/1781_1.
Episode: 1801/10000 (18.0100%),                 avg. length: 2681.1,                last time consumption/overall running time: 1402.2804s / 135588.4373 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.0090
env0_second_0:                 episode reward: -2.8000,                 loss: nan
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 2697.8,                last time consumption/overall running time: 1409.6522s / 136998.0895 s
env0_first_0:                 episode reward: 9.1000,                 loss: 0.0071
env0_second_0:                 episode reward: -9.1000,                 loss: nan
env1_first_0:                 episode reward: 7.3000,                 loss: nan
env1_second_0:                 episode reward: -7.3000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 3103.7,                last time consumption/overall running time: 3618.9376s / 140617.0271 s
env0_first_0:                 episode reward: 15.2500,                 loss: 0.0069
env0_second_0:                 episode reward: -15.2500,                 loss: 0.0090
env1_first_0:                 episode reward: 15.5000,                 loss: nan
env1_second_0:                 episode reward: -15.5000,                 loss: nan
Score delta: 79.0, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/1827_0.
Episode: 1861/10000 (18.6100%),                 avg. length: 2392.2,                last time consumption/overall running time: 2449.8882s / 143066.9152 s
env0_first_0:                 episode reward: -21.7000,                 loss: 0.0078
env0_second_0:                 episode reward: 21.7000,                 loss: 0.0056
env1_first_0:                 episode reward: -19.5500,                 loss: nan
env1_second_0:                 episode reward: 19.5500,                 loss: nan
Score delta: 36.8, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/1848_1.
Episode: 1881/10000 (18.8100%),                 avg. length: 2338.3,                last time consumption/overall running time: 1220.6972s / 144287.6124 s
env0_first_0:                 episode reward: 3.4000,                 loss: 0.0069
env0_second_0:                 episode reward: -3.4000,                 loss: nan
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 3042.65,                last time consumption/overall running time: 1584.6100s / 145872.2224 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0063
env0_second_0:                 episode reward: 1.2000,                 loss: nan
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 3368.65,                last time consumption/overall running time: 1731.3442s / 147603.5666 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0050
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 2903.5,                last time consumption/overall running time: 1509.4405s / 149113.0071 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.0053
env0_second_0:                 episode reward: -2.9500,                 loss: nan
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 2995.4,                last time consumption/overall running time: 1554.0906s / 150667.0977 s
env0_first_0:                 episode reward: 5.6500,                 loss: 0.0047
env0_second_0:                 episode reward: -5.6500,                 loss: nan
env1_first_0:                 episode reward: 4.6000,                 loss: nan
env1_second_0:                 episode reward: -4.6000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 2393.85,                last time consumption/overall running time: 1241.1381s / 151908.2358 s
env0_first_0:                 episode reward: 9.3000,                 loss: 0.0051
env0_second_0:                 episode reward: -9.3000,                 loss: nan
env1_first_0:                 episode reward: 8.5500,                 loss: nan
env1_second_0:                 episode reward: -8.5500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 3164.85,                last time consumption/overall running time: 3731.4286s / 155639.6644 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.0071
env0_second_0:                 episode reward: 8.2000,                 loss: 0.0076
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Score delta: 56.6, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/1984_0.
Episode: 2021/10000 (20.2100%),                 avg. length: 1968.75,                last time consumption/overall running time: 1823.5094s / 157463.1738 s
env0_first_0:                 episode reward: -16.4000,                 loss: 0.0067
env0_second_0:                 episode reward: 16.4000,                 loss: 0.0075
env1_first_0:                 episode reward: -14.1500,                 loss: nan
env1_second_0:                 episode reward: 14.1500,                 loss: nan
Score delta: 31.2, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/2010_1.
Episode: 2041/10000 (20.4100%),                 avg. length: 3393.2,                last time consumption/overall running time: 3610.7950s / 161073.9688 s
env0_first_0:                 episode reward: -20.2500,                 loss: 0.0084
env0_second_0:                 episode reward: 20.2500,                 loss: 0.0079
env1_first_0:                 episode reward: -20.0500,                 loss: nan
env1_second_0:                 episode reward: 20.0500,                 loss: nan
Score delta: 61.0, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/2031_0.
Episode: 2061/10000 (20.6100%),                 avg. length: 2751.05,                last time consumption/overall running time: 2686.7165s / 163760.6853 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.0091
env0_second_0:                 episode reward: 8.5000,                 loss: 0.0093
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Score delta: 30.8, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/2052_1.
Episode: 2081/10000 (20.8100%),                 avg. length: 2753.75,                last time consumption/overall running time: 1439.1172s / 165199.8025 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.0058
env0_second_0:                 episode reward: -2.9500,                 loss: nan
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 2780.5,                last time consumption/overall running time: 1461.5017s / 166661.3041 s
env0_first_0:                 episode reward: 6.9000,                 loss: 0.0053
env0_second_0:                 episode reward: -6.9000,                 loss: nan
env1_first_0:                 episode reward: 5.3500,                 loss: nan
env1_second_0:                 episode reward: -5.3500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 2796.4,                last time consumption/overall running time: 1460.6455s / 168121.9497 s
env0_first_0:                 episode reward: 4.3500,                 loss: 0.0057
env0_second_0:                 episode reward: -4.3500,                 loss: nan
env1_first_0:                 episode reward: 3.9000,                 loss: nan
env1_second_0:                 episode reward: -3.9000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 2538.5,                last time consumption/overall running time: 1313.2711s / 169435.2208 s
env0_first_0:                 episode reward: 8.4000,                 loss: 0.0057
env0_second_0:                 episode reward: -8.4000,                 loss: nan
env1_first_0:                 episode reward: 11.5500,                 loss: nan
env1_second_0:                 episode reward: -11.5500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 2646.8,                last time consumption/overall running time: 1358.4880s / 170793.7087 s
env0_first_0:                 episode reward: 7.9500,                 loss: 0.0059
env0_second_0:                 episode reward: -7.9500,                 loss: nan
env1_first_0:                 episode reward: 7.5000,                 loss: nan
env1_second_0:                 episode reward: -7.5000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 2373.9,                last time consumption/overall running time: 3750.6354s / 174544.3441 s
env0_first_0:                 episode reward: 13.0000,                 loss: 0.0059
env0_second_0:                 episode reward: -13.0000,                 loss: 0.0070
env1_first_0:                 episode reward: 12.1000,                 loss: nan
env1_second_0:                 episode reward: -12.1000,                 loss: nan
Score delta: 82.0, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/2170_0.
Episode: 2201/10000 (22.0100%),                 avg. length: 2226.55,                last time consumption/overall running time: 6197.0360s / 180741.3801 s
env0_first_0:                 episode reward: -12.5000,                 loss: 0.0110
env0_second_0:                 episode reward: 12.5000,                 loss: 0.0055
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Score delta: 31.6, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/2194_1.
Episode: 2221/10000 (22.2100%),                 avg. length: 2956.35,                last time consumption/overall running time: 1529.2848s / 182270.6649 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0074
env0_second_0:                 episode reward: -0.9000,                 loss: nan
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 2512.4,                last time consumption/overall running time: 1313.5226s / 183584.1876 s
env0_first_0:                 episode reward: 6.2000,                 loss: 0.0059
env0_second_0:                 episode reward: -6.2000,                 loss: nan
env1_first_0:                 episode reward: 6.1000,                 loss: nan
env1_second_0:                 episode reward: -6.1000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 2673.95,                last time consumption/overall running time: 1388.4835s / 184972.6711 s
env0_first_0:                 episode reward: 4.5500,                 loss: 0.0063
env0_second_0:                 episode reward: -4.5500,                 loss: nan
env1_first_0:                 episode reward: 7.6500,                 loss: nan
env1_second_0:                 episode reward: -7.6500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 2841.95,                last time consumption/overall running time: 4133.4392s / 189106.1103 s
env0_first_0:                 episode reward: 11.0000,                 loss: 0.0064
env0_second_0:                 episode reward: -11.0000,                 loss: 0.0091
env1_first_0:                 episode reward: 14.2000,                 loss: nan
env1_second_0:                 episode reward: -14.2000,                 loss: nan
Score delta: 63.2, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/2269_0.
Episode: 2301/10000 (23.0100%),                 avg. length: 2949.4,                last time consumption/overall running time: 4030.6006s / 193136.7108 s
env0_first_0:                 episode reward: -18.6500,                 loss: 0.0101
env0_second_0:                 episode reward: 18.6500,                 loss: 0.0071
env1_first_0:                 episode reward: -22.7500,                 loss: nan
env1_second_0:                 episode reward: 22.7500,                 loss: nan
Score delta: 76.6, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/2290_1.
Episode: 2321/10000 (23.2100%),                 avg. length: 2816.95,                last time consumption/overall running time: 1364.2366s / 194500.9474 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0073
env0_second_0:                 episode reward: -0.0500,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 2627.75,                last time consumption/overall running time: 3811.8315s / 198312.7789 s
env0_first_0:                 episode reward: 12.8500,                 loss: 0.0068
env0_second_0:                 episode reward: -12.8500,                 loss: 0.0176
env1_first_0:                 episode reward: 14.2500,                 loss: nan
env1_second_0:                 episode reward: -14.2500,                 loss: nan
Score delta: 30.4, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/2330_0.
Episode: 2361/10000 (23.6100%),                 avg. length: 2890.5,                last time consumption/overall running time: 1412.1787s / 199724.9576 s
env0_first_0:                 episode reward: -7.4500,                 loss: nan
env0_second_0:                 episode reward: 7.4500,                 loss: 0.0067
env1_first_0:                 episode reward: -6.3500,                 loss: nan
env1_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 2348.05,                last time consumption/overall running time: 3197.9135s / 202922.8711 s
env0_first_0:                 episode reward: -8.7500,                 loss: 0.0098
env0_second_0:                 episode reward: 8.7500,                 loss: 0.0054
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Score delta: 30.2, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/2372_1.
Episode: 2401/10000 (24.0100%),                 avg. length: 2272.65,                last time consumption/overall running time: 1118.3129s / 204041.1840 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0080
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 2518.45,                last time consumption/overall running time: 1219.3791s / 205260.5631 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0061
env0_second_0:                 episode reward: 2.5500,                 loss: nan
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 2550.6,                last time consumption/overall running time: 1256.5108s / 206517.0740 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0068
env0_second_0:                 episode reward: 3.0500,                 loss: nan
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 2343.4,                last time consumption/overall running time: 1159.6222s / 207676.6962 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0078
env0_second_0:                 episode reward: -0.6500,                 loss: nan
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 3046.2,                last time consumption/overall running time: 1490.5445s / 209167.2407 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0066
env0_second_0:                 episode reward: 3.3500,                 loss: nan
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 2682.65,                last time consumption/overall running time: 1301.7668s / 210469.0075 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0061
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 2284.35,                last time consumption/overall running time: 1120.4497s / 211589.4571 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.0074
env0_second_0:                 episode reward: -3.5000,                 loss: nan
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 2420.4,                last time consumption/overall running time: 1189.8267s / 212779.2838 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0071
env0_second_0:                 episode reward: -1.2000,                 loss: nan
env1_first_0:                 episode reward: 2.3000,                 loss: nan
env1_second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 2292.65,                last time consumption/overall running time: 1141.3866s / 213920.6705 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.0072
env0_second_0:                 episode reward: -2.6500,                 loss: nan
env1_first_0:                 episode reward: 3.8000,                 loss: nan
env1_second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 2118.25,                last time consumption/overall running time: 1050.6768s / 214971.3472 s
env0_first_0:                 episode reward: 3.7500,                 loss: 0.0065
env0_second_0:                 episode reward: -3.7500,                 loss: nan
env1_first_0:                 episode reward: 6.5000,                 loss: nan
env1_second_0:                 episode reward: -6.5000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 2811.6,                last time consumption/overall running time: 1380.4333s / 216351.7805 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0073
env0_second_0:                 episode reward: -1.1000,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 2671.65,                last time consumption/overall running time: 1254.7697s / 217606.5502 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.0076
env0_second_0:                 episode reward: -2.6500,                 loss: nan
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 2918.8,                last time consumption/overall running time: 1353.2141s / 218959.7643 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.0067
env0_second_0:                 episode reward: 2.7500,                 loss: nan
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 2264.7,                last time consumption/overall running time: 1063.1591s / 220022.9234 s
env0_first_0:                 episode reward: 6.2000,                 loss: 0.0072
env0_second_0:                 episode reward: -6.2000,                 loss: nan
env1_first_0:                 episode reward: 5.6500,                 loss: nan
env1_second_0:                 episode reward: -5.6500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 2682.45,                last time consumption/overall running time: 1254.9362s / 221277.8596 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0074
env0_second_0:                 episode reward: -2.5000,                 loss: nan
env1_first_0:                 episode reward: 3.7000,                 loss: nan
env1_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 3012.95,                last time consumption/overall running time: 1410.4856s / 222688.3452 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0079
env0_second_0:                 episode reward: -0.7500,                 loss: nan
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 2543.3,                last time consumption/overall running time: 1181.1162s / 223869.4614 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.0072
env0_second_0:                 episode reward: -3.6500,                 loss: nan
env1_first_0:                 episode reward: 4.8000,                 loss: nan
env1_second_0:                 episode reward: -4.8000,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 2775.7,                last time consumption/overall running time: 1273.4220s / 225142.8834 s
env0_first_0:                 episode reward: 7.1000,                 loss: 0.0065
env0_second_0:                 episode reward: -7.1000,                 loss: nan
env1_first_0:                 episode reward: 5.8500,                 loss: nan
env1_second_0:                 episode reward: -5.8500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 2836.6,                last time consumption/overall running time: 3884.6904s / 229027.5737 s
env0_first_0:                 episode reward: 8.1500,                 loss: 0.0080
env0_second_0:                 episode reward: -8.1500,                 loss: 0.0055
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Score delta: 42.6, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/2757_0.
Episode: 2781/10000 (27.8100%),                 avg. length: 2796.1,                last time consumption/overall running time: 1296.6568s / 230324.2306 s
env0_first_0:                 episode reward: -9.9000,                 loss: nan
env0_second_0:                 episode reward: 9.9000,                 loss: 0.0049
env1_first_0:                 episode reward: -8.9500,                 loss: nan
env1_second_0:                 episode reward: 8.9500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 2396.15,                last time consumption/overall running time: 4394.8397s / 234719.0703 s
env0_first_0:                 episode reward: -20.8500,                 loss: 0.0101
env0_second_0:                 episode reward: 20.8500,                 loss: 0.0049
env1_first_0:                 episode reward: -22.4500,                 loss: nan
env1_second_0:                 episode reward: 22.4500,                 loss: nan
Score delta: 77.0, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/2799_1.
Episode: 2821/10000 (28.2100%),                 avg. length: 2958.6,                last time consumption/overall running time: 1394.2562s / 236113.3266 s
env0_first_0:                 episode reward: -7.0500,                 loss: 0.0093
env0_second_0:                 episode reward: 7.0500,                 loss: nan
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 2539.9,                last time consumption/overall running time: 1171.0588s / 237284.3853 s
env0_first_0:                 episode reward: 4.5500,                 loss: 0.0074
env0_second_0:                 episode reward: -4.5500,                 loss: nan
env1_first_0:                 episode reward: 4.2500,                 loss: nan
env1_second_0:                 episode reward: -4.2500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 2227.8,                last time consumption/overall running time: 1018.8529s / 238303.2382 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0073
env0_second_0:                 episode reward: -1.4500,                 loss: nan
env1_first_0:                 episode reward: 4.3500,                 loss: nan
env1_second_0:                 episode reward: -4.3500,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 2558.35,                last time consumption/overall running time: 1174.9989s / 239478.2372 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.0076
env0_second_0:                 episode reward: -2.9000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 2211.7,                last time consumption/overall running time: 1028.1532s / 240506.3903 s
env0_first_0:                 episode reward: 4.1000,                 loss: 0.0075
env0_second_0:                 episode reward: -4.1000,                 loss: nan
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 2322.3,                last time consumption/overall running time: 1078.9839s / 241585.3742 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.0083
env0_second_0:                 episode reward: -3.5500,                 loss: nan
env1_first_0:                 episode reward: 4.6500,                 loss: nan
env1_second_0:                 episode reward: -4.6500,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 2175.2,                last time consumption/overall running time: 1011.1342s / 242596.5084 s
env0_first_0:                 episode reward: 6.6000,                 loss: 0.0073
env0_second_0:                 episode reward: -6.6000,                 loss: nan
env1_first_0:                 episode reward: 8.4000,                 loss: nan
env1_second_0:                 episode reward: -8.4000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 2939.8,                last time consumption/overall running time: 1379.1369s / 243975.6454 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0075
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: -4.5000,                 loss: nan
env1_second_0:                 episode reward: 4.5000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 2287.4,                last time consumption/overall running time: 1059.4945s / 245035.1399 s
env0_first_0:                 episode reward: 4.2000,                 loss: 0.0090
env0_second_0:                 episode reward: -4.2000,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 1960.4,                last time consumption/overall running time: 903.8913s / 245939.0312 s
env0_first_0:                 episode reward: 5.0500,                 loss: 0.0080
env0_second_0:                 episode reward: -5.0500,                 loss: nan
env1_first_0:                 episode reward: 4.8500,                 loss: nan
env1_second_0:                 episode reward: -4.8500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 2107.7,                last time consumption/overall running time: 968.1407s / 246907.1719 s
env0_first_0:                 episode reward: 5.1000,                 loss: 0.0091
env0_second_0:                 episode reward: -5.1000,                 loss: nan
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 2134.8,                last time consumption/overall running time: 985.9012s / 247893.0731 s
env0_first_0:                 episode reward: 3.7500,                 loss: 0.0089
env0_second_0:                 episode reward: -3.7500,                 loss: nan
env1_first_0:                 episode reward: 3.8500,                 loss: nan
env1_second_0:                 episode reward: -3.8500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 2194.95,                last time consumption/overall running time: 1021.6253s / 248914.6984 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0074
env0_second_0:                 episode reward: 1.1000,                 loss: nan
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 2072.1,                last time consumption/overall running time: 965.0570s / 249879.7554 s
env0_first_0:                 episode reward: 5.4000,                 loss: 0.0094
env0_second_0:                 episode reward: -5.4000,                 loss: nan
env1_first_0:                 episode reward: 4.9500,                 loss: nan
env1_second_0:                 episode reward: -4.9500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 2065.25,                last time consumption/overall running time: 961.5196s / 250841.2750 s
env0_first_0:                 episode reward: 5.9000,                 loss: 0.0085
env0_second_0:                 episode reward: -5.9000,                 loss: nan
env1_first_0:                 episode reward: 4.0500,                 loss: nan
env1_second_0:                 episode reward: -4.0500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 2219.05,                last time consumption/overall running time: 1048.0144s / 251889.2895 s
env0_first_0:                 episode reward: 7.9000,                 loss: 0.0086
env0_second_0:                 episode reward: -7.9000,                 loss: nan
env1_first_0:                 episode reward: 6.7500,                 loss: nan
env1_second_0:                 episode reward: -6.7500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 2017.9,                last time consumption/overall running time: 937.5789s / 252826.8684 s
env0_first_0:                 episode reward: 4.7000,                 loss: 0.0094
env0_second_0:                 episode reward: -4.7000,                 loss: nan
env1_first_0:                 episode reward: 6.6500,                 loss: nan
env1_second_0:                 episode reward: -6.6500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 2512.9,                last time consumption/overall running time: 1162.7860s / 253989.6544 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.0086
env0_second_0:                 episode reward: -3.6000,                 loss: nan
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 2367.1,                last time consumption/overall running time: 1090.9077s / 255080.5621 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.0092
env0_second_0:                 episode reward: -3.8000,                 loss: nan
env1_first_0:                 episode reward: 4.9000,                 loss: nan
env1_second_0:                 episode reward: -4.9000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 2740.7,                last time consumption/overall running time: 1264.5349s / 256345.0970 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0089
env0_second_0:                 episode reward: 1.7500,                 loss: nan
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 2630.15,                last time consumption/overall running time: 1156.9290s / 257502.0259 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.0083
env0_second_0:                 episode reward: 2.2000,                 loss: nan
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 2446.3,                last time consumption/overall running time: 1018.4121s / 258520.4381 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0085
env0_second_0:                 episode reward: -1.1000,                 loss: nan
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 2591.45,                last time consumption/overall running time: 1062.3004s / 259582.7384 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0079
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 2356.8,                last time consumption/overall running time: 953.6650s / 260536.4035 s
env0_first_0:                 episode reward: 3.9500,                 loss: 0.0077
env0_second_0:                 episode reward: -3.9500,                 loss: nan
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 2265.65,                last time consumption/overall running time: 914.7067s / 261451.1102 s
env0_first_0:                 episode reward: 4.4500,                 loss: 0.0079
env0_second_0:                 episode reward: -4.4500,                 loss: nan
env1_first_0:                 episode reward: 6.4500,                 loss: nan
env1_second_0:                 episode reward: -6.4500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 2766.6,                last time consumption/overall running time: 1121.5704s / 262572.6806 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0071
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 2264.8,                last time consumption/overall running time: 908.5876s / 263481.2682 s
env0_first_0:                 episode reward: 6.1000,                 loss: 0.0066
env0_second_0:                 episode reward: -6.1000,                 loss: nan
env1_first_0:                 episode reward: 6.8500,                 loss: nan
env1_second_0:                 episode reward: -6.8500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 2285.3,                last time consumption/overall running time: 920.4373s / 264401.7055 s
env0_first_0:                 episode reward: 5.3000,                 loss: 0.0072
env0_second_0:                 episode reward: -5.3000,                 loss: nan
env1_first_0:                 episode reward: 5.6000,                 loss: nan
env1_second_0:                 episode reward: -5.6000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 2475.75,                last time consumption/overall running time: 993.5931s / 265395.2985 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0076
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 2427.65,                last time consumption/overall running time: 973.8812s / 266369.1797 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.0079
env0_second_0:                 episode reward: -2.7500,                 loss: nan
env1_first_0:                 episode reward: 5.5000,                 loss: nan
env1_second_0:                 episode reward: -5.5000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 2354.85,                last time consumption/overall running time: 946.2343s / 267315.4140 s
env0_first_0:                 episode reward: 5.9000,                 loss: 0.0073
env0_second_0:                 episode reward: -5.9000,                 loss: nan
env1_first_0:                 episode reward: 5.0000,                 loss: nan
env1_second_0:                 episode reward: -5.0000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 2571.4,                last time consumption/overall running time: 1044.2680s / 268359.6820 s
env0_first_0:                 episode reward: 4.2000,                 loss: 0.0076
env0_second_0:                 episode reward: -4.2000,                 loss: nan
env1_first_0:                 episode reward: 4.3500,                 loss: nan
env1_second_0:                 episode reward: -4.3500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 2382.6,                last time consumption/overall running time: 976.6304s / 269336.3125 s
env0_first_0:                 episode reward: 5.5500,                 loss: 0.0083
env0_second_0:                 episode reward: -5.5500,                 loss: nan
env1_first_0:                 episode reward: 4.1000,                 loss: nan
env1_second_0:                 episode reward: -4.1000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 2599.35,                last time consumption/overall running time: 1072.0636s / 270408.3761 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.0082
env0_second_0:                 episode reward: -2.5500,                 loss: nan
env1_first_0:                 episode reward: 4.3000,                 loss: nan
env1_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 2724.65,                last time consumption/overall running time: 1102.5430s / 271510.9191 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0071
env0_second_0:                 episode reward: -1.9000,                 loss: nan
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 2388.7,                last time consumption/overall running time: 964.7011s / 272475.6202 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.0075
env0_second_0:                 episode reward: -3.7000,                 loss: nan
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 2566.65,                last time consumption/overall running time: 1026.3819s / 273502.0021 s
env0_first_0:                 episode reward: 4.0000,                 loss: 0.0071
env0_second_0:                 episode reward: -4.0000,                 loss: nan
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 2574.75,                last time consumption/overall running time: 1042.8771s / 274544.8793 s
env0_first_0:                 episode reward: 5.6500,                 loss: 0.0076
env0_second_0:                 episode reward: -5.6500,                 loss: nan
env1_first_0:                 episode reward: 5.4500,                 loss: nan
env1_second_0:                 episode reward: -5.4500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 2449.95,                last time consumption/overall running time: 1001.5077s / 275546.3869 s
env0_first_0:                 episode reward: 5.8500,                 loss: 0.0067
env0_second_0:                 episode reward: -5.8500,                 loss: nan
env1_first_0:                 episode reward: 4.5500,                 loss: nan
env1_second_0:                 episode reward: -4.5500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 2324.1,                last time consumption/overall running time: 942.4848s / 276488.8718 s
env0_first_0:                 episode reward: 5.8000,                 loss: 0.0088
env0_second_0:                 episode reward: -5.8000,                 loss: nan
env1_first_0:                 episode reward: 7.5000,                 loss: nan
env1_second_0:                 episode reward: -7.5000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 2235.65,                last time consumption/overall running time: 916.0080s / 277404.8798 s
env0_first_0:                 episode reward: 7.6500,                 loss: 0.0085
env0_second_0:                 episode reward: -7.6500,                 loss: nan
env1_first_0:                 episode reward: 5.2000,                 loss: nan
env1_second_0:                 episode reward: -5.2000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 2298.8,                last time consumption/overall running time: 927.0355s / 278331.9153 s
env0_first_0:                 episode reward: 6.5000,                 loss: 0.0077
env0_second_0:                 episode reward: -6.5000,                 loss: nan
env1_first_0:                 episode reward: 4.4500,                 loss: nan
env1_second_0:                 episode reward: -4.4500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 2640.85,                last time consumption/overall running time: 1062.4677s / 279394.3830 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.0065
env0_second_0:                 episode reward: -3.7000,                 loss: nan
env1_first_0:                 episode reward: 5.3000,                 loss: nan
env1_second_0:                 episode reward: -5.3000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 2623.85,                last time consumption/overall running time: 1060.5431s / 280454.9261 s
env0_first_0:                 episode reward: 5.1500,                 loss: 0.0069
env0_second_0:                 episode reward: -5.1500,                 loss: nan
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 2868.1,                last time consumption/overall running time: 1154.8327s / 281609.7588 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0072
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 2916.85,                last time consumption/overall running time: 1171.2354s / 282780.9942 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.0069
env0_second_0:                 episode reward: -1.7500,                 loss: nan
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 2741.2,                last time consumption/overall running time: 1099.5610s / 283880.5552 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.0062
env0_second_0:                 episode reward: -2.9000,                 loss: nan
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 2763.6,                last time consumption/overall running time: 1130.1775s / 285010.7327 s
env0_first_0:                 episode reward: 5.1000,                 loss: 0.0067
env0_second_0:                 episode reward: -5.1000,                 loss: nan
env1_first_0:                 episode reward: 6.5500,                 loss: nan
env1_second_0:                 episode reward: -6.5500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 2564.45,                last time consumption/overall running time: 1038.9329s / 286049.6656 s
env0_first_0:                 episode reward: 8.4000,                 loss: 0.0073
env0_second_0:                 episode reward: -8.4000,                 loss: nan
env1_first_0:                 episode reward: 6.2000,                 loss: nan
env1_second_0:                 episode reward: -6.2000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 2454.9,                last time consumption/overall running time: 979.2890s / 287028.9547 s
env0_first_0:                 episode reward: 8.2000,                 loss: 0.0066
env0_second_0:                 episode reward: -8.2000,                 loss: nan
env1_first_0:                 episode reward: 10.3000,                 loss: nan
env1_second_0:                 episode reward: -10.3000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 2272.8,                last time consumption/overall running time: 900.7252s / 287929.6799 s
env0_first_0:                 episode reward: 8.8000,                 loss: 0.0064
env0_second_0:                 episode reward: -8.8000,                 loss: nan
env1_first_0:                 episode reward: 6.2500,                 loss: nan
env1_second_0:                 episode reward: -6.2500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 2221.15,                last time consumption/overall running time: 877.1029s / 288806.7828 s
env0_first_0:                 episode reward: 7.6500,                 loss: 0.0068
env0_second_0:                 episode reward: -7.6500,                 loss: nan
env1_first_0:                 episode reward: 10.0500,                 loss: nan
env1_second_0:                 episode reward: -10.0500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 2228.3,                last time consumption/overall running time: 894.5098s / 289701.2926 s
env0_first_0:                 episode reward: 8.4500,                 loss: 0.0072
env0_second_0:                 episode reward: -8.4500,                 loss: nan
env1_first_0:                 episode reward: 8.7000,                 loss: nan
env1_second_0:                 episode reward: -8.7000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 2279.4,                last time consumption/overall running time: 935.0557s / 290636.3483 s
env0_first_0:                 episode reward: 8.9000,                 loss: 0.0063
env0_second_0:                 episode reward: -8.9000,                 loss: nan
env1_first_0:                 episode reward: 11.3000,                 loss: nan
env1_second_0:                 episode reward: -11.3000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 2287.05,                last time consumption/overall running time: 929.1539s / 291565.5022 s
env0_first_0:                 episode reward: 10.2000,                 loss: 0.0068
env0_second_0:                 episode reward: -10.2000,                 loss: nan
env1_first_0:                 episode reward: 9.7000,                 loss: nan
env1_second_0:                 episode reward: -9.7000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 1911.45,                last time consumption/overall running time: 772.4622s / 292337.9644 s
env0_first_0:                 episode reward: 12.2500,                 loss: 0.0070
env0_second_0:                 episode reward: -12.2500,                 loss: nan
env1_first_0:                 episode reward: 9.6000,                 loss: nan
env1_second_0:                 episode reward: -9.6000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 2096.7,                last time consumption/overall running time: 780.3911s / 293118.3555 s
env0_first_0:                 episode reward: 10.9000,                 loss: 0.0078
env0_second_0:                 episode reward: -10.9000,                 loss: nan
env1_first_0:                 episode reward: 12.0000,                 loss: nan
env1_second_0:                 episode reward: -12.0000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 2483.65,                last time consumption/overall running time: 2325.6844s / 295444.0399 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0072
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0069
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Score delta: 30.8, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/3946_0.
Episode: 3981/10000 (39.8100%),                 avg. length: 2969.0,                last time consumption/overall running time: 1003.7745s / 296447.8144 s
env0_first_0:                 episode reward: -6.2000,                 loss: nan
env0_second_0:                 episode reward: 6.2000,                 loss: 0.0051
env1_first_0:                 episode reward: -6.0000,                 loss: nan
env1_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 2400.25,                last time consumption/overall running time: 818.2967s / 297266.1111 s
env0_first_0:                 episode reward: -10.5500,                 loss: nan
env0_second_0:                 episode reward: 10.5500,                 loss: 0.0059
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 1937.85,                last time consumption/overall running time: 4388.5133s / 301654.6244 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.0075
env0_second_0:                 episode reward: 4.5000,                 loss: 0.0062
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
Score delta: 31.8, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/4015_1.
Episode: 4041/10000 (40.4100%),                 avg. length: 2532.3,                last time consumption/overall running time: 852.4985s / 302507.1230 s
env0_first_0:                 episode reward: 9.1000,                 loss: 0.0067
env0_second_0:                 episode reward: -9.1000,                 loss: nan
env1_first_0:                 episode reward: 8.1000,                 loss: nan
env1_second_0:                 episode reward: -8.1000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 2676.9,                last time consumption/overall running time: 2880.0271s / 305387.1501 s
env0_first_0:                 episode reward: 11.2500,                 loss: 0.0069
env0_second_0:                 episode reward: -11.2500,                 loss: 0.0051
env1_first_0:                 episode reward: 8.3000,                 loss: nan
env1_second_0:                 episode reward: -8.3000,                 loss: nan
Score delta: 42.2, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/4057_0.
Episode: 4081/10000 (40.8100%),                 avg. length: 2605.35,                last time consumption/overall running time: 869.0190s / 306256.1691 s
env0_first_0:                 episode reward: -1.8500,                 loss: nan
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0070
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 2123.65,                last time consumption/overall running time: 4964.0465s / 311220.2156 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.0080
env0_second_0:                 episode reward: 8.1500,                 loss: 0.0068
env1_first_0:                 episode reward: -7.5500,                 loss: nan
env1_second_0:                 episode reward: 7.5500,                 loss: nan
Score delta: 30.4, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/4092_1.
Episode: 4121/10000 (41.2100%),                 avg. length: 2485.05,                last time consumption/overall running time: 855.8738s / 312076.0894 s
env0_first_0:                 episode reward: 8.6500,                 loss: 0.0061
env0_second_0:                 episode reward: -8.6500,                 loss: nan
env1_first_0:                 episode reward: 10.7500,                 loss: nan
env1_second_0:                 episode reward: -10.7500,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 2149.05,                last time consumption/overall running time: 2627.1865s / 314703.2760 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0065
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0056
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Score delta: 31.4, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/4128_0.
Episode: 4161/10000 (41.6100%),                 avg. length: 2243.4,                last time consumption/overall running time: 4648.8856s / 319352.1616 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.0079
env0_second_0:                 episode reward: 10.7000,                 loss: 0.0071
env1_first_0:                 episode reward: -10.5000,                 loss: nan
env1_second_0:                 episode reward: 10.5000,                 loss: nan
Score delta: 30.4, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/4160_1.
Episode: 4181/10000 (41.8100%),                 avg. length: 2882.45,                last time consumption/overall running time: 968.4046s / 320320.5662 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.0070
env0_second_0:                 episode reward: -2.6500,                 loss: nan
env1_first_0:                 episode reward: 4.3000,                 loss: nan
env1_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 2174.7,                last time consumption/overall running time: 733.7562s / 321054.3224 s
env0_first_0:                 episode reward: 5.9500,                 loss: 0.0064
env0_second_0:                 episode reward: -5.9500,                 loss: nan
env1_first_0:                 episode reward: 6.9000,                 loss: nan
env1_second_0:                 episode reward: -6.9000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 2309.95,                last time consumption/overall running time: 784.3055s / 321838.6279 s
env0_first_0:                 episode reward: 6.7000,                 loss: 0.0060
env0_second_0:                 episode reward: -6.7000,                 loss: nan
env1_first_0:                 episode reward: 6.3500,                 loss: nan
env1_second_0:                 episode reward: -6.3500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 2432.8,                last time consumption/overall running time: 832.7504s / 322671.3783 s
env0_first_0:                 episode reward: 8.4500,                 loss: 0.0068
env0_second_0:                 episode reward: -8.4500,                 loss: nan
env1_first_0:                 episode reward: 8.6500,                 loss: nan
env1_second_0:                 episode reward: -8.6500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 2541.2,                last time consumption/overall running time: 806.8805s / 323478.2588 s
env0_first_0:                 episode reward: 6.3500,                 loss: 0.0062
env0_second_0:                 episode reward: -6.3500,                 loss: nan
env1_first_0:                 episode reward: 5.7500,                 loss: nan
env1_second_0:                 episode reward: -5.7500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 2927.75,                last time consumption/overall running time: 934.2511s / 324412.5099 s
env0_first_0:                 episode reward: 5.3500,                 loss: 0.0062
env0_second_0:                 episode reward: -5.3500,                 loss: nan
env1_first_0:                 episode reward: 4.4500,                 loss: nan
env1_second_0:                 episode reward: -4.4500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 2657.2,                last time consumption/overall running time: 839.0296s / 325251.5396 s
env0_first_0:                 episode reward: 7.1500,                 loss: 0.0060
env0_second_0:                 episode reward: -7.1500,                 loss: nan
env1_first_0:                 episode reward: 8.0000,                 loss: nan
env1_second_0:                 episode reward: -8.0000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 2352.6,                last time consumption/overall running time: 735.1498s / 325986.6893 s
env0_first_0:                 episode reward: 6.7500,                 loss: 0.0066
env0_second_0:                 episode reward: -6.7500,                 loss: nan
env1_first_0:                 episode reward: 10.8000,                 loss: nan
env1_second_0:                 episode reward: -10.8000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 2619.7,                last time consumption/overall running time: 817.6953s / 326804.3846 s
env0_first_0:                 episode reward: 7.4000,                 loss: 0.0066
env0_second_0:                 episode reward: -7.4000,                 loss: nan
env1_first_0:                 episode reward: 6.8000,                 loss: nan
env1_second_0:                 episode reward: -6.8000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 2393.1,                last time consumption/overall running time: 2551.3549s / 329355.7395 s
env0_first_0:                 episode reward: 12.7500,                 loss: 0.0072
env0_second_0:                 episode reward: -12.7500,                 loss: nan
env1_first_0:                 episode reward: 10.5000,                 loss: nan
env1_second_0:                 episode reward: -10.5000,                 loss: nan
Score delta: 32.6, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/4361_0.
Episode: 4381/10000 (43.8100%),                 avg. length: 2354.85,                last time consumption/overall running time: 739.2731s / 330095.0126 s
env0_first_0:                 episode reward: -8.3000,                 loss: nan
env0_second_0:                 episode reward: 8.3000,                 loss: 0.0055
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 2187.0,                last time consumption/overall running time: 698.3194s / 330793.3320 s
env0_first_0:                 episode reward: -11.9000,                 loss: nan
env0_second_0:                 episode reward: 11.9000,                 loss: 0.0068
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 984.15,                last time consumption/overall running time: 1489.5213s / 332282.8533 s
env0_first_0:                 episode reward: -20.4500,                 loss: 0.0166
env0_second_0:                 episode reward: 20.4500,                 loss: 0.0055
env1_first_0:                 episode reward: -19.7000,                 loss: nan
env1_second_0:                 episode reward: 19.7000,                 loss: nan
Score delta: 34.0, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/4406_1.
Episode: 4441/10000 (44.4100%),                 avg. length: 1726.3,                last time consumption/overall running time: 528.1060s / 332810.9593 s
env0_first_0:                 episode reward: -16.9500,                 loss: 0.0108
env0_second_0:                 episode reward: 16.9500,                 loss: nan
env1_first_0:                 episode reward: -17.1000,                 loss: nan
env1_second_0:                 episode reward: 17.1000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 3094.65,                last time consumption/overall running time: 950.3279s / 333761.2871 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.0052
env0_second_0:                 episode reward: 8.2500,                 loss: nan
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 3575.35,                last time consumption/overall running time: 1103.6279s / 334864.9150 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0045
env0_second_0:                 episode reward: 3.8500,                 loss: nan
env1_first_0:                 episode reward: -6.3500,                 loss: nan
env1_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 3845.9,                last time consumption/overall running time: 1200.1490s / 336065.0641 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0045
env0_second_0:                 episode reward: 3.2000,                 loss: nan
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 3807.85,                last time consumption/overall running time: 1192.0907s / 337257.1548 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0042
env0_second_0:                 episode reward: -0.3000,                 loss: nan
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 3826.5,                last time consumption/overall running time: 3343.2706s / 340600.4255 s
env0_first_0:                 episode reward: 14.1500,                 loss: 0.0048
env0_second_0:                 episode reward: -14.1500,                 loss: 0.0045
env1_first_0:                 episode reward: 7.0500,                 loss: nan
env1_second_0:                 episode reward: -7.0500,                 loss: nan
Score delta: 70.6, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/4531_0.
Episode: 4561/10000 (45.6100%),                 avg. length: 2579.25,                last time consumption/overall running time: 815.2653s / 341415.6908 s
env0_first_0:                 episode reward: -11.3500,                 loss: nan
env0_second_0:                 episode reward: 11.3500,                 loss: 0.0055
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 2093.3,                last time consumption/overall running time: 662.5034s / 342078.1942 s
env0_first_0:                 episode reward: -13.1500,                 loss: nan
env0_second_0:                 episode reward: 13.1500,                 loss: 0.0064
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 1189.55,                last time consumption/overall running time: 1186.7647s / 343264.9589 s
env0_first_0:                 episode reward: -20.1500,                 loss: 0.0151
env0_second_0:                 episode reward: 20.1500,                 loss: 0.0060
env1_first_0:                 episode reward: -20.2500,                 loss: nan
env1_second_0:                 episode reward: 20.2500,                 loss: nan
Score delta: 31.8, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/4582_1.
Episode: 4621/10000 (46.2100%),                 avg. length: 1607.8,                last time consumption/overall running time: 500.2295s / 343765.1884 s
env0_first_0:                 episode reward: -15.9000,                 loss: 0.0085
env0_second_0:                 episode reward: 15.9000,                 loss: nan
env1_first_0:                 episode reward: -17.1500,                 loss: nan
env1_second_0:                 episode reward: 17.1500,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 3069.1,                last time consumption/overall running time: 942.7003s / 344707.8887 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.0061
env0_second_0:                 episode reward: 10.5500,                 loss: nan
env1_first_0:                 episode reward: -8.7500,                 loss: nan
env1_second_0:                 episode reward: 8.7500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 3423.4,                last time consumption/overall running time: 1053.1074s / 345760.9962 s
env0_first_0:                 episode reward: -5.3500,                 loss: 0.0047
env0_second_0:                 episode reward: 5.3500,                 loss: nan
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 3549.15,                last time consumption/overall running time: 1105.3431s / 346866.3393 s
env0_first_0:                 episode reward: -9.0500,                 loss: 0.0044
env0_second_0:                 episode reward: 9.0500,                 loss: nan
env1_first_0:                 episode reward: -7.0000,                 loss: nan
env1_second_0:                 episode reward: 7.0000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 3368.55,                last time consumption/overall running time: 1063.0624s / 347929.4017 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.0045
env0_second_0:                 episode reward: 8.0500,                 loss: nan
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 3240.25,                last time consumption/overall running time: 1018.4941s / 348947.8957 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0044
env0_second_0:                 episode reward: 4.4500,                 loss: nan
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 3261.75,                last time consumption/overall running time: 2697.1481s / 351645.0439 s
env0_first_0:                 episode reward: 11.0500,                 loss: 0.0050
env0_second_0:                 episode reward: -11.0500,                 loss: 0.0064
env1_first_0:                 episode reward: 9.2000,                 loss: nan
env1_second_0:                 episode reward: -9.2000,                 loss: nan
Score delta: 55.2, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/4731_0.
Episode: 4761/10000 (47.6100%),                 avg. length: 2470.05,                last time consumption/overall running time: 685.1653s / 352330.2092 s
env0_first_0:                 episode reward: -9.3500,                 loss: nan
env0_second_0:                 episode reward: 9.3500,                 loss: 0.0060
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 2495.0,                last time consumption/overall running time: 696.2054s / 353026.4145 s
env0_first_0:                 episode reward: -10.2500,                 loss: nan
env0_second_0:                 episode reward: 10.2500,                 loss: 0.0059
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 1364.65,                last time consumption/overall running time: 1286.8462s / 354313.2607 s
env0_first_0:                 episode reward: -16.3500,                 loss: 0.0193
env0_second_0:                 episode reward: 16.3500,                 loss: 0.0055
env1_first_0:                 episode reward: -17.3500,                 loss: nan
env1_second_0:                 episode reward: 17.3500,                 loss: nan
Score delta: 30.2, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/4794_1.
Episode: 4821/10000 (48.2100%),                 avg. length: 1047.5,                last time consumption/overall running time: 303.0327s / 354616.2934 s
env0_first_0:                 episode reward: -23.4000,                 loss: 0.0137
env0_second_0:                 episode reward: 23.4000,                 loss: nan
env1_first_0:                 episode reward: -22.4500,                 loss: nan
env1_second_0:                 episode reward: 22.4500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 2419.7,                last time consumption/overall running time: 707.4514s / 355323.7448 s
env0_first_0:                 episode reward: -14.4500,                 loss: 0.0087
env0_second_0:                 episode reward: 14.4500,                 loss: nan
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 3350.1,                last time consumption/overall running time: 966.9594s / 356290.7042 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0061
env0_second_0:                 episode reward: -1.9000,                 loss: nan
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 2536.75,                last time consumption/overall running time: 3225.9390s / 359516.6431 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.0073
env0_second_0:                 episode reward: 5.2500,                 loss: 0.0058
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Score delta: 50.4, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/4863_0.
Episode: 4901/10000 (49.0100%),                 avg. length: 3181.45,                last time consumption/overall running time: 2568.2802s / 362084.9233 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0072
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0063
env1_first_0:                 episode reward: 5.9500,                 loss: nan
env1_second_0:                 episode reward: -5.9500,                 loss: nan
Score delta: 32.2, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/4895_1.
Episode: 4921/10000 (49.2100%),                 avg. length: 3181.7,                last time consumption/overall running time: 2722.4808s / 364807.4041 s
env0_first_0:                 episode reward: 6.7500,                 loss: 0.0074
env0_second_0:                 episode reward: -6.7500,                 loss: 0.0060
env1_first_0:                 episode reward: 8.4000,                 loss: nan
env1_second_0:                 episode reward: -8.4000,                 loss: nan
Score delta: 45.6, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/4916_0.
Episode: 4941/10000 (49.4100%),                 avg. length: 1880.8,                last time consumption/overall running time: 1793.6513s / 366601.0554 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.0234
env0_second_0:                 episode reward: 14.6500,                 loss: 0.0055
env1_first_0:                 episode reward: -17.0500,                 loss: nan
env1_second_0:                 episode reward: 17.0500,                 loss: nan
Score delta: 30.6, save the model to .//data/model/20220119_0526/pettingzoo_pong_v2_nxdo2/4940_1.
Episode: 4961/10000 (49.6100%),                 avg. length: 1149.5,                last time consumption/overall running time: 300.7356s / 366901.7910 s
env0_first_0:                 episode reward: -19.6500,                 loss: 0.0157
env0_second_0:                 episode reward: 19.6500,                 loss: nan
env1_first_0:                 episode reward: -19.2000,                 loss: nan
env1_second_0:                 episode reward: 19.2000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 2390.9,                last time consumption/overall running time: 634.1374s / 367535.9284 s
env0_first_0:                 episode reward: -11.0000,                 loss: 0.0068
env0_second_0:                 episode reward: 11.0000,                 loss: nan
env1_first_0:                 episode reward: -14.5000,                 loss: nan
env1_second_0:                 episode reward: 14.5000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 2897.15,                last time consumption/overall running time: 757.6543s / 368293.5826 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0049
env0_second_0:                 episode reward: 4.4500,                 loss: nan
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 2665.3,                last time consumption/overall running time: 691.9114s / 368985.4941 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0058
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 3070.55,                last time consumption/overall running time: 789.8340s / 369775.3281 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0055
env0_second_0:                 episode reward: 0.3500,                 loss: nan
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 3334.75,                last time consumption/overall running time: 868.3060s / 370643.6341 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0046
env0_second_0:                 episode reward: 1.9000,                 loss: nan
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 3187.65,                last time consumption/overall running time: 843.6889s / 371487.3230 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.0056
env0_second_0:                 episode reward: 1.8000,                 loss: nan
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 3434.5,                last time consumption/overall running time: 894.4571s / 372381.7802 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0046
env0_second_0:                 episode reward: 2.7000,                 loss: nan
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 3180.0,                last time consumption/overall running time: 838.5257s / 373220.3058 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0047
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 3300.35,                last time consumption/overall running time: 849.8161s / 374070.1219 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0053
env0_second_0:                 episode reward: -0.6000,                 loss: nan
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 3320.25,                last time consumption/overall running time: 859.3569s / 374929.4788 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0042
env0_second_0:                 episode reward: -1.2500,                 loss: nan
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 3335.3,                last time consumption/overall running time: 855.1670s / 375784.6458 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0055
env0_second_0:                 episode reward: 1.3000,                 loss: nan
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 3156.15,                last time consumption/overall running time: 818.4961s / 376603.1419 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.0049
env0_second_0:                 episode reward: -3.1500,                 loss: nan
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 3052.7,                last time consumption/overall running time: 784.6290s / 377387.7709 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0050
env0_second_0:                 episode reward: -0.7000,                 loss: nan
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 2947.8,                last time consumption/overall running time: 764.7104s / 378152.4813 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0054
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 3364.15,                last time consumption/overall running time: 869.9101s / 379022.3914 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0050
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 3587.4,                last time consumption/overall running time: 937.2056s / 379959.5969 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0047
env0_second_0:                 episode reward: 0.1500,                 loss: nan
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 3531.8,                last time consumption/overall running time: 921.1808s / 380880.7778 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0046
env0_second_0:                 episode reward: 0.9000,                 loss: nan
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 3236.25,                last time consumption/overall running time: 840.4055s / 381721.1833 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0049
env0_second_0:                 episode reward: -2.5000,                 loss: nan
env1_first_0:                 episode reward: 6.0000,                 loss: nan
env1_second_0:                 episode reward: -6.0000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 3419.85,                last time consumption/overall running time: 888.1549s / 382609.3382 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.0047
env0_second_0:                 episode reward: -2.8000,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 3216.95,                last time consumption/overall running time: 838.0435s / 383447.3817 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0044
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 3342.8,                last time consumption/overall running time: 878.4446s / 384325.8263 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.0048
env0_second_0:                 episode reward: -3.0000,                 loss: nan
env1_first_0:                 episode reward: 4.5000,                 loss: nan
env1_second_0:                 episode reward: -4.5000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 3112.85,                last time consumption/overall running time: 807.2761s / 385133.1024 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0055
env0_second_0:                 episode reward: 1.3000,                 loss: nan
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 3442.0,                last time consumption/overall running time: 1249.7912s / 386382.8936 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0048
env0_second_0:                 episode reward: 0.4500,                 loss: nan
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 3412.2,                last time consumption/overall running time: 1237.9037s / 387620.7973 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.0052
env0_second_0:                 episode reward: -2.0500,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 2638.4,                last time consumption/overall running time: 957.7545s / 388578.5517 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.0071
env0_second_0:                 episode reward: -3.5000,                 loss: nan
env1_first_0:                 episode reward: 5.6000,                 loss: nan
env1_second_0:                 episode reward: -5.6000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 3373.7,                last time consumption/overall running time: 1227.5850s / 389806.1367 s
env0_first_0:                 episode reward: 3.9500,                 loss: 0.0051
env0_second_0:                 episode reward: -3.9500,                 loss: nan
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 2994.45,                last time consumption/overall running time: 1094.7171s / 390900.8538 s
env0_first_0:                 episode reward: 4.3500,                 loss: 0.0048
env0_second_0:                 episode reward: -4.3500,                 loss: nan
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 3503.95,                last time consumption/overall running time: 1284.8753s / 392185.7291 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0047
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 3337.4,                last time consumption/overall running time: 1211.7813s / 393397.5104 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0045
env0_second_0:                 episode reward: 1.4500,                 loss: nan
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 3175.0,                last time consumption/overall running time: 1150.8178s / 394548.3282 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0055
env0_second_0:                 episode reward: -1.1500,                 loss: nan
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 3578.1,                last time consumption/overall running time: 1277.7204s / 395826.0486 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0051
env0_second_0:                 episode reward: 0.3000,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 3498.85,                last time consumption/overall running time: 1245.4106s / 397071.4592 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0048
env0_second_0:                 episode reward: -0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 3466.75,                last time consumption/overall running time: 1243.3181s / 398314.7774 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0046
env0_second_0:                 episode reward: -2.7000,                 loss: nan
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 3194.15,                last time consumption/overall running time: 1164.7993s / 399479.5766 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0051
env0_second_0:                 episode reward: -1.6500,                 loss: nan
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 3173.75,                last time consumption/overall running time: 1163.8371s / 400643.4137 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.0063
env0_second_0:                 episode reward: -3.6500,                 loss: nan
env1_first_0:                 episode reward: 5.3000,                 loss: nan
env1_second_0:                 episode reward: -5.3000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 3372.9,                last time consumption/overall running time: 1229.4814s / 401872.8951 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0053
env0_second_0:                 episode reward: -1.0500,                 loss: nan
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 3433.4,                last time consumption/overall running time: 1239.9921s / 403112.8872 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0054
env0_second_0:                 episode reward: 0.4000,                 loss: nan
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 3579.6,                last time consumption/overall running time: 1261.7031s / 404374.5903 s
env0_first_0:                 episode reward: 4.8000,                 loss: 0.0050
env0_second_0:                 episode reward: -4.8000,                 loss: nan
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 3354.25,                last time consumption/overall running time: 1195.8658s / 405570.4561 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.0053
env0_second_0:                 episode reward: -3.5000,                 loss: nan
env1_first_0:                 episode reward: 3.9000,                 loss: nan
env1_second_0:                 episode reward: -3.9000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 3270.25,                last time consumption/overall running time: 1178.0408s / 406748.4969 s
env0_first_0:                 episode reward: 3.3500,                 loss: 0.0056
env0_second_0:                 episode reward: -3.3500,                 loss: nan
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 3304.9,                last time consumption/overall running time: 1213.8696s / 407962.3665 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0048
env0_second_0:                 episode reward: -0.6500,                 loss: nan
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 3233.55,                last time consumption/overall running time: 1190.9723s / 409153.3387 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0056
env0_second_0:                 episode reward: -1.9000,                 loss: nan
env1_first_0:                 episode reward: 2.3000,                 loss: nan
env1_second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 3296.2,                last time consumption/overall running time: 1190.3749s / 410343.7137 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.0048
env0_second_0:                 episode reward: 1.8000,                 loss: nan
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 3205.0,                last time consumption/overall running time: 1151.1661s / 411494.8797 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0044
env0_second_0:                 episode reward: -1.2500,                 loss: nan
env1_first_0:                 episode reward: 4.1000,                 loss: nan
env1_second_0:                 episode reward: -4.1000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 3039.75,                last time consumption/overall running time: 1090.1342s / 412585.0139 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.0055
env0_second_0:                 episode reward: -2.8500,                 loss: nan
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 3339.5,                last time consumption/overall running time: 1197.7938s / 413782.8078 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0056
env0_second_0:                 episode reward: 0.6500,                 loss: nan
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 3505.75,                last time consumption/overall running time: 1247.0083s / 415029.8161 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0052
env0_second_0:                 episode reward: -1.1000,                 loss: nan
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 3312.6,                last time consumption/overall running time: 1204.0866s / 416233.9027 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0052
env0_second_0:                 episode reward: -0.4500,                 loss: nan
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 3060.45,                last time consumption/overall running time: 1120.5147s / 417354.4174 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.0049
env0_second_0:                 episode reward: -2.3000,                 loss: nan
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 3337.0,                last time consumption/overall running time: 1209.7494s / 418564.1668 s
env0_first_0:                 episode reward: 3.9000,                 loss: 0.0056
env0_second_0:                 episode reward: -3.9000,                 loss: nan
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 2698.7,                last time consumption/overall running time: 970.3472s / 419534.5140 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0055
env0_second_0:                 episode reward: -0.9500,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 3402.2,                last time consumption/overall running time: 1211.0800s / 420745.5940 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0052
env0_second_0:                 episode reward: 2.0000,                 loss: nan
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 3542.3,                last time consumption/overall running time: 1253.1578s / 421998.7518 s
env0_first_0:                 episode reward: 4.1000,                 loss: 0.0053
env0_second_0:                 episode reward: -4.1000,                 loss: nan
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 3532.45,                last time consumption/overall running time: 1256.0989s / 423254.8507 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0046
env0_second_0:                 episode reward: -0.4000,                 loss: nan
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 3094.05,                last time consumption/overall running time: 1131.6763s / 424386.5271 s