pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
random seed: 91
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f8632bbdac8>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  ./data/model/20220119_0524/pettingzoo_pong_v2_selfplay2/1_0
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220119_0524/pettingzoo_pong_v2_selfplay2/1_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 30, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220119_0524_exploit/pettingzoo_pong_v2_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0524_exploit/pettingzoo_pong_v2_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 973.0,                last time consumption/overall running time: 72.3661s / 72.3661 s
first_0:                 episode reward: 17.0000,                 loss: nan
second_0:                 episode reward: -17.0000,                 loss: 0.0106
Episode: 21/10000 (0.2100%),                 avg. length: 1126.25,                last time consumption/overall running time: 431.8547s / 504.2208 s
first_0:                 episode reward: 2.7000,                 loss: nan
second_0:                 episode reward: -2.7000,                 loss: 0.0025
Episode: 41/10000 (0.4100%),                 avg. length: 1068.95,                last time consumption/overall running time: 422.0053s / 926.2260 s
first_0:                 episode reward: -16.2500,                 loss: nan
second_0:                 episode reward: 16.2500,                 loss: 0.0037
Episode: 61/10000 (0.6100%),                 avg. length: 850.65,                last time consumption/overall running time: 341.3314s / 1267.5574 s
first_0:                 episode reward: -19.9500,                 loss: nan
second_0:                 episode reward: 19.9500,                 loss: 0.0057
Episode: 81/10000 (0.8100%),                 avg. length: 835.15,                last time consumption/overall running time: 338.2117s / 1605.7691 s
first_0:                 episode reward: -20.1000,                 loss: nan
second_0:                 episode reward: 20.1000,                 loss: 0.0051
Episode: 101/10000 (1.0100%),                 avg. length: 834.3,                last time consumption/overall running time: 340.4552s / 1946.2244 s
first_0:                 episode reward: -20.3000,                 loss: nan
second_0:                 episode reward: 20.3000,                 loss: 0.0048
Episode: 121/10000 (1.2100%),                 avg. length: 900.95,                last time consumption/overall running time: 368.0204s / 2314.2448 s
first_0:                 episode reward: -19.4500,                 loss: nan
second_0:                 episode reward: 19.4500,                 loss: 0.0043
Episode: 141/10000 (1.4100%),                 avg. length: 826.9,                last time consumption/overall running time: 334.4922s / 2648.7370 s
first_0:                 episode reward: -20.4000,                 loss: nan
second_0:                 episode reward: 20.4000,                 loss: 0.0032
Episode: 161/10000 (1.6100%),                 avg. length: 921.9,                last time consumption/overall running time: 375.1247s / 3023.8617 s
first_0:                 episode reward: -18.7500,                 loss: nan
second_0:                 episode reward: 18.7500,                 loss: 0.0026
Episode: 181/10000 (1.8100%),                 avg. length: 831.6,                last time consumption/overall running time: 338.4852s / 3362.3469 s
first_0:                 episode reward: -20.2500,                 loss: nan
second_0:                 episode reward: 20.2500,                 loss: 0.0025
Episode: 201/10000 (2.0100%),                 avg. length: 844.45,                last time consumption/overall running time: 344.5248s / 3706.8716 s
first_0:                 episode reward: -20.2000,                 loss: nan
second_0:                 episode reward: 20.2000,                 loss: 0.0023
Episode: 221/10000 (2.2100%),                 avg. length: 839.2,                last time consumption/overall running time: 340.8702s / 4047.7418 s
first_0:                 episode reward: -20.2000,                 loss: nan
second_0:                 episode reward: 20.2000,                 loss: 0.0027
Episode: 241/10000 (2.4100%),                 avg. length: 832.7,                last time consumption/overall running time: 338.1860s / 4385.9278 s
first_0:                 episode reward: -20.4000,                 loss: nan
second_0:                 episode reward: 20.4000,                 loss: 0.0026
Episode: 261/10000 (2.6100%),                 avg. length: 828.75,                last time consumption/overall running time: 336.2351s / 4722.1630 s
first_0:                 episode reward: -20.3500,                 loss: nan
second_0:                 episode reward: 20.3500,                 loss: 0.0022
Episode: 281/10000 (2.8100%),                 avg. length: 827.75,                last time consumption/overall running time: 336.8075s / 5058.9705 s
first_0:                 episode reward: -20.3000,                 loss: nan
second_0:                 episode reward: 20.3000,                 loss: 0.0023
Episode: 301/10000 (3.0100%),                 avg. length: 834.4,                last time consumption/overall running time: 338.8004s / 5397.7709 s
first_0:                 episode reward: -20.4000,                 loss: nan
second_0:                 episode reward: 20.4000,                 loss: 0.0023
Episode: 321/10000 (3.2100%),                 avg. length: 850.35,                last time consumption/overall running time: 346.1648s / 5743.9356 s
first_0:                 episode reward: -20.1500,                 loss: nan
second_0:                 episode reward: 20.1500,                 loss: 0.0025
Episode: 341/10000 (3.4100%),                 avg. length: 842.8,                last time consumption/overall running time: 341.4896s / 6085.4252 s
first_0:                 episode reward: -20.4500,                 loss: nan
second_0:                 episode reward: 20.4500,                 loss: 0.0023
Episode: 361/10000 (3.6100%),                 avg. length: 838.7,                last time consumption/overall running time: 341.6761s / 6427.1013 s
first_0:                 episode reward: -20.2000,                 loss: nan
second_0:                 episode reward: 20.2000,                 loss: 0.0019
Episode: 381/10000 (3.8100%),                 avg. length: 805.45,                last time consumption/overall running time: 327.7832s / 6754.8844 s
first_0:                 episode reward: -20.6500,                 loss: nan
second_0:                 episode reward: 20.6500,                 loss: 0.0019
Episode: 401/10000 (4.0100%),                 avg. length: 820.6,                last time consumption/overall running time: 333.9183s / 7088.8028 s
first_0:                 episode reward: -20.3000,                 loss: nan
second_0:                 episode reward: 20.3000,                 loss: 0.0017
Episode: 421/10000 (4.2100%),                 avg. length: 829.8,                last time consumption/overall running time: 337.0097s / 7425.8125 s
first_0:                 episode reward: -20.2500,                 loss: nan
second_0:                 episode reward: 20.2500,                 loss: 0.0017
Episode: 441/10000 (4.4100%),                 avg. length: 804.95,                last time consumption/overall running time: 327.1909s / 7753.0033 s
first_0:                 episode reward: -20.7000,                 loss: nan
second_0:                 episode reward: 20.7000,                 loss: 0.0017
Episode: 461/10000 (4.6100%),                 avg. length: 785.85,                last time consumption/overall running time: 320.6471s / 8073.6505 s
first_0:                 episode reward: -20.8500,                 loss: nan
second_0:                 episode reward: 20.8500,                 loss: 0.0017
Episode: 481/10000 (4.8100%),                 avg. length: 787.5,                last time consumption/overall running time: 319.9240s / 8393.5745 s
first_0:                 episode reward: -20.6500,                 loss: nan
second_0:                 episode reward: 20.6500,                 loss: 0.0015
Episode: 501/10000 (5.0100%),                 avg. length: 799.45,                last time consumption/overall running time: 324.7364s / 8718.3108 s
first_0:                 episode reward: -20.6500,                 loss: nan
second_0:                 episode reward: 20.6500,                 loss: 0.0014
Episode: 521/10000 (5.2100%),                 avg. length: 792.55,                last time consumption/overall running time: 322.9024s / 9041.2133 s
first_0:                 episode reward: -20.6500,                 loss: nan
second_0:                 episode reward: 20.6500,                 loss: 0.0014
Episode: 541/10000 (5.4100%),                 avg. length: 804.85,                last time consumption/overall running time: 326.8521s / 9368.0653 s
first_0:                 episode reward: -20.6500,                 loss: nan
second_0:                 episode reward: 20.6500,                 loss: 0.0013
Episode: 561/10000 (5.6100%),                 avg. length: 812.45,                last time consumption/overall running time: 329.5051s / 9697.5704 s
first_0:                 episode reward: -20.4000,                 loss: nan
second_0:                 episode reward: 20.4000,                 loss: 0.0010
Episode: 581/10000 (5.8100%),                 avg. length: 840.7,                last time consumption/overall running time: 342.8244s / 10040.3948 s
first_0:                 episode reward: -19.8500,                 loss: nan
second_0:                 episode reward: 19.8500,                 loss: 0.0010
Episode: 601/10000 (6.0100%),                 avg. length: 826.85,                last time consumption/overall running time: 336.5162s / 10376.9109 s
first_0:                 episode reward: -19.9500,                 loss: nan
second_0:                 episode reward: 19.9500,                 loss: 0.0009
Episode: 621/10000 (6.2100%),                 avg. length: 801.4,                last time consumption/overall running time: 325.3208s / 10702.2317 s
first_0:                 episode reward: -20.4000,                 loss: nan
second_0:                 episode reward: 20.4000,                 loss: 0.0007
Episode: 641/10000 (6.4100%),                 avg. length: 782.75,                last time consumption/overall running time: 317.8135s / 11020.0452 s
first_0:                 episode reward: -20.8500,                 loss: nan
second_0:                 episode reward: 20.8500,                 loss: 0.0006
Episode: 661/10000 (6.6100%),                 avg. length: 798.05,                last time consumption/overall running time: 323.6329s / 11343.6781 s
first_0:                 episode reward: -20.7000,                 loss: nan
second_0:                 episode reward: 20.7000,                 loss: 0.0006
Episode: 681/10000 (6.8100%),                 avg. length: 792.65,                last time consumption/overall running time: 323.1942s / 11666.8723 s
first_0:                 episode reward: -20.6000,                 loss: nan
second_0:                 episode reward: 20.6000,                 loss: 0.0005
Episode: 701/10000 (7.0100%),                 avg. length: 831.5,                last time consumption/overall running time: 337.5797s / 12004.4520 s
first_0:                 episode reward: -20.0000,                 loss: nan
second_0:                 episode reward: 20.0000,                 loss: 0.0005
Episode: 721/10000 (7.2100%),                 avg. length: 826.7,                last time consumption/overall running time: 335.6661s / 12340.1181 s
first_0:                 episode reward: -20.5500,                 loss: nan
second_0:                 episode reward: 20.5500,                 loss: 0.0006
Episode: 741/10000 (7.4100%),                 avg. length: 824.5,                last time consumption/overall running time: 334.5182s / 12674.6363 s
first_0:                 episode reward: -20.4000,                 loss: nan
second_0:                 episode reward: 20.4000,                 loss: 0.0007
Episode: 761/10000 (7.6100%),                 avg. length: 795.55,                last time consumption/overall running time: 324.1040s / 12998.7403 s
first_0:                 episode reward: -20.8000,                 loss: nan
second_0:                 episode reward: 20.8000,                 loss: 0.0006
Episode: 781/10000 (7.8100%),                 avg. length: 790.7,                last time consumption/overall running time: 321.1187s / 13319.8590 s
first_0:                 episode reward: -20.7500,                 loss: nan
second_0:                 episode reward: 20.7500,                 loss: 0.0006
Episode: 801/10000 (8.0100%),                 avg. length: 854.1,                last time consumption/overall running time: 346.8503s / 13666.7093 s
first_0:                 episode reward: -19.8000,                 loss: nan
second_0:                 episode reward: 19.8000,                 loss: 0.0007
Episode: 821/10000 (8.2100%),                 avg. length: 775.8,                last time consumption/overall running time: 315.3474s / 13982.0566 s
first_0:                 episode reward: -20.9500,                 loss: nan
second_0:                 episode reward: 20.9500,                 loss: 0.0007
Episode: 841/10000 (8.4100%),                 avg. length: 782.5,                last time consumption/overall running time: 317.8186s / 14299.8752 s
first_0:                 episode reward: -20.9000,                 loss: nan
second_0:                 episode reward: 20.9000,                 loss: 0.0006
Episode: 861/10000 (8.6100%),                 avg. length: 780.0,                last time consumption/overall running time: 318.5739s / 14618.4491 s
first_0:                 episode reward: -20.9000,                 loss: nan
second_0:                 episode reward: 20.9000,                 loss: 0.0004
Episode: 881/10000 (8.8100%),                 avg. length: 801.85,                last time consumption/overall running time: 325.8311s / 14944.2802 s
first_0:                 episode reward: -20.3000,                 loss: nan
second_0:                 episode reward: 20.3000,                 loss: 0.0003
Episode: 901/10000 (9.0100%),                 avg. length: 811.8,                last time consumption/overall running time: 329.8716s / 15274.1518 s
first_0:                 episode reward: -20.4000,                 loss: nan
second_0:                 episode reward: 20.4000,                 loss: 0.0003
Episode: 921/10000 (9.2100%),                 avg. length: 818.1,                last time consumption/overall running time: 332.6984s / 15606.8502 s
first_0:                 episode reward: -20.2500,                 loss: nan
second_0:                 episode reward: 20.2500,                 loss: 0.0003
Episode: 941/10000 (9.4100%),                 avg. length: 813.65,                last time consumption/overall running time: 329.7693s / 15936.6194 s
first_0:                 episode reward: -20.3500,                 loss: nan
second_0:                 episode reward: 20.3500,                 loss: 0.0003
Episode: 961/10000 (9.6100%),                 avg. length: 884.3,                last time consumption/overall running time: 361.5541s / 16298.1736 s
first_0:                 episode reward: -20.2000,                 loss: nan
second_0:                 episode reward: 20.2000,                 loss: 0.0005
Episode: 981/10000 (9.8100%),                 avg. length: 829.95,                last time consumption/overall running time: 337.7718s / 16635.9453 s
first_0:                 episode reward: -20.3500,                 loss: nan
second_0:                 episode reward: 20.3500,                 loss: 0.0006
Episode: 1001/10000 (10.0100%),                 avg. length: 814.8,                last time consumption/overall running time: 331.4633s / 16967.4086 s
first_0:                 episode reward: -20.7000,                 loss: nan
second_0:                 episode reward: 20.7000,                 loss: 0.0006
Episode: 1021/10000 (10.2100%),                 avg. length: 866.5,                last time consumption/overall running time: 352.6885s / 17320.0972 s
first_0:                 episode reward: -19.7500,                 loss: nan
second_0:                 episode reward: 19.7500,                 loss: 0.0007
Episode: 1041/10000 (10.4100%),                 avg. length: 823.05,                last time consumption/overall running time: 334.2745s / 17654.3717 s
first_0:                 episode reward: -20.1000,                 loss: nan
second_0:                 episode reward: 20.1000,                 loss: 0.0007
Episode: 1061/10000 (10.6100%),                 avg. length: 774.15,                last time consumption/overall running time: 315.9224s / 17970.2941 s
first_0:                 episode reward: -20.9000,                 loss: nan
second_0:                 episode reward: 20.9000,                 loss: 0.0007
Episode: 1081/10000 (10.8100%),                 avg. length: 797.95,                last time consumption/overall running time: 324.2747s / 18294.5687 s
first_0:                 episode reward: -20.6000,                 loss: nan
second_0:                 episode reward: 20.6000,                 loss: 0.0006
Episode: 1101/10000 (11.0100%),                 avg. length: 815.05,                last time consumption/overall running time: 331.7712s / 18626.3399 s
first_0:                 episode reward: -20.3500,                 loss: nan
second_0:                 episode reward: 20.3500,                 loss: 0.0005
Episode: 1121/10000 (11.2100%),                 avg. length: 780.6,                last time consumption/overall running time: 318.5197s / 18944.8596 s
first_0:                 episode reward: -20.8000,                 loss: nan
second_0:                 episode reward: 20.8000,                 loss: 0.0004
Episode: 1141/10000 (11.4100%),                 avg. length: 807.05,                last time consumption/overall running time: 327.8342s / 19272.6938 s
first_0:                 episode reward: -20.4500,                 loss: nan
second_0:                 episode reward: 20.4500,                 loss: 0.0003
Episode: 1161/10000 (11.6100%),                 avg. length: 833.65,                last time consumption/overall running time: 339.3136s / 19612.0074 s
first_0:                 episode reward: -20.4500,                 loss: nan
second_0:                 episode reward: 20.4500,                 loss: 0.0004
Episode: 1181/10000 (11.8100%),                 avg. length: 826.1,                last time consumption/overall running time: 335.8817s / 19947.8891 s
first_0:                 episode reward: -20.3500,                 loss: nan
second_0:                 episode reward: 20.3500,                 loss: 0.0004
Episode: 1201/10000 (12.0100%),                 avg. length: 808.45,                last time consumption/overall running time: 328.2889s / 20276.1780 s
first_0:                 episode reward: -20.3000,                 loss: nan
second_0:                 episode reward: 20.3000,                 loss: 0.0003
Episode: 1221/10000 (12.2100%),                 avg. length: 824.8,                last time consumption/overall running time: 336.1447s / 20612.3227 s
first_0:                 episode reward: -20.0500,                 loss: nan
second_0:                 episode reward: 20.0500,                 loss: 0.0004
Episode: 1241/10000 (12.4100%),                 avg. length: 787.9,                last time consumption/overall running time: 320.4996s / 20932.8223 s
first_0:                 episode reward: -20.5000,                 loss: nan
second_0:                 episode reward: 20.5000,                 loss: 0.0004
Episode: 1261/10000 (12.6100%),                 avg. length: 799.1,                last time consumption/overall running time: 326.0746s / 21258.8969 s
first_0:                 episode reward: -20.8000,                 loss: nan
second_0:                 episode reward: 20.8000,                 loss: 0.0004
Episode: 1281/10000 (12.8100%),                 avg. length: 804.85,                last time consumption/overall running time: 326.7073s / 21585.6042 s
first_0:                 episode reward: -20.5500,                 loss: nan
second_0:                 episode reward: 20.5500,                 loss: 0.0005
Episode: 1301/10000 (13.0100%),                 avg. length: 790.1,                last time consumption/overall running time: 321.0541s / 21906.6583 s
first_0:                 episode reward: -20.6500,                 loss: nan
second_0:                 episode reward: 20.6500,                 loss: 0.0006
Episode: 1321/10000 (13.2100%),                 avg. length: 829.8,                last time consumption/overall running time: 337.3713s / 22244.0296 s
first_0:                 episode reward: -20.2500,                 loss: nan
second_0:                 episode reward: 20.2500,                 loss: 0.0006
Episode: 1341/10000 (13.4100%),                 avg. length: 806.0,                last time consumption/overall running time: 327.6374s / 22571.6670 s
first_0:                 episode reward: -20.6500,                 loss: nan
second_0:                 episode reward: 20.6500,                 loss: 0.0005
Episode: 1361/10000 (13.6100%),                 avg. length: 779.5,                last time consumption/overall running time: 316.8663s / 22888.5333 s
first_0:                 episode reward: -20.8000,                 loss: nan
second_0:                 episode reward: 20.8000,                 loss: 0.0006
Episode: 1381/10000 (13.8100%),                 avg. length: 808.0,                last time consumption/overall running time: 329.1175s / 23217.6508 s
first_0:                 episode reward: -20.5000,                 loss: nan
second_0:                 episode reward: 20.5000,                 loss: 0.0005
Episode: 1401/10000 (14.0100%),                 avg. length: 825.25,                last time consumption/overall running time: 335.5600s / 23553.2108 s
first_0:                 episode reward: -20.5000,                 loss: nan
second_0:                 episode reward: 20.5000,                 loss: 0.0005
Episode: 1421/10000 (14.2100%),                 avg. length: 810.85,                last time consumption/overall running time: 328.4769s / 23881.6877 s
first_0:                 episode reward: -20.4000,                 loss: nan
second_0:                 episode reward: 20.4000,                 loss: 0.0004
Episode: 1441/10000 (14.4100%),                 avg. length: 822.75,                last time consumption/overall running time: 334.7272s / 24216.4149 s
first_0:                 episode reward: -20.2000,                 loss: nan
second_0:                 episode reward: 20.2000,                 loss: 0.0004
Episode: 1461/10000 (14.6100%),                 avg. length: 797.95,                last time consumption/overall running time: 323.6289s / 24540.0438 s
first_0:                 episode reward: -20.9000,                 loss: nan
second_0:                 episode reward: 20.9000,                 loss: 0.0004
Episode: 1481/10000 (14.8100%),                 avg. length: 784.45,                last time consumption/overall running time: 321.0819s / 24861.1257 s
first_0:                 episode reward: -20.8000,                 loss: nan
second_0:                 episode reward: 20.8000,                 loss: 0.0003
Episode: 1501/10000 (15.0100%),                 avg. length: 886.45,                last time consumption/overall running time: 361.0900s / 25222.2156 s
first_0:                 episode reward: -18.9500,                 loss: nan
second_0:                 episode reward: 18.9500,                 loss: 0.0004
Episode: 1521/10000 (15.2100%),                 avg. length: 790.8,                last time consumption/overall running time: 322.7605s / 25544.9761 s
first_0:                 episode reward: -20.7500,                 loss: nan
second_0:                 episode reward: 20.7500,                 loss: 0.0005
Episode: 1541/10000 (15.4100%),                 avg. length: 808.65,                last time consumption/overall running time: 328.4050s / 25873.3811 s
first_0:                 episode reward: -20.2500,                 loss: nan
second_0:                 episode reward: 20.2500,                 loss: 0.0005
Episode: 1561/10000 (15.6100%),                 avg. length: 805.55,                last time consumption/overall running time: 327.0441s / 26200.4252 s
first_0:                 episode reward: -20.6500,                 loss: nan
second_0:                 episode reward: 20.6500,                 loss: 0.0005
Episode: 1581/10000 (15.8100%),                 avg. length: 788.0,                last time consumption/overall running time: 320.1844s / 26520.6096 s
first_0:                 episode reward: -20.7000,                 loss: nan
second_0:                 episode reward: 20.7000,                 loss: 0.0004
Episode: 1601/10000 (16.0100%),                 avg. length: 787.25,                last time consumption/overall running time: 317.4079s / 26838.0174 s
first_0:                 episode reward: -20.8500,                 loss: nan
second_0:                 episode reward: 20.8500,                 loss: 0.0004
Episode: 1621/10000 (16.2100%),                 avg. length: 814.25,                last time consumption/overall running time: 329.2340s / 27167.2515 s
first_0:                 episode reward: -20.3000,                 loss: nan
second_0:                 episode reward: 20.3000,                 loss: 0.0003
Episode: 1641/10000 (16.4100%),                 avg. length: 829.35,                last time consumption/overall running time: 336.5688s / 27503.8203 s
first_0:                 episode reward: -20.4000,                 loss: nan
second_0:                 episode reward: 20.4000,                 loss: 0.0003
Episode: 1661/10000 (16.6100%),                 avg. length: 818.85,                last time consumption/overall running time: 333.3113s / 27837.1316 s
first_0:                 episode reward: -20.6500,                 loss: nan
second_0:                 episode reward: 20.6500,                 loss: 0.0003
Episode: 1681/10000 (16.8100%),                 avg. length: 794.6,                last time consumption/overall running time: 323.6444s / 28160.7760 s
first_0:                 episode reward: -20.8000,                 loss: nan
second_0:                 episode reward: 20.8000,                 loss: 0.0003
Episode: 1701/10000 (17.0100%),                 avg. length: 805.2,                last time consumption/overall running time: 326.5961s / 28487.3721 s
first_0:                 episode reward: -20.6500,                 loss: nan
second_0:                 episode reward: 20.6500,                 loss: 0.0003
Episode: 1721/10000 (17.2100%),                 avg. length: 804.0,                last time consumption/overall running time: 325.1089s / 28812.4809 s
first_0:                 episode reward: -20.7500,                 loss: nan
second_0:                 episode reward: 20.7500,                 loss: 0.0004
Episode: 1741/10000 (17.4100%),                 avg. length: 805.85,                last time consumption/overall running time: 326.4575s / 29138.9385 s
first_0:                 episode reward: -20.4000,                 loss: nan
second_0:                 episode reward: 20.4000,                 loss: 0.0004
Episode: 1761/10000 (17.6100%),                 avg. length: 809.7,                last time consumption/overall running time: 329.5766s / 29468.5151 s
first_0:                 episode reward: -20.4500,                 loss: nan
second_0:                 episode reward: 20.4500,                 loss: 0.0003
Episode: 1781/10000 (17.8100%),                 avg. length: 827.65,                last time consumption/overall running time: 336.0354s / 29804.5505 s
first_0:                 episode reward: -20.2000,                 loss: nan
second_0:                 episode reward: 20.2000,                 loss: 0.0004
Episode: 1801/10000 (18.0100%),                 avg. length: 801.35,                last time consumption/overall running time: 325.1523s / 30129.7028 s
first_0:                 episode reward: -20.3500,                 loss: nan
second_0:                 episode reward: 20.3500,                 loss: 0.0004
Episode: 1821/10000 (18.2100%),                 avg. length: 808.05,                last time consumption/overall running time: 328.5368s / 30458.2396 s
first_0:                 episode reward: -20.4000,                 loss: nan
second_0:                 episode reward: 20.4000,                 loss: 0.0005
Episode: 1841/10000 (18.4100%),                 avg. length: 794.65,                last time consumption/overall running time: 323.9742s / 30782.2138 s
first_0:                 episode reward: -20.6000,                 loss: nan
second_0:                 episode reward: 20.6000,                 loss: 0.0005
Episode: 1861/10000 (18.6100%),                 avg. length: 822.75,                last time consumption/overall running time: 333.3712s / 31115.5850 s
first_0:                 episode reward: -19.1500,                 loss: nan
second_0:                 episode reward: 19.1500,                 loss: 0.0005
Episode: 1881/10000 (18.8100%),                 avg. length: 802.7,                last time consumption/overall running time: 326.0638s / 31441.6488 s
first_0:                 episode reward: -20.4000,                 loss: nan
second_0:                 episode reward: 20.4000,                 loss: 0.0004
Episode: 1901/10000 (19.0100%),                 avg. length: 838.7,                last time consumption/overall running time: 340.1234s / 31781.7722 s
first_0:                 episode reward: -19.3500,                 loss: nan
second_0:                 episode reward: 19.3500,                 loss: 0.0004
Episode: 1921/10000 (19.2100%),                 avg. length: 850.45,                last time consumption/overall running time: 343.5672s / 32125.3394 s
first_0:                 episode reward: -19.9000,                 loss: nan
second_0:                 episode reward: 19.9000,                 loss: 0.0004
Episode: 1941/10000 (19.4100%),                 avg. length: 838.2,                last time consumption/overall running time: 337.8788s / 32463.2182 s
first_0:                 episode reward: -20.3000,                 loss: nan
second_0:                 episode reward: 20.3000,                 loss: 0.0005