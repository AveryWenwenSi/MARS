pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
random seed: 69
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f5d475ad198>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=1024, bias=True)
      (1): Tanh()
      (2): Linear(in_features=1024, out_features=1024, bias=True)
      (3): Tanh()
      (4): Linear(in_features=1024, out_features=1024, bias=True)
      (5): Tanh()
      (6): Linear(in_features=1024, out_features=6, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=1024, bias=True)
      (1): Tanh()
      (2): Linear(in_features=1024, out_features=1024, bias=True)
      (3): Tanh()
      (4): Linear(in_features=1024, out_features=1024, bias=True)
      (5): Tanh()
      (6): Linear(in_features=1024, out_features=6, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [array([0.043, 0.043, 0.043, ..., 0.043, 0.043, 0.043]) array([0.045, 0.045, 0.045, ..., 0.045, 0.045, 0.045])]
Load checkpoints (policy family):  [list(['49', '1109', '1363', '2349', '2899', '3213', '4001', '4486', '4644', '4796', '4965', '5613', '6265', '6718', '7072', '7204', '7307', '7473', '7551', '7613', '7788', '7870', '7987'])
 list(['702', '1158', '1398', '2404', '2940', '3269', '4042', '4543', '4712', '4862', '5022', '5679', '6290', '6746', '7170', '7246', '7404', '7503', '7591', '7745', '7816', '7963'])]
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 1, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 32, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220119_0524/slimevolley_SlimeVolley-v0_fictitious_selfplay2/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [1024, 1024, 1024], 'hidden_activation': 'Tanh', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 4, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
Save models to : /home/zihan/research/MARS/data/model/20220119_0524_exploit/slimevolley_SlimeVolley-v0_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0524_exploit/slimevolley_SlimeVolley-v0_fictitious_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 412.0,                last time consumption/overall running time: 6.3495s / 6.3495 s
first_0:                 episode reward: 5.0000,                 loss: nan
second_0:                 episode reward: -5.0000,                 loss: 0.0033
Episode: 21/10000 (0.2100%),                 avg. length: 678.45,                last time consumption/overall running time: 184.4166s / 190.7661 s
first_0:                 episode reward: 2.4000,                 loss: nan
second_0:                 episode reward: -2.4000,                 loss: 0.0064
Episode: 41/10000 (0.4100%),                 avg. length: 718.15,                last time consumption/overall running time: 200.4295s / 391.1956 s
first_0:                 episode reward: 3.2000,                 loss: nan
second_0:                 episode reward: -3.2000,                 loss: 0.0090
Episode: 61/10000 (0.6100%),                 avg. length: 614.4,                last time consumption/overall running time: 174.3425s / 565.5381 s
first_0:                 episode reward: 3.4000,                 loss: nan
second_0:                 episode reward: -3.4000,                 loss: 0.0101
Episode: 81/10000 (0.8100%),                 avg. length: 708.35,                last time consumption/overall running time: 203.1663s / 768.7044 s
first_0:                 episode reward: 2.5500,                 loss: nan
second_0:                 episode reward: -2.5500,                 loss: 0.0114
Episode: 101/10000 (1.0100%),                 avg. length: 623.65,                last time consumption/overall running time: 179.5174s / 948.2218 s
first_0:                 episode reward: 2.1000,                 loss: nan
second_0:                 episode reward: -2.1000,                 loss: 0.0122
Episode: 121/10000 (1.2100%),                 avg. length: 712.9,                last time consumption/overall running time: 206.1004s / 1154.3221 s
first_0:                 episode reward: 2.6500,                 loss: nan
second_0:                 episode reward: -2.6500,                 loss: 0.0141
Episode: 141/10000 (1.4100%),                 avg. length: 737.9,                last time consumption/overall running time: 213.3316s / 1367.6537 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0153
Episode: 161/10000 (1.6100%),                 avg. length: 765.9,                last time consumption/overall running time: 222.5691s / 1590.2228 s
first_0:                 episode reward: 3.3000,                 loss: nan
second_0:                 episode reward: -3.3000,                 loss: 0.0149
Episode: 181/10000 (1.8100%),                 avg. length: 778.1,                last time consumption/overall running time: 225.6166s / 1815.8395 s
first_0:                 episode reward: 2.9500,                 loss: nan
second_0:                 episode reward: -2.9500,                 loss: 0.0140
Episode: 201/10000 (2.0100%),                 avg. length: 749.9,                last time consumption/overall running time: 217.2678s / 2033.1072 s
first_0:                 episode reward: 3.2500,                 loss: nan
second_0:                 episode reward: -3.2500,                 loss: 0.0161
Episode: 221/10000 (2.2100%),                 avg. length: 763.45,                last time consumption/overall running time: 221.2094s / 2254.3166 s
first_0:                 episode reward: 1.3500,                 loss: nan
second_0:                 episode reward: -1.3500,                 loss: 0.0162
Episode: 241/10000 (2.4100%),                 avg. length: 754.5,                last time consumption/overall running time: 219.6268s / 2473.9433 s
first_0:                 episode reward: 3.1500,                 loss: nan
second_0:                 episode reward: -3.1500,                 loss: 0.0146
Episode: 261/10000 (2.6100%),                 avg. length: 728.1,                last time consumption/overall running time: 211.3249s / 2685.2683 s
first_0:                 episode reward: 2.7000,                 loss: nan
second_0:                 episode reward: -2.7000,                 loss: 0.0164
Episode: 281/10000 (2.8100%),                 avg. length: 802.35,                last time consumption/overall running time: 233.0770s / 2918.3453 s
first_0:                 episode reward: 1.6500,                 loss: nan
second_0:                 episode reward: -1.6500,                 loss: 0.0176
Episode: 301/10000 (3.0100%),                 avg. length: 772.85,                last time consumption/overall running time: 224.8329s / 3143.1782 s
first_0:                 episode reward: 2.4500,                 loss: nan
second_0:                 episode reward: -2.4500,                 loss: 0.0171
Episode: 321/10000 (3.2100%),                 avg. length: 773.6,                last time consumption/overall running time: 225.3459s / 3368.5241 s
first_0:                 episode reward: 1.8000,                 loss: nan
second_0:                 episode reward: -1.8000,                 loss: 0.0175
Episode: 341/10000 (3.4100%),                 avg. length: 872.0,                last time consumption/overall running time: 253.0602s / 3621.5843 s
first_0:                 episode reward: 1.8000,                 loss: nan
second_0:                 episode reward: -1.8000,                 loss: 0.0191
Episode: 361/10000 (3.6100%),                 avg. length: 792.0,                last time consumption/overall running time: 229.5269s / 3851.1112 s
first_0:                 episode reward: 2.6500,                 loss: nan
second_0:                 episode reward: -2.6500,                 loss: 0.0172
Episode: 381/10000 (3.8100%),                 avg. length: 858.9,                last time consumption/overall running time: 249.7856s / 4100.8968 s
first_0:                 episode reward: 3.3000,                 loss: nan
second_0:                 episode reward: -3.3000,                 loss: 0.0164
Episode: 401/10000 (4.0100%),                 avg. length: 884.15,                last time consumption/overall running time: 256.4927s / 4357.3895 s
first_0:                 episode reward: 1.9500,                 loss: nan
second_0:                 episode reward: -1.9500,                 loss: 0.0162
Episode: 421/10000 (4.2100%),                 avg. length: 1184.35,                last time consumption/overall running time: 343.6381s / 4701.0277 s
first_0:                 episode reward: 1.9000,                 loss: nan
second_0:                 episode reward: -1.9000,                 loss: 0.0144
Episode: 441/10000 (4.4100%),                 avg. length: 1043.2,                last time consumption/overall running time: 302.0531s / 5003.0808 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0125
Episode: 461/10000 (4.6100%),                 avg. length: 1266.2,                last time consumption/overall running time: 367.2817s / 5370.3624 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0144
Episode: 481/10000 (4.8100%),                 avg. length: 1463.35,                last time consumption/overall running time: 424.1097s / 5794.4722 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0122
Episode: 501/10000 (5.0100%),                 avg. length: 1421.25,                last time consumption/overall running time: 412.4552s / 6206.9274 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0098
Episode: 521/10000 (5.2100%),                 avg. length: 1683.65,                last time consumption/overall running time: 487.4391s / 6694.3665 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0088
Episode: 541/10000 (5.4100%),                 avg. length: 1524.9,                last time consumption/overall running time: 442.5344s / 7136.9010 s
first_0:                 episode reward: -1.0000,                 loss: nan
second_0:                 episode reward: 1.0000,                 loss: 0.0082
Episode: 561/10000 (5.6100%),                 avg. length: 1359.3,                last time consumption/overall running time: 394.1625s / 7531.0635 s
first_0:                 episode reward: -2.2000,                 loss: nan
second_0:                 episode reward: 2.2000,                 loss: 0.0077
Episode: 581/10000 (5.8100%),                 avg. length: 1492.4,                last time consumption/overall running time: 432.0736s / 7963.1371 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0080
Episode: 601/10000 (6.0100%),                 avg. length: 1354.0,                last time consumption/overall running time: 393.2494s / 8356.3865 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0071
Episode: 621/10000 (6.2100%),                 avg. length: 1539.45,                last time consumption/overall running time: 446.8711s / 8803.2577 s
first_0:                 episode reward: -1.8000,                 loss: nan
second_0:                 episode reward: 1.8000,                 loss: 0.0075
Episode: 641/10000 (6.4100%),                 avg. length: 1166.95,                last time consumption/overall running time: 338.7391s / 9141.9967 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0077
Episode: 661/10000 (6.6100%),                 avg. length: 1145.2,                last time consumption/overall running time: 332.4933s / 9474.4900 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0081
Episode: 681/10000 (6.8100%),                 avg. length: 1380.45,                last time consumption/overall running time: 400.5146s / 9875.0046 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0082
Episode: 701/10000 (7.0100%),                 avg. length: 1542.7,                last time consumption/overall running time: 447.4921s / 10322.4967 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0084
Episode: 721/10000 (7.2100%),                 avg. length: 1540.25,                last time consumption/overall running time: 446.6748s / 10769.1714 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0093
Episode: 741/10000 (7.4100%),                 avg. length: 1378.6,                last time consumption/overall running time: 400.5556s / 11169.7270 s
first_0:                 episode reward: -2.6500,                 loss: nan
second_0:                 episode reward: 2.6500,                 loss: 0.0079
Episode: 761/10000 (7.6100%),                 avg. length: 1615.45,                last time consumption/overall running time: 468.5700s / 11638.2970 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0074
Episode: 781/10000 (7.8100%),                 avg. length: 1118.65,                last time consumption/overall running time: 325.7502s / 11964.0473 s
first_0:                 episode reward: -1.9500,                 loss: nan
second_0:                 episode reward: 1.9500,                 loss: 0.0071
Episode: 801/10000 (8.0100%),                 avg. length: 1218.2,                last time consumption/overall running time: 353.6361s / 12317.6833 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0075
Episode: 821/10000 (8.2100%),                 avg. length: 1164.25,                last time consumption/overall running time: 337.8641s / 12655.5475 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0082
Episode: 841/10000 (8.4100%),                 avg. length: 1435.95,                last time consumption/overall running time: 415.9115s / 13071.4590 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0085
Episode: 861/10000 (8.6100%),                 avg. length: 1330.2,                last time consumption/overall running time: 386.1059s / 13457.5649 s
first_0:                 episode reward: -0.2500,                 loss: nan
second_0:                 episode reward: 0.2500,                 loss: 0.0085
Episode: 881/10000 (8.8100%),                 avg. length: 1409.1,                last time consumption/overall running time: 408.0703s / 13865.6352 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0093
Episode: 901/10000 (9.0100%),                 avg. length: 1787.4,                last time consumption/overall running time: 518.1165s / 14383.7516 s
first_0:                 episode reward: -2.0500,                 loss: nan
second_0:                 episode reward: 2.0500,                 loss: 0.0093
Episode: 921/10000 (9.2100%),                 avg. length: 1252.65,                last time consumption/overall running time: 362.5086s / 14746.2602 s
first_0:                 episode reward: -2.1500,                 loss: nan
second_0:                 episode reward: 2.1500,                 loss: 0.0080
Episode: 941/10000 (9.4100%),                 avg. length: 1408.25,                last time consumption/overall running time: 408.4059s / 15154.6661 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0082
Episode: 961/10000 (9.6100%),                 avg. length: 1214.35,                last time consumption/overall running time: 352.6143s / 15507.2804 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0078
Episode: 981/10000 (9.8100%),                 avg. length: 1167.6,                last time consumption/overall running time: 339.1756s / 15846.4560 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0088
Episode: 1001/10000 (10.0100%),                 avg. length: 1358.2,                last time consumption/overall running time: 393.6468s / 16240.1028 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0097
Episode: 1021/10000 (10.2100%),                 avg. length: 1320.0,                last time consumption/overall running time: 382.5401s / 16622.6429 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0119
Episode: 1041/10000 (10.4100%),                 avg. length: 1564.1,                last time consumption/overall running time: 452.8423s / 17075.4852 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0110
Episode: 1061/10000 (10.6100%),                 avg. length: 1442.4,                last time consumption/overall running time: 419.2662s / 17494.7514 s
first_0:                 episode reward: -2.7000,                 loss: nan
second_0:                 episode reward: 2.7000,                 loss: 0.0098
Episode: 1081/10000 (10.8100%),                 avg. length: 1303.4,                last time consumption/overall running time: 379.1285s / 17873.8799 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0091
Episode: 1101/10000 (11.0100%),                 avg. length: 1103.65,                last time consumption/overall running time: 320.7788s / 18194.6587 s
first_0:                 episode reward: -0.2000,                 loss: nan
second_0:                 episode reward: 0.2000,                 loss: 0.0090
Episode: 1121/10000 (11.2100%),                 avg. length: 1057.25,                last time consumption/overall running time: 306.1956s / 18500.8543 s
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0096
Episode: 1141/10000 (11.4100%),                 avg. length: 1374.35,                last time consumption/overall running time: 399.0580s / 18899.9123 s
first_0:                 episode reward: -2.1500,                 loss: nan
second_0:                 episode reward: 2.1500,                 loss: 0.0111
Episode: 1161/10000 (11.6100%),                 avg. length: 1406.1,                last time consumption/overall running time: 408.7781s / 19308.6904 s
first_0:                 episode reward: -2.1000,                 loss: nan
second_0:                 episode reward: 2.1000,                 loss: 0.0098
Episode: 1181/10000 (11.8100%),                 avg. length: 1154.5,                last time consumption/overall running time: 335.0226s / 19643.7130 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0093
Episode: 1201/10000 (12.0100%),                 avg. length: 1066.55,                last time consumption/overall running time: 310.6963s / 19954.4093 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0098
Episode: 1221/10000 (12.2100%),                 avg. length: 1240.55,                last time consumption/overall running time: 360.4341s / 20314.8434 s
first_0:                 episode reward: 1.5500,                 loss: nan
second_0:                 episode reward: -1.5500,                 loss: 0.0107
Episode: 1241/10000 (12.4100%),                 avg. length: 1063.25,                last time consumption/overall running time: 309.2324s / 20624.0758 s
first_0:                 episode reward: -0.7000,                 loss: nan
second_0:                 episode reward: 0.7000,                 loss: 0.0130
Episode: 1261/10000 (12.6100%),                 avg. length: 1545.05,                last time consumption/overall running time: 448.9934s / 21073.0691 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0147
Episode: 1281/10000 (12.8100%),                 avg. length: 1445.65,                last time consumption/overall running time: 419.7789s / 21492.8480 s
first_0:                 episode reward: -0.4000,                 loss: nan
second_0:                 episode reward: 0.4000,                 loss: 0.0130
Episode: 1301/10000 (13.0100%),                 avg. length: 1255.1,                last time consumption/overall running time: 364.5722s / 21857.4202 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0113
Episode: 1321/10000 (13.2100%),                 avg. length: 1080.8,                last time consumption/overall running time: 313.7334s / 22171.1535 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0110
Episode: 1341/10000 (13.4100%),                 avg. length: 1171.5,                last time consumption/overall running time: 340.0686s / 22511.2221 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0125
Episode: 1361/10000 (13.6100%),                 avg. length: 1171.95,                last time consumption/overall running time: 339.9143s / 22851.1364 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0143
Episode: 1381/10000 (13.8100%),                 avg. length: 1433.9,                last time consumption/overall running time: 415.6794s / 23266.8159 s
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0149
Episode: 1401/10000 (14.0100%),                 avg. length: 1196.3,                last time consumption/overall running time: 347.1238s / 23613.9396 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0126
Episode: 1421/10000 (14.2100%),                 avg. length: 1005.6,                last time consumption/overall running time: 292.0767s / 23906.0163 s
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0131
Episode: 1441/10000 (14.4100%),                 avg. length: 1021.05,                last time consumption/overall running time: 296.3750s / 24202.3913 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0134
Episode: 1461/10000 (14.6100%),                 avg. length: 990.7,                last time consumption/overall running time: 288.0876s / 24490.4789 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0149
Episode: 1481/10000 (14.8100%),                 avg. length: 1113.5,                last time consumption/overall running time: 323.0250s / 24813.5039 s
first_0:                 episode reward: 0.8500,                 loss: nan
second_0:                 episode reward: -0.8500,                 loss: 0.0162
Episode: 1501/10000 (15.0100%),                 avg. length: 1087.6,                last time consumption/overall running time: 316.8069s / 25130.3109 s
first_0:                 episode reward: 0.2000,                 loss: nan
second_0:                 episode reward: -0.2000,                 loss: 0.0155
Episode: 1521/10000 (15.2100%),                 avg. length: 1205.45,                last time consumption/overall running time: 350.1889s / 25480.4997 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0160
Episode: 1541/10000 (15.4100%),                 avg. length: 1048.1,                last time consumption/overall running time: 305.2484s / 25785.7481 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0165
Episode: 1561/10000 (15.6100%),                 avg. length: 928.15,                last time consumption/overall running time: 269.9449s / 26055.6930 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0158
Episode: 1581/10000 (15.8100%),                 avg. length: 1045.65,                last time consumption/overall running time: 303.7817s / 26359.4747 s
first_0:                 episode reward: 0.1500,                 loss: nan
second_0:                 episode reward: -0.1500,                 loss: 0.0150
Episode: 1601/10000 (16.0100%),                 avg. length: 924.8,                last time consumption/overall running time: 269.3496s / 26628.8244 s
first_0:                 episode reward: 0.5000,                 loss: nan
second_0:                 episode reward: -0.5000,                 loss: 0.0148
Episode: 1621/10000 (16.2100%),                 avg. length: 930.55,                last time consumption/overall running time: 270.5304s / 26899.3548 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0152
Episode: 1641/10000 (16.4100%),                 avg. length: 924.45,                last time consumption/overall running time: 269.0689s / 27168.4237 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0159
Episode: 1661/10000 (16.6100%),                 avg. length: 860.5,                last time consumption/overall running time: 250.5397s / 27418.9634 s
first_0:                 episode reward: 2.0500,                 loss: nan
second_0:                 episode reward: -2.0500,                 loss: 0.0152
Episode: 1681/10000 (16.8100%),                 avg. length: 818.35,                last time consumption/overall running time: 238.3379s / 27657.3013 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0170
Episode: 1701/10000 (17.0100%),                 avg. length: 878.1,                last time consumption/overall running time: 255.3862s / 27912.6875 s
first_0:                 episode reward: 1.6000,                 loss: nan
second_0:                 episode reward: -1.6000,                 loss: 0.0188
Episode: 1721/10000 (17.2100%),                 avg. length: 811.85,                last time consumption/overall running time: 236.4560s / 28149.1435 s
first_0:                 episode reward: 0.9000,                 loss: nan
second_0:                 episode reward: -0.9000,                 loss: 0.0203
Episode: 1741/10000 (17.4100%),                 avg. length: 826.25,                last time consumption/overall running time: 240.3332s / 28389.4767 s
first_0:                 episode reward: 1.2000,                 loss: nan
second_0:                 episode reward: -1.2000,                 loss: 0.0187
Episode: 1761/10000 (17.6100%),                 avg. length: 825.95,                last time consumption/overall running time: 240.4981s / 28629.9748 s
first_0:                 episode reward: 1.7000,                 loss: nan
second_0:                 episode reward: -1.7000,                 loss: 0.0202
Episode: 1781/10000 (17.8100%),                 avg. length: 861.25,                last time consumption/overall running time: 250.6652s / 28880.6400 s
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.0220
Episode: 1801/10000 (18.0100%),                 avg. length: 691.1,                last time consumption/overall running time: 201.5481s / 29082.1881 s
first_0:                 episode reward: 2.4000,                 loss: nan
second_0:                 episode reward: -2.4000,                 loss: 0.0202
Episode: 1821/10000 (18.2100%),                 avg. length: 857.0,                last time consumption/overall running time: 249.8837s / 29332.0718 s
first_0:                 episode reward: 1.0000,                 loss: nan
second_0:                 episode reward: -1.0000,                 loss: 0.0205
Episode: 1841/10000 (18.4100%),                 avg. length: 765.65,                last time consumption/overall running time: 222.9742s / 29555.0460 s
first_0:                 episode reward: 1.9000,                 loss: nan
second_0:                 episode reward: -1.9000,                 loss: 0.0249
Episode: 1861/10000 (18.6100%),                 avg. length: 864.55,                last time consumption/overall running time: 250.8812s / 29805.9272 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0227
Episode: 1881/10000 (18.8100%),                 avg. length: 1009.25,                last time consumption/overall running time: 293.6901s / 30099.6173 s
first_0:                 episode reward: 2.5000,                 loss: nan
second_0:                 episode reward: -2.5000,                 loss: 0.0215
Episode: 1901/10000 (19.0100%),                 avg. length: 953.25,                last time consumption/overall running time: 277.7612s / 30377.3784 s
first_0:                 episode reward: 2.2000,                 loss: nan
second_0:                 episode reward: -2.2000,                 loss: 0.0228
Episode: 1921/10000 (19.2100%),                 avg. length: 1012.1,                last time consumption/overall running time: 293.6094s / 30670.9878 s
first_0:                 episode reward: 2.4000,                 loss: nan
second_0:                 episode reward: -2.4000,                 loss: 0.0247
Episode: 1941/10000 (19.4100%),                 avg. length: 974.3,                last time consumption/overall running time: 283.7010s / 30954.6889 s
first_0:                 episode reward: 1.5500,                 loss: nan
second_0:                 episode reward: -1.5500,                 loss: 0.0223
Episode: 1961/10000 (19.6100%),                 avg. length: 1011.75,                last time consumption/overall running time: 293.5390s / 31248.2278 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0192
Episode: 1981/10000 (19.8100%),                 avg. length: 834.2,                last time consumption/overall running time: 243.0629s / 31491.2907 s
first_0:                 episode reward: 2.1500,                 loss: nan
second_0:                 episode reward: -2.1500,                 loss: 0.0188
Episode: 2001/10000 (20.0100%),                 avg. length: 970.55,                last time consumption/overall running time: 282.4110s / 31773.7018 s
first_0:                 episode reward: 1.4000,                 loss: nan
second_0:                 episode reward: -1.4000,                 loss: 0.0195
Episode: 2021/10000 (20.2100%),                 avg. length: 993.9,                last time consumption/overall running time: 288.5077s / 32062.2095 s
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.0188
Episode: 2041/10000 (20.4100%),                 avg. length: 1057.9,                last time consumption/overall running time: 307.5125s / 32369.7219 s
first_0:                 episode reward: -0.1500,                 loss: nan
second_0:                 episode reward: 0.1500,                 loss: 0.0205
Episode: 2061/10000 (20.6100%),                 avg. length: 1015.7,                last time consumption/overall running time: 295.3414s / 32665.0634 s
first_0:                 episode reward: 1.1500,                 loss: nan
second_0:                 episode reward: -1.1500,                 loss: 0.0221
Episode: 2081/10000 (20.8100%),                 avg. length: 995.6,                last time consumption/overall running time: 290.0455s / 32955.1089 s
first_0:                 episode reward: 1.2500,                 loss: nan
second_0:                 episode reward: -1.2500,                 loss: 0.0208
Episode: 2101/10000 (21.0100%),                 avg. length: 965.65,                last time consumption/overall running time: 280.8516s / 33235.9605 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0185
Episode: 2121/10000 (21.2100%),                 avg. length: 858.5,                last time consumption/overall running time: 249.1850s / 33485.1454 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0179
Episode: 2141/10000 (21.4100%),                 avg. length: 913.0,                last time consumption/overall running time: 266.1221s / 33751.2675 s
first_0:                 episode reward: 0.8000,                 loss: nan
second_0:                 episode reward: -0.8000,                 loss: 0.0182
Episode: 2161/10000 (21.6100%),                 avg. length: 991.9,                last time consumption/overall running time: 288.7174s / 34039.9849 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0213
Episode: 2181/10000 (21.8100%),                 avg. length: 1062.95,                last time consumption/overall running time: 308.3117s / 34348.2967 s
first_0:                 episode reward: 1.8000,                 loss: nan
second_0:                 episode reward: -1.8000,                 loss: 0.0201
Episode: 2201/10000 (22.0100%),                 avg. length: 1033.0,                last time consumption/overall running time: 300.8382s / 34649.1349 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0225
Episode: 2221/10000 (22.2100%),                 avg. length: 978.4,                last time consumption/overall running time: 285.1437s / 34934.2786 s
first_0:                 episode reward: 2.1000,                 loss: nan
second_0:                 episode reward: -2.1000,                 loss: 0.0214
Episode: 2241/10000 (22.4100%),                 avg. length: 1072.85,                last time consumption/overall running time: 313.2178s / 35247.4964 s
first_0:                 episode reward: 1.6000,                 loss: nan
second_0:                 episode reward: -1.6000,                 loss: 0.0204
Episode: 2261/10000 (22.6100%),                 avg. length: 950.1,                last time consumption/overall running time: 276.4545s / 35523.9509 s
first_0:                 episode reward: 0.0500,                 loss: nan
second_0:                 episode reward: -0.0500,                 loss: 0.0197
Episode: 2281/10000 (22.8100%),                 avg. length: 1015.7,                last time consumption/overall running time: 295.4492s / 35819.4001 s
first_0:                 episode reward: 1.5500,                 loss: nan
second_0:                 episode reward: -1.5500,                 loss: 0.0197
Episode: 2301/10000 (23.0100%),                 avg. length: 861.4,                last time consumption/overall running time: 250.3183s / 36069.7185 s
first_0:                 episode reward: 1.6000,                 loss: nan
second_0:                 episode reward: -1.6000,                 loss: 0.0194
Episode: 2321/10000 (23.2100%),                 avg. length: 929.3,                last time consumption/overall running time: 270.5814s / 36340.2999 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0208
Episode: 2341/10000 (23.4100%),                 avg. length: 890.1,                last time consumption/overall running time: 259.4617s / 36599.7616 s
first_0:                 episode reward: 0.9500,                 loss: nan
second_0:                 episode reward: -0.9500,                 loss: 0.0184
Episode: 2361/10000 (23.6100%),                 avg. length: 800.2,                last time consumption/overall running time: 233.2169s / 36832.9784 s
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.0187
Episode: 2381/10000 (23.8100%),                 avg. length: 842.4,                last time consumption/overall running time: 245.7722s / 37078.7506 s
first_0:                 episode reward: 1.9500,                 loss: nan
second_0:                 episode reward: -1.9500,                 loss: 0.0200
Episode: 2401/10000 (24.0100%),                 avg. length: 769.75,                last time consumption/overall running time: 223.9748s / 37302.7255 s
first_0:                 episode reward: 2.1500,                 loss: nan
second_0:                 episode reward: -2.1500,                 loss: 0.0226
Episode: 2421/10000 (24.2100%),                 avg. length: 860.0,                last time consumption/overall running time: 250.3413s / 37553.0667 s
first_0:                 episode reward: 2.7000,                 loss: nan
second_0:                 episode reward: -2.7000,                 loss: 0.0238
Episode: 2441/10000 (24.4100%),                 avg. length: 874.4,                last time consumption/overall running time: 253.9049s / 37806.9717 s
first_0:                 episode reward: 2.4000,                 loss: nan
second_0:                 episode reward: -2.4000,                 loss: 0.0255
Episode: 2461/10000 (24.6100%),                 avg. length: 903.15,                last time consumption/overall running time: 263.1826s / 38070.1543 s
first_0:                 episode reward: 2.6500,                 loss: nan
second_0:                 episode reward: -2.6500,                 loss: 0.0238
Episode: 2481/10000 (24.8100%),                 avg. length: 844.3,                last time consumption/overall running time: 246.3461s / 38316.5004 s