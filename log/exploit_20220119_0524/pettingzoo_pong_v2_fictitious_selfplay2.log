/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
random seed: 91
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f59cbc0f668>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [array([0.014, 0.014, 0.014, ..., 0.014, 0.014, 0.014]) array([0.014, 0.014, 0.014, ..., 0.014, 0.014, 0.014])]
Load checkpoints (policy family):  [list(['21', '91', '177', '219', '339', '525', '630', '711', '789', '844', '886', '960', '1024', '1089', '1156', '1211', '1257', '1335', '1448', '1551', '1598', '1701', '1780', '1835', '1900', '1982', '2069', '2130', '2233', '2293', '2355', '2429', '2516', '2603', '2673', '2768', '2857', '2960', '3058', '3158', '3240', '3397', '3512', '3622', '3725', '3839', '3933', '4029', '4158', '4288', '4426', '4605', '4739', '4908', '5035', '5149', '5302', '5473', '5672', '5794', '5916', '6094', '6227', '6368', '6515', '6649', '6791', '6927', '7101', '7271', '7472', '7629', '7778', '7953'])
 list(['44', '112', '198', '258', '373', '555', '657', '733', '810', '865', '907', '981', '1045', '1113', '1177', '1236', '1278', '1359', '1469', '1577', '1647', '1735', '1811', '1871', '1928', '2026', '2097', '2168', '2263', '2324', '2387', '2483', '2562', '2638', '2709', '2806', '2912', '3011', '3113', '3199', '3282', '3443', '3556', '3675', '3779', '3886', '3981', '4094', '4216', '4339', '4478', '4675', '4793', '4963', '5091', '5206', '5381', '5532', '5734', '5855', '6001', '6157', '6291', '6433', '6583', '6724', '6859', '7005', '7171', '7356', '7544', '7705', '7852'])]
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220119_0524/pettingzoo_pong_v2_fictitious_selfplay2/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 30, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220119_0524_exploit/pettingzoo_pong_v2_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0524_exploit/pettingzoo_pong_v2_fictitious_selfplay2.
Traceback (most recent call last):
  File "general_exploit.py", line 49, in <module>
    launch_rollout(parser_args.env, parser_args.method, parser_args.load_id, parser_args.save_id)
  File "general_exploit.py", line 41, in launch_rollout
    rollout(env, model, exploitation_args, save_id = load_id+'_exploit') # save results of exploitation in a separate folder
  File "/home/zihan/research/MARS/mars/rollout.py", line 21, in rollout
    rollout_normal(env, model, save_id, args)
  File "/home/zihan/research/MARS/mars/rollout.py", line 45, in rollout_normal
    obs_to_store)  # action: (agent, env, action_dim)
  File "/home/zihan/research/MARS/mars/rl/agents/multiagent.py", line 153, in choose_action
    action = agent.choose_action(state, Greedy=greedy)
  File "/home/zihan/research/MARS/mars/marl/meta_learner.py", line 16, in choose_action
    action = self.model.choose_action(state, *args, **kargs)
  File "/home/zihan/research/MARS/mars/rl/agents/dqn.py", line 89, in choose_action
    action = self.model.choose_action(state, epsilon)
  File "/home/zihan/research/MARS/mars/rl/agents/dqn.py", line 201, in choose_action
    q_value = self.net(state)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zihan/research/MARS/mars/rl/common/networks.py", line 69, in forward
    x = self.body(x)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/functional.py", line 1958, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
random seed: 91
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f42f385d400>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [array([0.014, 0.014, 0.014, ..., 0.014, 0.014, 0.014]) array([0.014, 0.014, 0.014, ..., 0.014, 0.014, 0.014])]
Load checkpoints (policy family):  [list(['21', '91', '177', '219', '339', '525', '630', '711', '789', '844', '886', '960', '1024', '1089', '1156', '1211', '1257', '1335', '1448', '1551', '1598', '1701', '1780', '1835', '1900', '1982', '2069', '2130', '2233', '2293', '2355', '2429', '2516', '2603', '2673', '2768', '2857', '2960', '3058', '3158', '3240', '3397', '3512', '3622', '3725', '3839', '3933', '4029', '4158', '4288', '4426', '4605', '4739', '4908', '5035', '5149', '5302', '5473', '5672', '5794', '5916', '6094', '6227', '6368', '6515', '6649', '6791', '6927', '7101', '7271', '7472', '7629', '7778', '7953'])
 list(['44', '112', '198', '258', '373', '555', '657', '733', '810', '865', '907', '981', '1045', '1113', '1177', '1236', '1278', '1359', '1469', '1577', '1647', '1735', '1811', '1871', '1928', '2026', '2097', '2168', '2263', '2324', '2387', '2483', '2562', '2638', '2709', '2806', '2912', '3011', '3113', '3199', '3282', '3443', '3556', '3675', '3779', '3886', '3981', '4094', '4216', '4339', '4478', '4675', '4793', '4963', '5091', '5206', '5381', '5532', '5734', '5855', '6001', '6157', '6291', '6433', '6583', '6724', '6859', '7005', '7171', '7356', '7544', '7705', '7852'])]
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220119_0524/pettingzoo_pong_v2_fictitious_selfplay2/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 30, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220119_0524_exploit/pettingzoo_pong_v2_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0524_exploit/pettingzoo_pong_v2_fictitious_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 1031.0,                last time consumption/overall running time: 10.6840s / 10.6840 s
first_0:                 episode reward: 19.0000,                 loss: nan
second_0:                 episode reward: -19.0000,                 loss: 0.0097
Episode: 21/10000 (0.2100%),                 avg. length: 1072.95,                last time consumption/overall running time: 281.2614s / 291.9454 s
first_0:                 episode reward: 17.4000,                 loss: nan
second_0:                 episode reward: -17.4000,                 loss: 0.0036
Episode: 41/10000 (0.4100%),                 avg. length: 2163.65,                last time consumption/overall running time: 658.1646s / 950.1100 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0081
Episode: 61/10000 (0.6100%),                 avg. length: 3677.75,                last time consumption/overall running time: 1147.9573s / 2098.0673 s
first_0:                 episode reward: -17.4000,                 loss: nan
second_0:                 episode reward: 17.4000,                 loss: 0.0089
Episode: 81/10000 (0.8100%),                 avg. length: 4432.85,                last time consumption/overall running time: 1390.6248s / 3488.6920 s
first_0:                 episode reward: -47.4000,                 loss: nan
second_0:                 episode reward: 47.4000,                 loss: 0.0078
Episode: 101/10000 (1.0100%),                 avg. length: 4237.15,                last time consumption/overall running time: 1331.7662s / 4820.4582 s
first_0:                 episode reward: -34.7000,                 loss: nan
second_0:                 episode reward: 34.7000,                 loss: 0.0081
Episode: 121/10000 (1.2100%),                 avg. length: 3339.7,                last time consumption/overall running time: 1054.0024s / 5874.4605 s
first_0:                 episode reward: -25.1000,                 loss: nan
second_0:                 episode reward: 25.1000,                 loss: 0.0067
Episode: 141/10000 (1.4100%),                 avg. length: 3790.55,                last time consumption/overall running time: 1194.5402s / 7069.0008 s
first_0:                 episode reward: -40.2500,                 loss: nan
second_0:                 episode reward: 40.2500,                 loss: 0.0066
Episode: 161/10000 (1.6100%),                 avg. length: 3431.2,                last time consumption/overall running time: 1091.0069s / 8160.0077 s
first_0:                 episode reward: -14.3000,                 loss: nan
second_0:                 episode reward: 14.3000,                 loss: 0.0074
Episode: 181/10000 (1.8100%),                 avg. length: 2861.6,                last time consumption/overall running time: 897.8764s / 9057.8841 s
first_0:                 episode reward: -12.4000,                 loss: nan
second_0:                 episode reward: 12.4000,                 loss: 0.0052
Episode: 201/10000 (2.0100%),                 avg. length: 4245.4,                last time consumption/overall running time: 1337.2004s / 10395.0845 s
first_0:                 episode reward: -48.2000,                 loss: nan
second_0:                 episode reward: 48.2000,                 loss: 0.0053
Episode: 221/10000 (2.2100%),                 avg. length: 3232.9,                last time consumption/overall running time: 1014.1730s / 11409.2575 s
first_0:                 episode reward: -17.2500,                 loss: nan
second_0:                 episode reward: 17.2500,                 loss: 0.0075
Episode: 241/10000 (2.4100%),                 avg. length: 3433.65,                last time consumption/overall running time: 1081.6968s / 12490.9543 s
first_0:                 episode reward: -30.8000,                 loss: nan
second_0:                 episode reward: 30.8000,                 loss: 0.0065
Episode: 261/10000 (2.6100%),                 avg. length: 3278.65,                last time consumption/overall running time: 1030.8053s / 13521.7596 s
first_0:                 episode reward: -22.4000,                 loss: nan
second_0:                 episode reward: 22.4000,                 loss: 0.0066
Episode: 281/10000 (2.8100%),                 avg. length: 2657.85,                last time consumption/overall running time: 834.9703s / 14356.7299 s
first_0:                 episode reward: -11.0500,                 loss: nan
second_0:                 episode reward: 11.0500,                 loss: 0.0052
Episode: 301/10000 (3.0100%),                 avg. length: 2975.3,                last time consumption/overall running time: 934.1176s / 15290.8475 s
first_0:                 episode reward: -26.2500,                 loss: nan
second_0:                 episode reward: 26.2500,                 loss: 0.0050
Episode: 321/10000 (3.2100%),                 avg. length: 2839.8,                last time consumption/overall running time: 891.5240s / 16182.3715 s
first_0:                 episode reward: -12.6000,                 loss: nan
second_0:                 episode reward: 12.6000,                 loss: 0.0061
Episode: 341/10000 (3.4100%),                 avg. length: 3194.5,                last time consumption/overall running time: 1001.1066s / 17183.4781 s
first_0:                 episode reward: -25.9000,                 loss: nan
second_0:                 episode reward: 25.9000,                 loss: 0.0056
Episode: 361/10000 (3.6100%),                 avg. length: 2583.5,                last time consumption/overall running time: 808.4294s / 17991.9075 s
first_0:                 episode reward: -12.5000,                 loss: nan
second_0:                 episode reward: 12.5000,                 loss: 0.0063
Episode: 381/10000 (3.8100%),                 avg. length: 3271.7,                last time consumption/overall running time: 1026.6548s / 19018.5623 s
first_0:                 episode reward: -30.0000,                 loss: nan
second_0:                 episode reward: 30.0000,                 loss: 0.0057
Episode: 401/10000 (4.0100%),                 avg. length: 3634.95,                last time consumption/overall running time: 1149.6758s / 20168.2381 s
first_0:                 episode reward: -48.1000,                 loss: nan
second_0:                 episode reward: 48.1000,                 loss: 0.0067
Episode: 421/10000 (4.2100%),                 avg. length: 2902.55,                last time consumption/overall running time: 921.2864s / 21089.5246 s
first_0:                 episode reward: -21.8500,                 loss: nan
second_0:                 episode reward: 21.8500,                 loss: 0.0077
Episode: 441/10000 (4.4100%),                 avg. length: 2710.25,                last time consumption/overall running time: 859.2575s / 21948.7821 s
first_0:                 episode reward: -7.4500,                 loss: nan
second_0:                 episode reward: 7.4500,                 loss: 0.0060
Episode: 461/10000 (4.6100%),                 avg. length: 2813.35,                last time consumption/overall running time: 889.6159s / 22838.3980 s
first_0:                 episode reward: -15.8500,                 loss: nan
second_0:                 episode reward: 15.8500,                 loss: 0.0049
Episode: 481/10000 (4.8100%),                 avg. length: 3311.6,                last time consumption/overall running time: 1042.8888s / 23881.2868 s
first_0:                 episode reward: -19.2500,                 loss: nan
second_0:                 episode reward: 19.2500,                 loss: 0.0050
Episode: 501/10000 (5.0100%),                 avg. length: 3569.7,                last time consumption/overall running time: 1122.6434s / 25003.9301 s
first_0:                 episode reward: -25.3000,                 loss: nan
second_0:                 episode reward: 25.3000,                 loss: 0.0056
Episode: 521/10000 (5.2100%),                 avg. length: 3247.25,                last time consumption/overall running time: 1021.8835s / 26025.8136 s
first_0:                 episode reward: -32.3500,                 loss: nan
second_0:                 episode reward: 32.3500,                 loss: 0.0065
Episode: 541/10000 (5.4100%),                 avg. length: 2919.85,                last time consumption/overall running time: 922.0477s / 26947.8614 s
first_0:                 episode reward: -20.6500,                 loss: nan
second_0:                 episode reward: 20.6500,                 loss: 0.0066
Episode: 561/10000 (5.6100%),                 avg. length: 2916.0,                last time consumption/overall running time: 918.0654s / 27865.9267 s
first_0:                 episode reward: -17.2500,                 loss: nan
second_0:                 episode reward: 17.2500,                 loss: 0.0057
Episode: 581/10000 (5.8100%),                 avg. length: 3048.9,                last time consumption/overall running time: 961.7914s / 28827.7181 s
first_0:                 episode reward: -16.5000,                 loss: nan
second_0:                 episode reward: 16.5000,                 loss: 0.0054
Episode: 601/10000 (6.0100%),                 avg. length: 2644.15,                last time consumption/overall running time: 837.9483s / 29665.6664 s
first_0:                 episode reward: -13.4500,                 loss: nan
second_0:                 episode reward: 13.4500,                 loss: 0.0046
Episode: 621/10000 (6.2100%),                 avg. length: 2520.85,                last time consumption/overall running time: 797.4284s / 30463.0948 s
first_0:                 episode reward: -14.5500,                 loss: nan
second_0:                 episode reward: 14.5500,                 loss: 0.0046
Episode: 641/10000 (6.4100%),                 avg. length: 3307.45,                last time consumption/overall running time: 1049.2878s / 31512.3826 s
first_0:                 episode reward: -31.8500,                 loss: nan
second_0:                 episode reward: 31.8500,                 loss: 0.0060
Episode: 661/10000 (6.6100%),                 avg. length: 3116.35,                last time consumption/overall running time: 981.9680s / 32494.3505 s
first_0:                 episode reward: -23.9000,                 loss: nan
second_0:                 episode reward: 23.9000,                 loss: 0.0066
Episode: 681/10000 (6.8100%),                 avg. length: 2908.95,                last time consumption/overall running time: 925.2181s / 33419.5686 s
first_0:                 episode reward: -9.7500,                 loss: nan
second_0:                 episode reward: 9.7500,                 loss: 0.0053
Episode: 701/10000 (7.0100%),                 avg. length: 2931.9,                last time consumption/overall running time: 925.9058s / 34345.4744 s
first_0:                 episode reward: -10.1000,                 loss: nan
second_0:                 episode reward: 10.1000,                 loss: 0.0045
Episode: 721/10000 (7.2100%),                 avg. length: 3012.95,                last time consumption/overall running time: 950.0353s / 35295.5097 s
first_0:                 episode reward: -25.1000,                 loss: nan
second_0:                 episode reward: 25.1000,                 loss: 0.0042
Episode: 741/10000 (7.4100%),                 avg. length: 3278.45,                last time consumption/overall running time: 1029.1974s / 36324.7071 s
first_0:                 episode reward: -10.9500,                 loss: nan
second_0:                 episode reward: 10.9500,                 loss: 0.0049
Episode: 761/10000 (7.6100%),                 avg. length: 3239.9,                last time consumption/overall running time: 1019.0971s / 37343.8042 s
first_0:                 episode reward: -27.4000,                 loss: nan
second_0:                 episode reward: 27.4000,                 loss: 0.0059
Episode: 781/10000 (7.8100%),                 avg. length: 3324.7,                last time consumption/overall running time: 1052.0570s / 38395.8612 s
first_0:                 episode reward: -8.3500,                 loss: nan
second_0:                 episode reward: 8.3500,                 loss: 0.0061
Episode: 801/10000 (8.0100%),                 avg. length: 2896.6,                last time consumption/overall running time: 911.0926s / 39306.9538 s
first_0:                 episode reward: -16.3500,                 loss: nan
second_0:                 episode reward: 16.3500,                 loss: 0.0043
Episode: 821/10000 (8.2100%),                 avg. length: 3291.55,                last time consumption/overall running time: 1035.8598s / 40342.8137 s
first_0:                 episode reward: -25.6000,                 loss: nan
second_0:                 episode reward: 25.6000,                 loss: 0.0053
Episode: 841/10000 (8.4100%),                 avg. length: 3075.0,                last time consumption/overall running time: 965.6640s / 41308.4777 s
first_0:                 episode reward: -19.6000,                 loss: nan
second_0:                 episode reward: 19.6000,                 loss: 0.0052
Episode: 861/10000 (8.6100%),                 avg. length: 2974.25,                last time consumption/overall running time: 935.8060s / 42244.2837 s
first_0:                 episode reward: -13.0500,                 loss: nan
second_0:                 episode reward: 13.0500,                 loss: 0.0051
Episode: 881/10000 (8.8100%),                 avg. length: 3203.85,                last time consumption/overall running time: 1006.9140s / 43251.1977 s
first_0:                 episode reward: -21.5000,                 loss: nan
second_0:                 episode reward: 21.5000,                 loss: 0.0042
Episode: 901/10000 (9.0100%),                 avg. length: 3474.95,                last time consumption/overall running time: 1102.1524s / 44353.3501 s
first_0:                 episode reward: -32.1000,                 loss: nan
second_0:                 episode reward: 32.1000,                 loss: 0.0053
Episode: 921/10000 (9.2100%),                 avg. length: 3394.05,                last time consumption/overall running time: 1076.4461s / 45429.7963 s
first_0:                 episode reward: -29.2000,                 loss: nan
second_0:                 episode reward: 29.2000,                 loss: 0.0064
Episode: 941/10000 (9.4100%),                 avg. length: 3074.3,                last time consumption/overall running time: 967.6468s / 46397.4431 s
first_0:                 episode reward: -26.6500,                 loss: nan
second_0:                 episode reward: 26.6500,                 loss: 0.0069
Episode: 961/10000 (9.6100%),                 avg. length: 3637.25,                last time consumption/overall running time: 1145.0424s / 47542.4855 s
first_0:                 episode reward: -31.8000,                 loss: nan
second_0:                 episode reward: 31.8000,                 loss: 0.0062
Episode: 981/10000 (9.8100%),                 avg. length: 3184.75,                last time consumption/overall running time: 1000.1998s / 48542.6853 s
first_0:                 episode reward: -25.6000,                 loss: nan
second_0:                 episode reward: 25.6000,                 loss: 0.0062
Episode: 1001/10000 (10.0100%),                 avg. length: 3488.0,                last time consumption/overall running time: 1096.9753s / 49639.6606 s
first_0:                 episode reward: -28.4500,                 loss: nan
second_0:                 episode reward: 28.4500,                 loss: 0.0061
Episode: 1021/10000 (10.2100%),                 avg. length: 3514.45,                last time consumption/overall running time: 1106.6705s / 50746.3311 s
first_0:                 episode reward: -36.3500,                 loss: nan
second_0:                 episode reward: 36.3500,                 loss: 0.0079
Episode: 1041/10000 (10.4100%),                 avg. length: 4080.95,                last time consumption/overall running time: 1301.0299s / 52047.3609 s
first_0:                 episode reward: -46.4500,                 loss: nan
second_0:                 episode reward: 46.4500,                 loss: 0.0078
Episode: 1061/10000 (10.6100%),                 avg. length: 3245.8,                last time consumption/overall running time: 1026.5450s / 53073.9060 s
first_0:                 episode reward: -14.6500,                 loss: nan
second_0:                 episode reward: 14.6500,                 loss: 0.0076
Episode: 1081/10000 (10.8100%),                 avg. length: 3123.55,                last time consumption/overall running time: 983.4437s / 54057.3497 s
first_0:                 episode reward: -16.5500,                 loss: nan
second_0:                 episode reward: 16.5500,                 loss: 0.0051
Episode: 1101/10000 (11.0100%),                 avg. length: 3397.6,                last time consumption/overall running time: 1070.5891s / 55127.9388 s
first_0:                 episode reward: -25.8500,                 loss: nan
second_0:                 episode reward: 25.8500,                 loss: 0.0051
Episode: 1121/10000 (11.2100%),                 avg. length: 2397.15,                last time consumption/overall running time: 758.3456s / 55886.2844 s
first_0:                 episode reward: -13.3000,                 loss: nan
second_0:                 episode reward: 13.3000,                 loss: 0.0056
Episode: 1141/10000 (11.4100%),                 avg. length: 3154.15,                last time consumption/overall running time: 1000.1702s / 56886.4546 s
first_0:                 episode reward: -27.1000,                 loss: nan
second_0:                 episode reward: 27.1000,                 loss: 0.0050
Episode: 1161/10000 (11.6100%),                 avg. length: 2979.4,                last time consumption/overall running time: 945.0409s / 57831.4955 s
first_0:                 episode reward: -11.9500,                 loss: nan
second_0:                 episode reward: 11.9500,                 loss: 0.0058
Episode: 1181/10000 (11.8100%),                 avg. length: 2905.9,                last time consumption/overall running time: 919.6703s / 58751.1657 s
first_0:                 episode reward: -11.5500,                 loss: nan
second_0:                 episode reward: 11.5500,                 loss: 0.0052
Episode: 1201/10000 (12.0100%),                 avg. length: 2786.55,                last time consumption/overall running time: 882.4424s / 59633.6081 s
first_0:                 episode reward: -12.0500,                 loss: nan
second_0:                 episode reward: 12.0500,                 loss: 0.0048
Episode: 1221/10000 (12.2100%),                 avg. length: 2472.05,                last time consumption/overall running time: 781.5961s / 60415.2043 s
first_0:                 episode reward: -15.0500,                 loss: nan
second_0:                 episode reward: 15.0500,                 loss: 0.0052
Episode: 1241/10000 (12.4100%),                 avg. length: 3067.2,                last time consumption/overall running time: 970.1127s / 61385.3170 s
first_0:                 episode reward: -21.6500,                 loss: nan
second_0:                 episode reward: 21.6500,                 loss: 0.0052
Episode: 1261/10000 (12.6100%),                 avg. length: 2472.7,                last time consumption/overall running time: 783.0856s / 62168.4026 s
first_0:                 episode reward: -15.8500,                 loss: nan
second_0:                 episode reward: 15.8500,                 loss: 0.0057
Episode: 1281/10000 (12.8100%),                 avg. length: 3122.05,                last time consumption/overall running time: 982.3613s / 63150.7639 s
first_0:                 episode reward: -12.7000,                 loss: nan
second_0:                 episode reward: 12.7000,                 loss: 0.0055
Episode: 1301/10000 (13.0100%),                 avg. length: 2843.9,                last time consumption/overall running time: 896.7077s / 64047.4716 s
first_0:                 episode reward: -19.2000,                 loss: nan
second_0:                 episode reward: 19.2000,                 loss: 0.0053
Episode: 1321/10000 (13.2100%),                 avg. length: 3041.45,                last time consumption/overall running time: 960.0875s / 65007.5591 s
first_0:                 episode reward: -15.7000,                 loss: nan
second_0:                 episode reward: 15.7000,                 loss: 0.0056
Episode: 1341/10000 (13.4100%),                 avg. length: 3381.4,                last time consumption/overall running time: 1067.5460s / 66075.1052 s
first_0:                 episode reward: -17.8000,                 loss: nan
second_0:                 episode reward: 17.8000,                 loss: 0.0055
Episode: 1361/10000 (13.6100%),                 avg. length: 2871.3,                last time consumption/overall running time: 906.9315s / 66982.0367 s
first_0:                 episode reward: -20.2500,                 loss: nan
second_0:                 episode reward: 20.2500,                 loss: 0.0054
Episode: 1381/10000 (13.8100%),                 avg. length: 2879.6,                last time consumption/overall running time: 908.3992s / 67890.4359 s
first_0:                 episode reward: -14.9500,                 loss: nan
second_0:                 episode reward: 14.9500,                 loss: 0.0053
Episode: 1401/10000 (14.0100%),                 avg. length: 2801.35,                last time consumption/overall running time: 865.6944s / 68756.1302 s
first_0:                 episode reward: -12.2000,                 loss: nan
second_0:                 episode reward: 12.2000,                 loss: 0.0050
Episode: 1421/10000 (14.2100%),                 avg. length: 3111.25,                last time consumption/overall running time: 905.4587s / 69661.5889 s
first_0:                 episode reward: -24.9000,                 loss: nan
second_0:                 episode reward: 24.9000,                 loss: 0.0049
Episode: 1441/10000 (14.4100%),                 avg. length: 3245.15,                last time consumption/overall running time: 947.2742s / 70608.8631 s
first_0:                 episode reward: -26.8000,                 loss: nan
second_0:                 episode reward: 26.8000,                 loss: 0.0065
Episode: 1461/10000 (14.6100%),                 avg. length: 2868.95,                last time consumption/overall running time: 838.5901s / 71447.4532 s
first_0:                 episode reward: -10.4500,                 loss: nan
second_0:                 episode reward: 10.4500,                 loss: 0.0064
Episode: 1481/10000 (14.8100%),                 avg. length: 3136.15,                last time consumption/overall running time: 916.4385s / 72363.8917 s
first_0:                 episode reward: -18.6000,                 loss: nan
second_0:                 episode reward: 18.6000,                 loss: 0.0052
Episode: 1501/10000 (15.0100%),                 avg. length: 3406.75,                last time consumption/overall running time: 999.5934s / 73363.4851 s
first_0:                 episode reward: -30.9500,                 loss: nan
second_0:                 episode reward: 30.9500,                 loss: 0.0053
Episode: 1521/10000 (15.2100%),                 avg. length: 3207.9,                last time consumption/overall running time: 939.0277s / 74302.5128 s
first_0:                 episode reward: -10.0000,                 loss: nan
second_0:                 episode reward: 10.0000,                 loss: 0.0067
Episode: 1541/10000 (15.4100%),                 avg. length: 3221.5,                last time consumption/overall running time: 941.9434s / 75244.4562 s
first_0:                 episode reward: -27.6500,                 loss: nan
second_0:                 episode reward: 27.6500,                 loss: 0.0059
Episode: 1561/10000 (15.6100%),                 avg. length: 3600.2,                last time consumption/overall running time: 1052.8753s / 76297.3314 s
first_0:                 episode reward: -16.0500,                 loss: nan
second_0:                 episode reward: 16.0500,                 loss: 0.0069
Episode: 1581/10000 (15.8100%),                 avg. length: 3320.0,                last time consumption/overall running time: 971.6067s / 77268.9381 s
first_0:                 episode reward: -32.3500,                 loss: nan
second_0:                 episode reward: 32.3500,                 loss: 0.0062
Episode: 1601/10000 (16.0100%),                 avg. length: 2774.3,                last time consumption/overall running time: 810.9890s / 78079.9271 s
first_0:                 episode reward: -24.2000,                 loss: nan
second_0:                 episode reward: 24.2000,                 loss: 0.0073
Episode: 1621/10000 (16.2100%),                 avg. length: 2930.8,                last time consumption/overall running time: 855.5445s / 78935.4717 s
first_0:                 episode reward: -13.8500,                 loss: nan
second_0:                 episode reward: 13.8500,                 loss: 0.0061
Episode: 1641/10000 (16.4100%),                 avg. length: 3642.2,                last time consumption/overall running time: 1064.9969s / 80000.4685 s
first_0:                 episode reward: -30.1500,                 loss: nan
second_0:                 episode reward: 30.1500,                 loss: 0.0064
Episode: 1661/10000 (16.6100%),                 avg. length: 3173.7,                last time consumption/overall running time: 927.4255s / 80927.8940 s
first_0:                 episode reward: -10.8000,                 loss: nan
second_0:                 episode reward: 10.8000,                 loss: 0.0060
Episode: 1681/10000 (16.8100%),                 avg. length: 3878.0,                last time consumption/overall running time: 1136.4428s / 82064.3368 s
first_0:                 episode reward: -39.7500,                 loss: nan
second_0:                 episode reward: 39.7500,                 loss: 0.0059
Episode: 1701/10000 (17.0100%),                 avg. length: 3520.2,                last time consumption/overall running time: 1034.0756s / 83098.4125 s
first_0:                 episode reward: -42.0500,                 loss: nan
second_0:                 episode reward: 42.0500,                 loss: 0.0074
Episode: 1721/10000 (17.2100%),                 avg. length: 3781.65,                last time consumption/overall running time: 1112.7579s / 84211.1704 s
first_0:                 episode reward: -37.5500,                 loss: nan
second_0:                 episode reward: 37.5500,                 loss: 0.0085
Episode: 1741/10000 (17.4100%),                 avg. length: 3455.15,                last time consumption/overall running time: 1017.2392s / 85228.4096 s
first_0:                 episode reward: -24.6500,                 loss: nan
second_0:                 episode reward: 24.6500,                 loss: 0.0072
Episode: 1761/10000 (17.6100%),                 avg. length: 2972.75,                last time consumption/overall running time: 872.4714s / 86100.8810 s
first_0:                 episode reward: -12.3500,                 loss: nan
second_0:                 episode reward: 12.3500,                 loss: 0.0061
Episode: 1781/10000 (17.8100%),                 avg. length: 3090.05,                last time consumption/overall running time: 906.5036s / 87007.3846 s
first_0:                 episode reward: -14.3000,                 loss: nan
second_0:                 episode reward: 14.3000,                 loss: 0.0055
Episode: 1801/10000 (18.0100%),                 avg. length: 3095.15,                last time consumption/overall running time: 910.2891s / 87917.6738 s
first_0:                 episode reward: -18.2500,                 loss: nan
second_0:                 episode reward: 18.2500,                 loss: 0.0046
Episode: 1821/10000 (18.2100%),                 avg. length: 2945.2,                last time consumption/overall running time: 867.0479s / 88784.7217 s
first_0:                 episode reward: -23.0500,                 loss: nan
second_0:                 episode reward: 23.0500,                 loss: 0.0059
Episode: 1841/10000 (18.4100%),                 avg. length: 3350.7,                last time consumption/overall running time: 988.4314s / 89773.1531 s
first_0:                 episode reward: -39.4500,                 loss: nan
second_0:                 episode reward: 39.4500,                 loss: 0.0067
Episode: 1861/10000 (18.6100%),                 avg. length: 3047.8,                last time consumption/overall running time: 896.6232s / 90669.7763 s
first_0:                 episode reward: -12.8000,                 loss: nan
second_0:                 episode reward: 12.8000,                 loss: 0.0073
Episode: 1881/10000 (18.8100%),                 avg. length: 3036.2,                last time consumption/overall running time: 895.3855s / 91565.1618 s
first_0:                 episode reward: -24.8000,                 loss: nan
second_0:                 episode reward: 24.8000,                 loss: 0.0059
Episode: 1901/10000 (19.0100%),                 avg. length: 2701.2,                last time consumption/overall running time: 798.3259s / 92363.4877 s
first_0:                 episode reward: -13.0000,                 loss: nan
second_0:                 episode reward: 13.0000,                 loss: 0.0060
Episode: 1921/10000 (19.2100%),                 avg. length: 2753.9,                last time consumption/overall running time: 812.0953s / 93175.5830 s
first_0:                 episode reward: -11.1500,                 loss: nan
second_0:                 episode reward: 11.1500,                 loss: 0.0051
Episode: 1941/10000 (19.4100%),                 avg. length: 3204.5,                last time consumption/overall running time: 942.7831s / 94118.3661 s
first_0:                 episode reward: -23.3500,                 loss: nan
second_0:                 episode reward: 23.3500,                 loss: 0.0053
Episode: 1961/10000 (19.6100%),                 avg. length: 3592.3,                last time consumption/overall running time: 1059.4346s / 95177.8007 s
first_0:                 episode reward: -23.2000,                 loss: nan
second_0:                 episode reward: 23.2000,                 loss: 0.0057
Episode: 1981/10000 (19.8100%),                 avg. length: 3265.35,                last time consumption/overall running time: 962.6061s / 96140.4068 s
first_0:                 episode reward: -20.1500,                 loss: nan
second_0:                 episode reward: 20.1500,                 loss: 0.0071
Episode: 2001/10000 (20.0100%),                 avg. length: 2982.15,                last time consumption/overall running time: 878.2381s / 97018.6449 s
first_0:                 episode reward: -16.2500,                 loss: nan
second_0:                 episode reward: 16.2500,                 loss: 0.0060
Episode: 2021/10000 (20.2100%),                 avg. length: 3204.85,                last time consumption/overall running time: 942.2950s / 97960.9400 s
first_0:                 episode reward: -26.5500,                 loss: nan
second_0:                 episode reward: 26.5500,                 loss: 0.0047
Episode: 2041/10000 (20.4100%),                 avg. length: 3103.1,                last time consumption/overall running time: 913.5006s / 98874.4405 s
first_0:                 episode reward: -12.1000,                 loss: nan
second_0:                 episode reward: 12.1000,                 loss: 0.0053
Episode: 2061/10000 (20.6100%),                 avg. length: 3309.2,                last time consumption/overall running time: 972.8815s / 99847.3220 s
first_0:                 episode reward: -17.2000,                 loss: nan
second_0:                 episode reward: 17.2000,                 loss: 0.0051
Episode: 2081/10000 (20.8100%),                 avg. length: 2648.8,                last time consumption/overall running time: 776.9315s / 100624.2535 s
first_0:                 episode reward: -15.3500,                 loss: nan
second_0:                 episode reward: 15.3500,                 loss: 0.0048
Episode: 2101/10000 (21.0100%),                 avg. length: 3377.8,                last time consumption/overall running time: 992.3294s / 101616.5829 s
first_0:                 episode reward: -28.0500,                 loss: nan
second_0:                 episode reward: 28.0500,                 loss: 0.0060
Episode: 2121/10000 (21.2100%),                 avg. length: 3020.2,                last time consumption/overall running time: 886.1471s / 102502.7300 s
first_0:                 episode reward: -24.2500,                 loss: nan
second_0:                 episode reward: 24.2500,                 loss: 0.0063
Episode: 2141/10000 (21.4100%),                 avg. length: 3363.8,                last time consumption/overall running time: 991.2199s / 103493.9499 s
first_0:                 episode reward: -32.6500,                 loss: nan
second_0:                 episode reward: 32.6500,                 loss: 0.0070
Episode: 2161/10000 (21.6100%),                 avg. length: 2928.15,                last time consumption/overall running time: 862.3596s / 104356.3095 s
first_0:                 episode reward: -26.4500,                 loss: nan
second_0:                 episode reward: 26.4500,                 loss: 0.0071
Episode: 2181/10000 (21.8100%),                 avg. length: 2781.35,                last time consumption/overall running time: 819.1782s / 105175.4877 s
first_0:                 episode reward: -10.5000,                 loss: nan
second_0:                 episode reward: 10.5000,                 loss: 0.0059
Episode: 2201/10000 (22.0100%),                 avg. length: 2993.7,                last time consumption/overall running time: 882.6800s / 106058.1677 s
first_0:                 episode reward: -9.4500,                 loss: nan
second_0:                 episode reward: 9.4500,                 loss: 0.0049
Episode: 2221/10000 (22.2100%),                 avg. length: 2768.35,                last time consumption/overall running time: 811.3150s / 106869.4828 s
first_0:                 episode reward: -12.6000,                 loss: nan
second_0:                 episode reward: 12.6000,                 loss: 0.0049
Episode: 2241/10000 (22.4100%),                 avg. length: 2840.45,                last time consumption/overall running time: 832.8137s / 107702.2965 s
first_0:                 episode reward: -18.5500,                 loss: nan
second_0:                 episode reward: 18.5500,                 loss: 0.0046
Episode: 2261/10000 (22.6100%),                 avg. length: 2830.7,                last time consumption/overall running time: 831.7833s / 108534.0798 s
first_0:                 episode reward: -17.9500,                 loss: nan
second_0:                 episode reward: 17.9500,                 loss: 0.0049
Episode: 2281/10000 (22.8100%),                 avg. length: 2852.7,                last time consumption/overall running time: 840.3463s / 109374.4261 s
first_0:                 episode reward: -10.8500,                 loss: nan
second_0:                 episode reward: 10.8500,                 loss: 0.0057
Episode: 2301/10000 (23.0100%),                 avg. length: 3860.75,                last time consumption/overall running time: 1136.6847s / 110511.1108 s
first_0:                 episode reward: -37.7500,                 loss: nan
second_0:                 episode reward: 37.7500,                 loss: 0.0095
Episode: 2321/10000 (23.2100%),                 avg. length: 3387.65,                last time consumption/overall running time: 1000.3005s / 111511.4113 s
first_0:                 episode reward: -20.5500,                 loss: nan
second_0:                 episode reward: 20.5500,                 loss: 0.0081
Episode: 2341/10000 (23.4100%),                 avg. length: 2719.35,                last time consumption/overall running time: 799.3803s / 112310.7916 s
first_0:                 episode reward: -19.6000,                 loss: nan
second_0:                 episode reward: 19.6000,                 loss: 0.0072
Episode: 2361/10000 (23.6100%),                 avg. length: 2758.25,                last time consumption/overall running time: 812.0823s / 113122.8739 s
first_0:                 episode reward: -18.1000,                 loss: nan
second_0:                 episode reward: 18.1000,                 loss: 0.0063
Episode: 2381/10000 (23.8100%),                 avg. length: 2697.65,                last time consumption/overall running time: 793.6348s / 113916.5086 s
first_0:                 episode reward: -15.0000,                 loss: nan
second_0:                 episode reward: 15.0000,                 loss: 0.0056
Episode: 2401/10000 (24.0100%),                 avg. length: 2852.1,                last time consumption/overall running time: 838.8241s / 114755.3327 s
first_0:                 episode reward: -30.9500,                 loss: nan
second_0:                 episode reward: 30.9500,                 loss: 0.0057
Episode: 2421/10000 (24.2100%),                 avg. length: 3107.0,                last time consumption/overall running time: 914.3956s / 115669.7282 s
first_0:                 episode reward: -11.5500,                 loss: nan
second_0:                 episode reward: 11.5500,                 loss: 0.0065
Episode: 2441/10000 (24.4100%),                 avg. length: 2992.9,                last time consumption/overall running time: 880.6411s / 116550.3693 s
first_0:                 episode reward: -24.5500,                 loss: nan
second_0:                 episode reward: 24.5500,                 loss: 0.0064
Episode: 2461/10000 (24.6100%),                 avg. length: 3034.55,                last time consumption/overall running time: 894.2102s / 117444.5795 s
first_0:                 episode reward: -26.5000,                 loss: nan
second_0:                 episode reward: 26.5000,                 loss: 0.0085
Episode: 2481/10000 (24.8100%),                 avg. length: 2843.2,                last time consumption/overall running time: 836.5010s / 118281.0806 s
first_0:                 episode reward: -14.1500,                 loss: nan
second_0:                 episode reward: 14.1500,                 loss: 0.0071
Episode: 2501/10000 (25.0100%),                 avg. length: 2650.6,                last time consumption/overall running time: 780.2377s / 119061.3183 s
first_0:                 episode reward: -12.1500,                 loss: nan
second_0:                 episode reward: 12.1500,                 loss: 0.0057
Episode: 2521/10000 (25.2100%),                 avg. length: 2877.35,                last time consumption/overall running time: 847.3494s / 119908.6677 s
first_0:                 episode reward: -14.7500,                 loss: nan
second_0:                 episode reward: 14.7500,                 loss: 0.0047
Episode: 2541/10000 (25.4100%),                 avg. length: 2820.75,                last time consumption/overall running time: 829.5216s / 120738.1893 s
first_0:                 episode reward: -12.8500,                 loss: nan
second_0:                 episode reward: 12.8500,                 loss: 0.0050
Episode: 2561/10000 (25.6100%),                 avg. length: 2988.55,                last time consumption/overall running time: 880.6626s / 121618.8519 s
first_0:                 episode reward: -26.6000,                 loss: nan
second_0:                 episode reward: 26.6000,                 loss: 0.0053
Episode: 2581/10000 (25.8100%),                 avg. length: 3406.7,                last time consumption/overall running time: 1002.0891s / 122620.9410 s
first_0:                 episode reward: -29.8500,                 loss: nan
second_0:                 episode reward: 29.8500,                 loss: 0.0070
Episode: 2601/10000 (26.0100%),                 avg. length: 3063.9,                last time consumption/overall running time: 898.0243s / 123518.9653 s
first_0:                 episode reward: -30.5000,                 loss: nan
second_0:                 episode reward: 30.5000,                 loss: 0.0074
Episode: 2621/10000 (26.2100%),                 avg. length: 3066.8,                last time consumption/overall running time: 898.0875s / 124417.0529 s
first_0:                 episode reward: -12.8000,                 loss: nan
second_0:                 episode reward: 12.8000,                 loss: 0.0067
Episode: 2641/10000 (26.4100%),                 avg. length: 3085.0,                last time consumption/overall running time: 904.4045s / 125321.4574 s
first_0:                 episode reward: -9.9500,                 loss: nan
second_0:                 episode reward: 9.9500,                 loss: 0.0050
Episode: 2661/10000 (26.6100%),                 avg. length: 3687.8,                last time consumption/overall running time: 1079.3444s / 126400.8018 s
first_0:                 episode reward: -43.2000,                 loss: nan
second_0:                 episode reward: 43.2000,                 loss: 0.0054
Episode: 2681/10000 (26.8100%),                 avg. length: 2561.75,                last time consumption/overall running time: 750.3756s / 127151.1774 s
first_0:                 episode reward: -14.6000,                 loss: nan
second_0:                 episode reward: 14.6000,                 loss: 0.0076
Episode: 2701/10000 (27.0100%),                 avg. length: 2715.3,                last time consumption/overall running time: 797.3174s / 127948.4948 s
first_0:                 episode reward: -23.6000,                 loss: nan
second_0:                 episode reward: 23.6000,                 loss: 0.0061
Episode: 2721/10000 (27.2100%),                 avg. length: 3010.35,                last time consumption/overall running time: 881.9658s / 128830.4606 s
first_0:                 episode reward: -12.9000,                 loss: nan
second_0:                 episode reward: 12.9000,                 loss: 0.0055
Episode: 2741/10000 (27.4100%),                 avg. length: 3321.9,                last time consumption/overall running time: 975.2625s / 129805.7230 s
first_0:                 episode reward: -38.8000,                 loss: nan
second_0:                 episode reward: 38.8000,                 loss: 0.0063
Episode: 2761/10000 (27.6100%),                 avg. length: 3087.85,                last time consumption/overall running time: 904.0607s / 130709.7837 s
first_0:                 episode reward: -32.4000,                 loss: nan
second_0:                 episode reward: 32.4000,                 loss: 0.0077
Episode: 2781/10000 (27.8100%),                 avg. length: 3091.8,                last time consumption/overall running time: 903.6063s / 131613.3900 s
first_0:                 episode reward: -20.7000,                 loss: nan
second_0:                 episode reward: 20.7000,                 loss: 0.0066
Episode: 2801/10000 (28.0100%),                 avg. length: 3102.4,                last time consumption/overall running time: 911.5585s / 132524.9485 s
first_0:                 episode reward: -16.5500,                 loss: nan
second_0:                 episode reward: 16.5500,                 loss: 0.0050
Episode: 2821/10000 (28.2100%),                 avg. length: 3352.75,                last time consumption/overall running time: 984.6093s / 133509.5578 s
first_0:                 episode reward: -33.8500,                 loss: nan
second_0:                 episode reward: 33.8500,                 loss: 0.0051
Episode: 2841/10000 (28.4100%),                 avg. length: 3359.35,                last time consumption/overall running time: 958.3314s / 134467.8893 s
first_0:                 episode reward: -39.1000,                 loss: nan
second_0:                 episode reward: 39.1000,                 loss: 0.0080
Episode: 2861/10000 (28.6100%),                 avg. length: 3155.05,                last time consumption/overall running time: 847.9265s / 135315.8157 s
first_0:                 episode reward: -35.6500,                 loss: nan
second_0:                 episode reward: 35.6500,                 loss: 0.0076
Episode: 2881/10000 (28.8100%),                 avg. length: 2878.95,                last time consumption/overall running time: 770.6697s / 136086.4854 s
first_0:                 episode reward: -17.2000,                 loss: nan
second_0:                 episode reward: 17.2000,                 loss: 0.0061
Episode: 2901/10000 (29.0100%),                 avg. length: 2623.5,                last time consumption/overall running time: 703.3949s / 136789.8803 s
first_0:                 episode reward: -14.8000,                 loss: nan
second_0:                 episode reward: 14.8000,                 loss: 0.0055
Episode: 2921/10000 (29.2100%),                 avg. length: 2566.05,                last time consumption/overall running time: 690.6461s / 137480.5264 s
first_0:                 episode reward: -19.7000,                 loss: nan
second_0:                 episode reward: 19.7000,                 loss: 0.0052
Episode: 2941/10000 (29.4100%),                 avg. length: 3280.2,                last time consumption/overall running time: 882.1669s / 138362.6933 s
first_0:                 episode reward: -14.4000,                 loss: nan
second_0:                 episode reward: 14.4000,                 loss: 0.0053
Episode: 2961/10000 (29.6100%),                 avg. length: 2863.05,                last time consumption/overall running time: 771.3557s / 139134.0491 s
first_0:                 episode reward: -13.0500,                 loss: nan
second_0:                 episode reward: 13.0500,                 loss: 0.0048
Episode: 2981/10000 (29.8100%),                 avg. length: 2501.15,                last time consumption/overall running time: 674.3808s / 139808.4298 s
first_0:                 episode reward: -19.2000,                 loss: nan
second_0:                 episode reward: 19.2000,                 loss: 0.0048
Episode: 3001/10000 (30.0100%),                 avg. length: 2711.65,                last time consumption/overall running time: 730.4328s / 140538.8626 s
first_0:                 episode reward: -20.1500,                 loss: nan
second_0:                 episode reward: 20.1500,                 loss: 0.0050
Episode: 3021/10000 (30.2100%),                 avg. length: 3002.8,                last time consumption/overall running time: 806.3083s / 141345.1710 s
first_0:                 episode reward: -23.9500,                 loss: nan
second_0:                 episode reward: 23.9500,                 loss: 0.0053
Episode: 3041/10000 (30.4100%),                 avg. length: 2400.75,                last time consumption/overall running time: 645.7881s / 141990.9591 s
first_0:                 episode reward: -15.9500,                 loss: nan
second_0:                 episode reward: 15.9500,                 loss: 0.0053
Episode: 3061/10000 (30.6100%),                 avg. length: 2581.55,                last time consumption/overall running time: 696.7656s / 142687.7247 s
first_0:                 episode reward: -14.6000,                 loss: nan
second_0:                 episode reward: 14.6000,                 loss: 0.0052
Episode: 3081/10000 (30.8100%),                 avg. length: 2796.65,                last time consumption/overall running time: 752.5546s / 143440.2793 s
first_0:                 episode reward: -11.8000,                 loss: nan
second_0:                 episode reward: 11.8000,                 loss: 0.0048
Episode: 3101/10000 (31.0100%),                 avg. length: 2984.7,                last time consumption/overall running time: 805.1575s / 144245.4368 s
first_0:                 episode reward: -25.4500,                 loss: nan
second_0:                 episode reward: 25.4500,                 loss: 0.0054
Episode: 3121/10000 (31.2100%),                 avg. length: 2504.45,                last time consumption/overall running time: 676.2314s / 144921.6682 s
first_0:                 episode reward: -16.8000,                 loss: nan
second_0:                 episode reward: 16.8000,                 loss: 0.0061
Episode: 3141/10000 (31.4100%),                 avg. length: 2539.6,                last time consumption/overall running time: 682.0797s / 145603.7479 s
first_0:                 episode reward: -15.0000,                 loss: nan
second_0:                 episode reward: 15.0000,                 loss: 0.0052
Episode: 3161/10000 (31.6100%),                 avg. length: 2970.1,                last time consumption/overall running time: 798.0296s / 146401.7775 s
first_0:                 episode reward: -19.1000,                 loss: nan
second_0:                 episode reward: 19.1000,                 loss: 0.0053
Episode: 3181/10000 (31.8100%),                 avg. length: 2912.75,                last time consumption/overall running time: 782.3836s / 147184.1611 s
first_0:                 episode reward: -14.2500,                 loss: nan
second_0:                 episode reward: 14.2500,                 loss: 0.0051
Episode: 3201/10000 (32.0100%),                 avg. length: 2625.0,                last time consumption/overall running time: 703.1133s / 147887.2744 s
first_0:                 episode reward: -13.2000,                 loss: nan
second_0:                 episode reward: 13.2000,                 loss: 0.0046
Episode: 3221/10000 (32.2100%),                 avg. length: 2506.15,                last time consumption/overall running time: 673.4323s / 148560.7067 s
first_0:                 episode reward: -14.5000,                 loss: nan
second_0:                 episode reward: 14.5000,                 loss: 0.0040
Episode: 3241/10000 (32.4100%),                 avg. length: 2451.5,                last time consumption/overall running time: 658.8351s / 149219.5418 s
first_0:                 episode reward: -16.0000,                 loss: nan
second_0:                 episode reward: 16.0000,                 loss: 0.0041
Episode: 3261/10000 (32.6100%),                 avg. length: 2785.95,                last time consumption/overall running time: 750.0075s / 149969.5493 s
first_0:                 episode reward: -30.6500,                 loss: nan
second_0:                 episode reward: 30.6500,                 loss: 0.0051
Episode: 3281/10000 (32.8100%),                 avg. length: 3207.5,                last time consumption/overall running time: 863.8015s / 150833.3508 s
first_0:                 episode reward: -32.3000,                 loss: nan
second_0:                 episode reward: 32.3000,                 loss: 0.0066
Episode: 3301/10000 (33.0100%),                 avg. length: 2602.05,                last time consumption/overall running time: 699.5067s / 151532.8575 s
first_0:                 episode reward: -17.0000,                 loss: nan
second_0:                 episode reward: 17.0000,                 loss: 0.0064
Episode: 3321/10000 (33.2100%),                 avg. length: 2817.05,                last time consumption/overall running time: 759.0211s / 152291.8786 s
first_0:                 episode reward: -26.6500,                 loss: nan
second_0:                 episode reward: 26.6500,                 loss: 0.0060
Episode: 3341/10000 (33.4100%),                 avg. length: 2747.95,                last time consumption/overall running time: 737.0468s / 153028.9254 s
first_0:                 episode reward: -11.9000,                 loss: nan
second_0:                 episode reward: 11.9000,                 loss: 0.0056
Episode: 3361/10000 (33.6100%),                 avg. length: 2319.6,                last time consumption/overall running time: 625.2638s / 153654.1892 s
first_0:                 episode reward: -15.9500,                 loss: nan
second_0:                 episode reward: 15.9500,                 loss: 0.0046
Episode: 3381/10000 (33.8100%),                 avg. length: 2907.35,                last time consumption/overall running time: 783.1786s / 154437.3677 s
first_0:                 episode reward: -12.8500,                 loss: nan
second_0:                 episode reward: 12.8500,                 loss: 0.0044
Episode: 3401/10000 (34.0100%),                 avg. length: 2743.3,                last time consumption/overall running time: 736.0221s / 155173.3898 s
first_0:                 episode reward: -20.4500,                 loss: nan
second_0:                 episode reward: 20.4500,                 loss: 0.0042
Episode: 3421/10000 (34.2100%),                 avg. length: 3006.1,                last time consumption/overall running time: 805.7451s / 155979.1349 s
first_0:                 episode reward: -30.9000,                 loss: nan
second_0:                 episode reward: 30.9000,                 loss: 0.0059
Episode: 3441/10000 (34.4100%),                 avg. length: 2629.55,                last time consumption/overall running time: 705.9953s / 156685.1302 s
first_0:                 episode reward: -14.1500,                 loss: nan
second_0:                 episode reward: 14.1500,                 loss: 0.0064
Episode: 3461/10000 (34.6100%),                 avg. length: 3032.0,                last time consumption/overall running time: 817.5890s / 157502.7192 s
first_0:                 episode reward: -38.2500,                 loss: nan
second_0:                 episode reward: 38.2500,                 loss: 0.0062
Episode: 3481/10000 (34.8100%),                 avg. length: 3228.35,                last time consumption/overall running time: 868.5379s / 158371.2571 s
first_0:                 episode reward: -20.0000,                 loss: nan
second_0:                 episode reward: 20.0000,                 loss: 0.0063
Episode: 3501/10000 (35.0100%),                 avg. length: 2855.35,                last time consumption/overall running time: 770.7582s / 159142.0153 s
first_0:                 episode reward: -30.6000,                 loss: nan
second_0:                 episode reward: 30.6000,                 loss: 0.0064
Episode: 3521/10000 (35.2100%),                 avg. length: 2878.75,                last time consumption/overall running time: 773.9865s / 159916.0018 s
first_0:                 episode reward: -14.1500,                 loss: nan
second_0:                 episode reward: 14.1500,                 loss: 0.0060
Episode: 3541/10000 (35.4100%),                 avg. length: 2523.6,                last time consumption/overall running time: 680.2190s / 160596.2208 s
first_0:                 episode reward: -11.7000,                 loss: nan
second_0:                 episode reward: 11.7000,                 loss: 0.0054
Episode: 3561/10000 (35.6100%),                 avg. length: 2566.55,                last time consumption/overall running time: 690.1238s / 161286.3446 s
first_0:                 episode reward: -14.6500,                 loss: nan
second_0:                 episode reward: 14.6500,                 loss: 0.0049
Episode: 3581/10000 (35.8100%),                 avg. length: 2651.15,                last time consumption/overall running time: 713.8563s / 162000.2009 s
first_0:                 episode reward: -14.5500,                 loss: nan
second_0:                 episode reward: 14.5500,                 loss: 0.0043
Episode: 3601/10000 (36.0100%),                 avg. length: 2519.4,                last time consumption/overall running time: 679.5258s / 162679.7267 s
first_0:                 episode reward: -14.2000,                 loss: nan
second_0:                 episode reward: 14.2000,                 loss: 0.0043
Episode: 3621/10000 (36.2100%),                 avg. length: 3023.85,                last time consumption/overall running time: 814.0117s / 163493.7384 s
first_0:                 episode reward: -34.2500,                 loss: nan
second_0:                 episode reward: 34.2500,                 loss: 0.0052
Episode: 3641/10000 (36.4100%),                 avg. length: 2857.45,                last time consumption/overall running time: 766.7562s / 164260.4945 s
first_0:                 episode reward: -20.6000,                 loss: nan
second_0:                 episode reward: 20.6000,                 loss: 0.0059
Episode: 3661/10000 (36.6100%),                 avg. length: 2848.85,                last time consumption/overall running time: 764.5790s / 165025.0735 s
first_0:                 episode reward: -25.2000,                 loss: nan
second_0:                 episode reward: 25.2000,                 loss: 0.0065
Episode: 3681/10000 (36.8100%),                 avg. length: 2458.5,                last time consumption/overall running time: 660.4170s / 165685.4906 s
first_0:                 episode reward: -20.9000,                 loss: nan
second_0:                 episode reward: 20.9000,                 loss: 0.0080
Episode: 3701/10000 (37.0100%),                 avg. length: 3085.75,                last time consumption/overall running time: 830.1266s / 166515.6172 s
first_0:                 episode reward: -28.2500,                 loss: nan
second_0:                 episode reward: 28.2500,                 loss: 0.0077
Episode: 3721/10000 (37.2100%),                 avg. length: 2515.4,                last time consumption/overall running time: 677.2695s / 167192.8868 s
first_0:                 episode reward: -16.9000,                 loss: nan
second_0:                 episode reward: 16.9000,                 loss: 0.0068
Episode: 3741/10000 (37.4100%),                 avg. length: 2475.3,                last time consumption/overall running time: 665.6025s / 167858.4892 s
first_0:                 episode reward: -14.3000,                 loss: nan
second_0:                 episode reward: 14.3000,                 loss: 0.0058
Episode: 3761/10000 (37.6100%),                 avg. length: 3718.25,                last time consumption/overall running time: 1001.6884s / 168860.1777 s
first_0:                 episode reward: -52.4000,                 loss: nan
second_0:                 episode reward: 52.4000,                 loss: 0.0062
Episode: 3781/10000 (37.8100%),                 avg. length: 2355.35,                last time consumption/overall running time: 631.5303s / 169491.7080 s
first_0:                 episode reward: -18.4500,                 loss: nan
second_0:                 episode reward: 18.4500,                 loss: 0.0092
Episode: 3801/10000 (38.0100%),                 avg. length: 2891.75,                last time consumption/overall running time: 775.0677s / 170266.7757 s
first_0:                 episode reward: -14.2000,                 loss: nan
second_0:                 episode reward: 14.2000,                 loss: 0.0073
Episode: 3821/10000 (38.2100%),                 avg. length: 2573.9,                last time consumption/overall running time: 690.8999s / 170957.6756 s
first_0:                 episode reward: -23.8500,                 loss: nan
second_0:                 episode reward: 23.8500,                 loss: 0.0051
Episode: 3841/10000 (38.4100%),                 avg. length: 3118.55,                last time consumption/overall running time: 837.1614s / 171794.8370 s
first_0:                 episode reward: -42.9500,                 loss: nan
second_0:                 episode reward: 42.9500,                 loss: 0.0060
Episode: 3861/10000 (38.6100%),                 avg. length: 2625.85,                last time consumption/overall running time: 706.9303s / 172501.7673 s
first_0:                 episode reward: -21.2500,                 loss: nan
second_0:                 episode reward: 21.2500,                 loss: 0.0075
Episode: 3881/10000 (38.8100%),                 avg. length: 2899.85,                last time consumption/overall running time: 775.6661s / 173277.4334 s
first_0:                 episode reward: -17.0500,                 loss: nan
second_0:                 episode reward: 17.0500,                 loss: 0.0063
Episode: 3901/10000 (39.0100%),                 avg. length: 2632.4,                last time consumption/overall running time: 705.2995s / 173982.7329 s
first_0:                 episode reward: -14.9000,                 loss: nan
second_0:                 episode reward: 14.9000,                 loss: 0.0053
Episode: 3921/10000 (39.2100%),                 avg. length: 2821.3,                last time consumption/overall running time: 754.0528s / 174736.7857 s
first_0:                 episode reward: -27.7500,                 loss: nan
second_0:                 episode reward: 27.7500,                 loss: 0.0047
Episode: 3941/10000 (39.4100%),                 avg. length: 2736.3,                last time consumption/overall running time: 733.8686s / 175470.6543 s
first_0:                 episode reward: -21.9500,                 loss: nan
second_0:                 episode reward: 21.9500,                 loss: 0.0063
Episode: 3961/10000 (39.6100%),                 avg. length: 2568.45,                last time consumption/overall running time: 690.0926s / 176160.7469 s
first_0:                 episode reward: -16.4500,                 loss: nan
second_0:                 episode reward: 16.4500,                 loss: 0.0061
Episode: 3981/10000 (39.8100%),                 avg. length: 3032.3,                last time consumption/overall running time: 813.6593s / 176974.4062 s