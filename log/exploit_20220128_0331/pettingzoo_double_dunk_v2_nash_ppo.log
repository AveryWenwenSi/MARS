pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
double_dunk_v2 pettingzoo
Load double_dunk_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 91
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7fe1f87430f0>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  ./data/model/20220128_0331/pettingzoo_double_dunk_v2_nash_ppo/8000_0
Arguments:  {'env_name': 'double_dunk_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220128_0331/pettingzoo_double_dunk_v2_nash_ppo/8000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220128_0331_exploit/pettingzoo_double_dunk_v2_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220128_0331_exploit/pettingzoo_double_dunk_v2_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 222.1143s / 222.1143 s
first_0:                 episode reward: -327.0000,                 loss: nan
second_0:                 episode reward: 327.0000,                 loss: 0.0160
Episode: 21/10000 (0.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4732.3892s / 4954.5034 s
first_0:                 episode reward: -325.8500,                 loss: nan
second_0:                 episode reward: 325.8500,                 loss: 0.0162
Episode: 41/10000 (0.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4774.5510s / 9729.0545 s
first_0:                 episode reward: -325.1000,                 loss: nan
second_0:                 episode reward: 325.1000,                 loss: 0.0163
Episode: 61/10000 (0.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4782.2048s / 14511.2592 s
first_0:                 episode reward: -323.9000,                 loss: nan
second_0:                 episode reward: 323.9000,                 loss: 0.0163
Episode: 81/10000 (0.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4783.5891s / 19294.8483 s
first_0:                 episode reward: -323.7000,                 loss: nan
second_0:                 episode reward: 323.7000,                 loss: 0.0161
Episode: 101/10000 (1.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4776.6762s / 24071.5246 s
first_0:                 episode reward: -322.7000,                 loss: nan
second_0:                 episode reward: 322.7000,                 loss: 0.0161
Episode: 121/10000 (1.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4780.0028s / 28851.5273 s
first_0:                 episode reward: -323.8000,                 loss: nan
second_0:                 episode reward: 323.8000,                 loss: 0.0161
Episode: 141/10000 (1.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4784.7045s / 33636.2318 s
first_0:                 episode reward: -325.0000,                 loss: nan
second_0:                 episode reward: 325.0000,                 loss: 0.0160
Episode: 161/10000 (1.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4524.8823s / 38161.1141 s
first_0:                 episode reward: -326.3500,                 loss: nan
second_0:                 episode reward: 326.3500,                 loss: 0.0160
Episode: 181/10000 (1.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4483.9018s / 42645.0159 s
first_0:                 episode reward: -324.4000,                 loss: nan
second_0:                 episode reward: 324.4000,                 loss: 0.0160
Episode: 201/10000 (2.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4479.9014s / 47124.9173 s
first_0:                 episode reward: -323.7000,                 loss: nan
second_0:                 episode reward: 323.7000,                 loss: 0.0162
Episode: 221/10000 (2.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4475.8649s / 51600.7822 s
first_0:                 episode reward: -322.8500,                 loss: nan
second_0:                 episode reward: 322.8500,                 loss: 0.0750
Episode: 241/10000 (2.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4479.2112s / 56079.9934 s
first_0:                 episode reward: -322.4000,                 loss: nan
second_0:                 episode reward: 322.4000,                 loss: 0.1313
Episode: 261/10000 (2.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4487.3939s / 60567.3873 s
first_0:                 episode reward: -318.0500,                 loss: nan
second_0:                 episode reward: 318.0500,                 loss: 0.1129
Episode: 281/10000 (2.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4472.6232s / 65040.0105 s
first_0:                 episode reward: -323.8500,                 loss: nan
second_0:                 episode reward: 323.8500,                 loss: 0.5823
Episode: 301/10000 (3.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4475.8751s / 69515.8856 s
first_0:                 episode reward: -316.5000,                 loss: nan
second_0:                 episode reward: 316.5000,                 loss: 0.6470
Episode: 321/10000 (3.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4476.3312s / 73992.2168 s
first_0:                 episode reward: -315.4500,                 loss: nan
second_0:                 episode reward: 315.4500,                 loss: 0.3179
Episode: 341/10000 (3.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4471.9453s / 78464.1621 s
first_0:                 episode reward: -314.4500,                 loss: nan
second_0:                 episode reward: 314.4500,                 loss: 0.6553
Episode: 361/10000 (3.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4468.8515s / 82933.0136 s
first_0:                 episode reward: -316.0000,                 loss: nan
second_0:                 episode reward: 316.0000,                 loss: 0.9252
Episode: 381/10000 (3.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4476.3935s / 87409.4072 s
first_0:                 episode reward: -323.2000,                 loss: nan
second_0:                 episode reward: 323.2000,                 loss: 1.2002
Episode: 401/10000 (4.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4468.6257s / 91878.0329 s
first_0:                 episode reward: -311.6000,                 loss: nan
second_0:                 episode reward: 311.6000,                 loss: 6.6492
Episode: 421/10000 (4.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4292.2850s / 96170.3179 s
first_0:                 episode reward: -318.3500,                 loss: nan
second_0:                 episode reward: 318.3500,                 loss: 6.9880
Episode: 441/10000 (4.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4218.8032s / 100389.1211 s
first_0:                 episode reward: -322.4500,                 loss: nan
second_0:                 episode reward: 322.4500,                 loss: 20.4723
Episode: 461/10000 (4.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4221.4541s / 104610.5752 s
first_0:                 episode reward: -316.0000,                 loss: nan
second_0:                 episode reward: 316.0000,                 loss: 56.5592
Episode: 481/10000 (4.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4208.9086s / 108819.4838 s
first_0:                 episode reward: -316.2500,                 loss: nan
second_0:                 episode reward: 316.2500,                 loss: 40.5949
Episode: 501/10000 (5.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4211.8223s / 113031.3062 s
first_0:                 episode reward: -317.7500,                 loss: nan
second_0:                 episode reward: 317.7500,                 loss: 23.5805
Episode: 521/10000 (5.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4215.1719s / 117246.4781 s
first_0:                 episode reward: -318.9000,                 loss: nan
second_0:                 episode reward: 318.9000,                 loss: 11.1829
Episode: 541/10000 (5.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 4092.4250s / 121338.9031 s
first_0:                 episode reward: -307.9500,                 loss: nan
second_0:                 episode reward: 307.9500,                 loss: 2.0265
Episode: 561/10000 (5.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 3976.8560s / 125315.7591 s
first_0:                 episode reward: -321.7500,                 loss: nan
second_0:                 episode reward: 321.7500,                 loss: 0.6609
Episode: 581/10000 (5.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 3973.8210s / 129289.5801 s
first_0:                 episode reward: -315.8000,                 loss: nan
second_0:                 episode reward: 315.8000,                 loss: 2.6629
Episode: 601/10000 (6.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 3962.6888s / 133252.2689 s
first_0:                 episode reward: -322.7000,                 loss: nan
second_0:                 episode reward: 322.7000,                 loss: 0.8799
Episode: 621/10000 (6.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 3548.0496s / 136800.3185 s
first_0:                 episode reward: -319.1000,                 loss: nan
second_0:                 episode reward: 319.1000,                 loss: 0.3091
Episode: 641/10000 (6.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 3350.4061s / 140150.7246 s
first_0:                 episode reward: -323.3500,                 loss: nan
second_0:                 episode reward: 323.3500,                 loss: 0.6655
Episode: 661/10000 (6.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 3349.6263s / 143500.3509 s
first_0:                 episode reward: -322.8000,                 loss: nan
second_0:                 episode reward: 322.8000,                 loss: 0.4480
Episode: 681/10000 (6.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 3350.9915s / 146851.3425 s
first_0:                 episode reward: -321.3000,                 loss: nan
second_0:                 episode reward: 321.3000,                 loss: 0.4274
Episode: 701/10000 (7.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 3351.2130s / 150202.5554 s
first_0:                 episode reward: -324.0000,                 loss: nan
second_0:                 episode reward: 324.0000,                 loss: 0.0656
Episode: 721/10000 (7.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 3082.8744s / 153285.4298 s
first_0:                 episode reward: -323.7000,                 loss: nan
second_0:                 episode reward: 323.7000,                 loss: 0.0609
Episode: 741/10000 (7.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 3063.9341s / 156349.3639 s
first_0:                 episode reward: -312.8500,                 loss: nan
second_0:                 episode reward: 312.8500,                 loss: 0.1362
Episode: 761/10000 (7.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 3062.8088s / 159412.1728 s
first_0:                 episode reward: -314.0500,                 loss: nan
second_0:                 episode reward: 314.0500,                 loss: 0.1724
Episode: 781/10000 (7.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 3056.4607s / 162468.6334 s
first_0:                 episode reward: -323.4000,                 loss: nan
second_0:                 episode reward: 323.4000,                 loss: 0.0367
Episode: 801/10000 (8.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2802.2298s / 165270.8632 s
first_0:                 episode reward: -319.6500,                 loss: nan
second_0:                 episode reward: 319.6500,                 loss: 0.1352
Episode: 821/10000 (8.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2730.5750s / 168001.4383 s
first_0:                 episode reward: -320.5000,                 loss: nan
second_0:                 episode reward: 320.5000,                 loss: 0.2438
Episode: 841/10000 (8.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2736.1045s / 170737.5427 s
first_0:                 episode reward: -317.4000,                 loss: nan
second_0:                 episode reward: 317.4000,                 loss: 0.0960
Episode: 861/10000 (8.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2728.5364s / 173466.0791 s
first_0:                 episode reward: -321.4500,                 loss: nan
second_0:                 episode reward: 321.4500,                 loss: 0.3110
Episode: 881/10000 (8.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2739.1000s / 176205.1791 s
first_0:                 episode reward: -321.6500,                 loss: nan
second_0:                 episode reward: 321.6500,                 loss: 0.6954
Episode: 901/10000 (9.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2732.4779s / 178937.6570 s
first_0:                 episode reward: -322.6000,                 loss: nan
second_0:                 episode reward: 322.6000,                 loss: 0.7107
Episode: 921/10000 (9.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2695.6235s / 181633.2805 s
first_0:                 episode reward: -318.3000,                 loss: nan
second_0:                 episode reward: 318.3000,                 loss: 0.8375
Episode: 941/10000 (9.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2496.1602s / 184129.4407 s
first_0:                 episode reward: -316.9500,                 loss: nan
second_0:                 episode reward: 316.9500,                 loss: 0.7544
Episode: 961/10000 (9.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2492.8407s / 186622.2814 s
first_0:                 episode reward: -310.3000,                 loss: nan
second_0:                 episode reward: 310.3000,                 loss: 0.5621
Episode: 981/10000 (9.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2487.6311s / 189109.9125 s
first_0:                 episode reward: -314.3000,                 loss: nan
second_0:                 episode reward: 314.3000,                 loss: 0.2840
Episode: 1001/10000 (10.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2491.7248s / 191601.6373 s
first_0:                 episode reward: -303.5500,                 loss: nan
second_0:                 episode reward: 303.5500,                 loss: 0.1622
Episode: 1021/10000 (10.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2478.7710s / 194080.4083 s
first_0:                 episode reward: -303.4500,                 loss: nan
second_0:                 episode reward: 303.4500,                 loss: 0.0856
Episode: 1041/10000 (10.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2493.8626s / 196574.2709 s
first_0:                 episode reward: -312.2000,                 loss: nan
second_0:                 episode reward: 312.2000,                 loss: 0.0655
Episode: 1061/10000 (10.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2490.4186s / 199064.6895 s
first_0:                 episode reward: -310.8500,                 loss: nan
second_0:                 episode reward: 310.8500,                 loss: 0.0533
Episode: 1081/10000 (10.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2487.6629s / 201552.3524 s
first_0:                 episode reward: -317.4000,                 loss: nan
second_0:                 episode reward: 317.4000,                 loss: 0.0359
Episode: 1101/10000 (11.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2495.1138s / 204047.4661 s
first_0:                 episode reward: -317.6500,                 loss: nan
second_0:                 episode reward: 317.6500,                 loss: 0.0332
Episode: 1121/10000 (11.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2489.6859s / 206537.1521 s
first_0:                 episode reward: -310.8500,                 loss: nan
second_0:                 episode reward: 310.8500,                 loss: 0.0377
Episode: 1141/10000 (11.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2462.2507s / 208999.4028 s
first_0:                 episode reward: -317.8500,                 loss: nan
second_0:                 episode reward: 317.8500,                 loss: 0.0348
Episode: 1161/10000 (11.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2240.7269s / 211240.1297 s
first_0:                 episode reward: -307.6500,                 loss: nan
second_0:                 episode reward: 307.6500,                 loss: 0.0389
Episode: 1181/10000 (11.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2244.5198s / 213484.6494 s
first_0:                 episode reward: -316.9500,                 loss: nan
second_0:                 episode reward: 316.9500,                 loss: 0.0837
Episode: 1201/10000 (12.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2241.1276s / 215725.7770 s
first_0:                 episode reward: -316.0500,                 loss: nan
second_0:                 episode reward: 316.0500,                 loss: 0.0446
Episode: 1221/10000 (12.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 2162.8241s / 217888.6011 s
first_0:                 episode reward: -322.6500,                 loss: nan
second_0:                 episode reward: 322.6500,                 loss: 0.0325
Episode: 1241/10000 (12.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1962.8218s / 219851.4229 s
first_0:                 episode reward: -320.5500,                 loss: nan
second_0:                 episode reward: 320.5500,                 loss: 0.0248
Episode: 1261/10000 (12.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1960.7295s / 221812.1524 s
first_0:                 episode reward: -324.8000,                 loss: nan
second_0:                 episode reward: 324.8000,                 loss: 0.0192
Episode: 1281/10000 (12.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1962.7037s / 223774.8561 s
first_0:                 episode reward: -320.6000,                 loss: nan
second_0:                 episode reward: 320.6000,                 loss: 0.0181
Episode: 1301/10000 (13.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1959.4213s / 225734.2773 s
first_0:                 episode reward: -319.3500,                 loss: nan
second_0:                 episode reward: 319.3500,                 loss: 0.0952
Episode: 1321/10000 (13.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1956.0913s / 227690.3687 s
first_0:                 episode reward: -317.7000,                 loss: nan
second_0:                 episode reward: 317.7000,                 loss: 0.4214
Episode: 1341/10000 (13.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1964.4349s / 229654.8036 s
first_0:                 episode reward: -312.4500,                 loss: nan
second_0:                 episode reward: 312.4500,                 loss: 1.7766
Episode: 1361/10000 (13.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1958.2948s / 231613.0983 s
first_0:                 episode reward: -311.7500,                 loss: nan
second_0:                 episode reward: 311.7500,                 loss: 0.6430
Episode: 1381/10000 (13.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1957.4347s / 233570.5330 s
first_0:                 episode reward: -323.2500,                 loss: nan
second_0:                 episode reward: 323.2500,                 loss: 0.2769
Episode: 1401/10000 (14.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1964.3650s / 235534.8980 s
first_0:                 episode reward: -316.4000,                 loss: nan
second_0:                 episode reward: 316.4000,                 loss: 0.4881
Episode: 1421/10000 (14.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1956.8122s / 237491.7102 s
first_0:                 episode reward: -314.8500,                 loss: nan
second_0:                 episode reward: 314.8500,                 loss: 0.4794
Episode: 1441/10000 (14.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1948.8969s / 239440.6071 s
first_0:                 episode reward: -320.5000,                 loss: nan
second_0:                 episode reward: 320.5000,                 loss: 0.8059
Episode: 1461/10000 (14.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1846.4676s / 241287.0747 s
first_0:                 episode reward: -319.4000,                 loss: nan
second_0:                 episode reward: 319.4000,                 loss: 1.3309
Episode: 1481/10000 (14.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1698.7773s / 242985.8520 s
first_0:                 episode reward: -324.0500,                 loss: nan
second_0:                 episode reward: 324.0500,                 loss: 1.0596
Episode: 1501/10000 (15.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1700.6122s / 244686.4642 s
first_0:                 episode reward: -322.5500,                 loss: nan
second_0:                 episode reward: 322.5500,                 loss: 0.8570
Episode: 1521/10000 (15.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1707.5014s / 246393.9656 s
first_0:                 episode reward: -319.2500,                 loss: nan
second_0:                 episode reward: 319.2500,                 loss: 0.0254
Episode: 1541/10000 (15.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1709.9920s / 248103.9576 s
first_0:                 episode reward: -325.1500,                 loss: nan
second_0:                 episode reward: 325.1500,                 loss: 0.0163
Episode: 1561/10000 (15.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1709.1220s / 249813.0796 s
first_0:                 episode reward: -325.7500,                 loss: nan
second_0:                 episode reward: 325.7500,                 loss: 0.0161
Episode: 1581/10000 (15.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1713.9342s / 251527.0138 s
first_0:                 episode reward: -325.3000,                 loss: nan
second_0:                 episode reward: 325.3000,                 loss: 0.0170
Episode: 1601/10000 (16.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1710.1780s / 253237.1918 s
first_0:                 episode reward: -321.5500,                 loss: nan
second_0:                 episode reward: 321.5500,                 loss: 0.0162
Episode: 1621/10000 (16.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1705.5886s / 254942.7804 s
first_0:                 episode reward: -326.1000,                 loss: nan
second_0:                 episode reward: 326.1000,                 loss: 0.0181
Episode: 1641/10000 (16.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1711.3918s / 256654.1722 s
first_0:                 episode reward: -322.3000,                 loss: nan
second_0:                 episode reward: 322.3000,                 loss: 0.0184
Episode: 1661/10000 (16.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1709.0086s / 258363.1807 s
first_0:                 episode reward: -324.4500,                 loss: nan
second_0:                 episode reward: 324.4500,                 loss: 0.0160
Episode: 1681/10000 (16.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1708.5921s / 260071.7729 s
first_0:                 episode reward: -316.6500,                 loss: nan
second_0:                 episode reward: 316.6500,                 loss: 0.0162
Episode: 1701/10000 (17.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1698.0041s / 261769.7769 s
first_0:                 episode reward: -323.0500,                 loss: nan
second_0:                 episode reward: 323.0500,                 loss: 0.0162
Episode: 1721/10000 (17.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1697.5739s / 263467.3508 s
first_0:                 episode reward: -321.7500,                 loss: nan
second_0:                 episode reward: 321.7500,                 loss: 0.0159
Episode: 1741/10000 (17.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1710.2610s / 265177.6118 s
first_0:                 episode reward: -326.3000,                 loss: nan
second_0:                 episode reward: 326.3000,                 loss: 0.0160
Episode: 1761/10000 (17.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1706.5437s / 266884.1555 s
first_0:                 episode reward: -322.7000,                 loss: nan
second_0:                 episode reward: 322.7000,                 loss: 0.0159
Episode: 1781/10000 (17.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1706.0062s / 268590.1616 s
first_0:                 episode reward: -320.2000,                 loss: nan
second_0:                 episode reward: 320.2000,                 loss: 0.0160
Episode: 1801/10000 (18.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1713.0304s / 270303.1920 s
first_0:                 episode reward: -324.4000,                 loss: nan
second_0:                 episode reward: 324.4000,                 loss: 0.0160
Episode: 1821/10000 (18.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1686.0239s / 271989.2160 s
first_0:                 episode reward: -324.0000,                 loss: nan
second_0:                 episode reward: 324.0000,                 loss: 0.0160
Episode: 1841/10000 (18.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1710.4029s / 273699.6189 s
first_0:                 episode reward: -318.6000,                 loss: nan
second_0:                 episode reward: 318.6000,                 loss: 0.0159
Episode: 1861/10000 (18.6100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1706.3391s / 275405.9580 s
first_0:                 episode reward: -320.9500,                 loss: nan
second_0:                 episode reward: 320.9500,                 loss: 0.0159
Episode: 1881/10000 (18.8100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1702.9672s / 277108.9252 s
first_0:                 episode reward: -319.5000,                 loss: nan
second_0:                 episode reward: 319.5000,                 loss: 0.0158
Episode: 1901/10000 (19.0100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1695.3678s / 278804.2930 s
first_0:                 episode reward: -320.5000,                 loss: nan
second_0:                 episode reward: 320.5000,                 loss: 0.0159
Episode: 1921/10000 (19.2100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1705.3785s / 280509.6715 s
first_0:                 episode reward: -324.0000,                 loss: nan
second_0:                 episode reward: 324.0000,                 loss: 0.0160
Episode: 1941/10000 (19.4100%),                 avg. length: 9999.0,                last time consumption/overall running time: 1711.4039s / 282221.0754 s
first_0:                 episode reward: -324.9500,                 loss: nan
second_0:                 episode reward: 324.9500,                 loss: 0.0159