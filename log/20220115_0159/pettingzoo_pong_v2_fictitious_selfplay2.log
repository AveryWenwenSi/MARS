pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [63, 35]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 30, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
Save models to : /home/zihan/research/MARS/data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 738.0,                last time consumption/overall running time: 8.6048s / 8.6048 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0122
env0_second_0:                 episode reward: -21.0000,                 loss: nan
env1_first_0:                 episode reward: 20.0000,                 loss: nan
env1_second_0:                 episode reward: -20.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 737.1,                last time consumption/overall running time: 136.4351s / 145.0398 s
env0_first_0:                 episode reward: 20.5000,                 loss: 0.0012
env0_second_0:                 episode reward: -20.5000,                 loss: nan
env1_first_0:                 episode reward: 20.5500,                 loss: nan
env1_second_0:                 episode reward: -20.5500,                 loss: nan
Score delta: 41.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/21_0.
Episode: 41/10000 (0.4100%),                 avg. length: 978.5,                last time consumption/overall running time: 185.2228s / 330.2626 s
env0_first_0:                 episode reward: -4.8000,                 loss: nan
env0_second_0:                 episode reward: 4.8000,                 loss: 0.0021
env1_first_0:                 episode reward: -8.5000,                 loss: nan
env1_second_0:                 episode reward: 8.5000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 795.75,                last time consumption/overall running time: 152.8921s / 483.1547 s
env0_first_0:                 episode reward: -0.7000,                 loss: nan
env0_second_0:                 episode reward: 0.7000,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Score delta: 32.4, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/53_1.
Episode: 81/10000 (0.8100%),                 avg. length: 892.75,                last time consumption/overall running time: 173.0310s / 656.1858 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.0008
env0_second_0:                 episode reward: -2.1500,                 loss: nan
env1_first_0:                 episode reward: 8.8500,                 loss: nan
env1_second_0:                 episode reward: -8.8500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 2457.95,                last time consumption/overall running time: 479.8923s / 1136.0781 s
env0_first_0:                 episode reward: -64.7500,                 loss: nan
env0_second_0:                 episode reward: 64.7500,                 loss: nan
env1_first_0:                 episode reward: -63.0500,                 loss: nan
env1_second_0:                 episode reward: 63.0500,                 loss: nan
Score delta: 32.4, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/85_0.
Episode: 121/10000 (1.2100%),                 avg. length: 2075.45,                last time consumption/overall running time: 406.5250s / 1542.6030 s
env0_first_0:                 episode reward: -43.9500,                 loss: nan
env0_second_0:                 episode reward: 43.9500,                 loss: nan
env1_first_0:                 episode reward: -44.0000,                 loss: nan
env1_second_0:                 episode reward: 44.0000,                 loss: nan
Score delta: 195.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/106_1.
Episode: 141/10000 (1.4100%),                 avg. length: 853.0,                last time consumption/overall running time: 169.8192s / 1712.4222 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.0038
env0_second_0:                 episode reward: -3.8000,                 loss: nan
env1_first_0:                 episode reward: 4.8500,                 loss: nan
env1_second_0:                 episode reward: -4.8500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 837.35,                last time consumption/overall running time: 165.3290s / 1877.7512 s
env0_first_0:                 episode reward: 10.4500,                 loss: 0.0056
env0_second_0:                 episode reward: -10.4500,                 loss: nan
env1_first_0:                 episode reward: 11.3500,                 loss: nan
env1_second_0:                 episode reward: -11.3500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 988.5,                last time consumption/overall running time: 195.5395s / 2073.2907 s
env0_first_0:                 episode reward: 6.5500,                 loss: 0.0074
env0_second_0:                 episode reward: -6.5500,                 loss: nan
env1_first_0:                 episode reward: 5.6000,                 loss: nan
env1_second_0:                 episode reward: -5.6000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 1996.45,                last time consumption/overall running time: 394.5297s / 2467.8204 s
env0_first_0:                 episode reward: -38.1000,                 loss: nan
env0_second_0:                 episode reward: 38.1000,                 loss: nan
env1_first_0:                 episode reward: -37.7000,                 loss: nan
env1_second_0:                 episode reward: 37.7000,                 loss: nan
Score delta: 31.8, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/185_0.
Episode: 221/10000 (2.2100%),                 avg. length: 2233.3,                last time consumption/overall running time: 443.2858s / 2911.1063 s
env0_first_0:                 episode reward: 19.6500,                 loss: nan
env0_second_0:                 episode reward: -19.6500,                 loss: nan
env1_first_0:                 episode reward: 18.1500,                 loss: nan
env1_second_0:                 episode reward: -18.1500,                 loss: nan
Score delta: 126.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/206_1.
Episode: 241/10000 (2.4100%),                 avg. length: 2623.2,                last time consumption/overall running time: 519.3265s / 3430.4328 s
env0_first_0:                 episode reward: -10.0500,                 loss: nan
env0_second_0:                 episode reward: 10.0500,                 loss: nan
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Score delta: 146.8, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/227_0.
Episode: 261/10000 (2.6100%),                 avg. length: 1267.4,                last time consumption/overall running time: 250.2509s / 3680.6837 s
env0_first_0:                 episode reward: -12.6000,                 loss: nan
env0_second_0:                 episode reward: 12.6000,                 loss: nan
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Score delta: 61.6, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/248_1.
Episode: 281/10000 (2.8100%),                 avg. length: 1032.8,                last time consumption/overall running time: 204.1784s / 3884.8621 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.0094
env0_second_0:                 episode reward: 15.2000,                 loss: nan
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 1351.25,                last time consumption/overall running time: 267.4347s / 4152.2968 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.0109
env0_second_0:                 episode reward: 7.6000,                 loss: nan
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 1543.0,                last time consumption/overall running time: 306.0555s / 4458.3523 s
env0_first_0:                 episode reward: 5.6500,                 loss: nan
env0_second_0:                 episode reward: -5.6500,                 loss: nan
env1_first_0:                 episode reward: 6.0500,                 loss: nan
env1_second_0:                 episode reward: -6.0500,                 loss: nan
Score delta: 33.4, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/314_0.
Episode: 341/10000 (3.4100%),                 avg. length: 1473.1,                last time consumption/overall running time: 292.3291s / 4750.6814 s
env0_first_0:                 episode reward: -23.7000,                 loss: nan
env0_second_0:                 episode reward: 23.7000,                 loss: nan
env1_first_0:                 episode reward: -24.7500,                 loss: nan
env1_second_0:                 episode reward: 24.7500,                 loss: nan
Score delta: 72.8, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/335_1.
Episode: 361/10000 (3.6100%),                 avg. length: 1488.55,                last time consumption/overall running time: 296.7712s / 5047.4526 s
env0_first_0:                 episode reward: 2.3000,                 loss: nan
env0_second_0:                 episode reward: -2.3000,                 loss: nan
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Score delta: 32.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/360_0.
Episode: 381/10000 (3.8100%),                 avg. length: 1361.8,                last time consumption/overall running time: 272.5234s / 5319.9761 s
env0_first_0:                 episode reward: -13.7000,                 loss: nan
env0_second_0:                 episode reward: 13.7000,                 loss: 0.0098
env1_first_0:                 episode reward: -15.3000,                 loss: nan
env1_second_0:                 episode reward: 15.3000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 2146.45,                last time consumption/overall running time: 425.5394s / 5745.5155 s
env0_first_0:                 episode reward: 13.3000,                 loss: nan
env0_second_0:                 episode reward: -13.3000,                 loss: nan
env1_first_0:                 episode reward: 14.5000,                 loss: nan
env1_second_0:                 episode reward: -14.5000,                 loss: nan
Score delta: 30.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/390_1.
Episode: 421/10000 (4.2100%),                 avg. length: 2087.5,                last time consumption/overall running time: 413.5527s / 6159.0682 s
env0_first_0:                 episode reward: 10.0500,                 loss: 0.0182
env0_second_0:                 episode reward: -10.0500,                 loss: nan
env1_first_0:                 episode reward: 12.7500,                 loss: nan
env1_second_0:                 episode reward: -12.7500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 1528.7,                last time consumption/overall running time: 304.5427s / 6463.6109 s
env0_first_0:                 episode reward: -3.1000,                 loss: nan
env0_second_0:                 episode reward: 3.1000,                 loss: nan
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Score delta: 47.8, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/425_0.
Episode: 461/10000 (4.6100%),                 avg. length: 1516.3,                last time consumption/overall running time: 301.8649s / 6765.4757 s
env0_first_0:                 episode reward: -2.3500,                 loss: nan
env0_second_0:                 episode reward: 2.3500,                 loss: nan
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Score delta: 30.4, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/447_1.
Episode: 481/10000 (4.8100%),                 avg. length: 1485.8,                last time consumption/overall running time: 294.9305s / 7060.4062 s
env0_first_0:                 episode reward: 9.0000,                 loss: 0.0218
env0_second_0:                 episode reward: -9.0000,                 loss: nan
env1_first_0:                 episode reward: 6.8000,                 loss: nan
env1_second_0:                 episode reward: -6.8000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 1290.75,                last time consumption/overall running time: 259.3497s / 7319.7559 s
env0_first_0:                 episode reward: 2.9500,                 loss: nan
env0_second_0:                 episode reward: -2.9500,                 loss: nan
env1_first_0:                 episode reward: 4.9500,                 loss: nan
env1_second_0:                 episode reward: -4.9500,                 loss: nan
Score delta: 36.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/493_0.
Episode: 521/10000 (5.2100%),                 avg. length: 1432.2,                last time consumption/overall running time: 285.7529s / 7605.5088 s
env0_first_0:                 episode reward: -21.0500,                 loss: nan
env0_second_0:                 episode reward: 21.0500,                 loss: nan
env1_first_0:                 episode reward: -22.5000,                 loss: nan
env1_second_0:                 episode reward: 22.5000,                 loss: nan
Score delta: 54.0, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/514_1.
Episode: 541/10000 (5.4100%),                 avg. length: 1434.6,                last time consumption/overall running time: 285.7673s / 7891.2761 s
env0_first_0:                 episode reward: 2.6500,                 loss: nan
env0_second_0:                 episode reward: -2.6500,                 loss: nan
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Score delta: 30.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/538_0.
Episode: 561/10000 (5.6100%),                 avg. length: 1497.7,                last time consumption/overall running time: 299.4099s / 8190.6860 s
env0_first_0:                 episode reward: -11.1000,                 loss: nan
env0_second_0:                 episode reward: 11.1000,                 loss: 0.0102
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 1105.15,                last time consumption/overall running time: 221.4805s / 8412.1665 s
env0_first_0:                 episode reward: -13.1000,                 loss: nan
env0_second_0:                 episode reward: 13.1000,                 loss: nan
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Score delta: 33.4, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/566_1.
Episode: 601/10000 (6.0100%),                 avg. length: 1555.6,                last time consumption/overall running time: 313.0361s / 8725.2026 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0161
env0_second_0:                 episode reward: -0.5000,                 loss: nan
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 1628.2,                last time consumption/overall running time: 323.8176s / 9049.0202 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0135
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 1455.45,                last time consumption/overall running time: 288.4152s / 9337.4354 s
env0_first_0:                 episode reward: 7.0500,                 loss: 0.0107
env0_second_0:                 episode reward: -7.0500,                 loss: nan
env1_first_0:                 episode reward: 10.0000,                 loss: nan
env1_second_0:                 episode reward: -10.0000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 1719.0,                last time consumption/overall running time: 342.6726s / 9680.1080 s
env0_first_0:                 episode reward: 8.9000,                 loss: 0.0108
env0_second_0:                 episode reward: -8.9000,                 loss: nan
env1_first_0:                 episode reward: 7.6500,                 loss: nan
env1_second_0:                 episode reward: -7.6500,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 1791.9,                last time consumption/overall running time: 357.1013s / 10037.2093 s
env0_first_0:                 episode reward: -3.9000,                 loss: nan
env0_second_0:                 episode reward: 3.9000,                 loss: nan
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Score delta: 30.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/668_0.
Episode: 701/10000 (7.0100%),                 avg. length: 1992.15,                last time consumption/overall running time: 395.7265s / 10432.9359 s
env0_first_0:                 episode reward: -0.7500,                 loss: nan
env0_second_0:                 episode reward: 0.7500,                 loss: nan
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Score delta: 33.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/689_1.
Episode: 721/10000 (7.2100%),                 avg. length: 2172.8,                last time consumption/overall running time: 431.8484s / 10864.7843 s
env0_first_0:                 episode reward: 6.4500,                 loss: nan
env0_second_0:                 episode reward: -6.4500,                 loss: nan
env1_first_0:                 episode reward: 5.7500,                 loss: nan
env1_second_0:                 episode reward: -5.7500,                 loss: nan
Score delta: 51.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/710_0.
Episode: 741/10000 (7.4100%),                 avg. length: 1297.45,                last time consumption/overall running time: 257.3788s / 11122.1631 s
env0_first_0:                 episode reward: -15.8500,                 loss: nan
env0_second_0:                 episode reward: 15.8500,                 loss: nan
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Score delta: 39.0, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/731_1.
Episode: 761/10000 (7.6100%),                 avg. length: 1648.8,                last time consumption/overall running time: 325.8376s / 11448.0006 s
env0_first_0:                 episode reward: 10.0500,                 loss: nan
env0_second_0:                 episode reward: -10.0500,                 loss: nan
env1_first_0:                 episode reward: 11.8500,                 loss: nan
env1_second_0:                 episode reward: -11.8500,                 loss: nan
Score delta: 43.6, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/753_0.
Episode: 781/10000 (7.8100%),                 avg. length: 1613.2,                last time consumption/overall running time: 318.7267s / 11766.7273 s
env0_first_0:                 episode reward: -17.7000,                 loss: nan
env0_second_0:                 episode reward: 17.7000,                 loss: 0.0072
env1_first_0:                 episode reward: -19.9500,                 loss: nan
env1_second_0:                 episode reward: 19.9500,                 loss: nan
Score delta: 31.6, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/781_1.
Episode: 801/10000 (8.0100%),                 avg. length: 1650.7,                last time consumption/overall running time: 327.7308s / 12094.4581 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.0171
env0_second_0:                 episode reward: 8.6000,                 loss: nan
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 2065.8,                last time consumption/overall running time: 409.9925s / 12504.4506 s
env0_first_0:                 episode reward: 1.6000,                 loss: nan
env0_second_0:                 episode reward: -1.6000,                 loss: nan
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Score delta: 30.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/806_0.
Episode: 841/10000 (8.4100%),                 avg. length: 1790.7,                last time consumption/overall running time: 354.7390s / 12859.1896 s
env0_first_0:                 episode reward: -13.3500,                 loss: nan
env0_second_0:                 episode reward: 13.3500,                 loss: nan
env1_first_0:                 episode reward: -17.0500,                 loss: nan
env1_second_0:                 episode reward: 17.0500,                 loss: nan
Score delta: 31.6, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/839_1.
Episode: 861/10000 (8.6100%),                 avg. length: 1197.4,                last time consumption/overall running time: 240.6632s / 13099.8528 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.0163
env0_second_0:                 episode reward: 11.7500,                 loss: nan
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 1518.9,                last time consumption/overall running time: 303.3077s / 13403.1605 s
env0_first_0:                 episode reward: 4.3500,                 loss: nan
env0_second_0:                 episode reward: -4.3500,                 loss: nan
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Score delta: 31.4, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/880_0.
Episode: 901/10000 (9.0100%),                 avg. length: 1571.5,                last time consumption/overall running time: 311.1182s / 13714.2787 s
env0_first_0:                 episode reward: -15.6000,                 loss: nan
env0_second_0:                 episode reward: 15.6000,                 loss: 0.0052
env1_first_0:                 episode reward: -15.0000,                 loss: nan
env1_second_0:                 episode reward: 15.0000,                 loss: nan
Score delta: 32.8, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/901_1.
Episode: 921/10000 (9.2100%),                 avg. length: 1824.45,                last time consumption/overall running time: 363.4774s / 14077.7561 s
env0_first_0:                 episode reward: 4.1000,                 loss: 0.0128
env0_second_0:                 episode reward: -4.1000,                 loss: nan
env1_first_0:                 episode reward: 3.8500,                 loss: nan
env1_second_0:                 episode reward: -3.8500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 1890.5,                last time consumption/overall running time: 376.9368s / 14454.6929 s
env0_first_0:                 episode reward: 6.1500,                 loss: 0.0105
env0_second_0:                 episode reward: -6.1500,                 loss: nan
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 2004.7,                last time consumption/overall running time: 397.1604s / 14851.8533 s
env0_first_0:                 episode reward: 5.1500,                 loss: 0.0101
env0_second_0:                 episode reward: -5.1500,                 loss: nan
env1_first_0:                 episode reward: 5.9500,                 loss: nan
env1_second_0:                 episode reward: -5.9500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 1881.9,                last time consumption/overall running time: 375.7189s / 15227.5722 s
env0_first_0:                 episode reward: 2.0500,                 loss: nan
env0_second_0:                 episode reward: -2.0500,                 loss: nan
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Score delta: 34.4, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/970_0.
Episode: 1001/10000 (10.0100%),                 avg. length: 1759.4,                last time consumption/overall running time: 351.3498s / 15578.9220 s
env0_first_0:                 episode reward: -11.1500,                 loss: nan
env0_second_0:                 episode reward: 11.1500,                 loss: nan
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Score delta: 46.0, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/991_1.
Episode: 1021/10000 (10.2100%),                 avg. length: 2011.9,                last time consumption/overall running time: 401.4342s / 15980.3562 s
env0_first_0:                 episode reward: 1.3000,                 loss: nan
env0_second_0:                 episode reward: -1.3000,                 loss: nan
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Score delta: 37.4, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1014_0.
Episode: 1041/10000 (10.4100%),                 avg. length: 2298.8,                last time consumption/overall running time: 460.6834s / 16441.0396 s
env0_first_0:                 episode reward: -1.9500,                 loss: nan
env0_second_0:                 episode reward: 1.9500,                 loss: nan
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Score delta: 33.6, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1035_1.
Episode: 1061/10000 (10.6100%),                 avg. length: 1990.85,                last time consumption/overall running time: 398.0927s / 16839.1323 s
env0_first_0:                 episode reward: 7.3500,                 loss: 0.0114
env0_second_0:                 episode reward: -7.3500,                 loss: nan
env1_first_0:                 episode reward: 6.7000,                 loss: nan
env1_second_0:                 episode reward: -6.7000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 3083.15,                last time consumption/overall running time: 614.6981s / 17453.8304 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0065
env0_second_0:                 episode reward: 1.7000,                 loss: nan
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 2484.85,                last time consumption/overall running time: 493.7235s / 17947.5539 s
env0_first_0:                 episode reward: 6.5000,                 loss: 0.0053
env0_second_0:                 episode reward: -6.5000,                 loss: nan
env1_first_0:                 episode reward: 7.8000,                 loss: nan
env1_second_0:                 episode reward: -7.8000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 2071.4,                last time consumption/overall running time: 414.0865s / 18361.6404 s
env0_first_0:                 episode reward: 6.8000,                 loss: nan
env0_second_0:                 episode reward: -6.8000,                 loss: nan
env1_first_0:                 episode reward: 4.2000,                 loss: nan
env1_second_0:                 episode reward: -4.2000,                 loss: nan
Score delta: 49.0, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1107_0.
Episode: 1141/10000 (11.4100%),                 avg. length: 1930.25,                last time consumption/overall running time: 384.9787s / 18746.6191 s
env0_first_0:                 episode reward: -2.4000,                 loss: nan
env0_second_0:                 episode reward: 2.4000,                 loss: nan
env1_first_0:                 episode reward: -4.4000,                 loss: nan
env1_second_0:                 episode reward: 4.4000,                 loss: nan
Score delta: 31.0, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1134_1.
Episode: 1161/10000 (11.6100%),                 avg. length: 2021.05,                last time consumption/overall running time: 401.4246s / 19148.0437 s
env0_first_0:                 episode reward: 4.8500,                 loss: nan
env0_second_0:                 episode reward: -4.8500,                 loss: nan
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Score delta: 31.4, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1155_0.
Episode: 1181/10000 (11.8100%),                 avg. length: 1748.75,                last time consumption/overall running time: 345.4759s / 19493.5195 s
env0_first_0:                 episode reward: -10.2000,                 loss: nan
env0_second_0:                 episode reward: 10.2000,                 loss: 0.0096
env1_first_0:                 episode reward: -5.2000,                 loss: nan
env1_second_0:                 episode reward: 5.2000,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 2220.7,                last time consumption/overall running time: 443.2027s / 19936.7222 s
env0_first_0:                 episode reward: -13.4000,                 loss: nan
env0_second_0:                 episode reward: 13.4000,                 loss: 0.0062
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 1241.65,                last time consumption/overall running time: 247.6519s / 20184.3741 s
env0_first_0:                 episode reward: -19.1500,                 loss: nan
env0_second_0:                 episode reward: 19.1500,                 loss: nan
env1_first_0:                 episode reward: -21.0500,                 loss: nan
env1_second_0:                 episode reward: 21.0500,                 loss: nan
Score delta: 31.8, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1208_1.
Episode: 1241/10000 (12.4100%),                 avg. length: 1361.85,                last time consumption/overall running time: 269.1488s / 20453.5229 s
env0_first_0:                 episode reward: -15.1000,                 loss: 0.0109
env0_second_0:                 episode reward: 15.1000,                 loss: nan
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 3348.55,                last time consumption/overall running time: 665.6954s / 21119.2182 s
env0_first_0:                 episode reward: -13.0000,                 loss: nan
env0_second_0:                 episode reward: 13.0000,                 loss: nan
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Score delta: 45.4, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1247_0.
Episode: 1281/10000 (12.8100%),                 avg. length: 1488.3,                last time consumption/overall running time: 296.5943s / 21415.8125 s
env0_first_0:                 episode reward: -22.8000,                 loss: nan
env0_second_0:                 episode reward: 22.8000,                 loss: nan
env1_first_0:                 episode reward: -22.2500,                 loss: nan
env1_second_0:                 episode reward: 22.2500,                 loss: nan
Score delta: 54.0, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1268_1.
Episode: 1301/10000 (13.0100%),                 avg. length: 1729.7,                last time consumption/overall running time: 343.8258s / 21759.6383 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0114
env0_second_0:                 episode reward: 0.5500,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 2150.95,                last time consumption/overall running time: 425.5277s / 22185.1660 s
env0_first_0:                 episode reward: -5.2000,                 loss: 0.0094
env0_second_0:                 episode reward: 5.2000,                 loss: nan
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 2204.2,                last time consumption/overall running time: 439.9737s / 22625.1397 s
env0_first_0:                 episode reward: -3.0500,                 loss: nan
env0_second_0:                 episode reward: 3.0500,                 loss: nan
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
Score delta: 30.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1330_0.
Episode: 1361/10000 (13.6100%),                 avg. length: 1592.9,                last time consumption/overall running time: 316.2605s / 22941.4002 s
env0_first_0:                 episode reward: -22.0500,                 loss: nan
env0_second_0:                 episode reward: 22.0500,                 loss: nan
env1_first_0:                 episode reward: -23.1000,                 loss: nan
env1_second_0:                 episode reward: 23.1000,                 loss: nan
Score delta: 48.8, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1351_1.
Episode: 1381/10000 (13.8100%),                 avg. length: 1420.65,                last time consumption/overall running time: 283.0883s / 23224.4885 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.0128
env0_second_0:                 episode reward: 10.7000,                 loss: nan
env1_first_0:                 episode reward: -8.5000,                 loss: nan
env1_second_0:                 episode reward: 8.5000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 1905.8,                last time consumption/overall running time: 377.7125s / 23602.2010 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0089
env0_second_0:                 episode reward: 3.0500,                 loss: nan
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 2096.95,                last time consumption/overall running time: 415.0196s / 24017.2206 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.0098
env0_second_0:                 episode reward: 2.9000,                 loss: nan
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 2725.55,                last time consumption/overall running time: 544.4766s / 24561.6971 s
env0_first_0:                 episode reward: -3.8000,                 loss: 0.0083
env0_second_0:                 episode reward: 3.8000,                 loss: nan
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 2544.55,                last time consumption/overall running time: 507.9393s / 25069.6365 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.0091
env0_second_0:                 episode reward: -2.8500,                 loss: nan
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 2316.1,                last time consumption/overall running time: 461.0763s / 25530.7127 s
env0_first_0:                 episode reward: 1.0500,                 loss: nan
env0_second_0:                 episode reward: -1.0500,                 loss: nan
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Score delta: 31.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1472_0.
Episode: 1501/10000 (15.0100%),                 avg. length: 1742.65,                last time consumption/overall running time: 349.6747s / 25880.3874 s
env0_first_0:                 episode reward: -22.7000,                 loss: nan
env0_second_0:                 episode reward: 22.7000,                 loss: nan
env1_first_0:                 episode reward: -24.8000,                 loss: nan
env1_second_0:                 episode reward: 24.8000,                 loss: nan
Score delta: 61.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1493_1.
Episode: 1521/10000 (15.2100%),                 avg. length: 2156.1,                last time consumption/overall running time: 429.4000s / 26309.7874 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0119
env0_second_0:                 episode reward: 0.1000,                 loss: nan
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 2641.05,                last time consumption/overall running time: 523.1356s / 26832.9230 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0073
env0_second_0:                 episode reward: -0.7500,                 loss: nan
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 2570.75,                last time consumption/overall running time: 514.9033s / 27347.8263 s
env0_first_0:                 episode reward: 1.2500,                 loss: nan
env0_second_0:                 episode reward: -1.2500,                 loss: nan
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Score delta: 37.6, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1552_0.
Episode: 1581/10000 (15.8100%),                 avg. length: 2174.25,                last time consumption/overall running time: 433.9099s / 27781.7362 s
env0_first_0:                 episode reward: -27.9500,                 loss: nan
env0_second_0:                 episode reward: 27.9500,                 loss: nan
env1_first_0:                 episode reward: -25.2000,                 loss: nan
env1_second_0:                 episode reward: 25.2000,                 loss: nan
Score delta: 99.4, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1573_1.
Episode: 1601/10000 (16.0100%),                 avg. length: 1069.7,                last time consumption/overall running time: 215.0779s / 27996.8142 s
env0_first_0:                 episode reward: -15.6500,                 loss: 0.0100
env0_second_0:                 episode reward: 15.6500,                 loss: nan
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 1684.9,                last time consumption/overall running time: 337.0301s / 28333.8442 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0074
env0_second_0:                 episode reward: -2.5000,                 loss: nan
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 2478.35,                last time consumption/overall running time: 493.9316s / 28827.7758 s
env0_first_0:                 episode reward: 8.1500,                 loss: 0.0106
env0_second_0:                 episode reward: -8.1500,                 loss: nan
env1_first_0:                 episode reward: 7.3500,                 loss: nan
env1_second_0:                 episode reward: -7.3500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 2835.9,                last time consumption/overall running time: 563.5368s / 29391.3126 s
env0_first_0:                 episode reward: -31.0000,                 loss: nan
env0_second_0:                 episode reward: 31.0000,                 loss: nan
env1_first_0:                 episode reward: -29.3500,                 loss: nan
env1_second_0:                 episode reward: 29.3500,                 loss: nan
Score delta: 44.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1642_0.
Episode: 1681/10000 (16.8100%),                 avg. length: 2528.75,                last time consumption/overall running time: 504.8834s / 29896.1960 s
env0_first_0:                 episode reward: -6.3500,                 loss: nan
env0_second_0:                 episode reward: 6.3500,                 loss: nan
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
Score delta: 70.6, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1663_1.
Episode: 1701/10000 (17.0100%),                 avg. length: 3017.55,                last time consumption/overall running time: 600.0809s / 30496.2769 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.0068
env0_second_0:                 episode reward: 4.5000,                 loss: nan
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 2855.6,                last time consumption/overall running time: 570.2190s / 31066.4959 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0060
env0_second_0:                 episode reward: -0.2500,                 loss: nan
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 2795.35,                last time consumption/overall running time: 560.5622s / 31627.0581 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.0051
env0_second_0:                 episode reward: -2.2000,                 loss: nan
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 3189.15,                last time consumption/overall running time: 636.2288s / 32263.2870 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0058
env0_second_0:                 episode reward: 3.1000,                 loss: nan
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 3381.9,                last time consumption/overall running time: 673.7907s / 32937.0776 s
env0_first_0:                 episode reward: 10.1000,                 loss: nan
env0_second_0:                 episode reward: -10.1000,                 loss: nan
env1_first_0:                 episode reward: 9.4000,                 loss: nan
env1_second_0:                 episode reward: -9.4000,                 loss: nan
Score delta: 58.0, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1777_0.
Episode: 1801/10000 (18.0100%),                 avg. length: 2161.0,                last time consumption/overall running time: 432.0748s / 33369.1524 s
env0_first_0:                 episode reward: -23.9500,                 loss: nan
env0_second_0:                 episode reward: 23.9500,                 loss: nan
env1_first_0:                 episode reward: -24.7000,                 loss: nan
env1_second_0:                 episode reward: 24.7000,                 loss: nan
Score delta: 44.8, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1798_1.
Episode: 1821/10000 (18.2100%),                 avg. length: 2126.95,                last time consumption/overall running time: 425.9059s / 33795.0583 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0092
env0_second_0:                 episode reward: 2.8500,                 loss: nan
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 2435.95,                last time consumption/overall running time: 484.1654s / 34279.2237 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0068
env0_second_0:                 episode reward: 2.7000,                 loss: nan
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 2647.75,                last time consumption/overall running time: 528.6546s / 34807.8783 s
env0_first_0:                 episode reward: 12.0000,                 loss: 0.0083
env0_second_0:                 episode reward: -12.0000,                 loss: nan
env1_first_0:                 episode reward: 12.5500,                 loss: nan
env1_second_0:                 episode reward: -12.5500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 3186.3,                last time consumption/overall running time: 636.9120s / 35444.7903 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0076
env0_second_0:                 episode reward: 0.9500,                 loss: nan
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 3322.2,                last time consumption/overall running time: 662.0077s / 36106.7980 s
env0_first_0:                 episode reward: 8.7500,                 loss: 0.0066
env0_second_0:                 episode reward: -8.7500,                 loss: nan
env1_first_0:                 episode reward: 12.7000,                 loss: nan
env1_second_0:                 episode reward: -12.7000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 2707.35,                last time consumption/overall running time: 535.7127s / 36642.5107 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0057
env0_second_0:                 episode reward: -0.1500,                 loss: nan
env1_first_0:                 episode reward: 4.1000,                 loss: nan
env1_second_0:                 episode reward: -4.1000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 3062.05,                last time consumption/overall running time: 607.6178s / 37250.1285 s
env0_first_0:                 episode reward: 4.0000,                 loss: 0.0060
env0_second_0:                 episode reward: -4.0000,                 loss: nan
env1_first_0:                 episode reward: 6.7500,                 loss: nan
env1_second_0:                 episode reward: -6.7500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 3091.0,                last time consumption/overall running time: 612.9418s / 37863.0703 s
env0_first_0:                 episode reward: 7.8500,                 loss: nan
env0_second_0:                 episode reward: -7.8500,                 loss: nan
env1_first_0:                 episode reward: 8.3000,                 loss: nan
env1_second_0:                 episode reward: -8.3000,                 loss: nan
Score delta: 35.4, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1957_0.
Episode: 1981/10000 (19.8100%),                 avg. length: 3051.45,                last time consumption/overall running time: 600.5961s / 38463.6664 s
env0_first_0:                 episode reward: -42.9000,                 loss: nan
env0_second_0:                 episode reward: 42.9000,                 loss: nan
env1_first_0:                 episode reward: -42.8000,                 loss: nan
env1_second_0:                 episode reward: 42.8000,                 loss: nan
Score delta: 41.6, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/1979_1.
Episode: 2001/10000 (20.0100%),                 avg. length: 1151.95,                last time consumption/overall running time: 227.2415s / 38690.9079 s
env0_first_0:                 episode reward: -16.3500,                 loss: 0.0113
env0_second_0:                 episode reward: 16.3500,                 loss: nan
env1_first_0:                 episode reward: -16.2000,                 loss: nan
env1_second_0:                 episode reward: 16.2000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 1892.8,                last time consumption/overall running time: 374.3724s / 39065.2803 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.0078
env0_second_0:                 episode reward: 7.9500,                 loss: nan
env1_first_0:                 episode reward: -7.8500,                 loss: nan
env1_second_0:                 episode reward: 7.8500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 3050.9,                last time consumption/overall running time: 606.5441s / 39671.8244 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0077
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 2845.1,                last time consumption/overall running time: 564.4485s / 40236.2729 s
env0_first_0:                 episode reward: -2.7500,                 loss: 0.0083
env0_second_0:                 episode reward: 2.7500,                 loss: nan
env1_first_0:                 episode reward: -5.4000,                 loss: nan
env1_second_0:                 episode reward: 5.4000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 3096.65,                last time consumption/overall running time: 614.5492s / 40850.8220 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0061
env0_second_0:                 episode reward: 1.6500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 3408.2,                last time consumption/overall running time: 676.5583s / 41527.3803 s
env0_first_0:                 episode reward: 5.2500,                 loss: 0.0060
env0_second_0:                 episode reward: -5.2500,                 loss: nan
env1_first_0:                 episode reward: 6.4000,                 loss: nan
env1_second_0:                 episode reward: -6.4000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 2672.4,                last time consumption/overall running time: 530.2379s / 42057.6182 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0061
env0_second_0:                 episode reward: 1.3500,                 loss: nan
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 2706.45,                last time consumption/overall running time: 539.8930s / 42597.5112 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0062
env0_second_0:                 episode reward: 0.2500,                 loss: nan
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 3798.6,                last time consumption/overall running time: 751.2944s / 43348.8056 s
env0_first_0:                 episode reward: -30.6000,                 loss: nan
env0_second_0:                 episode reward: 30.6000,                 loss: nan
env1_first_0:                 episode reward: -31.1000,                 loss: nan
env1_second_0:                 episode reward: 31.1000,                 loss: nan
Score delta: 45.6, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/2145_0.
Episode: 2181/10000 (21.8100%),                 avg. length: 2278.35,                last time consumption/overall running time: 450.7386s / 43799.5442 s
env0_first_0:                 episode reward: -6.7000,                 loss: nan
env0_second_0:                 episode reward: 6.7000,                 loss: nan
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Score delta: 82.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/2166_1.
Episode: 2201/10000 (22.0100%),                 avg. length: 2711.75,                last time consumption/overall running time: 538.4188s / 44337.9629 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.0092
env0_second_0:                 episode reward: 7.5000,                 loss: nan
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 2206.25,                last time consumption/overall running time: 439.6442s / 44777.6071 s
env0_first_0:                 episode reward: 12.6500,                 loss: nan
env0_second_0:                 episode reward: -12.6500,                 loss: nan
env1_first_0:                 episode reward: 13.6500,                 loss: nan
env1_second_0:                 episode reward: -13.6500,                 loss: nan
Score delta: 46.6, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/2211_0.
Episode: 2241/10000 (22.4100%),                 avg. length: 2007.95,                last time consumption/overall running time: 395.0417s / 45172.6489 s
env0_first_0:                 episode reward: -14.5500,                 loss: nan
env0_second_0:                 episode reward: 14.5500,                 loss: nan
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Score delta: 34.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/2239_1.
Episode: 2261/10000 (22.6100%),                 avg. length: 2897.9,                last time consumption/overall running time: 570.8075s / 45743.4563 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0095
env0_second_0:                 episode reward: 2.5000,                 loss: nan
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 2857.3,                last time consumption/overall running time: 569.7055s / 46313.1618 s
env0_first_0:                 episode reward: 8.3500,                 loss: nan
env0_second_0:                 episode reward: -8.3500,                 loss: nan
env1_first_0:                 episode reward: 4.6500,                 loss: nan
env1_second_0:                 episode reward: -4.6500,                 loss: nan
Score delta: 57.0, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/2270_0.
Episode: 2301/10000 (23.0100%),                 avg. length: 2000.7,                last time consumption/overall running time: 399.6331s / 46712.7949 s
env0_first_0:                 episode reward: -15.9000,                 loss: nan
env0_second_0:                 episode reward: 15.9000,                 loss: nan
env1_first_0:                 episode reward: -15.6500,                 loss: nan
env1_second_0:                 episode reward: 15.6500,                 loss: nan
Score delta: 31.0, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/2296_1.
Episode: 2321/10000 (23.2100%),                 avg. length: 981.7,                last time consumption/overall running time: 195.1717s / 46907.9666 s
env0_first_0:                 episode reward: -18.9500,                 loss: 0.0095
env0_second_0:                 episode reward: 18.9500,                 loss: nan
env1_first_0:                 episode reward: -18.8500,                 loss: nan
env1_second_0:                 episode reward: 18.8500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 1292.9,                last time consumption/overall running time: 256.3690s / 47164.3356 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.0080
env0_second_0:                 episode reward: 14.3500,                 loss: nan
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 2193.3,                last time consumption/overall running time: 434.1432s / 47598.4788 s
env0_first_0:                 episode reward: -9.6000,                 loss: 0.0080
env0_second_0:                 episode reward: 9.6000,                 loss: nan
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 2714.85,                last time consumption/overall running time: 534.3562s / 48132.8350 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.0067
env0_second_0:                 episode reward: 5.2500,                 loss: nan
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 3147.65,                last time consumption/overall running time: 626.6800s / 48759.5150 s
env0_first_0:                 episode reward: -4.0500,                 loss: 0.0064
env0_second_0:                 episode reward: 4.0500,                 loss: nan
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 2687.15,                last time consumption/overall running time: 531.9974s / 49291.5124 s
env0_first_0:                 episode reward: 7.4500,                 loss: nan
env0_second_0:                 episode reward: -7.4500,                 loss: nan
env1_first_0:                 episode reward: 4.9000,                 loss: nan
env1_second_0:                 episode reward: -4.9000,                 loss: nan
Score delta: 39.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/2420_0.
Episode: 2441/10000 (24.4100%),                 avg. length: 2441.45,                last time consumption/overall running time: 486.2129s / 49777.7253 s
env0_first_0:                 episode reward: -16.6500,                 loss: nan
env0_second_0:                 episode reward: 16.6500,                 loss: 0.0074
env1_first_0:                 episode reward: -20.5500,                 loss: nan
env1_second_0:                 episode reward: 20.5500,                 loss: nan
Score delta: 33.0, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/2441_1.
Episode: 2461/10000 (24.6100%),                 avg. length: 1654.3,                last time consumption/overall running time: 328.5660s / 50106.2913 s
env0_first_0:                 episode reward: -18.8500,                 loss: 0.0152
env0_second_0:                 episode reward: 18.8500,                 loss: nan
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 2223.7,                last time consumption/overall running time: 439.6246s / 50545.9159 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.5000,                 loss: nan
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 2594.7,                last time consumption/overall running time: 517.6473s / 51063.5632 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.0096
env0_second_0:                 episode reward: 5.2500,                 loss: nan
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 2450.65,                last time consumption/overall running time: 485.7172s / 51549.2804 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.0068
env0_second_0:                 episode reward: 5.7000,                 loss: nan
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 2853.45,                last time consumption/overall running time: 564.4502s / 52113.7306 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.0083
env0_second_0:                 episode reward: -2.4500,                 loss: nan
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 3003.1,                last time consumption/overall running time: 593.9899s / 52707.7205 s
env0_first_0:                 episode reward: 4.8000,                 loss: nan
env0_second_0:                 episode reward: -4.8000,                 loss: nan
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
Score delta: 43.4, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/2553_0.
Episode: 2581/10000 (25.8100%),                 avg. length: 2369.05,                last time consumption/overall running time: 471.1160s / 53178.8365 s
env0_first_0:                 episode reward: -16.6500,                 loss: nan
env0_second_0:                 episode reward: 16.6500,                 loss: nan
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Score delta: 52.2, save the model to .//data/model/20220115_0159/pettingzoo_pong_v2_fictitious_selfplay2/2574_1.
Episode: 2601/10000 (26.0100%),                 avg. length: 2792.95,                last time consumption/overall running time: 555.9141s / 53734.7506 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.0060
env0_second_0:                 episode reward: -3.7000,                 loss: nan
env1_first_0:                 episode reward: 3.8500,                 loss: nan
env1_second_0:                 episode reward: -3.8500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 2558.05,                last time consumption/overall running time: 506.6970s / 54241.4476 s
env0_first_0:                 episode reward: 4.1000,                 loss: 0.0079
env0_second_0:                 episode reward: -4.1000,                 loss: nan
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 2881.3,                last time consumption/overall running time: 572.8339s / 54814.2815 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0066
env0_second_0:                 episode reward: 1.9500,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 2707.65,                last time consumption/overall running time: 534.0543s / 55348.3358 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0059
env0_second_0:                 episode reward: 2.5000,                 loss: nan
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 3000.15,                last time consumption/overall running time: 593.7507s / 55942.0865 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0064
env0_second_0:                 episode reward: 0.8000,                 loss: nan
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 2910.85,                last time consumption/overall running time: 577.0768s / 56519.1633 s
env0_first_0:                 episode reward: 4.5000,                 loss: 0.0071
env0_second_0:                 episode reward: -4.5000,                 loss: nan