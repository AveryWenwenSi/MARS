pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [96, 45]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=1024, bias=True)
      (1): Tanh()
      (2): Linear(in_features=1024, out_features=1024, bias=True)
      (3): Tanh()
      (4): Linear(in_features=1024, out_features=1024, bias=True)
      (5): Tanh()
      (6): Linear(in_features=1024, out_features=6, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=1024, bias=True)
      (1): Tanh()
      (2): Linear(in_features=1024, out_features=1024, bias=True)
      (3): Tanh()
      (4): Linear(in_features=1024, out_features=1024, bias=True)
      (5): Tanh()
      (6): Linear(in_features=1024, out_features=6, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 2, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 32, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [1024, 1024, 1024], 'hidden_activation': 'Tanh', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220114_0533/slimevolley_SlimeVolley-v0_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20220114_0533/slimevolley_SlimeVolley-v0_nash_dqn.
Episode: 1/10000 (0.0100%),                 avg. length: 744.0,                last time consumption/overall running time: 3.7156s / 3.7156 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0169
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0202
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 591.35,                last time consumption/overall running time: 35.7356s / 39.4512 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0130
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0134
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 534.3,                last time consumption/overall running time: 42.0753s / 81.5265 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0130
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 562.95,                last time consumption/overall running time: 51.8915s / 133.4180 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0125
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0112
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 577.8,                last time consumption/overall running time: 58.0314s / 191.4493 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0125
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0125
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 548.7,                last time consumption/overall running time: 57.5716s / 249.0209 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0137
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0126
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 560.35,                last time consumption/overall running time: 60.4732s / 309.4941 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0133
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0125
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 599.4,                last time consumption/overall running time: 67.8004s / 377.2945 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0145
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0136
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 574.7,                last time consumption/overall running time: 65.3166s / 442.6111 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0161
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0155
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 589.35,                last time consumption/overall running time: 67.4904s / 510.1014 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0172
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0179
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 563.1,                last time consumption/overall running time: 66.3335s / 576.4349 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0170
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0174
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 566.55,                last time consumption/overall running time: 65.7900s / 642.2250 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0191
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0180
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 554.7,                last time consumption/overall running time: 65.0409s / 707.2659 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0199
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0213
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 576.7,                last time consumption/overall running time: 67.7761s / 775.0420 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0188
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0203
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 567.95,                last time consumption/overall running time: 67.5992s / 842.6412 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0203
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0212
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 608.55,                last time consumption/overall running time: 71.5078s / 914.1491 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0191
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0220
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 561.45,                last time consumption/overall running time: 66.0652s / 980.2143 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0195
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0217
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 554.55,                last time consumption/overall running time: 65.5059s / 1045.7201 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0199
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0227
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 588.65,                last time consumption/overall running time: 68.8063s / 1114.5264 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0186
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0206
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 581.6,                last time consumption/overall running time: 67.7675s / 1182.2939 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0192
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0196
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 547.65,                last time consumption/overall running time: 64.2095s / 1246.5034 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0185
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0199
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 590.8,                last time consumption/overall running time: 69.9647s / 1316.4681 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0202
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0206
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 562.95,                last time consumption/overall running time: 66.5417s / 1383.0098 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0210
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0199
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 558.85,                last time consumption/overall running time: 65.5249s / 1448.5347 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0225
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0205
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 564.2,                last time consumption/overall running time: 65.8707s / 1514.4054 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0225
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0208
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 570.85,                last time consumption/overall running time: 67.1667s / 1581.5721 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0234
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0201
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 555.4,                last time consumption/overall running time: 64.8742s / 1646.4464 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0212
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0202
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 534.85,                last time consumption/overall running time: 61.9772s / 1708.4236 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0228
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0207
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 565.9,                last time consumption/overall running time: 66.2485s / 1774.6721 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0226
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0213
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 555.15,                last time consumption/overall running time: 65.3546s / 1840.0268 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0216
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0218
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 558.3,                last time consumption/overall running time: 64.9469s / 1904.9736 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0217
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0228
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 567.1,                last time consumption/overall running time: 66.6189s / 1971.5926 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0207
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0223
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 556.4,                last time consumption/overall running time: 65.3992s / 2036.9918 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0227
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0219
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 592.65,                last time consumption/overall running time: 69.4576s / 2106.4494 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0228
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0208
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 593.75,                last time consumption/overall running time: 69.6457s / 2176.0951 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0230
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0209
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 568.1,                last time consumption/overall running time: 67.1894s / 2243.2845 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0217
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0209
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 544.4,                last time consumption/overall running time: 63.5228s / 2306.8073 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0235
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0188
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 547.5,                last time consumption/overall running time: 64.3825s / 2371.1898 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0231
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0216
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 561.45,                last time consumption/overall running time: 67.1740s / 2438.3638 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0226
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0215
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 581.55,                last time consumption/overall running time: 68.3943s / 2506.7582 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0223
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0202
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 572.95,                last time consumption/overall running time: 67.2395s / 2573.9977 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0214
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0217
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 615.15,                last time consumption/overall running time: 72.2856s / 2646.2833 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0212
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0219
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 541.05,                last time consumption/overall running time: 63.2071s / 2709.4905 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0204
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0223
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 559.75,                last time consumption/overall running time: 65.9058s / 2775.3962 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0213
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0217
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 569.9,                last time consumption/overall running time: 66.7752s / 2842.1715 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0211
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0233
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 550.45,                last time consumption/overall running time: 65.3458s / 2907.5172 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0208
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0208
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 586.25,                last time consumption/overall running time: 69.0062s / 2976.5234 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0212
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0214
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 565.5,                last time consumption/overall running time: 66.6414s / 3043.1648 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0207
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0218
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 579.15,                last time consumption/overall running time: 67.6328s / 3110.7976 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0188
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0209
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 523.0,                last time consumption/overall running time: 61.5769s / 3172.3745 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0204
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0206
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 546.1,                last time consumption/overall running time: 63.5378s / 3235.9123 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0220
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0221
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 549.35,                last time consumption/overall running time: 64.2193s / 3300.1316 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0216
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0207
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 562.25,                last time consumption/overall running time: 65.3687s / 3365.5003 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0198
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0224
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 575.9,                last time consumption/overall running time: 66.5622s / 3432.0625 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0206
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0207
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 531.45,                last time consumption/overall running time: 62.1253s / 3494.1878 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0213
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0231
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 573.45,                last time consumption/overall running time: 66.4119s / 3560.5998 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0207
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0227
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 581.1,                last time consumption/overall running time: 66.8843s / 3627.4840 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0208
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0238
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 548.8,                last time consumption/overall running time: 64.0074s / 3691.4915 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0232
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0237
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 586.8,                last time consumption/overall running time: 67.8188s / 3759.3103 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0218
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0226
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 586.8,                last time consumption/overall running time: 68.1341s / 3827.4443 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0231
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0250
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 561.85,                last time consumption/overall running time: 64.7253s / 3892.1697 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0219
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0252
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 579.5,                last time consumption/overall running time: 66.9411s / 3959.1108 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0219
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0247
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 551.05,                last time consumption/overall running time: 63.7083s / 4022.8191 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0227
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0230
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 574.2,                last time consumption/overall running time: 65.7698s / 4088.5888 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0223
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0253
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 541.05,                last time consumption/overall running time: 62.4495s / 4151.0383 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0236
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0264
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 609.6,                last time consumption/overall running time: 70.9380s / 4221.9763 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0210
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0243
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 575.5,                last time consumption/overall running time: 66.5947s / 4288.5710 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0212
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0254
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 543.05,                last time consumption/overall running time: 62.2051s / 4350.7761 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0224
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0250
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 585.35,                last time consumption/overall running time: 67.8833s / 4418.6594 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0209
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0232
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 569.05,                last time consumption/overall running time: 65.6237s / 4484.2832 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0218
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0244
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 612.35,                last time consumption/overall running time: 71.1249s / 4555.4080 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0207
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0228
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 568.25,                last time consumption/overall running time: 65.5747s / 4620.9828 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0219
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0217
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 575.5,                last time consumption/overall running time: 66.4585s / 4687.4413 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0220
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0221
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 541.7,                last time consumption/overall running time: 62.5533s / 4749.9946 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0234
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0233
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 593.4,                last time consumption/overall running time: 68.5698s / 4818.5644 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0233
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0251
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 582.15,                last time consumption/overall running time: 67.1006s / 4885.6650 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0228
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0220
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 581.35,                last time consumption/overall running time: 67.1067s / 4952.7717 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0220
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0223
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 591.05,                last time consumption/overall running time: 68.8281s / 5021.5998 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0217
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0245
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 581.35,                last time consumption/overall running time: 66.5357s / 5088.1355 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0241
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0248
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 559.1,                last time consumption/overall running time: 65.1999s / 5153.3354 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0222
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0238
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 546.05,                last time consumption/overall running time: 63.0446s / 5216.3799 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0232
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0230
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 544.1,                last time consumption/overall running time: 63.2044s / 5279.5843 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0223
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0261
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 529.7,                last time consumption/overall running time: 62.1234s / 5341.7078 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0221
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0260
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 552.3,                last time consumption/overall running time: 64.5606s / 5406.2684 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0233
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0240
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 562.85,                last time consumption/overall running time: 65.6195s / 5471.8879 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0229
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0256
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 602.85,                last time consumption/overall running time: 70.3870s / 5542.2749 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0224
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0245
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 559.3,                last time consumption/overall running time: 64.8411s / 5607.1160 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0230
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0267
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 551.7,                last time consumption/overall running time: 63.9390s / 5671.0551 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0231
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0255
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 621.25,                last time consumption/overall running time: 71.9039s / 5742.9590 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0233
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0237
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 519.5,                last time consumption/overall running time: 60.4800s / 5803.4389 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0219
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0251
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 560.7,                last time consumption/overall running time: 64.6333s / 5868.0722 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0249
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0231
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 551.85,                last time consumption/overall running time: 63.8461s / 5931.9184 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0246
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0242
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 567.25,                last time consumption/overall running time: 65.3361s / 5997.2545 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0214
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0237
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 541.05,                last time consumption/overall running time: 62.2442s / 6059.4987 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0235
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0229
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 589.85,                last time consumption/overall running time: 68.2412s / 6127.7399 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0255
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0241
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 555.2,                last time consumption/overall running time: 64.5579s / 6192.2978 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0247
env0_second_0:                 episode reward: 1.7500,                 loss: 0.0239
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 586.95,                last time consumption/overall running time: 67.9132s / 6260.2110 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0240
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0237
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 584.3,                last time consumption/overall running time: 67.8493s / 6328.0603 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0241
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0243
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 583.3,                last time consumption/overall running time: 66.9337s / 6394.9939 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0228
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0232
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 582.6,                last time consumption/overall running time: 67.3855s / 6462.3794 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0231
env0_second_0:                 episode reward: -1.3500,                 loss: 0.0223
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 591.35,                last time consumption/overall running time: 68.4131s / 6530.7925 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0246
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0247
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 610.15,                last time consumption/overall running time: 70.7629s / 6601.5553 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0228
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0226
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 565.4,                last time consumption/overall running time: 65.6381s / 6667.1934 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0253
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0234
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 575.0,                last time consumption/overall running time: 66.8939s / 6734.0873 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0231
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0223
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 553.65,                last time consumption/overall running time: 64.2014s / 6798.2887 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0249
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0237
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 564.3,                last time consumption/overall running time: 66.2176s / 6864.5064 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0244
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0238
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 569.45,                last time consumption/overall running time: 65.6143s / 6930.1207 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0229
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0232
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 568.5,                last time consumption/overall running time: 66.6915s / 6996.8122 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0227
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0238
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 571.0,                last time consumption/overall running time: 66.3816s / 7063.1938 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0234
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0226
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 577.65,                last time consumption/overall running time: 68.4110s / 7131.6048 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0227
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0243
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 585.3,                last time consumption/overall running time: 68.2934s / 7199.8982 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0221
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0256
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 583.05,                last time consumption/overall running time: 67.5107s / 7267.4089 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0229
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0233
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 574.45,                last time consumption/overall running time: 67.4082s / 7334.8171 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0228
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0236
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 550.95,                last time consumption/overall running time: 64.0624s / 7398.8795 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0226
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0250
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 562.7,                last time consumption/overall running time: 65.7253s / 7464.6048 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0240
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0264
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 565.5,                last time consumption/overall running time: 65.1669s / 7529.7717 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0227
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0242
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 542.7,                last time consumption/overall running time: 62.8641s / 7592.6358 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0223
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0235
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 609.15,                last time consumption/overall running time: 71.4128s / 7664.0486 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0240
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0224
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 584.7,                last time consumption/overall running time: 67.6643s / 7731.7129 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0251
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0251
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 529.3,                last time consumption/overall running time: 61.8530s / 7793.5659 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0229
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0246
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 587.9,                last time consumption/overall running time: 68.2903s / 7861.8562 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0230
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0250
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 536.25,                last time consumption/overall running time: 62.4406s / 7924.2968 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0223
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0232
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 538.7,                last time consumption/overall running time: 63.0659s / 7987.3626 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0231
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0233
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 532.6,                last time consumption/overall running time: 61.9814s / 8049.3441 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0222
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0226
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 560.2,                last time consumption/overall running time: 64.6991s / 8114.0432 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0234
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0244
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 601.45,                last time consumption/overall running time: 69.9494s / 8183.9926 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0231
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0239
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 579.65,                last time consumption/overall running time: 67.4538s / 8251.4464 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0236
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0232
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 554.55,                last time consumption/overall running time: 64.5048s / 8315.9512 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0211
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0230
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 554.3,                last time consumption/overall running time: 63.9193s / 8379.8705 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0218
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0235
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 549.0,                last time consumption/overall running time: 63.9431s / 8443.8135 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0220
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0247
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 553.6,                last time consumption/overall running time: 64.3908s / 8508.2043 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0244
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0252
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 590.25,                last time consumption/overall running time: 68.9652s / 8577.1696 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0262
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0260
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 585.3,                last time consumption/overall running time: 67.8197s / 8644.9893 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0237
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0243
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 551.6,                last time consumption/overall running time: 63.6018s / 8708.5911 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0234
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0230
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 545.1,                last time consumption/overall running time: 64.1113s / 8772.7024 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0259
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0239
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 571.25,                last time consumption/overall running time: 66.4096s / 8839.1121 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0263
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0253
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 548.0,                last time consumption/overall running time: 64.2138s / 8903.3259 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0229
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0245
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 550.7,                last time consumption/overall running time: 64.4741s / 8967.8000 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0244
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0235
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 559.9,                last time consumption/overall running time: 65.3020s / 9033.1020 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0225
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0247
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 531.25,                last time consumption/overall running time: 61.3448s / 9094.4468 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0228
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0241
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 594.85,                last time consumption/overall running time: 69.0913s / 9163.5382 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0231
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0253
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 558.55,                last time consumption/overall running time: 64.7087s / 9228.2469 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0250
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0244
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 557.45,                last time consumption/overall running time: 65.1584s / 9293.4052 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0217
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0248
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 546.65,                last time consumption/overall running time: 64.0121s / 9357.4174 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0221
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0260
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 553.55,                last time consumption/overall running time: 64.5615s / 9421.9788 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0212
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0244
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 575.8,                last time consumption/overall running time: 67.2049s / 9489.1838 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0205
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0249
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 557.65,                last time consumption/overall running time: 64.7404s / 9553.9242 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0229
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0252
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 570.75,                last time consumption/overall running time: 65.9932s / 9619.9173 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0240
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0244
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 577.5,                last time consumption/overall running time: 65.8525s / 9685.7698 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0221
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0254
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 541.7,                last time consumption/overall running time: 62.7363s / 9748.5060 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0249
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0252
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 538.6,                last time consumption/overall running time: 62.3244s / 9810.8304 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0229
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0245
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 593.35,                last time consumption/overall running time: 69.0687s / 9879.8991 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0231
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0201
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 576.15,                last time consumption/overall running time: 65.9171s / 9945.8162 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0228
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0238
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 571.55,                last time consumption/overall running time: 66.4526s / 10012.2688 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0240
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0242
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 566.65,                last time consumption/overall running time: 65.6104s / 10077.8793 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0237
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0253
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 574.65,                last time consumption/overall running time: 66.1403s / 10144.0196 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0217
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0241
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 579.9,                last time consumption/overall running time: 67.1566s / 10211.1761 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0243
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0263
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 573.3,                last time consumption/overall running time: 66.3793s / 10277.5555 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0222
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0259
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 583.45,                last time consumption/overall running time: 67.8219s / 10345.3774 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0256
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0256
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 550.3,                last time consumption/overall running time: 63.7039s / 10409.0812 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0244
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0269
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 611.6,                last time consumption/overall running time: 72.0465s / 10481.1277 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0255
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0245
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 567.5,                last time consumption/overall running time: 65.8849s / 10547.0127 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0250
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0254
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 606.95,                last time consumption/overall running time: 70.1373s / 10617.1500 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0257
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0237
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 539.85,                last time consumption/overall running time: 61.9811s / 10679.1311 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0225
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0234
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 555.3,                last time consumption/overall running time: 64.5546s / 10743.6857 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0236
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0237
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 553.3,                last time consumption/overall running time: 64.2511s / 10807.9368 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0215
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0227
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 589.3,                last time consumption/overall running time: 69.0703s / 10877.0071 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0239
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0221
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 601.45,                last time consumption/overall running time: 70.1670s / 10947.1740 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0223
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0212
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 568.35,                last time consumption/overall running time: 65.9571s / 11013.1311 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0230
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0236
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 564.35,                last time consumption/overall running time: 65.3265s / 11078.4576 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0229
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0247
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 606.55,                last time consumption/overall running time: 70.1444s / 11148.6020 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0257
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0231
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 534.15,                last time consumption/overall running time: 61.8491s / 11210.4511 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0262
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0237
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 573.65,                last time consumption/overall running time: 66.3488s / 11276.7999 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0236
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0249
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 582.0,                last time consumption/overall running time: 68.1520s / 11344.9519 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0238
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0219
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 581.3,                last time consumption/overall running time: 67.2594s / 11412.2113 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0247
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0232
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 535.15,                last time consumption/overall running time: 62.3301s / 11474.5413 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0252
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0235
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 533.8,                last time consumption/overall running time: 61.9795s / 11536.5208 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0254
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0245
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 579.55,                last time consumption/overall running time: 66.5711s / 11603.0919 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0248
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0250
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 580.0,                last time consumption/overall running time: 66.8140s / 11669.9059 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0239
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0252
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 561.85,                last time consumption/overall running time: 64.6174s / 11734.5233 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0242
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0260
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 592.75,                last time consumption/overall running time: 68.2155s / 11802.7388 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0255
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0241
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 541.05,                last time consumption/overall running time: 62.0647s / 11864.8035 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0226
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0248
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 617.25,                last time consumption/overall running time: 70.7935s / 11935.5970 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0231
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0239
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 568.65,                last time consumption/overall running time: 65.2530s / 12000.8500 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0263
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0228
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 589.35,                last time consumption/overall running time: 67.4486s / 12068.2987 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0239
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0262
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 601.3,                last time consumption/overall running time: 69.1414s / 12137.4401 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0247
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0235
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 551.1,                last time consumption/overall running time: 63.2689s / 12200.7090 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0250
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0226
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 586.75,                last time consumption/overall running time: 67.5065s / 12268.2155 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0264
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0236
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 574.95,                last time consumption/overall running time: 67.1410s / 12335.3565 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0257
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0224
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 581.75,                last time consumption/overall running time: 67.1555s / 12402.5120 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0244
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0237
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 536.4,                last time consumption/overall running time: 62.0118s / 12464.5238 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0238
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0232
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 575.8,                last time consumption/overall running time: 66.8237s / 12531.3475 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0230
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0244
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 563.45,                last time consumption/overall running time: 65.7973s / 12597.1448 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0215
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0238
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 529.25,                last time consumption/overall running time: 61.0286s / 12658.1733 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0239
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0226
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 568.7,                last time consumption/overall running time: 65.1960s / 12723.3693 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0231
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0240
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 526.65,                last time consumption/overall running time: 60.6388s / 12784.0081 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0236
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0251
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 552.65,                last time consumption/overall running time: 63.2618s / 12847.2699 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0224
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0216
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 577.2,                last time consumption/overall running time: 66.2276s / 12913.4974 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0215
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0224
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 553.2,                last time consumption/overall running time: 63.4828s / 12976.9802 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0233
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0227
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 537.2,                last time consumption/overall running time: 61.8126s / 13038.7928 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0218
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0252
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 555.6,                last time consumption/overall running time: 64.5137s / 13103.3066 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0216
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0246
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 590.15,                last time consumption/overall running time: 67.6004s / 13170.9070 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0235
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0232
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 557.1,                last time consumption/overall running time: 64.0262s / 13234.9332 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0225
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0241
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 580.15,                last time consumption/overall running time: 66.5802s / 13301.5134 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0228
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0226
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 574.0,                last time consumption/overall running time: 66.2723s / 13367.7857 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0202
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0228
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 596.05,                last time consumption/overall running time: 68.8932s / 13436.6789 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0234
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0246
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 581.3,                last time consumption/overall running time: 67.5839s / 13504.2628 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0229
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0253
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 611.5,                last time consumption/overall running time: 70.3647s / 13574.6275 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0214
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0225
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 566.9,                last time consumption/overall running time: 65.3248s / 13639.9523 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0247
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0240
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 590.25,                last time consumption/overall running time: 67.7218s / 13707.6741 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0238
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0253
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 543.1,                last time consumption/overall running time: 62.0654s / 13769.7395 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0230
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0234
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 574.4,                last time consumption/overall running time: 65.4754s / 13835.2149 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0229
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0225
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 605.5,                last time consumption/overall running time: 68.8780s / 13904.0929 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0234
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0239
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 550.05,                last time consumption/overall running time: 62.7636s / 13966.8566 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0242
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0238
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 584.75,                last time consumption/overall running time: 67.1755s / 14034.0320 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0235
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0236
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 573.95,                last time consumption/overall running time: 66.6911s / 14100.7231 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0227
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0238
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 575.05,                last time consumption/overall running time: 66.6131s / 14167.3362 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0248
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0228
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 581.45,                last time consumption/overall running time: 67.2803s / 14234.6165 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0244
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0225
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 568.2,                last time consumption/overall running time: 65.6299s / 14300.2464 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0232
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0229
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 555.45,                last time consumption/overall running time: 64.0786s / 14364.3250 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0234
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0251
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 594.2,                last time consumption/overall running time: 68.5342s / 14432.8592 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0243
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0259
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 599.7,                last time consumption/overall running time: 69.3859s / 14502.2452 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0236
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0252
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 536.05,                last time consumption/overall running time: 62.1990s / 14564.4442 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0238
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0247
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 620.5,                last time consumption/overall running time: 71.8879s / 14636.3321 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0240
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0263
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 580.15,                last time consumption/overall running time: 67.1687s / 14703.5007 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0241
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0238
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 550.7,                last time consumption/overall running time: 63.9068s / 14767.4076 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0236
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0235
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 556.1,                last time consumption/overall running time: 64.8996s / 14832.3071 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0245
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0252
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 594.75,                last time consumption/overall running time: 68.2602s / 14900.5673 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0233
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0244
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 566.7,                last time consumption/overall running time: 65.3112s / 14965.8785 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0234
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0236
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 592.6,                last time consumption/overall running time: 69.3296s / 15035.2081 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0239
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0244
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 564.0,                last time consumption/overall running time: 65.2301s / 15100.4382 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0232
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0230
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 536.1,                last time consumption/overall running time: 61.8691s / 15162.3073 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0226
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0225
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 598.2,                last time consumption/overall running time: 68.5810s / 15230.8883 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0229
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0230
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 553.1,                last time consumption/overall running time: 63.4624s / 15294.3506 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0223
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0238
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 546.65,                last time consumption/overall running time: 62.9853s / 15357.3360 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0223
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0242
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 583.9,                last time consumption/overall running time: 67.0067s / 15424.3426 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0220
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0224
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 580.05,                last time consumption/overall running time: 67.0012s / 15491.3438 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0245
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0235
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 558.55,                last time consumption/overall running time: 64.2567s / 15555.6005 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0244
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0229
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 562.5,                last time consumption/overall running time: 65.0280s / 15620.6285 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0244
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0220
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 584.5,                last time consumption/overall running time: 68.3931s / 15689.0216 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0240
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0237
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 563.15,                last time consumption/overall running time: 65.6355s / 15754.6571 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0230
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0225
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 549.9,                last time consumption/overall running time: 63.3359s / 15817.9930 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0231
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0210
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 570.9,                last time consumption/overall running time: 66.7346s / 15884.7276 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0223
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0243
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 545.95,                last time consumption/overall running time: 63.3049s / 15948.0324 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0231
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0210
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 533.55,                last time consumption/overall running time: 62.2231s / 16010.2555 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0247
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0255
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 594.6,                last time consumption/overall running time: 69.4164s / 16079.6720 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0250
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0237
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 534.7,                last time consumption/overall running time: 62.5205s / 16142.1924 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0226
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0231
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 564.25,                last time consumption/overall running time: 64.9450s / 16207.1375 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0233
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0236
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 558.35,                last time consumption/overall running time: 64.6408s / 16271.7783 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0219
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0230
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 551.4,                last time consumption/overall running time: 63.0912s / 16334.8695 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0220
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0232
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 566.65,                last time consumption/overall running time: 65.1241s / 16399.9936 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0210
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0238
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 604.8,                last time consumption/overall running time: 69.5749s / 16469.5685 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0225
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0230
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 590.3,                last time consumption/overall running time: 68.8322s / 16538.4007 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0248
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0226
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 583.85,                last time consumption/overall running time: 67.4162s / 16605.8169 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0244
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0236
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 582.5,                last time consumption/overall running time: 67.7617s / 16673.5786 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0260
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0239
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 584.6,                last time consumption/overall running time: 68.2650s / 16741.8436 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0229
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0242
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 585.05,                last time consumption/overall running time: 67.8231s / 16809.6667 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0232
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0222
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 581.0,                last time consumption/overall running time: 66.8742s / 16876.5410 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0235
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0218
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 578.05,                last time consumption/overall running time: 66.5284s / 16943.0694 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0222
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0227
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 570.25,                last time consumption/overall running time: 66.0660s / 17009.1354 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0244
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0233
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 569.35,                last time consumption/overall running time: 65.3349s / 17074.4703 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0230
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0226
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 590.45,                last time consumption/overall running time: 68.5765s / 17143.0469 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0227
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0215
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 555.6,                last time consumption/overall running time: 63.9254s / 17206.9723 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0263
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0226
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 613.05,                last time consumption/overall running time: 69.8968s / 17276.8691 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0239
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0242
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 572.0,                last time consumption/overall running time: 66.2559s / 17343.1250 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0247
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0236
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 592.3,                last time consumption/overall running time: 68.0279s / 17411.1529 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0239
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0245
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 573.75,                last time consumption/overall running time: 66.8739s / 17478.0268 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0255
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0242
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 597.0,                last time consumption/overall running time: 68.7211s / 17546.7479 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0261
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0231
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 553.45,                last time consumption/overall running time: 63.6967s / 17610.4446 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0242
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0258
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 563.5,                last time consumption/overall running time: 65.3038s / 17675.7484 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0247
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0231
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 590.65,                last time consumption/overall running time: 68.3060s / 17744.0544 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0253
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0230
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 554.35,                last time consumption/overall running time: 63.6193s / 17807.6737 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0257
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0244
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 565.1,                last time consumption/overall running time: 65.6304s / 17873.3041 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0255
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0219
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 556.75,                last time consumption/overall running time: 64.7192s / 17938.0233 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0235
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0240
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 582.05,                last time consumption/overall running time: 66.8328s / 18004.8561 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0242
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0253
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 619.2,                last time consumption/overall running time: 70.8455s / 18075.7016 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0252
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0247
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 559.6,                last time consumption/overall running time: 64.2273s / 18139.9289 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0247
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0247
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 551.7,                last time consumption/overall running time: 63.4874s / 18203.4162 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0242
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0247
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 607.0,                last time consumption/overall running time: 69.6609s / 18273.0771 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0225
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0233
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 602.35,                last time consumption/overall running time: 69.8768s / 18342.9539 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0234
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0228
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 559.7,                last time consumption/overall running time: 65.1446s / 18408.0984 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0232
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0225
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 568.45,                last time consumption/overall running time: 65.5802s / 18473.6786 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0223
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0233
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 559.3,                last time consumption/overall running time: 64.0258s / 18537.7044 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0250
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0235
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 558.7,                last time consumption/overall running time: 64.4054s / 18602.1098 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0250
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0230
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 554.0,                last time consumption/overall running time: 63.8726s / 18665.9824 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0228
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0233
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 585.25,                last time consumption/overall running time: 68.1213s / 18734.1037 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0237
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0240
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 571.15,                last time consumption/overall running time: 66.4324s / 18800.5361 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0244
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0239
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 567.25,                last time consumption/overall running time: 65.2688s / 18865.8049 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0248
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0229
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 592.35,                last time consumption/overall running time: 69.1945s / 18934.9993 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0250
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0212
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 568.4,                last time consumption/overall running time: 65.8644s / 19000.8637 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0251
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0225
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 586.8,                last time consumption/overall running time: 67.4143s / 19068.2780 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0245
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0222
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 579.4,                last time consumption/overall running time: 67.4510s / 19135.7290 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0241
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0211
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 592.5,                last time consumption/overall running time: 68.8506s / 19204.5796 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0238
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0229
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 546.2,                last time consumption/overall running time: 62.7416s / 19267.3211 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0260
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0229
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 534.2,                last time consumption/overall running time: 60.9490s / 19328.2701 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0256
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0233
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 563.25,                last time consumption/overall running time: 64.9178s / 19393.1880 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0251
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0225
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 571.55,                last time consumption/overall running time: 66.5156s / 19459.7036 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0239
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0233
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 559.25,                last time consumption/overall running time: 65.5019s / 19525.2055 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0235
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0235
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 556.65,                last time consumption/overall running time: 63.8159s / 19589.0214 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0236
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0246
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 579.1,                last time consumption/overall running time: 66.1173s / 19655.1387 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0239
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0249
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 585.45,                last time consumption/overall running time: 67.9822s / 19723.1209 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0239
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0241
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 570.15,                last time consumption/overall running time: 66.1035s / 19789.2244 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0236
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0232
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 561.7,                last time consumption/overall running time: 64.6978s / 19853.9222 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0241
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0243
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 550.35,                last time consumption/overall running time: 63.3559s / 19917.2781 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0239
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0255
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 550.9,                last time consumption/overall running time: 64.6687s / 19981.9469 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0235
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0240
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 577.65,                last time consumption/overall running time: 66.6501s / 20048.5970 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0232
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0231
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 594.65,                last time consumption/overall running time: 68.4663s / 20117.0632 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0228
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0234
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 544.45,                last time consumption/overall running time: 62.9146s / 20179.9778 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0244
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0229
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 547.9,                last time consumption/overall running time: 63.4344s / 20243.4122 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0235
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0228
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 554.9,                last time consumption/overall running time: 63.6944s / 20307.1066 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0240
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0239
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 600.45,                last time consumption/overall running time: 69.5113s / 20376.6179 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0243
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0233
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 603.9,                last time consumption/overall running time: 69.5101s / 20446.1280 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0235
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0243
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 588.05,                last time consumption/overall running time: 67.6219s / 20513.7499 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0247
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0242
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 578.65,                last time consumption/overall running time: 68.0867s / 20581.8365 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0251
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0243
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 561.5,                last time consumption/overall running time: 65.1074s / 20646.9440 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0261
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0235
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 600.65,                last time consumption/overall running time: 70.3064s / 20717.2504 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0264
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0256
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 545.45,                last time consumption/overall running time: 62.5059s / 20779.7562 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0253
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0263
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 590.55,                last time consumption/overall running time: 67.9368s / 20847.6930 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0238
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0229
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 555.1,                last time consumption/overall running time: 63.8504s / 20911.5434 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0225
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0237
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 555.95,                last time consumption/overall running time: 64.6610s / 20976.2043 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0246
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0230
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 556.5,                last time consumption/overall running time: 64.1392s / 21040.3435 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0246
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0240
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 561.4,                last time consumption/overall running time: 64.7926s / 21105.1361 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0231
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0234
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 558.3,                last time consumption/overall running time: 65.2889s / 21170.4250 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0226
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0243
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 587.95,                last time consumption/overall running time: 68.8275s / 21239.2525 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0244
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0231
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 557.05,                last time consumption/overall running time: 64.6885s / 21303.9410 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0273
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0219
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 560.8,                last time consumption/overall running time: 65.2362s / 21369.1772 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0232
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0241
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 614.1,                last time consumption/overall running time: 71.2501s / 21440.4274 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0256
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0224
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 592.55,                last time consumption/overall running time: 68.6111s / 21509.0385 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0252
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0232
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 551.0,                last time consumption/overall running time: 64.0980s / 21573.1365 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0271
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0229
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 590.9,                last time consumption/overall running time: 68.2607s / 21641.3971 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0230
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0232
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 582.3,                last time consumption/overall running time: 67.7248s / 21709.1220 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0240
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0238
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 576.7,                last time consumption/overall running time: 66.4455s / 21775.5675 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0239
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0229
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 526.1,                last time consumption/overall running time: 60.8823s / 21836.4498 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0231
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0244
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 590.55,                last time consumption/overall running time: 67.8119s / 21904.2617 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0269
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0221
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 591.35,                last time consumption/overall running time: 68.9108s / 21973.1725 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0243
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0239
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 570.95,                last time consumption/overall running time: 65.8828s / 22039.0553 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0269
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0220
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 582.2,                last time consumption/overall running time: 67.4331s / 22106.4884 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0241
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0228
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 589.8,                last time consumption/overall running time: 67.8262s / 22174.3146 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0256
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0210
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 546.05,                last time consumption/overall running time: 63.2269s / 22237.5415 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0235
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0248
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 571.65,                last time consumption/overall running time: 66.0656s / 22303.6070 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0237
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0234
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 585.25,                last time consumption/overall running time: 67.9283s / 22371.5353 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0243
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0213
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 573.9,                last time consumption/overall running time: 66.3919s / 22437.9272 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0219
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0228
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 610.9,                last time consumption/overall running time: 69.9328s / 22507.8601 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0243
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0232
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 590.35,                last time consumption/overall running time: 67.6023s / 22575.4623 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0234
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0234
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 561.0,                last time consumption/overall running time: 64.6758s / 22640.1382 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0257
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0218
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 564.7,                last time consumption/overall running time: 66.0575s / 22706.1957 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0264
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0248
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 588.45,                last time consumption/overall running time: 68.5135s / 22774.7091 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0233
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0230
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 591.6,                last time consumption/overall running time: 69.1062s / 22843.8153 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0235
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0237
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 556.05,                last time consumption/overall running time: 64.0957s / 22907.9110 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0233
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0251
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 574.5,                last time consumption/overall running time: 66.9003s / 22974.8113 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0230
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0230
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 557.55,                last time consumption/overall running time: 64.9038s / 23039.7151 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0243
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0242
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 540.95,                last time consumption/overall running time: 63.0748s / 23102.7899 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0244
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0248
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 568.6,                last time consumption/overall running time: 65.6922s / 23168.4821 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0236
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0232
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 560.15,                last time consumption/overall running time: 64.8425s / 23233.3246 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0250
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0231
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 567.7,                last time consumption/overall running time: 65.5359s / 23298.8605 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0218
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0231
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 570.85,                last time consumption/overall running time: 65.6752s / 23364.5357 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0231
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0264
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 555.65,                last time consumption/overall running time: 64.3782s / 23428.9139 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0234
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0232
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 562.05,                last time consumption/overall running time: 64.7779s / 23493.6918 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0227
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0233
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 555.85,                last time consumption/overall running time: 64.1256s / 23557.8175 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0238
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0227
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 582.6,                last time consumption/overall running time: 66.8369s / 23624.6544 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0232
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0230
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 586.7,                last time consumption/overall running time: 67.9089s / 23692.5633 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0237
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0228
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 584.65,                last time consumption/overall running time: 68.1880s / 23760.7512 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0235
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0232
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 571.15,                last time consumption/overall running time: 66.3847s / 23827.1359 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0242
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0248
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 582.7,                last time consumption/overall running time: 67.1633s / 23894.2992 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0258
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0236
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 594.9,                last time consumption/overall running time: 68.8555s / 23963.1547 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0221
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0239
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 581.25,                last time consumption/overall running time: 67.5063s / 24030.6610 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0248
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0244
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 557.55,                last time consumption/overall running time: 63.9126s / 24094.5736 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0244
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0236
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 574.4,                last time consumption/overall running time: 66.2056s / 24160.7793 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0251
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0241
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 589.85,                last time consumption/overall running time: 68.5303s / 24229.3096 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0230
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0228
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 575.55,                last time consumption/overall running time: 66.8606s / 24296.1701 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0219
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0245
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 584.4,                last time consumption/overall running time: 68.3021s / 24364.4723 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0239
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0239
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 589.05,                last time consumption/overall running time: 67.7768s / 24432.2490 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0225
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0233
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 596.45,                last time consumption/overall running time: 69.7603s / 24502.0093 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0233
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0226
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 577.15,                last time consumption/overall running time: 67.3854s / 24569.3948 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0239
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0254
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 566.05,                last time consumption/overall running time: 65.0921s / 24634.4869 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0200
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0254
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 548.85,                last time consumption/overall running time: 62.7168s / 24697.2037 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0221
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0220
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 583.75,                last time consumption/overall running time: 67.2270s / 24764.4307 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0233
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0242
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 575.8,                last time consumption/overall running time: 66.4525s / 24830.8832 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0222
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0236
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 563.05,                last time consumption/overall running time: 65.4133s / 24896.2965 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0237
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0240
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 616.9,                last time consumption/overall running time: 71.6395s / 24967.9360 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0240
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0258
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 574.05,                last time consumption/overall running time: 65.9285s / 25033.8644 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0251
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0252
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 558.75,                last time consumption/overall running time: 64.4586s / 25098.3230 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0235
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0243
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 551.15,                last time consumption/overall running time: 63.5842s / 25161.9072 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0226
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0228
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 593.4,                last time consumption/overall running time: 68.2871s / 25230.1943 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0230
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0259
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 586.1,                last time consumption/overall running time: 67.7790s / 25297.9733 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0237
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0251
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 571.8,                last time consumption/overall running time: 65.7108s / 25363.6841 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0223
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0228
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 566.3,                last time consumption/overall running time: 65.8999s / 25429.5840 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0241
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0224
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 571.65,                last time consumption/overall running time: 66.4773s / 25496.0613 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0237
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0232
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 573.0,                last time consumption/overall running time: 65.9053s / 25561.9666 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0236
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0240
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 557.85,                last time consumption/overall running time: 64.0252s / 25625.9918 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0241
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0243
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 586.8,                last time consumption/overall running time: 67.5680s / 25693.5598 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0232
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0245
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 544.0,                last time consumption/overall running time: 62.7019s / 25756.2616 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0245
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0224
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 551.5,                last time consumption/overall running time: 63.3220s / 25819.5837 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0225
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0235
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 553.25,                last time consumption/overall running time: 63.6930s / 25883.2767 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0238
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0226
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 558.6,                last time consumption/overall running time: 64.4561s / 25947.7328 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0233
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0230
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 592.9,                last time consumption/overall running time: 68.8051s / 26016.5379 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0242
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0254
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 573.15,                last time consumption/overall running time: 66.4405s / 26082.9784 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0235
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0228
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 554.15,                last time consumption/overall running time: 63.6455s / 26146.6239 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0245
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0226
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 509.5,                last time consumption/overall running time: 58.7546s / 26205.3785 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0216
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0235
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 588.75,                last time consumption/overall running time: 67.8418s / 26273.2202 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0250
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0238
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 587.6,                last time consumption/overall running time: 67.0061s / 26340.2264 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0251
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0234
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 580.25,                last time consumption/overall running time: 66.1844s / 26406.4107 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0239
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0224
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 596.75,                last time consumption/overall running time: 68.1421s / 26474.5528 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0242
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0264
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 584.05,                last time consumption/overall running time: 66.9173s / 26541.4701 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0243
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0233
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 578.35,                last time consumption/overall running time: 66.3464s / 26607.8164 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0231
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0243
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 586.45,                last time consumption/overall running time: 68.7993s / 26676.6158 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0240
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0241
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 594.6,                last time consumption/overall running time: 68.5068s / 26745.1226 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0236
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0237
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 545.5,                last time consumption/overall running time: 63.2483s / 26808.3708 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0249
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0250
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 620.4,                last time consumption/overall running time: 71.9517s / 26880.3225 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0223
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0256
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 601.8,                last time consumption/overall running time: 69.1169s / 26949.4395 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0218
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0240
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 552.2,                last time consumption/overall running time: 63.7704s / 27013.2099 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0238
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0237
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 590.25,                last time consumption/overall running time: 67.5661s / 27080.7759 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0225
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0258
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 525.15,                last time consumption/overall running time: 60.4601s / 27141.2360 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0247
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0247
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 584.3,                last time consumption/overall running time: 66.6097s / 27207.8457 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0224
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0241
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 579.95,                last time consumption/overall running time: 67.5403s / 27275.3860 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0224
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0232
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 579.75,                last time consumption/overall running time: 66.3627s / 27341.7487 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0226
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0240
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 586.4,                last time consumption/overall running time: 68.0706s / 27409.8193 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0239
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0236
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 535.6,                last time consumption/overall running time: 61.5985s / 27471.4178 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0241
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0244
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 593.1,                last time consumption/overall running time: 67.6738s / 27539.0916 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0246
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0249
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 588.7,                last time consumption/overall running time: 67.6438s / 27606.7354 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0243
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0224
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 595.75,                last time consumption/overall running time: 68.7911s / 27675.5265 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0261
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0225
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 546.55,                last time consumption/overall running time: 63.3101s / 27738.8366 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0255
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0222
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 559.45,                last time consumption/overall running time: 64.2955s / 27803.1321 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0240
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0250
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 580.9,                last time consumption/overall running time: 67.2701s / 27870.4021 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0225
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0212
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 567.15,                last time consumption/overall running time: 65.8333s / 27936.2354 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0240
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0224
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 566.9,                last time consumption/overall running time: 66.1242s / 28002.3596 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0257
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0212
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 565.35,                last time consumption/overall running time: 64.7888s / 28067.1484 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0235
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0231
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 566.9,                last time consumption/overall running time: 64.8052s / 28131.9536 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0231
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0234
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 537.0,                last time consumption/overall running time: 61.7897s / 28193.7433 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0228
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0230
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 568.4,                last time consumption/overall running time: 65.8181s / 28259.5613 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0232
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0228
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 585.2,                last time consumption/overall running time: 67.5950s / 28327.1564 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0226
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0216
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 545.4,                last time consumption/overall running time: 63.4006s / 28390.5570 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0228
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0219
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 589.9,                last time consumption/overall running time: 67.6475s / 28458.2045 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0226
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0241
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 608.1,                last time consumption/overall running time: 69.5427s / 28527.7472 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0232
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0231
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 548.15,                last time consumption/overall running time: 63.2632s / 28591.0104 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0253
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0240
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 567.85,                last time consumption/overall running time: 65.2810s / 28656.2914 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0229
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0238
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 610.7,                last time consumption/overall running time: 70.3946s / 28726.6860 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0244
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0234
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 610.15,                last time consumption/overall running time: 70.9102s / 28797.5961 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0241
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0240
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 578.85,                last time consumption/overall running time: 67.1749s / 28864.7710 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0235
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0248
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 573.5,                last time consumption/overall running time: 66.1596s / 28930.9307 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0233
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0245
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 536.8,                last time consumption/overall running time: 61.8098s / 28992.7404 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0234
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0243
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 545.65,                last time consumption/overall running time: 62.8844s / 29055.6248 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0226
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0230
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 604.95,                last time consumption/overall running time: 69.8743s / 29125.4992 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0210
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0232
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 557.05,                last time consumption/overall running time: 63.9886s / 29189.4878 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0233
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0227
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 578.75,                last time consumption/overall running time: 66.7051s / 29256.1929 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0223
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0236
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 568.8,                last time consumption/overall running time: 66.0274s / 29322.2203 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0215
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0243
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 550.6,                last time consumption/overall running time: 63.9219s / 29386.1422 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0223
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0233
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 625.1,                last time consumption/overall running time: 73.0726s / 29459.2149 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0227
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0254
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 559.1,                last time consumption/overall running time: 64.8779s / 29524.0928 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0244
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0245
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 538.25,                last time consumption/overall running time: 62.2089s / 29586.3017 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0232
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0220
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 602.8,                last time consumption/overall running time: 69.2440s / 29655.5457 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0228
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0221
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 597.3,                last time consumption/overall running time: 68.6529s / 29724.1986 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0230
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0232
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 555.4,                last time consumption/overall running time: 64.2799s / 29788.4785 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0257
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0251
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 582.8,                last time consumption/overall running time: 67.6088s / 29856.0873 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0228
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0252
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 549.7,                last time consumption/overall running time: 63.1058s / 29919.1932 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0230
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0224
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 570.7,                last time consumption/overall running time: 65.7410s / 29984.9341 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0237
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0237
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 567.0,                last time consumption/overall running time: 66.1026s / 30051.0367 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0237
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0240
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 534.55,                last time consumption/overall running time: 62.3829s / 30113.4196 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0227
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0240
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 541.65,                last time consumption/overall running time: 63.1960s / 30176.6156 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0245
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0232
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 586.9,                last time consumption/overall running time: 67.6942s / 30244.3098 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0232
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0244
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 530.1,                last time consumption/overall running time: 62.1401s / 30306.4499 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0238
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0243
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 542.2,                last time consumption/overall running time: 62.6192s / 30369.0691 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0220
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0235
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 556.75,                last time consumption/overall running time: 64.1877s / 30433.2568 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0234
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0227
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 589.4,                last time consumption/overall running time: 67.8889s / 30501.1457 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0239
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0220
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 607.2,                last time consumption/overall running time: 69.8258s / 30570.9715 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0242
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0230
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 597.7,                last time consumption/overall running time: 68.8428s / 30639.8143 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0233
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0233
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 551.15,                last time consumption/overall running time: 63.7283s / 30703.5425 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0237
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0238
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 584.55,                last time consumption/overall running time: 67.8975s / 30771.4400 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0254
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0217
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 565.85,                last time consumption/overall running time: 64.9595s / 30836.3995 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0247
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0247
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 561.7,                last time consumption/overall running time: 64.8459s / 30901.2454 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0230
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0238
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 592.05,                last time consumption/overall running time: 68.8072s / 30970.0526 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0244
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0227
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 619.6,                last time consumption/overall running time: 72.0368s / 31042.0894 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0236
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0238
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 540.65,                last time consumption/overall running time: 62.6232s / 31104.7126 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0219
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0251
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 565.75,                last time consumption/overall running time: 65.3278s / 31170.0404 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0240
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0219
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 551.9,                last time consumption/overall running time: 63.7014s / 31233.7418 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0233
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0240
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 581.05,                last time consumption/overall running time: 66.7358s / 31300.4776 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0249
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0237
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 596.45,                last time consumption/overall running time: 69.5269s / 31370.0045 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0231
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0232
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 582.2,                last time consumption/overall running time: 67.7259s / 31437.7305 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0247
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0238
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 592.0,                last time consumption/overall running time: 68.5391s / 31506.2696 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0246
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0245
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 529.45,                last time consumption/overall running time: 60.7387s / 31567.0082 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0244
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0241
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 591.1,                last time consumption/overall running time: 68.4356s / 31635.4439 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0218
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0247
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 575.2,                last time consumption/overall running time: 66.5099s / 31701.9537 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0245
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0239
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 559.55,                last time consumption/overall running time: 64.6013s / 31766.5551 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0223
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0240
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 568.55,                last time consumption/overall running time: 66.1124s / 31832.6675 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0234
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0241
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 582.8,                last time consumption/overall running time: 68.2494s / 31900.9168 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0242
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0234
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 589.85,                last time consumption/overall running time: 68.0047s / 31968.9215 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0242
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0229
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 598.8,                last time consumption/overall running time: 68.8468s / 32037.7683 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0244
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0243
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 564.15,                last time consumption/overall running time: 64.4222s / 32102.1906 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0264
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0254
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 558.4,                last time consumption/overall running time: 64.4794s / 32166.6699 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0229
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0244
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 606.85,                last time consumption/overall running time: 70.6602s / 32237.3301 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0247
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0251
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 541.7,                last time consumption/overall running time: 62.6860s / 32300.0162 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0254
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0258
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 583.8,                last time consumption/overall running time: 67.6871s / 32367.7033 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0241
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0228
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 604.2,                last time consumption/overall running time: 69.2022s / 32436.9055 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0260
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0251
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 562.95,                last time consumption/overall running time: 65.1853s / 32502.0909 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0236
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0240
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 573.25,                last time consumption/overall running time: 66.7513s / 32568.8422 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0244
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0258Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
/home/zihan/research/MARS/mars/rl/agents/nash_dqn.py:289: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  action = torch.FloatTensor(action).to(self.device)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 586.9,                last time consumption/overall running time: 68.3709s / 32637.2131 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0250
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0241
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 556.45,                last time consumption/overall running time: 63.7914s / 32701.0046 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0253
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0239
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 558.75,                last time consumption/overall running time: 64.5979s / 32765.6025 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0236
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0215
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 580.05,                last time consumption/overall running time: 67.1743s / 32832.7768 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0241
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0243
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 566.9,                last time consumption/overall running time: 64.7729s / 32897.5497 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0231
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0246
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
