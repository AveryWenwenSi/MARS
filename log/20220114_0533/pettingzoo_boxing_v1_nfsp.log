pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [70, 30]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=64, bias=True)
      (1): ReLU()
      (2): Linear(in_features=64, out_features=64, bias=True)
      (3): ReLU()
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): ReLU()
      (6): Linear(in_features=64, out_features=64, bias=True)
      (7): ReLU()
      (8): Linear(in_features=64, out_features=18, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=64, bias=True)
      (1): ReLU()
      (2): Linear(in_features=64, out_features=64, bias=True)
      (3): ReLU()
      (4): Linear(in_features=64, out_features=64, bias=True)
      (5): ReLU()
      (6): Linear(in_features=64, out_features=64, bias=True)
      (7): ReLU()
      (8): Linear(in_features=64, out_features=18, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 10000, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nfsp', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'eta': 0.1}}
Save models to : /home/zihan/research/MARS/data/model/20220114_0533/pettingzoo_boxing_v1_nfsp. 
 Save logs to: /home/zihan/research/MARS/data/log/20220114_0533/pettingzoo_boxing_v1_nfsp.
Episode: 1/10000 (0.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 6.1947s / 6.1947 s
env0_first_0:                 episode reward: -6.0000,                 loss: nan
env0_second_0:                 episode reward: 6.0000,                 loss: nan
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 1784.0,                last time consumption/overall running time: 474.7878s / 480.9825 s
env0_first_0:                 episode reward: -1.7500,                 loss: nan
env0_second_0:                 episode reward: 1.7500,                 loss: nan
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 1784.0,                last time consumption/overall running time: 614.8574s / 1095.8399 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.0092
env0_second_0:                 episode reward: 10.6500,                 loss: 0.0091
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 1784.0,                last time consumption/overall running time: 617.4851s / 1713.3250 s
env0_first_0:                 episode reward: -21.1500,                 loss: 0.0169
env0_second_0:                 episode reward: 21.1500,                 loss: 0.0181
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1726.55,                last time consumption/overall running time: 604.5186s / 2317.8437 s
env0_first_0:                 episode reward: -20.5500,                 loss: 0.0359
env0_second_0:                 episode reward: 20.5500,                 loss: 0.0431
env1_first_0:                 episode reward: -22.5500,                 loss: nan
env1_second_0:                 episode reward: 22.5500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 1745.05,                last time consumption/overall running time: 608.2490s / 2926.0927 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0649
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0737
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 1711.55,                last time consumption/overall running time: 596.8449s / 3522.9376 s
env0_first_0:                 episode reward: -33.7500,                 loss: 0.0553
env0_second_0:                 episode reward: 33.7500,                 loss: 0.0659
env1_first_0:                 episode reward: -36.4500,                 loss: nan
env1_second_0:                 episode reward: 36.4500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 1184.9,                last time consumption/overall running time: 414.8164s / 3937.7539 s
env0_first_0:                 episode reward: -45.9000,                 loss: 0.0613
env0_second_0:                 episode reward: 45.9000,                 loss: 0.0746
env1_first_0:                 episode reward: -48.7500,                 loss: nan
env1_second_0:                 episode reward: 48.7500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 602.0,                last time consumption/overall running time: 210.8885s / 4148.6424 s
env0_first_0:                 episode reward: -57.5500,                 loss: 0.0979
env0_second_0:                 episode reward: 57.5500,                 loss: 0.1064
env1_first_0:                 episode reward: -60.5000,                 loss: nan
env1_second_0:                 episode reward: 60.5000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 464.8,                last time consumption/overall running time: 163.1180s / 4311.7604 s
env0_first_0:                 episode reward: -84.0000,                 loss: 0.1453
env0_second_0:                 episode reward: 84.0000,                 loss: 0.1498
env1_first_0:                 episode reward: -58.0000,                 loss: nan
env1_second_0:                 episode reward: 58.0000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 707.65,                last time consumption/overall running time: 247.2482s / 4559.0086 s
env0_first_0:                 episode reward: -59.1500,                 loss: 0.1766
env0_second_0:                 episode reward: 59.1500,                 loss: 0.2014
env1_first_0:                 episode reward: -52.2500,                 loss: nan
env1_second_0:                 episode reward: 52.2500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 789.2,                last time consumption/overall running time: 278.2772s / 4837.2858 s
env0_first_0:                 episode reward: -55.6000,                 loss: 0.2265
env0_second_0:                 episode reward: 55.6000,                 loss: 0.2337
env1_first_0:                 episode reward: -61.6500,                 loss: nan
env1_second_0:                 episode reward: 61.6500,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 346.65,                last time consumption/overall running time: 121.6880s / 4958.9738 s
env0_first_0:                 episode reward: -81.4500,                 loss: 0.2406
env0_second_0:                 episode reward: 81.4500,                 loss: 0.2483
env1_first_0:                 episode reward: -70.3000,                 loss: nan
env1_second_0:                 episode reward: 70.3000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 445.55,                last time consumption/overall running time: 156.4556s / 5115.4293 s
env0_first_0:                 episode reward: -81.4000,                 loss: 0.2642
env0_second_0:                 episode reward: 81.4000,                 loss: 0.2657
env1_first_0:                 episode reward: -64.6000,                 loss: nan
env1_second_0:                 episode reward: 64.6000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 718.5,                last time consumption/overall running time: 252.0449s / 5367.4743 s
env0_first_0:                 episode reward: -46.7000,                 loss: 0.2674
env0_second_0:                 episode reward: 46.7000,                 loss: 0.2667
env1_first_0:                 episode reward: -48.3500,                 loss: nan
env1_second_0:                 episode reward: 48.3500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 844.7,                last time consumption/overall running time: 296.8785s / 5664.3528 s
env0_first_0:                 episode reward: -54.1000,                 loss: 0.2876
env0_second_0:                 episode reward: 54.1000,                 loss: 0.3030
env1_first_0:                 episode reward: -49.4000,                 loss: nan
env1_second_0:                 episode reward: 49.4000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 441.75,                last time consumption/overall running time: 155.2097s / 5819.5625 s
env0_first_0:                 episode reward: -64.0000,                 loss: 0.3102
env0_second_0:                 episode reward: 64.0000,                 loss: 0.3445
env1_first_0:                 episode reward: -59.4000,                 loss: nan
env1_second_0:                 episode reward: 59.4000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 383.75,                last time consumption/overall running time: 133.7526s / 5953.3151 s
env0_first_0:                 episode reward: -66.4000,                 loss: 0.2982
env0_second_0:                 episode reward: 66.4000,                 loss: 0.3253
env1_first_0:                 episode reward: -63.2500,                 loss: nan
env1_second_0:                 episode reward: 63.2500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 458.3,                last time consumption/overall running time: 161.0909s / 6114.4060 s
env0_first_0:                 episode reward: -45.8000,                 loss: 0.3165
env0_second_0:                 episode reward: 45.8000,                 loss: 0.3308
env1_first_0:                 episode reward: -69.8500,                 loss: nan
env1_second_0:                 episode reward: 69.8500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 287.15,                last time consumption/overall running time: 100.9347s / 6215.3407 s
env0_first_0:                 episode reward: -87.4000,                 loss: 0.3818
env0_second_0:                 episode reward: 87.4000,                 loss: 0.3793
env1_first_0:                 episode reward: -64.6000,                 loss: nan
env1_second_0:                 episode reward: 64.6000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 276.05,                last time consumption/overall running time: 96.4642s / 6311.8050 s
env0_first_0:                 episode reward: -76.1500,                 loss: 0.4443
env0_second_0:                 episode reward: 76.1500,                 loss: 0.4436
env1_first_0:                 episode reward: -77.5000,                 loss: nan
env1_second_0:                 episode reward: 77.5000,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 247.65,                last time consumption/overall running time: 87.4601s / 6399.2651 s
env0_first_0:                 episode reward: -74.7500,                 loss: 0.4787
env0_second_0:                 episode reward: 74.7500,                 loss: 0.5081
env1_first_0:                 episode reward: -76.8500,                 loss: nan
env1_second_0:                 episode reward: 76.8500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 339.2,                last time consumption/overall running time: 119.0989s / 6518.3639 s
env0_first_0:                 episode reward: -69.3500,                 loss: 0.5240
env0_second_0:                 episode reward: 69.3500,                 loss: 0.5483
env1_first_0:                 episode reward: -68.6000,                 loss: nan
env1_second_0:                 episode reward: 68.6000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 296.55,                last time consumption/overall running time: 104.1152s / 6622.4792 s
env0_first_0:                 episode reward: -55.1000,                 loss: 0.5696
env0_second_0:                 episode reward: 55.1000,                 loss: 0.5777
env1_first_0:                 episode reward: -54.4500,                 loss: nan
env1_second_0:                 episode reward: 54.4500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 315.1,                last time consumption/overall running time: 109.8621s / 6732.3412 s
env0_first_0:                 episode reward: -59.9500,                 loss: 0.6056
env0_second_0:                 episode reward: 59.9500,                 loss: 0.6149
env1_first_0:                 episode reward: -74.1000,                 loss: nan
env1_second_0:                 episode reward: 74.1000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 261.95,                last time consumption/overall running time: 91.9109s / 6824.2521 s
env0_first_0:                 episode reward: -84.7500,                 loss: 0.6279
env0_second_0:                 episode reward: 84.7500,                 loss: 0.6533
env1_first_0:                 episode reward: -87.1000,                 loss: nan
env1_second_0:                 episode reward: 87.1000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 274.6,                last time consumption/overall running time: 94.8396s / 6919.0916 s
env0_first_0:                 episode reward: -84.6000,                 loss: 0.6688
env0_second_0:                 episode reward: 84.6000,                 loss: 0.7195
env1_first_0:                 episode reward: -79.4500,                 loss: nan
env1_second_0:                 episode reward: 79.4500,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 315.25,                last time consumption/overall running time: 110.4519s / 7029.5435 s
env0_first_0:                 episode reward: -67.5000,                 loss: 0.7739
env0_second_0:                 episode reward: 67.5000,                 loss: 0.7523
env1_first_0:                 episode reward: -79.8500,                 loss: nan
env1_second_0:                 episode reward: 79.8500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 287.5,                last time consumption/overall running time: 101.1586s / 7130.7021 s
env0_first_0:                 episode reward: -73.6500,                 loss: 0.7631
env0_second_0:                 episode reward: 73.6500,                 loss: 0.7679
env1_first_0:                 episode reward: -75.9000,                 loss: nan
env1_second_0:                 episode reward: 75.9000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 306.15,                last time consumption/overall running time: 107.7368s / 7238.4389 s
env0_first_0:                 episode reward: -76.0000,                 loss: 0.7791
env0_second_0:                 episode reward: 76.0000,                 loss: 0.7888
env1_first_0:                 episode reward: -74.4000,                 loss: nan
env1_second_0:                 episode reward: 74.4000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 333.3,                last time consumption/overall running time: 118.5951s / 7357.0340 s
env0_first_0:                 episode reward: -68.4000,                 loss: 0.7592
env0_second_0:                 episode reward: 68.4000,                 loss: 0.8490
env1_first_0:                 episode reward: -70.2500,                 loss: nan
env1_second_0:                 episode reward: 70.2500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 332.35,                last time consumption/overall running time: 117.2708s / 7474.3048 s
env0_first_0:                 episode reward: -65.0500,                 loss: 0.7987
env0_second_0:                 episode reward: 65.0500,                 loss: 0.8370
env1_first_0:                 episode reward: -81.4000,                 loss: nan
env1_second_0:                 episode reward: 81.4000,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 385.9,                last time consumption/overall running time: 135.0113s / 7609.3162 s
env0_first_0:                 episode reward: -70.8500,                 loss: 0.8233
env0_second_0:                 episode reward: 70.8500,                 loss: 0.8216
env1_first_0:                 episode reward: -59.1500,                 loss: nan
env1_second_0:                 episode reward: 59.1500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 304.95,                last time consumption/overall running time: 107.0567s / 7716.3728 s
env0_first_0:                 episode reward: -83.5500,                 loss: 0.8050
env0_second_0:                 episode reward: 83.5500,                 loss: 0.7974
env1_first_0:                 episode reward: -78.0500,                 loss: nan
env1_second_0:                 episode reward: 78.0500,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 289.85,                last time consumption/overall running time: 103.2557s / 7819.6285 s
env0_first_0:                 episode reward: -84.0000,                 loss: 0.8235
env0_second_0:                 episode reward: 84.0000,                 loss: 0.8149
env1_first_0:                 episode reward: -68.4000,                 loss: nan
env1_second_0:                 episode reward: 68.4000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 272.05,                last time consumption/overall running time: 95.6027s / 7915.2312 s
env0_first_0:                 episode reward: -84.6500,                 loss: 0.8354
env0_second_0:                 episode reward: 84.6500,                 loss: 0.7765
env1_first_0:                 episode reward: -70.0500,                 loss: nan
env1_second_0:                 episode reward: 70.0500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 276.0,                last time consumption/overall running time: 96.5536s / 8011.7848 s
env0_first_0:                 episode reward: -76.7500,                 loss: 0.8262
env0_second_0:                 episode reward: 76.7500,                 loss: 0.7402
env1_first_0:                 episode reward: -82.0500,                 loss: nan
env1_second_0:                 episode reward: 82.0500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 541.5,                last time consumption/overall running time: 189.9264s / 8201.7112 s
env0_first_0:                 episode reward: -64.6000,                 loss: 0.8368
env0_second_0:                 episode reward: 64.6000,                 loss: 0.7543
env1_first_0:                 episode reward: -62.0500,                 loss: nan
env1_second_0:                 episode reward: 62.0500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 583.55,                last time consumption/overall running time: 205.9024s / 8407.6136 s
env0_first_0:                 episode reward: -62.5500,                 loss: 0.7301
env0_second_0:                 episode reward: 62.5500,                 loss: 0.7204
env1_first_0:                 episode reward: -59.1000,                 loss: nan
env1_second_0:                 episode reward: 59.1000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 677.6,                last time consumption/overall running time: 241.2361s / 8648.8497 s
env0_first_0:                 episode reward: -51.7000,                 loss: 0.6506
env0_second_0:                 episode reward: 51.7000,                 loss: 0.6625
env1_first_0:                 episode reward: -59.7500,                 loss: nan
env1_second_0:                 episode reward: 59.7500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 817.2,                last time consumption/overall running time: 286.8156s / 8935.6653 s
env0_first_0:                 episode reward: -51.1500,                 loss: 0.5025
env0_second_0:                 episode reward: 51.1500,                 loss: 0.4923
env1_first_0:                 episode reward: -46.4000,                 loss: nan
env1_second_0:                 episode reward: 46.4000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 569.9,                last time consumption/overall running time: 199.7914s / 9135.4567 s
env0_first_0:                 episode reward: -68.6500,                 loss: 0.4114
env0_second_0:                 episode reward: 68.6500,                 loss: 0.3920
env1_first_0:                 episode reward: -71.6500,                 loss: nan
env1_second_0:                 episode reward: 71.6500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 445.1,                last time consumption/overall running time: 156.3460s / 9291.8027 s
env0_first_0:                 episode reward: -60.9500,                 loss: 0.4752
env0_second_0:                 episode reward: 60.9500,                 loss: 0.5012
env1_first_0:                 episode reward: -68.1000,                 loss: nan
env1_second_0:                 episode reward: 68.1000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 520.55,                last time consumption/overall running time: 182.5464s / 9474.3491 s
env0_first_0:                 episode reward: -73.1000,                 loss: 0.5093
env0_second_0:                 episode reward: 73.1000,                 loss: 0.4983
env1_first_0:                 episode reward: -66.4500,                 loss: nan
env1_second_0:                 episode reward: 66.4500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 477.45,                last time consumption/overall running time: 171.1031s / 9645.4522 s
env0_first_0:                 episode reward: -74.6500,                 loss: 0.5837
env0_second_0:                 episode reward: 74.6500,                 loss: 0.5197
env1_first_0:                 episode reward: -71.9000,                 loss: nan
env1_second_0:                 episode reward: 71.9000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 279.75,                last time consumption/overall running time: 100.2676s / 9745.7198 s
env0_first_0:                 episode reward: -73.0000,                 loss: 0.6996
env0_second_0:                 episode reward: 73.0000,                 loss: 0.5499
env1_first_0:                 episode reward: -78.6500,                 loss: nan
env1_second_0:                 episode reward: 78.6500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 304.2,                last time consumption/overall running time: 106.0624s / 9851.7822 s
env0_first_0:                 episode reward: -71.5000,                 loss: 0.8064
env0_second_0:                 episode reward: 71.5000,                 loss: 0.6468
env1_first_0:                 episode reward: -79.9500,                 loss: nan
env1_second_0:                 episode reward: 79.9500,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 293.0,                last time consumption/overall running time: 102.9355s / 9954.7177 s
env0_first_0:                 episode reward: -78.2000,                 loss: 0.8595
env0_second_0:                 episode reward: 78.2000,                 loss: 0.7372
env1_first_0:                 episode reward: -69.4500,                 loss: nan
env1_second_0:                 episode reward: 69.4500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 277.45,                last time consumption/overall running time: 97.8147s / 10052.5324 s
env0_first_0:                 episode reward: -79.7000,                 loss: 0.9403
env0_second_0:                 episode reward: 79.7000,                 loss: 0.8062
env1_first_0:                 episode reward: -71.8000,                 loss: nan
env1_second_0:                 episode reward: 71.8000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 299.35,                last time consumption/overall running time: 104.9022s / 10157.4346 s
env0_first_0:                 episode reward: -75.2000,                 loss: 0.9190
env0_second_0:                 episode reward: 75.2000,                 loss: 0.8035
env1_first_0:                 episode reward: -71.0000,                 loss: nan
env1_second_0:                 episode reward: 71.0000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 271.0,                last time consumption/overall running time: 95.9902s / 10253.4249 s
env0_first_0:                 episode reward: -81.1500,                 loss: 0.9647
env0_second_0:                 episode reward: 81.1500,                 loss: 0.8299
env1_first_0:                 episode reward: -80.3000,                 loss: nan
env1_second_0:                 episode reward: 80.3000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 317.95,                last time consumption/overall running time: 111.7933s / 10365.2182 s
env0_first_0:                 episode reward: -73.8500,                 loss: 1.0200
env0_second_0:                 episode reward: 73.8500,                 loss: 0.9131
env1_first_0:                 episode reward: -67.1500,                 loss: nan
env1_second_0:                 episode reward: 67.1500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 390.35,                last time consumption/overall running time: 136.0480s / 10501.2662 s
env0_first_0:                 episode reward: -67.9000,                 loss: 1.0521
env0_second_0:                 episode reward: 67.9000,                 loss: 0.9628
env1_first_0:                 episode reward: -54.1500,                 loss: nan
env1_second_0:                 episode reward: 54.1500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 335.05,                last time consumption/overall running time: 117.9383s / 10619.2045 s
env0_first_0:                 episode reward: -85.1500,                 loss: 1.2066
env0_second_0:                 episode reward: 85.1500,                 loss: 1.0693
env1_first_0:                 episode reward: -50.4500,                 loss: nan
env1_second_0:                 episode reward: 50.4500,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 314.35,                last time consumption/overall running time: 110.9015s / 10730.1060 s
env0_first_0:                 episode reward: -77.7000,                 loss: 1.2740
env0_second_0:                 episode reward: 77.7000,                 loss: 1.0471
env1_first_0:                 episode reward: -75.2000,                 loss: nan
env1_second_0:                 episode reward: 75.2000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 319.55,                last time consumption/overall running time: 112.4708s / 10842.5768 s
env0_first_0:                 episode reward: -72.7000,                 loss: 1.2150
env0_second_0:                 episode reward: 72.7000,                 loss: 1.0475
env1_first_0:                 episode reward: -74.9500,                 loss: nan
env1_second_0:                 episode reward: 74.9500,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 312.4,                last time consumption/overall running time: 110.1667s / 10952.7435 s
env0_first_0:                 episode reward: -71.1000,                 loss: 1.1857
env0_second_0:                 episode reward: 71.1000,                 loss: 1.0635
env1_first_0:                 episode reward: -87.3000,                 loss: nan
env1_second_0:                 episode reward: 87.3000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 370.95,                last time consumption/overall running time: 128.9866s / 11081.7301 s
env0_first_0:                 episode reward: -74.8500,                 loss: 1.2073
env0_second_0:                 episode reward: 74.8500,                 loss: 1.0951
env1_first_0:                 episode reward: -66.9500,                 loss: nan
env1_second_0:                 episode reward: 66.9500,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 322.25,                last time consumption/overall running time: 113.2469s / 11194.9770 s
env0_first_0:                 episode reward: -83.4500,                 loss: 1.2199
env0_second_0:                 episode reward: 83.4500,                 loss: 1.0479
env1_first_0:                 episode reward: -64.1500,                 loss: nan
env1_second_0:                 episode reward: 64.1500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 330.15,                last time consumption/overall running time: 115.5523s / 11310.5293 s
env0_first_0:                 episode reward: -73.4000,                 loss: 1.1857
env0_second_0:                 episode reward: 73.4000,                 loss: 0.9789
env1_first_0:                 episode reward: -75.4500,                 loss: nan
env1_second_0:                 episode reward: 75.4500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 290.8,                last time consumption/overall running time: 102.9817s / 11413.5109 s
env0_first_0:                 episode reward: -74.6500,                 loss: 1.1958
env0_second_0:                 episode reward: 74.6500,                 loss: 0.8898
env1_first_0:                 episode reward: -67.6000,                 loss: nan
env1_second_0:                 episode reward: 67.6000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 347.8,                last time consumption/overall running time: 123.4244s / 11536.9354 s
env0_first_0:                 episode reward: -78.4000,                 loss: 1.1641
env0_second_0:                 episode reward: 78.4000,                 loss: 0.8912
env1_first_0:                 episode reward: -66.8500,                 loss: nan
env1_second_0:                 episode reward: 66.8500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 250.35,                last time consumption/overall running time: 88.4921s / 11625.4275 s
env0_first_0:                 episode reward: -78.2000,                 loss: 1.1056
env0_second_0:                 episode reward: 78.2000,                 loss: 0.8240
env1_first_0:                 episode reward: -77.3500,                 loss: nan
env1_second_0:                 episode reward: 77.3500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 309.5,                last time consumption/overall running time: 108.3522s / 11733.7797 s
env0_first_0:                 episode reward: -69.3000,                 loss: 1.0777
env0_second_0:                 episode reward: 69.3000,                 loss: 0.7799
env1_first_0:                 episode reward: -83.0000,                 loss: nan
env1_second_0:                 episode reward: 83.0000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 274.6,                last time consumption/overall running time: 96.5645s / 11830.3442 s
env0_first_0:                 episode reward: -79.4000,                 loss: 1.0189
env0_second_0:                 episode reward: 79.4000,                 loss: 0.7777
env1_first_0:                 episode reward: -78.4000,                 loss: nan
env1_second_0:                 episode reward: 78.4000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 291.6,                last time consumption/overall running time: 101.5740s / 11931.9182 s
env0_first_0:                 episode reward: -78.4500,                 loss: 1.0341
env0_second_0:                 episode reward: 78.4500,                 loss: 0.8032
env1_first_0:                 episode reward: -83.4500,                 loss: nan
env1_second_0:                 episode reward: 83.4500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 275.35,                last time consumption/overall running time: 97.3091s / 12029.2273 s
env0_first_0:                 episode reward: -86.7500,                 loss: 1.0358
env0_second_0:                 episode reward: 86.7500,                 loss: 0.7705
env1_first_0:                 episode reward: -85.0500,                 loss: nan
env1_second_0:                 episode reward: 85.0500,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 309.25,                last time consumption/overall running time: 108.7920s / 12138.0193 s
env0_first_0:                 episode reward: -71.5000,                 loss: 1.0096
env0_second_0:                 episode reward: 71.5000,                 loss: 0.7564
env1_first_0:                 episode reward: -75.5000,                 loss: nan
env1_second_0:                 episode reward: 75.5000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 415.45,                last time consumption/overall running time: 145.0452s / 12283.0646 s
env0_first_0:                 episode reward: -70.6500,                 loss: 1.0402
env0_second_0:                 episode reward: 70.6500,                 loss: 0.7603
env1_first_0:                 episode reward: -71.0500,                 loss: nan
env1_second_0:                 episode reward: 71.0500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 522.5,                last time consumption/overall running time: 182.3285s / 12465.3931 s
env0_first_0:                 episode reward: -45.3000,                 loss: 0.9880
env0_second_0:                 episode reward: 45.3000,                 loss: 0.7584
env1_first_0:                 episode reward: -73.5000,                 loss: nan
env1_second_0:                 episode reward: 73.5000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 758.65,                last time consumption/overall running time: 263.5974s / 12728.9905 s
env0_first_0:                 episode reward: -58.2000,                 loss: 1.0317
env0_second_0:                 episode reward: 58.2000,                 loss: 0.8753
env1_first_0:                 episode reward: -55.1000,                 loss: nan
env1_second_0:                 episode reward: 55.1000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 1286.1,                last time consumption/overall running time: 446.6882s / 13175.6787 s
env0_first_0:                 episode reward: -36.5500,                 loss: 0.7279
env0_second_0:                 episode reward: 36.5500,                 loss: 0.6265
env1_first_0:                 episode reward: -38.9000,                 loss: nan
env1_second_0:                 episode reward: 38.9000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 488.0,                last time consumption/overall running time: 170.8993s / 13346.5779 s
env0_first_0:                 episode reward: -49.6000,                 loss: 0.5660
env0_second_0:                 episode reward: 49.6000,                 loss: 0.4810
env1_first_0:                 episode reward: -69.6000,                 loss: nan
env1_second_0:                 episode reward: 69.6000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 395.1,                last time consumption/overall running time: 139.1110s / 13485.6889 s
env0_first_0:                 episode reward: -65.2500,                 loss: 0.5178
env0_second_0:                 episode reward: 65.2500,                 loss: 0.4375
env1_first_0:                 episode reward: -79.8500,                 loss: nan
env1_second_0:                 episode reward: 79.8500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 357.5,                last time consumption/overall running time: 125.4895s / 13611.1785 s
env0_first_0:                 episode reward: -75.4500,                 loss: 0.5443
env0_second_0:                 episode reward: 75.4500,                 loss: 0.4744
env1_first_0:                 episode reward: -67.7000,                 loss: nan
env1_second_0:                 episode reward: 67.7000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 786.5,                last time consumption/overall running time: 273.6059s / 13884.7843 s
env0_first_0:                 episode reward: -39.7500,                 loss: 0.5577
env0_second_0:                 episode reward: 39.7500,                 loss: 0.5634
env1_first_0:                 episode reward: -50.6500,                 loss: nan
env1_second_0:                 episode reward: 50.6500,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 451.7,                last time consumption/overall running time: 157.3087s / 14042.0931 s
env0_first_0:                 episode reward: -52.5000,                 loss: 0.6801
env0_second_0:                 episode reward: 52.5000,                 loss: 0.6759
env1_first_0:                 episode reward: -66.4500,                 loss: nan
env1_second_0:                 episode reward: 66.4500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 394.55,                last time consumption/overall running time: 141.1562s / 14183.2493 s
env0_first_0:                 episode reward: -60.4000,                 loss: 0.7453
env0_second_0:                 episode reward: 60.4000,                 loss: 0.7133
env1_first_0:                 episode reward: -66.5500,                 loss: nan
env1_second_0:                 episode reward: 66.5500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 434.6,                last time consumption/overall running time: 152.8298s / 14336.0790 s
env0_first_0:                 episode reward: -72.0500,                 loss: 0.7355
env0_second_0:                 episode reward: 72.0500,                 loss: 0.7506
env1_first_0:                 episode reward: -75.0000,                 loss: nan
env1_second_0:                 episode reward: 75.0000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 553.9,                last time consumption/overall running time: 195.1428s / 14531.2219 s
env0_first_0:                 episode reward: -58.2500,                 loss: 0.7902
env0_second_0:                 episode reward: 58.2500,                 loss: 0.8337
env1_first_0:                 episode reward: -60.2500,                 loss: nan
env1_second_0:                 episode reward: 60.2500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 473.5,                last time consumption/overall running time: 164.5741s / 14695.7959 s
env0_first_0:                 episode reward: -58.3500,                 loss: 0.8793
env0_second_0:                 episode reward: 58.3500,                 loss: 1.0271
env1_first_0:                 episode reward: -55.5000,                 loss: nan
env1_second_0:                 episode reward: 55.5000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 498.55,                last time consumption/overall running time: 174.8980s / 14870.6939 s
env0_first_0:                 episode reward: -60.4500,                 loss: 1.0595
env0_second_0:                 episode reward: 60.4500,                 loss: 1.2641
env1_first_0:                 episode reward: -62.2500,                 loss: nan
env1_second_0:                 episode reward: 62.2500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 475.3,                last time consumption/overall running time: 165.7924s / 15036.4863 s
env0_first_0:                 episode reward: -70.0000,                 loss: 1.1620
env0_second_0:                 episode reward: 70.0000,                 loss: 1.3506
env1_first_0:                 episode reward: -53.2000,                 loss: nan
env1_second_0:                 episode reward: 53.2000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 356.1,                last time consumption/overall running time: 123.8187s / 15160.3050 s
env0_first_0:                 episode reward: -77.7500,                 loss: 1.2022
env0_second_0:                 episode reward: 77.7500,                 loss: 1.3294
env1_first_0:                 episode reward: -76.5000,                 loss: nan
env1_second_0:                 episode reward: 76.5000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 474.15,                last time consumption/overall running time: 168.5869s / 15328.8920 s
env0_first_0:                 episode reward: -60.0000,                 loss: 1.2546
env0_second_0:                 episode reward: 60.0000,                 loss: 1.3397
env1_first_0:                 episode reward: -64.2500,                 loss: nan
env1_second_0:                 episode reward: 64.2500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 677.0,                last time consumption/overall running time: 236.1916s / 15565.0836 s
env0_first_0:                 episode reward: -55.8000,                 loss: 1.2391
env0_second_0:                 episode reward: 55.8000,                 loss: 1.4149
env1_first_0:                 episode reward: -52.1500,                 loss: nan
env1_second_0:                 episode reward: 52.1500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 579.1,                last time consumption/overall running time: 200.2948s / 15765.3784 s
env0_first_0:                 episode reward: -64.5000,                 loss: 1.1534
env0_second_0:                 episode reward: 64.5000,                 loss: 1.3375
env1_first_0:                 episode reward: -66.3500,                 loss: nan
env1_second_0:                 episode reward: 66.3500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 652.3,                last time consumption/overall running time: 226.7500s / 15992.1284 s
env0_first_0:                 episode reward: -50.4500,                 loss: 0.9473
env0_second_0:                 episode reward: 50.4500,                 loss: 1.0944
env1_first_0:                 episode reward: -66.2000,                 loss: nan
env1_second_0:                 episode reward: 66.2000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 423.0,                last time consumption/overall running time: 148.2686s / 16140.3970 s
env0_first_0:                 episode reward: -66.6000,                 loss: 0.8668
env0_second_0:                 episode reward: 66.6000,                 loss: 1.0091
env1_first_0:                 episode reward: -65.3000,                 loss: nan
env1_second_0:                 episode reward: 65.3000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 417.0,                last time consumption/overall running time: 145.5394s / 16285.9364 s
env0_first_0:                 episode reward: -60.3000,                 loss: 0.8934
env0_second_0:                 episode reward: 60.3000,                 loss: 1.0164
env1_first_0:                 episode reward: -69.6000,                 loss: nan
env1_second_0:                 episode reward: 69.6000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 570.85,                last time consumption/overall running time: 197.9218s / 16483.8582 s
env0_first_0:                 episode reward: -64.1500,                 loss: 0.9810
env0_second_0:                 episode reward: 64.1500,                 loss: 1.1384
env1_first_0:                 episode reward: -69.7500,                 loss: nan
env1_second_0:                 episode reward: 69.7500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 406.25,                last time consumption/overall running time: 140.0012s / 16623.8594 s
env0_first_0:                 episode reward: -62.0000,                 loss: 0.9544
env0_second_0:                 episode reward: 62.0000,                 loss: 1.1568
env1_first_0:                 episode reward: -73.0500,                 loss: nan
env1_second_0:                 episode reward: 73.0500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 513.85,                last time consumption/overall running time: 180.3729s / 16804.2323 s
env0_first_0:                 episode reward: -64.5500,                 loss: 0.9772
env0_second_0:                 episode reward: 64.5500,                 loss: 1.1925
env1_first_0:                 episode reward: -74.8500,                 loss: nan
env1_second_0:                 episode reward: 74.8500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 359.15,                last time consumption/overall running time: 124.4599s / 16928.6923 s
env0_first_0:                 episode reward: -67.6000,                 loss: 1.1309
env0_second_0:                 episode reward: 67.6000,                 loss: 1.2903
env1_first_0:                 episode reward: -70.0500,                 loss: nan
env1_second_0:                 episode reward: 70.0500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 314.55,                last time consumption/overall running time: 109.3727s / 17038.0649 s
env0_first_0:                 episode reward: -69.9000,                 loss: 1.2530
env0_second_0:                 episode reward: 69.9000,                 loss: 1.3523
env1_first_0:                 episode reward: -73.3500,                 loss: nan
env1_second_0:                 episode reward: 73.3500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 342.7,                last time consumption/overall running time: 118.2518s / 17156.3168 s
env0_first_0:                 episode reward: -73.4500,                 loss: 1.3330
env0_second_0:                 episode reward: 73.4500,                 loss: 1.3123
env1_first_0:                 episode reward: -64.8000,                 loss: nan
env1_second_0:                 episode reward: 64.8000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 420.1,                last time consumption/overall running time: 146.8234s / 17303.1402 s
env0_first_0:                 episode reward: -68.4000,                 loss: 1.4435
env0_second_0:                 episode reward: 68.4000,                 loss: 1.3301
env1_first_0:                 episode reward: -76.9500,                 loss: nan
env1_second_0:                 episode reward: 76.9500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 312.95,                last time consumption/overall running time: 108.9935s / 17412.1336 s
env0_first_0:                 episode reward: -84.7500,                 loss: 1.5297
env0_second_0:                 episode reward: 84.7500,                 loss: 1.3567
env1_first_0:                 episode reward: -70.7000,                 loss: nan
env1_second_0:                 episode reward: 70.7000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 591.2,                last time consumption/overall running time: 205.5974s / 17617.7310 s
env0_first_0:                 episode reward: -55.8000,                 loss: 1.5246
env0_second_0:                 episode reward: 55.8000,                 loss: 1.3334
env1_first_0:                 episode reward: -61.5500,                 loss: nan
env1_second_0:                 episode reward: 61.5500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 1213.25,                last time consumption/overall running time: 422.7920s / 18040.5230 s
env0_first_0:                 episode reward: -18.6500,                 loss: 1.0835
env0_second_0:                 episode reward: 18.6500,                 loss: 0.9983
env1_first_0:                 episode reward: -30.2000,                 loss: nan
env1_second_0:                 episode reward: 30.2000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 1060.5,                last time consumption/overall running time: 371.0715s / 18411.5945 s
env0_first_0:                 episode reward: -33.7000,                 loss: 0.5895
env0_second_0:                 episode reward: 33.7000,                 loss: 0.6347
env1_first_0:                 episode reward: -36.8500,                 loss: nan
env1_second_0:                 episode reward: 36.8500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 498.75,                last time consumption/overall running time: 173.7821s / 18585.3766 s
env0_first_0:                 episode reward: -59.1000,                 loss: 0.8211
env0_second_0:                 episode reward: 59.1000,                 loss: 0.9081
env1_first_0:                 episode reward: -62.0000,                 loss: nan
env1_second_0:                 episode reward: 62.0000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 611.55,                last time consumption/overall running time: 213.9729s / 18799.3495 s
env0_first_0:                 episode reward: -55.3500,                 loss: 1.0698
env0_second_0:                 episode reward: 55.3500,                 loss: 1.1608
env1_first_0:                 episode reward: -68.1500,                 loss: nan
env1_second_0:                 episode reward: 68.1500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 572.65,                last time consumption/overall running time: 198.9516s / 18998.3011 s
env0_first_0:                 episode reward: -66.9500,                 loss: 1.2278
env0_second_0:                 episode reward: 66.9500,                 loss: 1.0680
env1_first_0:                 episode reward: -45.1500,                 loss: nan
env1_second_0:                 episode reward: 45.1500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 332.2,                last time consumption/overall running time: 118.1387s / 19116.4398 s
env0_first_0:                 episode reward: -72.8500,                 loss: 1.2899
env0_second_0:                 episode reward: 72.8500,                 loss: 1.2837
env1_first_0:                 episode reward: -58.6500,                 loss: nan
env1_second_0:                 episode reward: 58.6500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 356.45,                last time consumption/overall running time: 124.2952s / 19240.7350 s
env0_first_0:                 episode reward: -60.0500,                 loss: 1.4551
env0_second_0:                 episode reward: 60.0500,                 loss: 1.4282
env1_first_0:                 episode reward: -84.8500,                 loss: nan
env1_second_0:                 episode reward: 84.8500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 386.2,                last time consumption/overall running time: 133.6289s / 19374.3639 s
env0_first_0:                 episode reward: -65.2000,                 loss: 1.3440
env0_second_0:                 episode reward: 65.2000,                 loss: 1.2461
env1_first_0:                 episode reward: -65.9500,                 loss: nan
env1_second_0:                 episode reward: 65.9500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 332.35,                last time consumption/overall running time: 114.2734s / 19488.6373 s
env0_first_0:                 episode reward: -64.3500,                 loss: 1.2581
env0_second_0:                 episode reward: 64.3500,                 loss: 1.0742
env1_first_0:                 episode reward: -78.1000,                 loss: nan
env1_second_0:                 episode reward: 78.1000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 478.25,                last time consumption/overall running time: 166.6342s / 19655.2715 s
env0_first_0:                 episode reward: -66.6500,                 loss: 1.2694
env0_second_0:                 episode reward: 66.6500,                 loss: 1.0951
env1_first_0:                 episode reward: -69.7000,                 loss: nan
env1_second_0:                 episode reward: 69.7000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 742.6,                last time consumption/overall running time: 258.8576s / 19914.1292 s
env0_first_0:                 episode reward: -63.0500,                 loss: 1.4145
env0_second_0:                 episode reward: 63.0500,                 loss: 1.1268
env1_first_0:                 episode reward: -52.2500,                 loss: nan
env1_second_0:                 episode reward: 52.2500,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 471.1,                last time consumption/overall running time: 165.4254s / 20079.5546 s
env0_first_0:                 episode reward: -66.4500,                 loss: 1.1378
env0_second_0:                 episode reward: 66.4500,                 loss: 1.0947
env1_first_0:                 episode reward: -70.5500,                 loss: nan
env1_second_0:                 episode reward: 70.5500,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 409.3,                last time consumption/overall running time: 143.6422s / 20223.1968 s
env0_first_0:                 episode reward: -65.9000,                 loss: 1.1546
env0_second_0:                 episode reward: 65.9000,                 loss: 1.0485
env1_first_0:                 episode reward: -61.4000,                 loss: nan
env1_second_0:                 episode reward: 61.4000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 305.6,                last time consumption/overall running time: 108.6305s / 20331.8273 s
env0_first_0:                 episode reward: -67.6500,                 loss: 1.1246
env0_second_0:                 episode reward: 67.6500,                 loss: 1.0821
env1_first_0:                 episode reward: -69.9500,                 loss: nan
env1_second_0:                 episode reward: 69.9500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 548.95,                last time consumption/overall running time: 190.7050s / 20522.5324 s
env0_first_0:                 episode reward: -48.3500,                 loss: 1.0594
env0_second_0:                 episode reward: 48.3500,                 loss: 0.9830
env1_first_0:                 episode reward: -62.6000,                 loss: nan
env1_second_0:                 episode reward: 62.6000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 473.25,                last time consumption/overall running time: 165.3787s / 20687.9111 s
env0_first_0:                 episode reward: -46.4500,                 loss: 0.9391
env0_second_0:                 episode reward: 46.4500,                 loss: 0.9009
env1_first_0:                 episode reward: -54.2000,                 loss: nan
env1_second_0:                 episode reward: 54.2000,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 427.35,                last time consumption/overall running time: 149.6144s / 20837.5255 s
env0_first_0:                 episode reward: -64.6000,                 loss: 1.0207
env0_second_0:                 episode reward: 64.6000,                 loss: 1.0237
env1_first_0:                 episode reward: -76.5500,                 loss: nan
env1_second_0:                 episode reward: 76.5500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 476.4,                last time consumption/overall running time: 165.5889s / 21003.1144 s
env0_first_0:                 episode reward: -61.1500,                 loss: 1.0728
env0_second_0:                 episode reward: 61.1500,                 loss: 1.1505
env1_first_0:                 episode reward: -66.7500,                 loss: nan
env1_second_0:                 episode reward: 66.7500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 796.2,                last time consumption/overall running time: 277.7024s / 21280.8169 s
env0_first_0:                 episode reward: -64.5000,                 loss: 1.1017
env0_second_0:                 episode reward: 64.5000,                 loss: 1.2717
env1_first_0:                 episode reward: -52.9500,                 loss: nan
env1_second_0:                 episode reward: 52.9500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 1094.9,                last time consumption/overall running time: 381.0381s / 21661.8549 s
env0_first_0:                 episode reward: -44.9500,                 loss: 0.8923
env0_second_0:                 episode reward: 44.9500,                 loss: 1.2240
env1_first_0:                 episode reward: -35.4000,                 loss: nan
env1_second_0:                 episode reward: 35.4000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 1053.35,                last time consumption/overall running time: 367.8203s / 22029.6753 s
env0_first_0:                 episode reward: -51.7000,                 loss: 0.5579
env0_second_0:                 episode reward: 51.7000,                 loss: 0.9115
env1_first_0:                 episode reward: -45.5500,                 loss: nan
env1_second_0:                 episode reward: 45.5500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 780.7,                last time consumption/overall running time: 270.3581s / 22300.0334 s
env0_first_0:                 episode reward: -61.9000,                 loss: 0.5663
env0_second_0:                 episode reward: 61.9000,                 loss: 0.8215
env1_first_0:                 episode reward: -37.5000,                 loss: nan
env1_second_0:                 episode reward: 37.5000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 640.25,                last time consumption/overall running time: 222.6303s / 22522.6637 s
env0_first_0:                 episode reward: -49.5500,                 loss: 0.7348
env0_second_0:                 episode reward: 49.5500,                 loss: 0.8571
env1_first_0:                 episode reward: -55.3000,                 loss: nan
env1_second_0:                 episode reward: 55.3000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 441.5,                last time consumption/overall running time: 153.4414s / 22676.1051 s
env0_first_0:                 episode reward: -56.6500,                 loss: 0.8323
env0_second_0:                 episode reward: 56.6500,                 loss: 0.8596
env1_first_0:                 episode reward: -70.4500,                 loss: nan
env1_second_0:                 episode reward: 70.4500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 390.35,                last time consumption/overall running time: 135.8000s / 22811.9051 s
env0_first_0:                 episode reward: -71.1000,                 loss: 0.8624
env0_second_0:                 episode reward: 71.1000,                 loss: 0.9814
env1_first_0:                 episode reward: -55.6500,                 loss: nan
env1_second_0:                 episode reward: 55.6500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 381.0,                last time consumption/overall running time: 133.5600s / 22945.4651 s
env0_first_0:                 episode reward: -67.5500,                 loss: 0.9869
env0_second_0:                 episode reward: 67.5500,                 loss: 1.1122
env1_first_0:                 episode reward: -59.1500,                 loss: nan
env1_second_0:                 episode reward: 59.1500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 447.9,                last time consumption/overall running time: 155.7937s / 23101.2588 s
env0_first_0:                 episode reward: -65.0500,                 loss: 1.0820
env0_second_0:                 episode reward: 65.0500,                 loss: 1.2501
env1_first_0:                 episode reward: -64.1500,                 loss: nan
env1_second_0:                 episode reward: 64.1500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 345.85,                last time consumption/overall running time: 120.4600s / 23221.7187 s
env0_first_0:                 episode reward: -60.8500,                 loss: 1.2714
env0_second_0:                 episode reward: 60.8500,                 loss: 1.4403
env1_first_0:                 episode reward: -79.9000,                 loss: nan
env1_second_0:                 episode reward: 79.9000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 440.05,                last time consumption/overall running time: 153.8103s / 23375.5290 s
env0_first_0:                 episode reward: -67.4500,                 loss: 1.3623
env0_second_0:                 episode reward: 67.4500,                 loss: 1.5006
env1_first_0:                 episode reward: -66.5500,                 loss: nan
env1_second_0:                 episode reward: 66.5500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 584.8,                last time consumption/overall running time: 202.6755s / 23578.2045 s
env0_first_0:                 episode reward: -53.9000,                 loss: 1.2701
env0_second_0:                 episode reward: 53.9000,                 loss: 1.4164
env1_first_0:                 episode reward: -79.2500,                 loss: nan
env1_second_0:                 episode reward: 79.2500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 1316.8,                last time consumption/overall running time: 456.4511s / 24034.6557 s
env0_first_0:                 episode reward: -41.8000,                 loss: 0.9180
env0_second_0:                 episode reward: 41.8000,                 loss: 1.1470
env1_first_0:                 episode reward: -34.2000,                 loss: nan
env1_second_0:                 episode reward: 34.2000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 858.15,                last time consumption/overall running time: 301.6072s / 24336.2629 s
env0_first_0:                 episode reward: -46.3500,                 loss: 0.5282
env0_second_0:                 episode reward: 46.3500,                 loss: 0.7695
env1_first_0:                 episode reward: -34.6000,                 loss: nan
env1_second_0:                 episode reward: 34.6000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 477.35,                last time consumption/overall running time: 168.4247s / 24504.6876 s
env0_first_0:                 episode reward: -47.0500,                 loss: 0.6705
env0_second_0:                 episode reward: 47.0500,                 loss: 0.9912
env1_first_0:                 episode reward: -54.7500,                 loss: nan
env1_second_0:                 episode reward: 54.7500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 507.75,                last time consumption/overall running time: 178.1444s / 24682.8320 s
env0_first_0:                 episode reward: -49.7000,                 loss: 0.9188
env0_second_0:                 episode reward: 49.7000,                 loss: 1.1289
env1_first_0:                 episode reward: -42.1000,                 loss: nan
env1_second_0:                 episode reward: 42.1000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 398.0,                last time consumption/overall running time: 139.6512s / 24822.4832 s
env0_first_0:                 episode reward: -60.3500,                 loss: 1.1193
env0_second_0:                 episode reward: 60.3500,                 loss: 1.3089
env1_first_0:                 episode reward: -57.8000,                 loss: nan
env1_second_0:                 episode reward: 57.8000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 519.6,                last time consumption/overall running time: 180.1014s / 25002.5846 s
env0_first_0:                 episode reward: -50.5500,                 loss: 1.3150
env0_second_0:                 episode reward: 50.5500,                 loss: 1.6140
env1_first_0:                 episode reward: -58.2500,                 loss: nan
env1_second_0:                 episode reward: 58.2500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 403.65,                last time consumption/overall running time: 139.8660s / 25142.4506 s
env0_first_0:                 episode reward: -70.5000,                 loss: 1.5082
env0_second_0:                 episode reward: 70.5000,                 loss: 1.8638
env1_first_0:                 episode reward: -60.9000,                 loss: nan
env1_second_0:                 episode reward: 60.9000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 371.55,                last time consumption/overall running time: 128.4206s / 25270.8713 s
env0_first_0:                 episode reward: -60.3500,                 loss: 1.5477
env0_second_0:                 episode reward: 60.3500,                 loss: 1.7890
env1_first_0:                 episode reward: -71.0000,                 loss: nan
env1_second_0:                 episode reward: 71.0000,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 324.25,                last time consumption/overall running time: 112.9274s / 25383.7986 s
env0_first_0:                 episode reward: -72.7000,                 loss: 1.5027
env0_second_0:                 episode reward: 72.7000,                 loss: 1.7416
env1_first_0:                 episode reward: -70.5500,                 loss: nan
env1_second_0:                 episode reward: 70.5500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 296.15,                last time consumption/overall running time: 102.1257s / 25485.9244 s
env0_first_0:                 episode reward: -68.1500,                 loss: 1.5424
env0_second_0:                 episode reward: 68.1500,                 loss: 1.7055
env1_first_0:                 episode reward: -66.6500,                 loss: nan
env1_second_0:                 episode reward: 66.6500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 301.05,                last time consumption/overall running time: 105.4022s / 25591.3265 s
env0_first_0:                 episode reward: -76.6500,                 loss: 1.5343
env0_second_0:                 episode reward: 76.6500,                 loss: 1.6574
env1_first_0:                 episode reward: -76.6000,                 loss: nan
env1_second_0:                 episode reward: 76.6000,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 298.2,                last time consumption/overall running time: 103.1387s / 25694.4653 s
env0_first_0:                 episode reward: -90.0500,                 loss: 1.4369
env0_second_0:                 episode reward: 90.0500,                 loss: 1.4827
env1_first_0:                 episode reward: -71.2500,                 loss: nan
env1_second_0:                 episode reward: 71.2500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 351.85,                last time consumption/overall running time: 122.9525s / 25817.4178 s
env0_first_0:                 episode reward: -72.6500,                 loss: 1.4858
env0_second_0:                 episode reward: 72.6500,                 loss: 1.3793
env1_first_0:                 episode reward: -68.0500,                 loss: nan
env1_second_0:                 episode reward: 68.0500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 431.5,                last time consumption/overall running time: 149.5647s / 25966.9824 s
env0_first_0:                 episode reward: -66.1000,                 loss: 1.4757
env0_second_0:                 episode reward: 66.1000,                 loss: 1.4711
env1_first_0:                 episode reward: -66.5500,                 loss: nan
env1_second_0:                 episode reward: 66.5500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 391.5,                last time consumption/overall running time: 136.7252s / 26103.7076 s
env0_first_0:                 episode reward: -73.8000,                 loss: 1.5456
env0_second_0:                 episode reward: 73.8000,                 loss: 1.4532
env1_first_0:                 episode reward: -53.2000,                 loss: nan
env1_second_0:                 episode reward: 53.2000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 414.5,                last time consumption/overall running time: 146.7888s / 26250.4964 s
env0_first_0:                 episode reward: -67.1000,                 loss: 1.5045
env0_second_0:                 episode reward: 67.1000,                 loss: 1.3733
env1_first_0:                 episode reward: -70.6500,                 loss: nan
env1_second_0:                 episode reward: 70.6500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 450.15,                last time consumption/overall running time: 156.0628s / 26406.5592 s
env0_first_0:                 episode reward: -68.2000,                 loss: 1.5212
env0_second_0:                 episode reward: 68.2000,                 loss: 1.4646
env1_first_0:                 episode reward: -54.2000,                 loss: nan
env1_second_0:                 episode reward: 54.2000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 626.9,                last time consumption/overall running time: 218.9129s / 26625.4721 s
env0_first_0:                 episode reward: -72.7500,                 loss: 1.5356
env0_second_0:                 episode reward: 72.7500,                 loss: 1.7616
env1_first_0:                 episode reward: -69.2000,                 loss: nan
env1_second_0:                 episode reward: 69.2000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 711.65,                last time consumption/overall running time: 247.6058s / 26873.0779 s
env0_first_0:                 episode reward: -46.3000,                 loss: 1.5883
env0_second_0:                 episode reward: 46.3000,                 loss: 1.7056
env1_first_0:                 episode reward: -52.8000,                 loss: nan
env1_second_0:                 episode reward: 52.8000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 550.75,                last time consumption/overall running time: 192.7926s / 27065.8705 s
env0_first_0:                 episode reward: -17.8000,                 loss: 1.7682
env0_second_0:                 episode reward: 17.8000,                 loss: 0.9963
env1_first_0:                 episode reward: -34.8500,                 loss: nan
env1_second_0:                 episode reward: 34.8500,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 429.8,                last time consumption/overall running time: 149.6229s / 27215.4934 s
env0_first_0:                 episode reward: -45.5500,                 loss: 1.7078
env0_second_0:                 episode reward: 45.5500,                 loss: 0.6848
env1_first_0:                 episode reward: -38.6000,                 loss: nan
env1_second_0:                 episode reward: 38.6000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 325.55,                last time consumption/overall running time: 113.7275s / 27329.2209 s
env0_first_0:                 episode reward: -65.0000,                 loss: 1.6393
env0_second_0:                 episode reward: 65.0000,                 loss: 0.6388
env1_first_0:                 episode reward: -63.8000,                 loss: nan
env1_second_0:                 episode reward: 63.8000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 326.05,                last time consumption/overall running time: 114.0488s / 27443.2697 s
env0_first_0:                 episode reward: -63.8500,                 loss: 1.7095
env0_second_0:                 episode reward: 63.8500,                 loss: 0.5947
env1_first_0:                 episode reward: -82.8500,                 loss: nan
env1_second_0:                 episode reward: 82.8500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 306.7,                last time consumption/overall running time: 108.5714s / 27551.8411 s
env0_first_0:                 episode reward: -87.1000,                 loss: 1.6272
env0_second_0:                 episode reward: 87.1000,                 loss: 0.6107
env1_first_0:                 episode reward: -78.7000,                 loss: nan
env1_second_0:                 episode reward: 78.7000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 254.85,                last time consumption/overall running time: 89.0752s / 27640.9163 s
env0_first_0:                 episode reward: -89.4500,                 loss: 1.5445
env0_second_0:                 episode reward: 89.4500,                 loss: 0.6101
env1_first_0:                 episode reward: -87.5500,                 loss: nan
env1_second_0:                 episode reward: 87.5500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 273.55,                last time consumption/overall running time: 95.6197s / 27736.5360 s
env0_first_0:                 episode reward: -70.7000,                 loss: 1.4727
env0_second_0:                 episode reward: 70.7000,                 loss: 0.5945
env1_first_0:                 episode reward: -83.5500,                 loss: nan
env1_second_0:                 episode reward: 83.5500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 286.05,                last time consumption/overall running time: 99.0301s / 27835.5661 s
env0_first_0:                 episode reward: -73.5000,                 loss: 1.3732
env0_second_0:                 episode reward: 73.5000,                 loss: 0.5846
env1_first_0:                 episode reward: -79.6500,                 loss: nan
env1_second_0:                 episode reward: 79.6500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 290.0,                last time consumption/overall running time: 100.1426s / 27935.7086 s
env0_first_0:                 episode reward: -79.0000,                 loss: 1.2269
env0_second_0:                 episode reward: 79.0000,                 loss: 0.5599
env1_first_0:                 episode reward: -84.7000,                 loss: nan
env1_second_0:                 episode reward: 84.7000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 260.7,                last time consumption/overall running time: 91.0888s / 28026.7974 s
env0_first_0:                 episode reward: -79.0500,                 loss: 1.1759
env0_second_0:                 episode reward: 79.0500,                 loss: 0.5513
env1_first_0:                 episode reward: -90.7000,                 loss: nan
env1_second_0:                 episode reward: 90.7000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 294.0,                last time consumption/overall running time: 103.0827s / 28129.8801 s
env0_first_0:                 episode reward: -88.7500,                 loss: 1.1366
env0_second_0:                 episode reward: 88.7500,                 loss: 0.5411
env1_first_0:                 episode reward: -81.7000,                 loss: nan
env1_second_0:                 episode reward: 81.7000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 313.55,                last time consumption/overall running time: 109.4029s / 28239.2830 s
env0_first_0:                 episode reward: -76.6000,                 loss: 1.0768
env0_second_0:                 episode reward: 76.6000,                 loss: 0.5423
env1_first_0:                 episode reward: -85.2500,                 loss: nan
env1_second_0:                 episode reward: 85.2500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 356.1,                last time consumption/overall running time: 124.3646s / 28363.6476 s
env0_first_0:                 episode reward: -81.3500,                 loss: 0.9850
env0_second_0:                 episode reward: 81.3500,                 loss: 0.5332
env1_first_0:                 episode reward: -74.4000,                 loss: nan
env1_second_0:                 episode reward: 74.4000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 334.5,                last time consumption/overall running time: 116.4447s / 28480.0923 s
env0_first_0:                 episode reward: -80.9000,                 loss: 0.9406
env0_second_0:                 episode reward: 80.9000,                 loss: 0.5413
env1_first_0:                 episode reward: -73.1500,                 loss: nan
env1_second_0:                 episode reward: 73.1500,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 314.2,                last time consumption/overall running time: 110.2510s / 28590.3433 s
env0_first_0:                 episode reward: -85.6000,                 loss: 0.9890
env0_second_0:                 episode reward: 85.6000,                 loss: 0.5625
env1_first_0:                 episode reward: -68.3000,                 loss: nan
env1_second_0:                 episode reward: 68.3000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 258.9,                last time consumption/overall running time: 90.4328s / 28680.7762 s
env0_first_0:                 episode reward: -86.4000,                 loss: 1.0095
env0_second_0:                 episode reward: 86.4000,                 loss: 0.5709
env1_first_0:                 episode reward: -81.1000,                 loss: nan
env1_second_0:                 episode reward: 81.1000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 268.35,                last time consumption/overall running time: 94.4503s / 28775.2265 s
env0_first_0:                 episode reward: -84.4000,                 loss: 0.9898
env0_second_0:                 episode reward: 84.4000,                 loss: 0.5744
env1_first_0:                 episode reward: -84.7500,                 loss: nan
env1_second_0:                 episode reward: 84.7500,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 259.75,                last time consumption/overall running time: 90.9813s / 28866.2078 s
env0_first_0:                 episode reward: -83.3000,                 loss: 1.0178
env0_second_0:                 episode reward: 83.3000,                 loss: 0.5771
env1_first_0:                 episode reward: -79.4500,                 loss: nan
env1_second_0:                 episode reward: 79.4500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 269.3,                last time consumption/overall running time: 93.1467s / 28959.3545 s
env0_first_0:                 episode reward: -78.3500,                 loss: 1.0501
env0_second_0:                 episode reward: 78.3500,                 loss: 0.5777
env1_first_0:                 episode reward: -74.7500,                 loss: nan
env1_second_0:                 episode reward: 74.7500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 320.95,                last time consumption/overall running time: 113.4420s / 29072.7966 s
env0_first_0:                 episode reward: -71.9500,                 loss: 1.0404
env0_second_0:                 episode reward: 71.9500,                 loss: 0.5999
env1_first_0:                 episode reward: -78.3000,                 loss: nan
env1_second_0:                 episode reward: 78.3000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 266.45,                last time consumption/overall running time: 92.6754s / 29165.4720 s
env0_first_0:                 episode reward: -81.4000,                 loss: 1.0229
env0_second_0:                 episode reward: 81.4000,                 loss: 0.6351
env1_first_0:                 episode reward: -87.6000,                 loss: nan
env1_second_0:                 episode reward: 87.6000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 413.05,                last time consumption/overall running time: 144.0457s / 29309.5176 s
env0_first_0:                 episode reward: -76.4000,                 loss: 1.0257
env0_second_0:                 episode reward: 76.4000,                 loss: 0.6987
env1_first_0:                 episode reward: -62.0500,                 loss: nan
env1_second_0:                 episode reward: 62.0500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 470.6,                last time consumption/overall running time: 163.4819s / 29472.9995 s
env0_first_0:                 episode reward: -48.0000,                 loss: 1.0107
env0_second_0:                 episode reward: 48.0000,                 loss: 0.7151
env1_first_0:                 episode reward: -47.5000,                 loss: nan
env1_second_0:                 episode reward: 47.5000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 280.7,                last time consumption/overall running time: 98.6757s / 29571.6753 s
env0_first_0:                 episode reward: -72.7000,                 loss: 1.0408
env0_second_0:                 episode reward: 72.7000,                 loss: 0.7537
env1_first_0:                 episode reward: -85.2500,                 loss: nan
env1_second_0:                 episode reward: 85.2500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 389.65,                last time consumption/overall running time: 136.3463s / 29708.0216 s
env0_first_0:                 episode reward: -65.7000,                 loss: 1.1128
env0_second_0:                 episode reward: 65.7000,                 loss: 0.8111
env1_first_0:                 episode reward: -52.9500,                 loss: nan
env1_second_0:                 episode reward: 52.9500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 267.65,                last time consumption/overall running time: 92.9721s / 29800.9936 s
env0_first_0:                 episode reward: -63.2500,                 loss: 1.1810
env0_second_0:                 episode reward: 63.2500,                 loss: 0.8332
env1_first_0:                 episode reward: -84.5000,                 loss: nan
env1_second_0:                 episode reward: 84.5000,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 282.6,                last time consumption/overall running time: 99.0286s / 29900.0222 s
env0_first_0:                 episode reward: -73.5000,                 loss: 1.1878
env0_second_0:                 episode reward: 73.5000,                 loss: 0.7928
env1_first_0:                 episode reward: -83.7500,                 loss: nan
env1_second_0:                 episode reward: 83.7500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 374.05,                last time consumption/overall running time: 130.7835s / 30030.8058 s
env0_first_0:                 episode reward: -68.7500,                 loss: 1.2787
env0_second_0:                 episode reward: 68.7500,                 loss: 0.8594
env1_first_0:                 episode reward: -66.3000,                 loss: nan
env1_second_0:                 episode reward: 66.3000,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 388.75,                last time consumption/overall running time: 135.3145s / 30166.1203 s
env0_first_0:                 episode reward: -67.7500,                 loss: 1.3471
env0_second_0:                 episode reward: 67.7500,                 loss: 0.8646
env1_first_0:                 episode reward: -66.7500,                 loss: nan
env1_second_0:                 episode reward: 66.7500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 333.2,                last time consumption/overall running time: 117.8948s / 30284.0151 s
env0_first_0:                 episode reward: -79.3000,                 loss: 1.2767
env0_second_0:                 episode reward: 79.3000,                 loss: 0.8418
env1_first_0:                 episode reward: -77.8000,                 loss: nan
env1_second_0:                 episode reward: 77.8000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 627.5,                last time consumption/overall running time: 219.1513s / 30503.1665 s
env0_first_0:                 episode reward: -59.1500,                 loss: 1.1646
env0_second_0:                 episode reward: 59.1500,                 loss: 0.8127
env1_first_0:                 episode reward: -64.3500,                 loss: nan
env1_second_0:                 episode reward: 64.3500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 352.95,                last time consumption/overall running time: 123.2367s / 30626.4032 s
env0_first_0:                 episode reward: -74.4000,                 loss: 0.9647
env0_second_0:                 episode reward: 74.4000,                 loss: 0.7140
env1_first_0:                 episode reward: -78.9500,                 loss: nan
env1_second_0:                 episode reward: 78.9500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 345.0,                last time consumption/overall running time: 120.7353s / 30747.1384 s
env0_first_0:                 episode reward: -73.3000,                 loss: 0.9664
env0_second_0:                 episode reward: 73.3000,                 loss: 0.6639
env1_first_0:                 episode reward: -70.3500,                 loss: nan
env1_second_0:                 episode reward: 70.3500,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 322.65,                last time consumption/overall running time: 111.9128s / 30859.0513 s
env0_first_0:                 episode reward: -62.7000,                 loss: 0.9703
env0_second_0:                 episode reward: 62.7000,                 loss: 0.6715
env1_first_0:                 episode reward: -53.3000,                 loss: nan
env1_second_0:                 episode reward: 53.3000,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 802.35,                last time consumption/overall running time: 275.0184s / 31134.0697 s
env0_first_0:                 episode reward: -49.1500,                 loss: 0.9526
env0_second_0:                 episode reward: 49.1500,                 loss: 0.6689
env1_first_0:                 episode reward: -45.3000,                 loss: nan
env1_second_0:                 episode reward: 45.3000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 338.95,                last time consumption/overall running time: 117.3228s / 31251.3925 s
env0_first_0:                 episode reward: -79.9500,                 loss: 0.7976
env0_second_0:                 episode reward: 79.9500,                 loss: 0.5624
env1_first_0:                 episode reward: -80.0500,                 loss: nan
env1_second_0:                 episode reward: 80.0500,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 605.7,                last time consumption/overall running time: 209.6192s / 31461.0116 s
env0_first_0:                 episode reward: -64.9000,                 loss: 0.8670
env0_second_0:                 episode reward: 64.9000,                 loss: 0.6265
env1_first_0:                 episode reward: -55.0500,                 loss: nan
env1_second_0:                 episode reward: 55.0500,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 466.25,                last time consumption/overall running time: 162.9285s / 31623.9401 s
env0_first_0:                 episode reward: -64.4000,                 loss: 0.8484
env0_second_0:                 episode reward: 64.4000,                 loss: 0.6375
env1_first_0:                 episode reward: -64.1500,                 loss: nan
env1_second_0:                 episode reward: 64.1500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 395.65,                last time consumption/overall running time: 138.4370s / 31762.3772 s
env0_first_0:                 episode reward: -60.6000,                 loss: 0.8293
env0_second_0:                 episode reward: 60.6000,                 loss: 0.5957
env1_first_0:                 episode reward: -75.9000,                 loss: nan
env1_second_0:                 episode reward: 75.9000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 343.55,                last time consumption/overall running time: 119.1645s / 31881.5417 s
env0_first_0:                 episode reward: -69.1000,                 loss: 1.0094
env0_second_0:                 episode reward: 69.1000,                 loss: 0.6749
env1_first_0:                 episode reward: -64.0000,                 loss: nan
env1_second_0:                 episode reward: 64.0000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 281.65,                last time consumption/overall running time: 98.4801s / 31980.0218 s
env0_first_0:                 episode reward: -74.5500,                 loss: 1.2546
env0_second_0:                 episode reward: 74.5500,                 loss: 0.8997
env1_first_0:                 episode reward: -76.0500,                 loss: nan
env1_second_0:                 episode reward: 76.0500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 394.1,                last time consumption/overall running time: 136.9260s / 32116.9478 s
env0_first_0:                 episode reward: -69.5500,                 loss: 1.4958
env0_second_0:                 episode reward: 69.5500,                 loss: 1.0633
env1_first_0:                 episode reward: -70.3500,                 loss: nan
env1_second_0:                 episode reward: 70.3500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 513.95,                last time consumption/overall running time: 177.4313s / 32294.3790 s
env0_first_0:                 episode reward: -73.9000,                 loss: 1.5283
env0_second_0:                 episode reward: 73.9000,                 loss: 1.1191
env1_first_0:                 episode reward: -72.5500,                 loss: nan
env1_second_0:                 episode reward: 72.5500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 1085.2,                last time consumption/overall running time: 376.2512s / 32670.6302 s
env0_first_0:                 episode reward: -55.2500,                 loss: 1.3231
env0_second_0:                 episode reward: 55.2500,                 loss: 0.9744
env1_first_0:                 episode reward: -44.6500,                 loss: nan
env1_second_0:                 episode reward: 44.6500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 692.3,                last time consumption/overall running time: 241.9866s / 32912.6168 s
env0_first_0:                 episode reward: -63.1000,                 loss: 0.6452
env0_second_0:                 episode reward: 63.1000,                 loss: 0.4580
env1_first_0:                 episode reward: -60.4000,                 loss: nan
env1_second_0:                 episode reward: 60.4000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 342.6,                last time consumption/overall running time: 119.4039s / 33032.0207 s
env0_first_0:                 episode reward: -76.4500,                 loss: 0.5396
env0_second_0:                 episode reward: 76.4500,                 loss: 0.3888
env1_first_0:                 episode reward: -71.9000,                 loss: nan
env1_second_0:                 episode reward: 71.9000,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 369.95,                last time consumption/overall running time: 128.7694s / 33160.7902 s
env0_first_0:                 episode reward: -58.9500,                 loss: 0.6881
env0_second_0:                 episode reward: 58.9500,                 loss: 0.5189
env1_first_0:                 episode reward: -62.2500,                 loss: nan
env1_second_0:                 episode reward: 62.2500,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 326.7,                last time consumption/overall running time: 113.3851s / 33274.1753 s
env0_first_0:                 episode reward: -68.7500,                 loss: 0.8614
env0_second_0:                 episode reward: 68.7500,                 loss: 0.7126
env1_first_0:                 episode reward: -78.0500,                 loss: nan
env1_second_0:                 episode reward: 78.0500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 331.4,                last time consumption/overall running time: 115.2624s / 33389.4377 s
env0_first_0:                 episode reward: -63.0500,                 loss: 1.0146
env0_second_0:                 episode reward: 63.0500,                 loss: 0.8066
env1_first_0:                 episode reward: -58.6000,                 loss: nan
env1_second_0:                 episode reward: 58.6000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 265.75,                last time consumption/overall running time: 93.7208s / 33483.1585 s
env0_first_0:                 episode reward: -72.6500,                 loss: 1.1563
env0_second_0:                 episode reward: 72.6500,                 loss: 0.9486
env1_first_0:                 episode reward: -78.9000,                 loss: nan
env1_second_0:                 episode reward: 78.9000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 258.9,                last time consumption/overall running time: 89.9289s / 33573.0874 s
env0_first_0:                 episode reward: -86.6500,                 loss: 1.2968
env0_second_0:                 episode reward: 86.6500,                 loss: 1.0966
env1_first_0:                 episode reward: -79.0500,                 loss: nan
env1_second_0:                 episode reward: 79.0500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 260.6,                last time consumption/overall running time: 91.0593s / 33664.1466 s
env0_first_0:                 episode reward: -72.3000,                 loss: 1.4969
env0_second_0:                 episode reward: 72.3000,                 loss: 1.2184
env1_first_0:                 episode reward: -87.1500,                 loss: nan
env1_second_0:                 episode reward: 87.1500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 277.8,                last time consumption/overall running time: 96.6088s / 33760.7554 s
env0_first_0:                 episode reward: -85.6000,                 loss: 1.6326
env0_second_0:                 episode reward: 85.6000,                 loss: 1.3374
env1_first_0:                 episode reward: -81.6500,                 loss: nan
env1_second_0:                 episode reward: 81.6500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 302.1,                last time consumption/overall running time: 105.6581s / 33866.4135 s
env0_first_0:                 episode reward: -79.6500,                 loss: 1.6808
env0_second_0:                 episode reward: 79.6500,                 loss: 1.3294
env1_first_0:                 episode reward: -77.9500,                 loss: nan
env1_second_0:                 episode reward: 77.9500,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 286.0,                last time consumption/overall running time: 99.7342s / 33966.1477 s
env0_first_0:                 episode reward: -72.7500,                 loss: 1.6568
env0_second_0:                 episode reward: 72.7500,                 loss: 1.3513
env1_first_0:                 episode reward: -82.0500,                 loss: nan
env1_second_0:                 episode reward: 82.0500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 283.4,                last time consumption/overall running time: 98.2205s / 34064.3682 s
env0_first_0:                 episode reward: -73.6500,                 loss: 1.5451
env0_second_0:                 episode reward: 73.6500,                 loss: 1.3766
env1_first_0:                 episode reward: -75.0000,                 loss: nan
env1_second_0:                 episode reward: 75.0000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 351.7,                last time consumption/overall running time: 122.3212s / 34186.6894 s
env0_first_0:                 episode reward: -70.4500,                 loss: 1.5583
env0_second_0:                 episode reward: 70.4500,                 loss: 1.3650
env1_first_0:                 episode reward: -85.2500,                 loss: nan
env1_second_0:                 episode reward: 85.2500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 308.65,                last time consumption/overall running time: 108.7425s / 34295.4319 s
env0_first_0:                 episode reward: -65.4500,                 loss: 1.5846
env0_second_0:                 episode reward: 65.4500,                 loss: 1.2741
env1_first_0:                 episode reward: -80.4500,                 loss: nan
env1_second_0:                 episode reward: 80.4500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 307.4,                last time consumption/overall running time: 107.4721s / 34402.9040 s
env0_first_0:                 episode reward: -67.9000,                 loss: 1.5847
env0_second_0:                 episode reward: 67.9000,                 loss: 1.2289
env1_first_0:                 episode reward: -80.7000,                 loss: nan
env1_second_0:                 episode reward: 80.7000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 293.35,                last time consumption/overall running time: 101.4503s / 34504.3543 s
env0_first_0:                 episode reward: -74.8500,                 loss: 1.5662
env0_second_0:                 episode reward: 74.8500,                 loss: 1.2048
env1_first_0:                 episode reward: -72.5500,                 loss: nan
env1_second_0:                 episode reward: 72.5500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 420.05,                last time consumption/overall running time: 145.2720s / 34649.6263 s
env0_first_0:                 episode reward: -65.9500,                 loss: 1.4869
env0_second_0:                 episode reward: 65.9500,                 loss: 1.1837
env1_first_0:                 episode reward: -50.3000,                 loss: nan
env1_second_0:                 episode reward: 50.3000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 336.65,                last time consumption/overall running time: 118.8930s / 34768.5193 s
env0_first_0:                 episode reward: -65.0500,                 loss: 1.4667
env0_second_0:                 episode reward: 65.0500,                 loss: 1.2317
env1_first_0:                 episode reward: -61.6500,                 loss: nan
env1_second_0:                 episode reward: 61.6500,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 368.35,                last time consumption/overall running time: 130.0997s / 34898.6190 s
env0_first_0:                 episode reward: -47.9500,                 loss: 1.4479
env0_second_0:                 episode reward: 47.9500,                 loss: 1.2959
env1_first_0:                 episode reward: -47.1500,                 loss: nan
env1_second_0:                 episode reward: 47.1500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 308.4,                last time consumption/overall running time: 106.8817s / 35005.5007 s
env0_first_0:                 episode reward: -83.6500,                 loss: 1.4949
env0_second_0:                 episode reward: 83.6500,                 loss: 1.3109
env1_first_0:                 episode reward: -79.9000,                 loss: nan
env1_second_0:                 episode reward: 79.9000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 301.5,                last time consumption/overall running time: 104.5636s / 35110.0643 s
env0_first_0:                 episode reward: -80.0500,                 loss: 1.5395
env0_second_0:                 episode reward: 80.0500,                 loss: 1.3214
env1_first_0:                 episode reward: -76.1000,                 loss: nan
env1_second_0:                 episode reward: 76.1000,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 296.4,                last time consumption/overall running time: 103.1513s / 35213.2156 s
env0_first_0:                 episode reward: -68.1000,                 loss: 1.4689
env0_second_0:                 episode reward: 68.1000,                 loss: 1.3005
env1_first_0:                 episode reward: -81.1500,                 loss: nan
env1_second_0:                 episode reward: 81.1500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 302.25,                last time consumption/overall running time: 105.0483s / 35318.2639 s
env0_first_0:                 episode reward: -88.8500,                 loss: 1.4801
env0_second_0:                 episode reward: 88.8500,                 loss: 1.3421
env1_first_0:                 episode reward: -73.6000,                 loss: nan
env1_second_0:                 episode reward: 73.6000,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 306.4,                last time consumption/overall running time: 108.0829s / 35426.3468 s
env0_first_0:                 episode reward: -78.5500,                 loss: 1.6455
env0_second_0:                 episode reward: 78.5500,                 loss: 1.3817
env1_first_0:                 episode reward: -75.6500,                 loss: nan
env1_second_0:                 episode reward: 75.6500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 317.55,                last time consumption/overall running time: 109.8491s / 35536.1959 s
env0_first_0:                 episode reward: -73.5000,                 loss: 1.6562
env0_second_0:                 episode reward: 73.5000,                 loss: 1.4573
env1_first_0:                 episode reward: -80.4500,                 loss: nan
env1_second_0:                 episode reward: 80.4500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 268.45,                last time consumption/overall running time: 93.2346s / 35629.4305 s
env0_first_0:                 episode reward: -72.5500,                 loss: 1.6565
env0_second_0:                 episode reward: 72.5500,                 loss: 1.4316
env1_first_0:                 episode reward: -82.9000,                 loss: nan
env1_second_0:                 episode reward: 82.9000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 312.85,                last time consumption/overall running time: 109.5786s / 35739.0091 s
env0_first_0:                 episode reward: -63.0500,                 loss: 1.6509
env0_second_0:                 episode reward: 63.0500,                 loss: 1.3590
env1_first_0:                 episode reward: -83.6500,                 loss: nan
env1_second_0:                 episode reward: 83.6500,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 382.85,                last time consumption/overall running time: 133.8870s / 35872.8961 s
env0_first_0:                 episode reward: -55.0500,                 loss: 1.6211
env0_second_0:                 episode reward: 55.0500,                 loss: 1.2698
env1_first_0:                 episode reward: -62.9500,                 loss: nan
env1_second_0:                 episode reward: 62.9500,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 351.35,                last time consumption/overall running time: 122.7162s / 35995.6123 s
env0_first_0:                 episode reward: -62.5500,                 loss: 1.5376
env0_second_0:                 episode reward: 62.5500,                 loss: 1.2421
env1_first_0:                 episode reward: -51.6000,                 loss: nan
env1_second_0:                 episode reward: 51.6000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 329.15,                last time consumption/overall running time: 116.1077s / 36111.7199 s
env0_first_0:                 episode reward: -63.8500,                 loss: 1.5913
env0_second_0:                 episode reward: 63.8500,                 loss: 1.2581
env1_first_0:                 episode reward: -58.3500,                 loss: nan
env1_second_0:                 episode reward: 58.3500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 364.45,                last time consumption/overall running time: 128.7797s / 36240.4996 s
env0_first_0:                 episode reward: -57.2000,                 loss: 1.6074
env0_second_0:                 episode reward: 57.2000,                 loss: 1.3209
env1_first_0:                 episode reward: -68.2500,                 loss: nan
env1_second_0:                 episode reward: 68.2500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 481.35,                last time consumption/overall running time: 167.3346s / 36407.8342 s
env0_first_0:                 episode reward: -75.4500,                 loss: 1.5129
env0_second_0:                 episode reward: 75.4500,                 loss: 1.2017
env1_first_0:                 episode reward: -66.3500,                 loss: nan
env1_second_0:                 episode reward: 66.3500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 332.9,                last time consumption/overall running time: 115.9571s / 36523.7913 s
env0_first_0:                 episode reward: -74.5500,                 loss: 1.4198
env0_second_0:                 episode reward: 74.5500,                 loss: 1.1094
env1_first_0:                 episode reward: -77.8500,                 loss: nan
env1_second_0:                 episode reward: 77.8500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 302.7,                last time consumption/overall running time: 104.8549s / 36628.6462 s
env0_first_0:                 episode reward: -71.7000,                 loss: 1.4416
env0_second_0:                 episode reward: 71.7000,                 loss: 1.1349
env1_first_0:                 episode reward: -82.7500,                 loss: nan
env1_second_0:                 episode reward: 82.7500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 311.45,                last time consumption/overall running time: 109.3360s / 36737.9823 s
env0_first_0:                 episode reward: -85.9000,                 loss: 1.4775
env0_second_0:                 episode reward: 85.9000,                 loss: 1.2013
env1_first_0:                 episode reward: -79.9000,                 loss: nan
env1_second_0:                 episode reward: 79.9000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 325.3,                last time consumption/overall running time: 112.5780s / 36850.5603 s
env0_first_0:                 episode reward: -71.7000,                 loss: 1.4346
env0_second_0:                 episode reward: 71.7000,                 loss: 1.1544
env1_first_0:                 episode reward: -80.1500,                 loss: nan
env1_second_0:                 episode reward: 80.1500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 304.1,                last time consumption/overall running time: 104.7245s / 36955.2848 s
env0_first_0:                 episode reward: -80.0000,                 loss: 1.3889
env0_second_0:                 episode reward: 80.0000,                 loss: 1.0887
env1_first_0:                 episode reward: -63.0000,                 loss: nan
env1_second_0:                 episode reward: 63.0000,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 405.7,                last time consumption/overall running time: 140.9217s / 37096.2066 s
env0_first_0:                 episode reward: -57.9500,                 loss: 1.2768
env0_second_0:                 episode reward: 57.9500,                 loss: 1.0658
env1_first_0:                 episode reward: -56.9000,                 loss: nan
env1_second_0:                 episode reward: 56.9000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 332.7,                last time consumption/overall running time: 115.6533s / 37211.8599 s
env0_first_0:                 episode reward: -74.3000,                 loss: 1.2095
env0_second_0:                 episode reward: 74.3000,                 loss: 1.1150
env1_first_0:                 episode reward: -62.7500,                 loss: nan
env1_second_0:                 episode reward: 62.7500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 325.8,                last time consumption/overall running time: 113.5265s / 37325.3864 s
env0_first_0:                 episode reward: -64.7000,                 loss: 1.3035
env0_second_0:                 episode reward: 64.7000,                 loss: 1.1964
env1_first_0:                 episode reward: -61.6000,                 loss: nan
env1_second_0:                 episode reward: 61.6000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 418.5,                last time consumption/overall running time: 144.9927s / 37470.3791 s
env0_first_0:                 episode reward: -65.4000,                 loss: 1.3969
env0_second_0:                 episode reward: 65.4000,                 loss: 1.2745
env1_first_0:                 episode reward: -51.7500,                 loss: nan
env1_second_0:                 episode reward: 51.7500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 377.25,                last time consumption/overall running time: 132.0617s / 37602.4408 s
env0_first_0:                 episode reward: -66.2000,                 loss: 1.4189
env0_second_0:                 episode reward: 66.2000,                 loss: 1.2932
env1_first_0:                 episode reward: -53.3000,                 loss: nan
env1_second_0:                 episode reward: 53.3000,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 297.4,                last time consumption/overall running time: 103.7120s / 37706.1528 s
env0_first_0:                 episode reward: -62.6500,                 loss: 1.4833
env0_second_0:                 episode reward: 62.6500,                 loss: 1.3440
env1_first_0:                 episode reward: -72.3500,                 loss: nan
env1_second_0:                 episode reward: 72.3500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 315.3,                last time consumption/overall running time: 109.9934s / 37816.1462 s
env0_first_0:                 episode reward: -48.9500,                 loss: 1.5406
env0_second_0:                 episode reward: 48.9500,                 loss: 1.3539
env1_first_0:                 episode reward: -71.9000,                 loss: nan
env1_second_0:                 episode reward: 71.9000,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 300.45,                last time consumption/overall running time: 104.9918s / 37921.1379 s
env0_first_0:                 episode reward: -65.5000,                 loss: 1.6666
env0_second_0:                 episode reward: 65.5000,                 loss: 1.3638
env1_first_0:                 episode reward: -67.6500,                 loss: nan
env1_second_0:                 episode reward: 67.6500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 329.4,                last time consumption/overall running time: 114.2796s / 38035.4175 s
env0_first_0:                 episode reward: -73.4500,                 loss: 1.7062
env0_second_0:                 episode reward: 73.4500,                 loss: 1.3820
env1_first_0:                 episode reward: -55.7500,                 loss: nan
env1_second_0:                 episode reward: 55.7500,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 357.3,                last time consumption/overall running time: 123.6275s / 38159.0450 s
env0_first_0:                 episode reward: -66.5500,                 loss: 1.6209
env0_second_0:                 episode reward: 66.5500,                 loss: 1.3789
env1_first_0:                 episode reward: -72.2500,                 loss: nan
env1_second_0:                 episode reward: 72.2500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 272.55,                last time consumption/overall running time: 94.3910s / 38253.4359 s
env0_first_0:                 episode reward: -82.7500,                 loss: 1.5787
env0_second_0:                 episode reward: 82.7500,                 loss: 1.2840
env1_first_0:                 episode reward: -82.7500,                 loss: nan
env1_second_0:                 episode reward: 82.7500,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 309.5,                last time consumption/overall running time: 107.6629s / 38361.0989 s
env0_first_0:                 episode reward: -63.8500,                 loss: 1.5057
env0_second_0:                 episode reward: 63.8500,                 loss: 1.2346
env1_first_0:                 episode reward: -65.2500,                 loss: nan
env1_second_0:                 episode reward: 65.2500,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 310.6,                last time consumption/overall running time: 107.1477s / 38468.2466 s
env0_first_0:                 episode reward: -63.8000,                 loss: 1.4206
env0_second_0:                 episode reward: 63.8000,                 loss: 1.1865
env1_first_0:                 episode reward: -81.3000,                 loss: nan
env1_second_0:                 episode reward: 81.3000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 333.4,                last time consumption/overall running time: 116.5848s / 38584.8313 s
env0_first_0:                 episode reward: -70.0500,                 loss: 1.3734
env0_second_0:                 episode reward: 70.0500,                 loss: 1.1956
env1_first_0:                 episode reward: -67.7500,                 loss: nan
env1_second_0:                 episode reward: 67.7500,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 345.9,                last time consumption/overall running time: 119.2182s / 38704.0495 s
env0_first_0:                 episode reward: -75.3000,                 loss: 1.3983
env0_second_0:                 episode reward: 75.3000,                 loss: 1.1717
env1_first_0:                 episode reward: -59.6000,                 loss: nan
env1_second_0:                 episode reward: 59.6000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 319.85,                last time consumption/overall running time: 114.0715s / 38818.1210 s
env0_first_0:                 episode reward: -48.3000,                 loss: 1.4031
env0_second_0:                 episode reward: 48.3000,                 loss: 1.1236
env1_first_0:                 episode reward: -68.2000,                 loss: nan
env1_second_0:                 episode reward: 68.2000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 314.15,                last time consumption/overall running time: 111.9660s / 38930.0870 s
env0_first_0:                 episode reward: -44.3000,                 loss: 1.4786
env0_second_0:                 episode reward: 44.3000,                 loss: 1.1727
env1_first_0:                 episode reward: -64.5000,                 loss: nan
env1_second_0:                 episode reward: 64.5000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 300.35,                last time consumption/overall running time: 104.7198s / 39034.8067 s
env0_first_0:                 episode reward: -57.8500,                 loss: 1.4771
env0_second_0:                 episode reward: 57.8500,                 loss: 1.1715
env1_first_0:                 episode reward: -59.0500,                 loss: nan
env1_second_0:                 episode reward: 59.0500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 310.5,                last time consumption/overall running time: 108.4451s / 39143.2518 s
env0_first_0:                 episode reward: -54.6000,                 loss: 1.4806
env0_second_0:                 episode reward: 54.6000,                 loss: 1.2202
env1_first_0:                 episode reward: -54.3500,                 loss: nan
env1_second_0:                 episode reward: 54.3500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 465.6,                last time consumption/overall running time: 163.4338s / 39306.6856 s
env0_first_0:                 episode reward: -66.4500,                 loss: 1.4561
env0_second_0:                 episode reward: 66.4500,                 loss: 1.2047
env1_first_0:                 episode reward: -38.2000,                 loss: nan
env1_second_0:                 episode reward: 38.2000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 415.65,                last time consumption/overall running time: 142.8335s / 39449.5191 s
env0_first_0:                 episode reward: -68.2500,                 loss: 1.4244
env0_second_0:                 episode reward: 68.2500,                 loss: 1.1512
env1_first_0:                 episode reward: -52.1000,                 loss: nan
env1_second_0:                 episode reward: 52.1000,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 285.0,                last time consumption/overall running time: 100.5737s / 39550.0928 s
env0_first_0:                 episode reward: -26.6000,                 loss: 1.3856
env0_second_0:                 episode reward: 26.6000,                 loss: 1.1197
env1_first_0:                 episode reward: -54.7000,                 loss: nan
env1_second_0:                 episode reward: 54.7000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 374.8,                last time consumption/overall running time: 131.7476s / 39681.8404 s
env0_first_0:                 episode reward: -61.2000,                 loss: 1.3646
env0_second_0:                 episode reward: 61.2000,                 loss: 1.1001
env1_first_0:                 episode reward: -49.5500,                 loss: nan
env1_second_0:                 episode reward: 49.5500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 467.55,                last time consumption/overall running time: 161.2661s / 39843.1065 s
env0_first_0:                 episode reward: -40.9500,                 loss: 1.2382
env0_second_0:                 episode reward: 40.9500,                 loss: 1.0281
env1_first_0:                 episode reward: -34.5000,                 loss: nan
env1_second_0:                 episode reward: 34.5000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 531.1,                last time consumption/overall running time: 186.1198s / 40029.2263 s
env0_first_0:                 episode reward: -38.2500,                 loss: 1.1391
env0_second_0:                 episode reward: 38.2500,                 loss: 0.9545
env1_first_0:                 episode reward: -26.2500,                 loss: nan
env1_second_0:                 episode reward: 26.2500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 355.15,                last time consumption/overall running time: 122.7907s / 40152.0170 s
env0_first_0:                 episode reward: -54.0000,                 loss: 0.9711
env0_second_0:                 episode reward: 54.0000,                 loss: 0.8643
env1_first_0:                 episode reward: -67.8000,                 loss: nan
env1_second_0:                 episode reward: 67.8000,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 526.6,                last time consumption/overall running time: 183.8652s / 40335.8822 s
env0_first_0:                 episode reward: -33.8000,                 loss: 1.0065
env0_second_0:                 episode reward: 33.8000,                 loss: 0.9045
env1_first_0:                 episode reward: -53.6500,                 loss: nan
env1_second_0:                 episode reward: 53.6500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 512.0,                last time consumption/overall running time: 181.2120s / 40517.0942 s
env0_first_0:                 episode reward: -43.3000,                 loss: 0.9612
env0_second_0:                 episode reward: 43.3000,                 loss: 0.8411
env1_first_0:                 episode reward: -39.7500,                 loss: nan
env1_second_0:                 episode reward: 39.7500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 334.35,                last time consumption/overall running time: 116.1774s / 40633.2715 s
env0_first_0:                 episode reward: -59.9000,                 loss: 1.0499
env0_second_0:                 episode reward: 59.9000,                 loss: 0.8561
env1_first_0:                 episode reward: -58.0000,                 loss: nan
env1_second_0:                 episode reward: 58.0000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 301.2,                last time consumption/overall running time: 105.2572s / 40738.5287 s
env0_first_0:                 episode reward: -41.6500,                 loss: 1.1746
env0_second_0:                 episode reward: 41.6500,                 loss: 0.9882
env1_first_0:                 episode reward: -22.3500,                 loss: nan
env1_second_0:                 episode reward: 22.3500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 252.3,                last time consumption/overall running time: 87.7908s / 40826.3195 s
env0_first_0:                 episode reward: -33.1500,                 loss: 1.2738
env0_second_0:                 episode reward: 33.1500,                 loss: 1.0692
env1_first_0:                 episode reward: -54.7000,                 loss: nan
env1_second_0:                 episode reward: 54.7000,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 265.75,                last time consumption/overall running time: 92.7740s / 40919.0935 s
env0_first_0:                 episode reward: -55.9000,                 loss: 1.4298
env0_second_0:                 episode reward: 55.9000,                 loss: 1.1068
env1_first_0:                 episode reward: -62.5500,                 loss: nan
env1_second_0:                 episode reward: 62.5500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 326.15,                last time consumption/overall running time: 111.6653s / 41030.7588 s
env0_first_0:                 episode reward: -52.1500,                 loss: 1.4743
env0_second_0:                 episode reward: 52.1500,                 loss: 1.1516
env1_first_0:                 episode reward: -58.8000,                 loss: nan
env1_second_0:                 episode reward: 58.8000,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 325.0,                last time consumption/overall running time: 114.3981s / 41145.1568 s
env0_first_0:                 episode reward: -58.4000,                 loss: 1.5687
env0_second_0:                 episode reward: 58.4000,                 loss: 1.2307
env1_first_0:                 episode reward: -38.7000,                 loss: nan
env1_second_0:                 episode reward: 38.7000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 294.4,                last time consumption/overall running time: 105.7960s / 41250.9528 s
env0_first_0:                 episode reward: -21.9500,                 loss: 1.7501
env0_second_0:                 episode reward: 21.9500,                 loss: 1.4104
env1_first_0:                 episode reward: -43.8000,                 loss: nan
env1_second_0:                 episode reward: 43.8000,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 302.1,                last time consumption/overall running time: 105.6084s / 41356.5612 s
env0_first_0:                 episode reward: -22.5000,                 loss: 1.8216
env0_second_0:                 episode reward: 22.5000,                 loss: 1.4261
env1_first_0:                 episode reward: -40.2000,                 loss: nan
env1_second_0:                 episode reward: 40.2000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 283.6,                last time consumption/overall running time: 98.1243s / 41454.6855 s
env0_first_0:                 episode reward: -30.6500,                 loss: 1.8860
env0_second_0:                 episode reward: 30.6500,                 loss: 1.5090
env1_first_0:                 episode reward: -44.4500,                 loss: nan
env1_second_0:                 episode reward: 44.4500,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 361.7,                last time consumption/overall running time: 125.4799s / 41580.1654 s
env0_first_0:                 episode reward: -44.1000,                 loss: 1.8907
env0_second_0:                 episode reward: 44.1000,                 loss: 1.4612
env1_first_0:                 episode reward: -49.3000,                 loss: nan
env1_second_0:                 episode reward: 49.3000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 893.25,                last time consumption/overall running time: 312.4627s / 41892.6281 s
env0_first_0:                 episode reward: -34.0500,                 loss: 1.7681
env0_second_0:                 episode reward: 34.0500,                 loss: 1.4059
env1_first_0:                 episode reward: -31.1000,                 loss: nan
env1_second_0:                 episode reward: 31.1000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 412.95,                last time consumption/overall running time: 143.4652s / 42036.0933 s
env0_first_0:                 episode reward: -54.5500,                 loss: 1.5313
env0_second_0:                 episode reward: 54.5500,                 loss: 1.1853
env1_first_0:                 episode reward: -46.3500,                 loss: nan
env1_second_0:                 episode reward: 46.3500,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 570.3,                last time consumption/overall running time: 198.4488s / 42234.5421 s
env0_first_0:                 episode reward: 5.2000,                 loss: 1.3662
env0_second_0:                 episode reward: -5.2000,                 loss: 1.0526
env1_first_0:                 episode reward: 26.7500,                 loss: nan
env1_second_0:                 episode reward: -26.7500,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 400.8,                last time consumption/overall running time: 137.6726s / 42372.2147 s
env0_first_0:                 episode reward: 15.6500,                 loss: 1.3793
env0_second_0:                 episode reward: -15.6500,                 loss: 1.0388
env1_first_0:                 episode reward: 30.7000,                 loss: nan
env1_second_0:                 episode reward: -30.7000,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 335.75,                last time consumption/overall running time: 114.7018s / 42486.9165 s
env0_first_0:                 episode reward: -0.3500,                 loss: 1.4728
env0_second_0:                 episode reward: 0.3500,                 loss: 1.1010
env1_first_0:                 episode reward: 15.5000,                 loss: nan
env1_second_0:                 episode reward: -15.5000,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 394.15,                last time consumption/overall running time: 136.0805s / 42622.9970 s
env0_first_0:                 episode reward: -8.9000,                 loss: 1.6043
env0_second_0:                 episode reward: 8.9000,                 loss: 1.1616
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 463.45,                last time consumption/overall running time: 161.3634s / 42784.3604 s
env0_first_0:                 episode reward: -46.2500,                 loss: 1.6565
env0_second_0:                 episode reward: 46.2500,                 loss: 1.2641
env1_first_0:                 episode reward: -34.0500,                 loss: nan
env1_second_0:                 episode reward: 34.0500,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 372.2,                last time consumption/overall running time: 130.6320s / 42914.9924 s
env0_first_0:                 episode reward: -39.1000,                 loss: 1.6108
env0_second_0:                 episode reward: 39.1000,                 loss: 1.2419
env1_first_0:                 episode reward: -49.0500,                 loss: nan
env1_second_0:                 episode reward: 49.0500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 442.2,                last time consumption/overall running time: 154.5116s / 43069.5039 s
env0_first_0:                 episode reward: -33.1000,                 loss: 1.6641
env0_second_0:                 episode reward: 33.1000,                 loss: 1.3369
env1_first_0:                 episode reward: -39.5500,                 loss: nan
env1_second_0:                 episode reward: 39.5500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 418.15,                last time consumption/overall running time: 146.9431s / 43216.4471 s
env0_first_0:                 episode reward: -37.4000,                 loss: 1.6758
env0_second_0:                 episode reward: 37.4000,                 loss: 1.3589
env1_first_0:                 episode reward: -28.7500,                 loss: nan
env1_second_0:                 episode reward: 28.7500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 303.55,                last time consumption/overall running time: 105.4082s / 43321.8552 s
env0_first_0:                 episode reward: -6.6500,                 loss: 1.6317
env0_second_0:                 episode reward: 6.6500,                 loss: 1.2843
env1_first_0:                 episode reward: 5.3500,                 loss: nan
env1_second_0:                 episode reward: -5.3500,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 320.5,                last time consumption/overall running time: 112.2341s / 43434.0893 s
env0_first_0:                 episode reward: -52.4500,                 loss: 1.6494
env0_second_0:                 episode reward: 52.4500,                 loss: 1.2859
env1_first_0:                 episode reward: -44.9000,                 loss: nan
env1_second_0:                 episode reward: 44.9000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 340.55,                last time consumption/overall running time: 117.7107s / 43551.8000 s
env0_first_0:                 episode reward: -27.8500,                 loss: 1.7758
env0_second_0:                 episode reward: 27.8500,                 loss: 1.3133
env1_first_0:                 episode reward: -55.8500,                 loss: nan
env1_second_0:                 episode reward: 55.8500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 407.0,                last time consumption/overall running time: 142.9746s / 43694.7746 s
env0_first_0:                 episode reward: -69.1000,                 loss: 1.8645
env0_second_0:                 episode reward: 69.1000,                 loss: 1.3615
env1_first_0:                 episode reward: -52.2000,                 loss: nan
env1_second_0:                 episode reward: 52.2000,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 421.35,                last time consumption/overall running time: 145.6507s / 43840.4253 s
env0_first_0:                 episode reward: -57.1500,                 loss: 2.0131
env0_second_0:                 episode reward: 57.1500,                 loss: 1.4705
env1_first_0:                 episode reward: -55.3000,                 loss: nan
env1_second_0:                 episode reward: 55.3000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 368.3,                last time consumption/overall running time: 127.6594s / 43968.0846 s
env0_first_0:                 episode reward: -41.3000,                 loss: 1.8373
env0_second_0:                 episode reward: 41.3000,                 loss: 1.3893
env1_first_0:                 episode reward: -59.4000,                 loss: nan
env1_second_0:                 episode reward: 59.4000,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 280.3,                last time consumption/overall running time: 98.0095s / 44066.0941 s
env0_first_0:                 episode reward: -24.9000,                 loss: 1.8096
env0_second_0:                 episode reward: 24.9000,                 loss: 1.3863
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 254.65,                last time consumption/overall running time: 87.9149s / 44154.0090 s
env0_first_0:                 episode reward: -22.2500,                 loss: 1.7948
env0_second_0:                 episode reward: 22.2500,                 loss: 1.3430
env1_first_0:                 episode reward: -19.2000,                 loss: nan
env1_second_0:                 episode reward: 19.2000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 398.25,                last time consumption/overall running time: 136.9521s / 44290.9612 s
env0_first_0:                 episode reward: -48.5000,                 loss: 1.7059
env0_second_0:                 episode reward: 48.5000,                 loss: 1.2585
env1_first_0:                 episode reward: -67.9000,                 loss: nan
env1_second_0:                 episode reward: 67.9000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 612.6,                last time consumption/overall running time: 213.2852s / 44504.2464 s
env0_first_0:                 episode reward: -6.0500,                 loss: 1.4640
env0_second_0:                 episode reward: 6.0500,                 loss: 1.1289
env1_first_0:                 episode reward: -17.6500,                 loss: nan
env1_second_0:                 episode reward: 17.6500,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 397.85,                last time consumption/overall running time: 141.9076s / 44646.1540 s
env0_first_0:                 episode reward: 7.9000,                 loss: 1.3171
env0_second_0:                 episode reward: -7.9000,                 loss: 1.0683
env1_first_0:                 episode reward: 40.4000,                 loss: nan
env1_second_0:                 episode reward: -40.4000,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 318.15,                last time consumption/overall running time: 110.6647s / 44756.8187 s
env0_first_0:                 episode reward: 26.0000,                 loss: 1.3682
env0_second_0:                 episode reward: -26.0000,                 loss: 1.1370
env1_first_0:                 episode reward: 12.0000,                 loss: nan
env1_second_0:                 episode reward: -12.0000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 286.6,                last time consumption/overall running time: 101.4354s / 44858.2541 s
env0_first_0:                 episode reward: 32.8000,                 loss: 1.4820
env0_second_0:                 episode reward: -32.8000,                 loss: 1.2555
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 392.9,                last time consumption/overall running time: 136.3739s / 44994.6281 s
env0_first_0:                 episode reward: 7.3000,                 loss: 1.4619
env0_second_0:                 episode reward: -7.3000,                 loss: 1.3844
env1_first_0:                 episode reward: 27.8500,                 loss: nan
env1_second_0:                 episode reward: -27.8500,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 436.35,                last time consumption/overall running time: 152.3014s / 45146.9295 s
env0_first_0:                 episode reward: 30.3500,                 loss: 1.3328
env0_second_0:                 episode reward: -30.3500,                 loss: 1.3535
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 286.55,                last time consumption/overall running time: 99.6087s / 45246.5382 s
env0_first_0:                 episode reward: -20.2000,                 loss: 1.5483
env0_second_0:                 episode reward: 20.2000,                 loss: 1.4608
env1_first_0:                 episode reward: -44.2000,                 loss: nan
env1_second_0:                 episode reward: 44.2000,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 261.9,                last time consumption/overall running time: 91.1837s / 45337.7218 s
env0_first_0:                 episode reward: -52.4500,                 loss: 1.6756
env0_second_0:                 episode reward: 52.4500,                 loss: 1.4425
env1_first_0:                 episode reward: -56.0500,                 loss: nan
env1_second_0:                 episode reward: 56.0500,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 289.25,                last time consumption/overall running time: 100.3030s / 45438.0248 s
env0_first_0:                 episode reward: -33.6000,                 loss: 1.8038
env0_second_0:                 episode reward: 33.6000,                 loss: 1.5356
env1_first_0:                 episode reward: -30.4500,                 loss: nan
env1_second_0:                 episode reward: 30.4500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 405.55,                last time consumption/overall running time: 141.0556s / 45579.0804 s
env0_first_0:                 episode reward: 3.9000,                 loss: 1.9892
env0_second_0:                 episode reward: -3.9000,                 loss: 1.6894
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 430.7,                last time consumption/overall running time: 150.9957s / 45730.0761 s
env0_first_0:                 episode reward: -25.9500,                 loss: 1.9229
env0_second_0:                 episode reward: 25.9500,                 loss: 1.5583
env1_first_0:                 episode reward: -42.5500,                 loss: nan
env1_second_0:                 episode reward: 42.5500,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 529.95,                last time consumption/overall running time: 184.0223s / 45914.0984 s
env0_first_0:                 episode reward: -0.6000,                 loss: 1.8589
env0_second_0:                 episode reward: 0.6000,                 loss: 1.4967
env1_first_0:                 episode reward: 7.9500,                 loss: nan
env1_second_0:                 episode reward: -7.9500,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 379.5,                last time consumption/overall running time: 132.7117s / 46046.8101 s
env0_first_0:                 episode reward: -0.2000,                 loss: 1.9175
env0_second_0:                 episode reward: 0.2000,                 loss: 1.5006
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 486.1,                last time consumption/overall running time: 171.2916s / 46218.1017 s
env0_first_0:                 episode reward: 12.1500,                 loss: 1.8576
env0_second_0:                 episode reward: -12.1500,                 loss: 1.5309
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 319.5,                last time consumption/overall running time: 111.1176s / 46329.2193 s
env0_first_0:                 episode reward: -5.2500,                 loss: 1.9482
env0_second_0:                 episode reward: 5.2500,                 loss: 1.6403
env1_first_0:                 episode reward: -13.1000,                 loss: nan
env1_second_0:                 episode reward: 13.1000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 343.1,                last time consumption/overall running time: 121.0678s / 46450.2871 s
env0_first_0:                 episode reward: -37.0000,                 loss: 1.9605
env0_second_0:                 episode reward: 37.0000,                 loss: 1.6654
env1_first_0:                 episode reward: -38.6500,                 loss: nan
env1_second_0:                 episode reward: 38.6500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 271.35,                last time consumption/overall running time: 96.4499s / 46546.7369 s
env0_first_0:                 episode reward: -39.7000,                 loss: 2.2241
env0_second_0:                 episode reward: 39.7000,                 loss: 1.6999
env1_first_0:                 episode reward: -29.4000,                 loss: nan
env1_second_0:                 episode reward: 29.4000,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 343.3,                last time consumption/overall running time: 119.1674s / 46665.9043 s
env0_first_0:                 episode reward: -65.9000,                 loss: 2.6060
env0_second_0:                 episode reward: 65.9000,                 loss: 1.7164
env1_first_0:                 episode reward: -61.3000,                 loss: nan
env1_second_0:                 episode reward: 61.3000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 258.65,                last time consumption/overall running time: 90.7637s / 46756.6680 s
env0_first_0:                 episode reward: -77.4500,                 loss: 2.7003
env0_second_0:                 episode reward: 77.4500,                 loss: 1.6860
env1_first_0:                 episode reward: -58.2000,                 loss: nan
env1_second_0:                 episode reward: 58.2000,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 294.55,                last time consumption/overall running time: 104.5645s / 46861.2325 s
env0_first_0:                 episode reward: -73.3500,                 loss: 3.0604
env0_second_0:                 episode reward: 73.3500,                 loss: 1.6817
env1_first_0:                 episode reward: -76.6500,                 loss: nan
env1_second_0:                 episode reward: 76.6500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 249.3,                last time consumption/overall running time: 88.5550s / 46949.7875 s
env0_first_0:                 episode reward: -88.6500,                 loss: 3.2249
env0_second_0:                 episode reward: 88.6500,                 loss: 1.6959
env1_first_0:                 episode reward: -86.8000,                 loss: nan
env1_second_0:                 episode reward: 86.8000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 239.4,                last time consumption/overall running time: 83.0545s / 47032.8420 s
env0_first_0:                 episode reward: -96.8000,                 loss: 3.0944
env0_second_0:                 episode reward: 96.8000,                 loss: 1.6910
env1_first_0:                 episode reward: -82.4000,                 loss: nan
env1_second_0:                 episode reward: 82.4000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 248.4,                last time consumption/overall running time: 87.2669s / 47120.1090 s
env0_first_0:                 episode reward: -84.6000,                 loss: 2.8058
env0_second_0:                 episode reward: 84.6000,                 loss: 1.5414
env1_first_0:                 episode reward: -97.2500,                 loss: nan
env1_second_0:                 episode reward: 97.2500,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 231.95,                last time consumption/overall running time: 80.1398s / 47200.2487 s
env0_first_0:                 episode reward: -88.5000,                 loss: 2.5121
env0_second_0:                 episode reward: 88.5000,                 loss: 1.3088
env1_first_0:                 episode reward: -95.6000,                 loss: nan
env1_second_0:                 episode reward: 95.6000,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 235.95,                last time consumption/overall running time: 83.9619s / 47284.2106 s
env0_first_0:                 episode reward: -90.2000,                 loss: 2.3314
env0_second_0:                 episode reward: 90.2000,                 loss: 1.2539
env1_first_0:                 episode reward: -82.5000,                 loss: nan
env1_second_0:                 episode reward: 82.5000,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 260.3,                last time consumption/overall running time: 91.9794s / 47376.1900 s
env0_first_0:                 episode reward: -87.4500,                 loss: 2.2134
env0_second_0:                 episode reward: 87.4500,                 loss: 1.2204
env1_first_0:                 episode reward: -95.5000,                 loss: nan
env1_second_0:                 episode reward: 95.5000,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 293.35,                last time consumption/overall running time: 101.2333s / 47477.4233 s
env0_first_0:                 episode reward: -73.7500,                 loss: 2.2947
env0_second_0:                 episode reward: 73.7500,                 loss: 1.0666
env1_first_0:                 episode reward: -66.3000,                 loss: nan
env1_second_0:                 episode reward: 66.3000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 322.95,                last time consumption/overall running time: 110.5441s / 47587.9674 s
env0_first_0:                 episode reward: -53.5500,                 loss: 2.4115
env0_second_0:                 episode reward: 53.5500,                 loss: 0.9986
env1_first_0:                 episode reward: -48.5000,                 loss: nan
env1_second_0:                 episode reward: 48.5000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 514.25,                last time consumption/overall running time: 180.8777s / 47768.8451 s
env0_first_0:                 episode reward: -5.4000,                 loss: 2.4462
env0_second_0:                 episode reward: 5.4000,                 loss: 0.9383
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 680.0,                last time consumption/overall running time: 233.6498s / 48002.4949 s
env0_first_0:                 episode reward: -22.4000,                 loss: 2.2068
env0_second_0:                 episode reward: 22.4000,                 loss: 0.9504
env1_first_0:                 episode reward: -38.0000,                 loss: nan
env1_second_0:                 episode reward: 38.0000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 1102.0,                last time consumption/overall running time: 379.8247s / 48382.3195 s
env0_first_0:                 episode reward: -35.7500,                 loss: 1.9313
env0_second_0:                 episode reward: 35.7500,                 loss: 0.8719
env1_first_0:                 episode reward: -29.4000,                 loss: nan
env1_second_0:                 episode reward: 29.4000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 825.5,                last time consumption/overall running time: 289.9113s / 48672.2308 s
env0_first_0:                 episode reward: -34.4000,                 loss: 1.1798
env0_second_0:                 episode reward: 34.4000,                 loss: 0.4470
env1_first_0:                 episode reward: -39.5000,                 loss: nan
env1_second_0:                 episode reward: 39.5000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 420.95,                last time consumption/overall running time: 147.9146s / 48820.1454 s
env0_first_0:                 episode reward: -80.2000,                 loss: 1.0628
env0_second_0:                 episode reward: 80.2000,                 loss: 0.3435