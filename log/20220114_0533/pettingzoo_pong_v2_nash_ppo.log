pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [15, 53]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220114_0533/pettingzoo_pong_v2_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220114_0533/pettingzoo_pong_v2_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 1408.0,                last time consumption/overall running time: 12.5422s / 12.5422 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2924
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2929
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 1279.05,                last time consumption/overall running time: 193.6645s / 206.2067 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2770
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2750
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 1189.75,                last time consumption/overall running time: 184.8506s / 391.0573 s
env0_first_0:                 episode reward: 10.1500,                 loss: 0.3948
env0_second_0:                 episode reward: -10.1500,                 loss: 0.4299
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 1232.55,                last time consumption/overall running time: 187.1598s / 578.2171 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.5246
env0_second_0:                 episode reward: -2.9000,                 loss: 0.5374
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 1222.0,                last time consumption/overall running time: 185.7284s / 763.9455 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.6641
env0_second_0:                 episode reward: -0.1500,                 loss: 0.6035
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 1195.25,                last time consumption/overall running time: 177.3749s / 941.3204 s
env0_first_0:                 episode reward: 4.0000,                 loss: 0.6580
env0_second_0:                 episode reward: -4.0000,                 loss: 0.6344
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 1238.2,                last time consumption/overall running time: 183.3683s / 1124.6888 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.6636
env0_second_0:                 episode reward: -0.8500,                 loss: 0.6312
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 1155.85,                last time consumption/overall running time: 176.8446s / 1301.5333 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.6217
env0_second_0:                 episode reward: 1.1000,                 loss: 0.5719
env1_first_0:                 episode reward: 4.5500,                 loss: nan
env1_second_0:                 episode reward: -4.5500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 1201.05,                last time consumption/overall running time: 179.7880s / 1481.3214 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.6476
env0_second_0:                 episode reward: -2.2000,                 loss: 0.6112
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 1173.05,                last time consumption/overall running time: 173.4925s / 1654.8139 s
env0_first_0:                 episode reward: 3.9500,                 loss: 0.6089
env0_second_0:                 episode reward: -3.9500,                 loss: 0.5945
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 1158.05,                last time consumption/overall running time: 175.4934s / 1830.3072 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.5996
env0_second_0:                 episode reward: -2.4000,                 loss: 0.5852
env1_first_0:                 episode reward: 2.3000,                 loss: nan
env1_second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 1289.7,                last time consumption/overall running time: 193.9125s / 2024.2198 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.5409
env0_second_0:                 episode reward: 1.0000,                 loss: 0.5480
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 1237.6,                last time consumption/overall running time: 184.9134s / 2209.1331 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.5290
env0_second_0:                 episode reward: 2.0500,                 loss: 0.5339
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 1304.95,                last time consumption/overall running time: 194.7557s / 2403.8888 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.4964
env0_second_0:                 episode reward: -3.0000,                 loss: 0.5084
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 1181.85,                last time consumption/overall running time: 180.3630s / 2584.2518 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.5493
env0_second_0:                 episode reward: -3.4500,                 loss: 0.5594
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 1241.85,                last time consumption/overall running time: 184.8048s / 2769.0567 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.5204
env0_second_0:                 episode reward: -0.3000,                 loss: 0.5388
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 1252.9,                last time consumption/overall running time: 185.4150s / 2954.4717 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.5145
env0_second_0:                 episode reward: -2.4500,                 loss: 0.5244
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 1140.55,                last time consumption/overall running time: 170.1975s / 3124.6692 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.5250
env0_second_0:                 episode reward: 0.8500,                 loss: 0.5305
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 1224.45,                last time consumption/overall running time: 182.4697s / 3307.1389 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.5013
env0_second_0:                 episode reward: -3.2000,                 loss: 0.5220
env1_first_0:                 episode reward: 4.5000,                 loss: nan
env1_second_0:                 episode reward: -4.5000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 1252.55,                last time consumption/overall running time: 187.6582s / 3494.7971 s
env0_first_0:                 episode reward: 4.7000,                 loss: 0.4807
env0_second_0:                 episode reward: -4.7000,                 loss: 0.5206
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 1178.95,                last time consumption/overall running time: 174.6018s / 3669.3989 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.5161
env0_second_0:                 episode reward: 0.6000,                 loss: 0.5275
env1_first_0:                 episode reward: 4.5500,                 loss: nan
env1_second_0:                 episode reward: -4.5500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 1175.9,                last time consumption/overall running time: 177.7367s / 3847.1357 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.4760
env0_second_0:                 episode reward: -2.4000,                 loss: 0.5009
env1_first_0:                 episode reward: 5.0500,                 loss: nan
env1_second_0:                 episode reward: -5.0500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 1173.5,                last time consumption/overall running time: 176.4260s / 4023.5617 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.4755
env0_second_0:                 episode reward: -2.3000,                 loss: 0.5162
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 1352.95,                last time consumption/overall running time: 202.3431s / 4225.9048 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.4746
env0_second_0:                 episode reward: -0.7500,                 loss: 0.4996
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 1170.9,                last time consumption/overall running time: 175.2234s / 4401.1282 s
env0_first_0:                 episode reward: 5.3000,                 loss: 0.4706
env0_second_0:                 episode reward: -5.3000,                 loss: 0.4884
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 1200.9,                last time consumption/overall running time: 179.2913s / 4580.4194 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.4901
env0_second_0:                 episode reward: -1.9000,                 loss: 0.5204
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 1169.3,                last time consumption/overall running time: 176.0179s / 4756.4373 s
env0_first_0:                 episode reward: 6.0000,                 loss: 0.4898
env0_second_0:                 episode reward: -6.0000,                 loss: 0.5253
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 1190.45,                last time consumption/overall running time: 178.3801s / 4934.8174 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.4678
env0_second_0:                 episode reward: -2.1000,                 loss: 0.4842
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 1192.05,                last time consumption/overall running time: 177.9177s / 5112.7351 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.4971
env0_second_0:                 episode reward: -1.6000,                 loss: 0.5199
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 1291.15,                last time consumption/overall running time: 193.3979s / 5306.1329 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.4672
env0_second_0:                 episode reward: -2.9000,                 loss: 0.4885
env1_first_0:                 episode reward: 3.7000,                 loss: nan
env1_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 1261.75,                last time consumption/overall running time: 189.4607s / 5495.5936 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.4190
env0_second_0:                 episode reward: -2.0000,                 loss: 0.4433
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 1151.35,                last time consumption/overall running time: 177.3575s / 5672.9511 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.4666
env0_second_0:                 episode reward: 4.3000,                 loss: 0.4874
env1_first_0:                 episode reward: 3.8500,                 loss: nan
env1_second_0:                 episode reward: -3.8500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 1224.3,                last time consumption/overall running time: 184.8816s / 5857.8327 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.4259
env0_second_0:                 episode reward: -1.1000,                 loss: 0.4428
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 1228.0,                last time consumption/overall running time: 183.8274s / 6041.6600 s
env0_first_0:                 episode reward: 4.1000,                 loss: 0.4472
env0_second_0:                 episode reward: -4.1000,                 loss: 0.4672
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 1227.9,                last time consumption/overall running time: 185.5541s / 6227.2141 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.4526
env0_second_0:                 episode reward: -2.8500,                 loss: 0.4538
env1_first_0:                 episode reward: 7.3000,                 loss: nan
env1_second_0:                 episode reward: -7.3000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 1201.95,                last time consumption/overall running time: 182.7833s / 6409.9974 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.4516
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4563
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 1271.6,                last time consumption/overall running time: 189.1344s / 6599.1318 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.4405
env0_second_0:                 episode reward: -0.4500,                 loss: 0.4507
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 1094.0,                last time consumption/overall running time: 163.8304s / 6762.9622 s
env0_first_0:                 episode reward: 4.5500,                 loss: 0.4257
env0_second_0:                 episode reward: -4.5500,                 loss: 0.4322
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 1258.1,                last time consumption/overall running time: 186.4988s / 6949.4610 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.4409
env0_second_0:                 episode reward: -3.5000,                 loss: 0.4387
env1_first_0:                 episode reward: 3.8000,                 loss: nan
env1_second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 1183.5,                last time consumption/overall running time: 178.5350s / 7127.9960 s
env0_first_0:                 episode reward: 4.9500,                 loss: 0.3905
env0_second_0:                 episode reward: -4.9500,                 loss: 0.3946
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 1216.05,                last time consumption/overall running time: 182.5528s / 7310.5489 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.4468
env0_second_0:                 episode reward: -0.8500,                 loss: 0.4409
env1_first_0:                 episode reward: 5.0500,                 loss: nan
env1_second_0:                 episode reward: -5.0500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 1261.1,                last time consumption/overall running time: 189.6693s / 7500.2182 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.4017
env0_second_0:                 episode reward: -0.3000,                 loss: 0.4006
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 1134.25,                last time consumption/overall running time: 169.8859s / 7670.1040 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.4567
env0_second_0:                 episode reward: 1.5000,                 loss: 0.4428
env1_first_0:                 episode reward: 4.2000,                 loss: nan
env1_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 1124.0,                last time consumption/overall running time: 170.8484s / 7840.9525 s
env0_first_0:                 episode reward: 4.6000,                 loss: 0.4234
env0_second_0:                 episode reward: -4.6000,                 loss: 0.4165
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 1139.65,                last time consumption/overall running time: 173.6730s / 8014.6255 s
env0_first_0:                 episode reward: 4.4000,                 loss: 0.4304
env0_second_0:                 episode reward: -4.4000,                 loss: 0.4186
env1_first_0:                 episode reward: 4.4000,                 loss: nan
env1_second_0:                 episode reward: -4.4000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 1248.0,                last time consumption/overall running time: 187.0067s / 8201.6322 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.4480
env0_second_0:                 episode reward: -2.2000,                 loss: 0.4417
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 1289.4,                last time consumption/overall running time: 191.1598s / 8392.7920 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.4306
env0_second_0:                 episode reward: -1.6000,                 loss: 0.4328
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 1198.4,                last time consumption/overall running time: 179.8474s / 8572.6394 s
env0_first_0:                 episode reward: 6.8000,                 loss: 0.4564
env0_second_0:                 episode reward: -6.8000,                 loss: 0.4545
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 1086.55,                last time consumption/overall running time: 168.1271s / 8740.7665 s
env0_first_0:                 episode reward: 8.2000,                 loss: 0.3963
env0_second_0:                 episode reward: -8.2000,                 loss: 0.3874
env1_first_0:                 episode reward: 6.7500,                 loss: nan
env1_second_0:                 episode reward: -6.7500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 1196.95,                last time consumption/overall running time: 179.8935s / 8920.6599 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.4148
env0_second_0:                 episode reward: -0.4000,                 loss: 0.4104
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 1234.15,                last time consumption/overall running time: 183.9422s / 9104.6021 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.4442
env0_second_0:                 episode reward: 0.4000,                 loss: 0.4329
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 1236.1,                last time consumption/overall running time: 185.2199s / 9289.8220 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.4317
env0_second_0:                 episode reward: -1.4000,                 loss: 0.4242
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 1319.2,                last time consumption/overall running time: 198.1608s / 9487.9828 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.4095
env0_second_0:                 episode reward: 0.3000,                 loss: 0.4150
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 1269.85,                last time consumption/overall running time: 190.9813s / 9678.9640 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.4325
env0_second_0:                 episode reward: -3.7000,                 loss: 0.4203
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 1152.0,                last time consumption/overall running time: 175.5200s / 9854.4840 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.4536
env0_second_0:                 episode reward: 1.6000,                 loss: 0.4333
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 1156.55,                last time consumption/overall running time: 174.2721s / 10028.7561 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.4089
env0_second_0:                 episode reward: 1.1000,                 loss: 0.4042
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 1257.3,                last time consumption/overall running time: 187.0310s / 10215.7871 s
env0_first_0:                 episode reward: 4.2000,                 loss: 0.4329
env0_second_0:                 episode reward: -4.2000,                 loss: 0.4258
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 1184.0,                last time consumption/overall running time: 180.1635s / 10395.9506 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.3989
env0_second_0:                 episode reward: -1.2500,                 loss: 0.3984
env1_first_0:                 episode reward: 4.7500,                 loss: nan
env1_second_0:                 episode reward: -4.7500,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 1237.95,                last time consumption/overall running time: 187.5254s / 10583.4760 s
env0_first_0:                 episode reward: 3.7500,                 loss: 0.4479
env0_second_0:                 episode reward: -3.7500,                 loss: 0.4386
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 1188.55,                last time consumption/overall running time: 181.0791s / 10764.5551 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.3857
env0_second_0:                 episode reward: -1.4000,                 loss: 0.3780
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 1121.35,                last time consumption/overall running time: 170.9697s / 10935.5248 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.4444
env0_second_0:                 episode reward: -1.5000,                 loss: 0.4466
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 1256.45,                last time consumption/overall running time: 189.3849s / 11124.9097 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.4358
env0_second_0:                 episode reward: -2.4000,                 loss: 0.4314
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 1216.8,                last time consumption/overall running time: 182.6963s / 11307.6060 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.4220
env0_second_0:                 episode reward: -2.2000,                 loss: 0.4123
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 1216.9,                last time consumption/overall running time: 181.6018s / 11489.2079 s
env0_first_0:                 episode reward: 5.8500,                 loss: 0.4125
env0_second_0:                 episode reward: -5.8500,                 loss: 0.3993
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 1314.9,                last time consumption/overall running time: 197.0270s / 11686.2349 s
env0_first_0:                 episode reward: 5.7500,                 loss: 0.4340
env0_second_0:                 episode reward: -5.7500,                 loss: 0.4374
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 1211.85,                last time consumption/overall running time: 180.1901s / 11866.4250 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.4199
env0_second_0:                 episode reward: 0.3500,                 loss: 0.4236
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 1176.8,                last time consumption/overall running time: 176.6525s / 12043.0775 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.4119
env0_second_0:                 episode reward: -1.3500,                 loss: 0.4074
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 1194.3,                last time consumption/overall running time: 180.8352s / 12223.9126 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.4275
env0_second_0:                 episode reward: -2.8500,                 loss: 0.4224
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 1099.25,                last time consumption/overall running time: 168.8074s / 12392.7200 s
env0_first_0:                 episode reward: 4.9500,                 loss: 0.4134
env0_second_0:                 episode reward: -4.9500,                 loss: 0.4095
env1_first_0:                 episode reward: 7.7000,                 loss: nan
env1_second_0:                 episode reward: -7.7000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 1107.7,                last time consumption/overall running time: 167.4555s / 12560.1755 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.3826
env0_second_0:                 episode reward: -1.9500,                 loss: 0.3819
env1_first_0:                 episode reward: 4.4000,                 loss: nan
env1_second_0:                 episode reward: -4.4000,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 1148.0,                last time consumption/overall running time: 174.5988s / 12734.7743 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.4522
env0_second_0:                 episode reward: -0.8500,                 loss: 0.4501
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 1175.9,                last time consumption/overall running time: 177.8141s / 12912.5884 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.4064
env0_second_0:                 episode reward: -3.0000,                 loss: 0.4164
env1_first_0:                 episode reward: 6.8500,                 loss: nan
env1_second_0:                 episode reward: -6.8500,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 1251.15,                last time consumption/overall running time: 189.4590s / 13102.0475 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.4059
env0_second_0:                 episode reward: -2.3000,                 loss: 0.4133
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 1164.35,                last time consumption/overall running time: 176.5942s / 13278.6417 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3982
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4121
env1_first_0:                 episode reward: 3.8000,                 loss: nan
env1_second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 1210.05,                last time consumption/overall running time: 185.3205s / 13463.9622 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.3925
env0_second_0:                 episode reward: -1.2500,                 loss: 0.4073
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 1227.0,                last time consumption/overall running time: 187.8966s / 13651.8588 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.4173
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4159
env1_first_0:                 episode reward: 4.6000,                 loss: nan
env1_second_0:                 episode reward: -4.6000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 1254.6,                last time consumption/overall running time: 189.1865s / 13841.0453 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.3930
env0_second_0:                 episode reward: -2.4000,                 loss: 0.3912
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 1159.35,                last time consumption/overall running time: 175.5128s / 14016.5581 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.4243
env0_second_0:                 episode reward: 4.3000,                 loss: 0.4447
env1_first_0:                 episode reward: 4.7000,                 loss: nan
env1_second_0:                 episode reward: -4.7000,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 1273.3,                last time consumption/overall running time: 188.2315s / 14204.7897 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.4423
env0_second_0:                 episode reward: -1.5000,                 loss: 0.4380
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 1206.9,                last time consumption/overall running time: 183.3324s / 14388.1220 s
env0_first_0:                 episode reward: 4.6000,                 loss: 0.4034
env0_second_0:                 episode reward: -4.6000,                 loss: 0.4074
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 1249.85,                last time consumption/overall running time: 188.3145s / 14576.4366 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3985
env0_second_0:                 episode reward: 0.2500,                 loss: 0.4067
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 1221.85,                last time consumption/overall running time: 185.6975s / 14762.1341 s
env0_first_0:                 episode reward: 5.1500,                 loss: 0.3677
env0_second_0:                 episode reward: -5.1500,                 loss: 0.3613
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 1181.1,                last time consumption/overall running time: 178.1966s / 14940.3307 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.4348
env0_second_0:                 episode reward: -2.4500,                 loss: 0.4396
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 1275.7,                last time consumption/overall running time: 193.7953s / 15134.1260 s
env0_first_0:                 episode reward: 3.2500,                 loss: 0.4111
env0_second_0:                 episode reward: -3.2500,                 loss: 0.4249
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 1140.85,                last time consumption/overall running time: 172.1372s / 15306.2632 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.4192
env0_second_0:                 episode reward: -1.3000,                 loss: 0.4115
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 1252.3,                last time consumption/overall running time: 192.0065s / 15498.2697 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.4328
env0_second_0:                 episode reward: -3.6500,                 loss: 0.4388
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 1228.85,                last time consumption/overall running time: 187.3274s / 15685.5971 s
env0_first_0:                 episode reward: 3.9000,                 loss: 0.4377
env0_second_0:                 episode reward: -3.9000,                 loss: 0.4511
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 1296.05,                last time consumption/overall running time: 198.0636s / 15883.6607 s
env0_first_0:                 episode reward: 5.2000,                 loss: 0.3777
env0_second_0:                 episode reward: -5.2000,                 loss: 0.3859
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 1286.0,                last time consumption/overall running time: 190.8125s / 16074.4733 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3931
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3961
env1_first_0:                 episode reward: 5.5500,                 loss: nan
env1_second_0:                 episode reward: -5.5500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 1169.65,                last time consumption/overall running time: 179.3564s / 16253.8296 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.4002
env0_second_0:                 episode reward: -2.5500,                 loss: 0.4153
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 1237.6,                last time consumption/overall running time: 187.5787s / 16441.4083 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.3956
env0_second_0:                 episode reward: 0.9000,                 loss: 0.3999
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 1244.3,                last time consumption/overall running time: 184.5262s / 16625.9345 s
env0_first_0:                 episode reward: 3.2500,                 loss: 0.4441
env0_second_0:                 episode reward: -3.2500,                 loss: 0.4557
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 1159.6,                last time consumption/overall running time: 174.7290s / 16800.6635 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.4235
env0_second_0:                 episode reward: -2.0000,                 loss: 0.4196
env1_first_0:                 episode reward: 4.8500,                 loss: nan
env1_second_0:                 episode reward: -4.8500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 1218.85,                last time consumption/overall running time: 184.0185s / 16984.6820 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3839
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4023
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 1131.65,                last time consumption/overall running time: 174.5303s / 17159.2123 s
env0_first_0:                 episode reward: 3.9500,                 loss: 0.4446
env0_second_0:                 episode reward: -3.9500,                 loss: 0.4542
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 1206.25,                last time consumption/overall running time: 183.2596s / 17342.4720 s
env0_first_0:                 episode reward: 5.8500,                 loss: 0.4489
env0_second_0:                 episode reward: -5.8500,                 loss: 0.4404
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 1184.75,                last time consumption/overall running time: 179.0087s / 17521.4807 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.4610
env0_second_0:                 episode reward: -3.4500,                 loss: 0.4536
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 1202.8,                last time consumption/overall running time: 180.8968s / 17702.3775 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.4533
env0_second_0:                 episode reward: 2.2000,                 loss: 0.4581
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 1228.9,                last time consumption/overall running time: 186.3938s / 17888.7713 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.3789
env0_second_0:                 episode reward: 1.8500,                 loss: 0.3794
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 1189.65,                last time consumption/overall running time: 177.6941s / 18066.4654 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.4163
env0_second_0:                 episode reward: -0.7000,                 loss: 0.4078
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 1218.05,                last time consumption/overall running time: 186.9808s / 18253.4462 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.4483
env0_second_0:                 episode reward: -2.6000,                 loss: 0.4542
env1_first_0:                 episode reward: 5.3000,                 loss: nan
env1_second_0:                 episode reward: -5.3000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 1187.6,                last time consumption/overall running time: 184.1808s / 18437.6270 s
env0_first_0:                 episode reward: 3.7500,                 loss: 0.4111
env0_second_0:                 episode reward: -3.7500,                 loss: 0.4191
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 1265.1,                last time consumption/overall running time: 190.6406s / 18628.2676 s
env0_first_0:                 episode reward: 5.5500,                 loss: 0.3782
env0_second_0:                 episode reward: -5.5500,                 loss: 0.3856
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 1217.05,                last time consumption/overall running time: 183.0471s / 18811.3146 s
env0_first_0:                 episode reward: 3.8500,                 loss: 0.4004
env0_second_0:                 episode reward: -3.8500,                 loss: 0.4108
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 1278.0,                last time consumption/overall running time: 191.8738s / 19003.1884 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.3774
env0_second_0:                 episode reward: -1.5000,                 loss: 0.3898
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 1204.95,                last time consumption/overall running time: 181.9460s / 19185.1344 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.4582
env0_second_0:                 episode reward: -2.6000,                 loss: 0.4611
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 1236.7,                last time consumption/overall running time: 189.3652s / 19374.4996 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.3855
env0_second_0:                 episode reward: -0.9500,                 loss: 0.3772
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 1083.95,                last time consumption/overall running time: 164.0087s / 19538.5083 s
env0_first_0:                 episode reward: 3.2500,                 loss: 0.4408
env0_second_0:                 episode reward: -3.2500,                 loss: 0.4354
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 1215.7,                last time consumption/overall running time: 183.3485s / 19721.8568 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.3906
env0_second_0:                 episode reward: -1.7000,                 loss: 0.3964
env1_first_0:                 episode reward: 3.9000,                 loss: nan
env1_second_0:                 episode reward: -3.9000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 1240.05,                last time consumption/overall running time: 186.3325s / 19908.1893 s
env0_first_0:                 episode reward: 2.2500,                 loss: 0.4049
env0_second_0:                 episode reward: -2.2500,                 loss: 0.4091
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 1209.95,                last time consumption/overall running time: 186.2713s / 20094.4606 s
env0_first_0:                 episode reward: 2.2500,                 loss: 0.4091
env0_second_0:                 episode reward: -2.2500,                 loss: 0.4106
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 1173.75,                last time consumption/overall running time: 176.9067s / 20271.3673 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.4184
env0_second_0:                 episode reward: -0.2000,                 loss: 0.4260
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 1245.85,                last time consumption/overall running time: 187.0186s / 20458.3859 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.4119
env0_second_0:                 episode reward: -1.6000,                 loss: 0.4093
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 1229.8,                last time consumption/overall running time: 185.6069s / 20643.9928 s
env0_first_0:                 episode reward: 4.1000,                 loss: 0.3930
env0_second_0:                 episode reward: -4.1000,                 loss: 0.4054
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 1223.75,                last time consumption/overall running time: 186.0823s / 20830.0751 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.4212
env0_second_0:                 episode reward: -1.3000,                 loss: 0.4220
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 1208.35,                last time consumption/overall running time: 185.7470s / 21015.8221 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.4588
env0_second_0:                 episode reward: -2.2000,                 loss: 0.4465
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 1153.5,                last time consumption/overall running time: 173.7660s / 21189.5881 s
env0_first_0:                 episode reward: 3.7500,                 loss: 0.4405
env0_second_0:                 episode reward: -3.7500,                 loss: 0.4465
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 1259.9,                last time consumption/overall running time: 193.2618s / 21382.8500 s
env0_first_0:                 episode reward: 3.2500,                 loss: 0.4090
env0_second_0:                 episode reward: -3.2500,                 loss: 0.4152
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 1284.35,                last time consumption/overall running time: 194.5173s / 21577.3672 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.4399
env0_second_0:                 episode reward: -1.5000,                 loss: 0.4461
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 1329.65,                last time consumption/overall running time: 201.6176s / 21778.9849 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.4309
env0_second_0:                 episode reward: -0.6000,                 loss: 0.4385
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 1160.45,                last time consumption/overall running time: 176.6079s / 21955.5928 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3888
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3863
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 1244.55,                last time consumption/overall running time: 189.0222s / 22144.6150 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.3983
env0_second_0:                 episode reward: -2.7000,                 loss: 0.3935
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 1244.55,                last time consumption/overall running time: 189.2242s / 22333.8392 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.4150
env0_second_0:                 episode reward: 1.6500,                 loss: 0.4202
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 1182.35,                last time consumption/overall running time: 179.6280s / 22513.4673 s
env0_first_0:                 episode reward: 5.9000,                 loss: 0.4134
env0_second_0:                 episode reward: -5.9000,                 loss: 0.4223
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 1159.55,                last time consumption/overall running time: 180.2829s / 22693.7501 s
env0_first_0:                 episode reward: 5.7500,                 loss: 0.3998
env0_second_0:                 episode reward: -5.7500,                 loss: 0.3938
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 1082.75,                last time consumption/overall running time: 163.0845s / 22856.8346 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.3648
env0_second_0:                 episode reward: -2.9000,                 loss: 0.3737
env1_first_0:                 episode reward: 6.9000,                 loss: nan
env1_second_0:                 episode reward: -6.9000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 1127.0,                last time consumption/overall running time: 168.4747s / 23025.3094 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.4125
env0_second_0:                 episode reward: 1.1000,                 loss: 0.4160
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 1171.95,                last time consumption/overall running time: 180.3805s / 23205.6898 s
env0_first_0:                 episode reward: 8.3000,                 loss: 0.3892
env0_second_0:                 episode reward: -8.3000,                 loss: 0.4032
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 1255.9,                last time consumption/overall running time: 191.2158s / 23396.9056 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.4327
env0_second_0:                 episode reward: -0.9000,                 loss: 0.4319
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 1264.2,                last time consumption/overall running time: 190.3280s / 23587.2337 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.4037
env0_second_0:                 episode reward: -1.6000,                 loss: 0.4308
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 1127.1,                last time consumption/overall running time: 168.4023s / 23755.6360 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.4026
env0_second_0:                 episode reward: -1.8500,                 loss: 0.4015
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 1186.2,                last time consumption/overall running time: 180.0000s / 23935.6360 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.4039
env0_second_0:                 episode reward: 0.6000,                 loss: 0.4002
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 1196.5,                last time consumption/overall running time: 180.5009s / 24116.1369 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.4337
env0_second_0:                 episode reward: -2.3500,                 loss: 0.4331
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 1164.6,                last time consumption/overall running time: 178.0613s / 24294.1982 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.4128
env0_second_0:                 episode reward: -1.0500,                 loss: 0.4223
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 1259.55,                last time consumption/overall running time: 192.4731s / 24486.6713 s
env0_first_0:                 episode reward: 4.7000,                 loss: 0.4313
env0_second_0:                 episode reward: -4.7000,                 loss: 0.4366
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 1156.9,                last time consumption/overall running time: 175.3887s / 24662.0600 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.4465
env0_second_0:                 episode reward: 0.0500,                 loss: 0.4377
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 1247.75,                last time consumption/overall running time: 186.5943s / 24848.6543 s
env0_first_0:                 episode reward: 2.1500,                 loss: 0.4212
env0_second_0:                 episode reward: -2.1500,                 loss: 0.4221
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 1184.05,                last time consumption/overall running time: 179.0606s / 25027.7150 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.4048
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4001
env1_first_0:                 episode reward: 6.7500,                 loss: nan
env1_second_0:                 episode reward: -6.7500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 1218.8,                last time consumption/overall running time: 186.4279s / 25214.1428 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.3776
env0_second_0:                 episode reward: 3.1000,                 loss: 0.3811
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 1036.6,                last time consumption/overall running time: 160.4099s / 25374.5527 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.3941
env0_second_0:                 episode reward: 1.7000,                 loss: 0.4078
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 1219.65,                last time consumption/overall running time: 179.9430s / 25554.4957 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.4592
env0_second_0:                 episode reward: -2.5000,                 loss: 0.4805
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 1286.3,                last time consumption/overall running time: 190.3325s / 25744.8283 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.3808
env0_second_0:                 episode reward: -0.2000,                 loss: 0.3920
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 1125.2,                last time consumption/overall running time: 171.8306s / 25916.6588 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.4062
env0_second_0:                 episode reward: 0.4500,                 loss: 0.4016
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 1253.8,                last time consumption/overall running time: 190.3434s / 26107.0022 s
env0_first_0:                 episode reward: 3.4000,                 loss: 0.4133
env0_second_0:                 episode reward: -3.4000,                 loss: 0.4284
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 1284.35,                last time consumption/overall running time: 193.1374s / 26300.1397 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3762
env0_second_0:                 episode reward: -0.7000,                 loss: 0.3737
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 1213.0,                last time consumption/overall running time: 185.6213s / 26485.7610 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.4120
env0_second_0:                 episode reward: -1.9000,                 loss: 0.4255
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 1303.9,                last time consumption/overall running time: 195.5441s / 26681.3051 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.4082
env0_second_0:                 episode reward: 1.0000,                 loss: 0.4170
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 1272.1,                last time consumption/overall running time: 190.5490s / 26871.8541 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.4269
env0_second_0:                 episode reward: 1.9000,                 loss: 0.4283
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 1306.35,                last time consumption/overall running time: 196.2809s / 27068.1350 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.4201
env0_second_0:                 episode reward: -2.7500,                 loss: 0.4245
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 1241.5,                last time consumption/overall running time: 185.2659s / 27253.4009 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.3848
env0_second_0:                 episode reward: 1.2500,                 loss: 0.3865
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 1298.25,                last time consumption/overall running time: 198.5843s / 27451.9852 s
env0_first_0:                 episode reward: 4.2500,                 loss: 0.4111
env0_second_0:                 episode reward: -4.2500,                 loss: 0.4181
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 1145.6,                last time consumption/overall running time: 173.0805s / 27625.0656 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.4105
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4264
env1_first_0:                 episode reward: 6.1000,                 loss: nan
env1_second_0:                 episode reward: -6.1000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 1165.65,                last time consumption/overall running time: 174.9902s / 27800.0558 s
env0_first_0:                 episode reward: 7.9500,                 loss: 0.3894
env0_second_0:                 episode reward: -7.9500,                 loss: 0.4063
env1_first_0:                 episode reward: 4.6500,                 loss: nan
env1_second_0:                 episode reward: -4.6500,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 1258.45,                last time consumption/overall running time: 189.8998s / 27989.9556 s
env0_first_0:                 episode reward: 4.3000,                 loss: 0.3676
env0_second_0:                 episode reward: -4.3000,                 loss: 0.3506
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 1153.15,                last time consumption/overall running time: 174.9213s / 28164.8770 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.4033
env0_second_0:                 episode reward: -3.5000,                 loss: 0.4045
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 1190.1,                last time consumption/overall running time: 179.2689s / 28344.1458 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.4542
env0_second_0:                 episode reward: 0.6500,                 loss: 0.4686
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 1225.5,                last time consumption/overall running time: 184.5305s / 28528.6763 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.4042
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3943
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 1204.4,                last time consumption/overall running time: 186.7288s / 28715.4051 s
env0_first_0:                 episode reward: 5.4000,                 loss: 0.4166
env0_second_0:                 episode reward: -5.4000,                 loss: 0.4125
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 1165.4,                last time consumption/overall running time: 175.4573s / 28890.8625 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.4285
env0_second_0:                 episode reward: -1.3500,                 loss: 0.4325
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 1239.4,                last time consumption/overall running time: 187.4347s / 29078.2972 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.4722
env0_second_0:                 episode reward: -3.7000,                 loss: 0.4756
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 1344.4,                last time consumption/overall running time: 199.7248s / 29278.0220 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.3947
env0_second_0:                 episode reward: 0.0500,                 loss: 0.4134
env1_first_0:                 episode reward: 4.5500,                 loss: nan
env1_second_0:                 episode reward: -4.5500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 1268.1,                last time consumption/overall running time: 189.4939s / 29467.5159 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.4231
env0_second_0:                 episode reward: -1.9500,                 loss: 0.4211
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 1221.4,                last time consumption/overall running time: 184.3429s / 29651.8588 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.4535
env0_second_0:                 episode reward: 1.3000,                 loss: 0.4604
env1_first_0:                 episode reward: 3.8000,                 loss: nan
env1_second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 1181.25,                last time consumption/overall running time: 178.9139s / 29830.7727 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.3878
env0_second_0:                 episode reward: -1.4500,                 loss: 0.4038
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 1169.95,                last time consumption/overall running time: 177.5839s / 30008.3567 s
env0_first_0:                 episode reward: 3.1000,                 loss: 0.4011
env0_second_0:                 episode reward: -3.1000,                 loss: 0.3953
env1_first_0:                 episode reward: 7.0000,                 loss: nan
env1_second_0:                 episode reward: -7.0000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 1158.0,                last time consumption/overall running time: 176.3150s / 30184.6717 s
env0_first_0:                 episode reward: 4.9500,                 loss: 0.4120
env0_second_0:                 episode reward: -4.9500,                 loss: 0.4014
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 1173.65,                last time consumption/overall running time: 178.5871s / 30363.2588 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.3997
env0_second_0:                 episode reward: -0.9000,                 loss: 0.3987
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 1294.0,                last time consumption/overall running time: 199.2811s / 30562.5399 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.4072
env0_second_0:                 episode reward: -0.5000,                 loss: 0.4073
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 1190.1,                last time consumption/overall running time: 177.4513s / 30739.9912 s
env0_first_0:                 episode reward: 4.0500,                 loss: 0.3978
env0_second_0:                 episode reward: -4.0500,                 loss: 0.4119
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 1239.65,                last time consumption/overall running time: 185.9911s / 30925.9822 s
env0_first_0:                 episode reward: 4.9000,                 loss: 0.4016
env0_second_0:                 episode reward: -4.9000,                 loss: 0.4017
env1_first_0:                 episode reward: 5.1500,                 loss: nan
env1_second_0:                 episode reward: -5.1500,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 1126.1,                last time consumption/overall running time: 168.8073s / 31094.7895 s
env0_first_0:                 episode reward: 5.9500,                 loss: 0.3973
env0_second_0:                 episode reward: -5.9500,                 loss: 0.4102
env1_first_0:                 episode reward: 6.0500,                 loss: nan
env1_second_0:                 episode reward: -6.0500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 1150.8,                last time consumption/overall running time: 176.1093s / 31270.8988 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.3873
env0_second_0:                 episode reward: -1.7500,                 loss: 0.3978
env1_first_0:                 episode reward: 5.6000,                 loss: nan
env1_second_0:                 episode reward: -5.6000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 1293.4,                last time consumption/overall running time: 191.3323s / 31462.2311 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.3831
env0_second_0:                 episode reward: -2.8500,                 loss: 0.3824
env1_first_0:                 episode reward: 4.9500,                 loss: nan
env1_second_0:                 episode reward: -4.9500,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 1289.9,                last time consumption/overall running time: 196.2949s / 31658.5260 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.3753
env0_second_0:                 episode reward: -2.4500,                 loss: 0.3883
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 1194.2,                last time consumption/overall running time: 179.4454s / 31837.9715 s
env0_first_0:                 episode reward: 4.4000,                 loss: 0.3874
env0_second_0:                 episode reward: -4.4000,                 loss: 0.3961
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 1197.45,                last time consumption/overall running time: 178.6937s / 32016.6652 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.4215
env0_second_0:                 episode reward: 0.7000,                 loss: 0.4289
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 1239.4,                last time consumption/overall running time: 186.1976s / 32202.8628 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.3794
env0_second_0:                 episode reward: -1.2000,                 loss: 0.3841
env1_first_0:                 episode reward: 4.8500,                 loss: nan
env1_second_0:                 episode reward: -4.8500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 1254.55,                last time consumption/overall running time: 191.8095s / 32394.6723 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3645
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3716
env1_first_0:                 episode reward: 2.3000,                 loss: nan
env1_second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 1179.25,                last time consumption/overall running time: 179.6070s / 32574.2793 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.3945
env0_second_0:                 episode reward: -1.3500,                 loss: 0.4121
env1_first_0:                 episode reward: 5.0500,                 loss: nan
env1_second_0:                 episode reward: -5.0500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 1270.4,                last time consumption/overall running time: 189.2711s / 32763.5504 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.3651
env0_second_0:                 episode reward: -2.9000,                 loss: 0.3726
env1_first_0:                 episode reward: 3.8000,                 loss: nan
env1_second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 1270.85,                last time consumption/overall running time: 193.7950s / 32957.3453 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.4052
env0_second_0:                 episode reward: -3.0000,                 loss: 0.3917
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 1194.0,                last time consumption/overall running time: 184.8047s / 33142.1500 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.3662
env0_second_0:                 episode reward: 1.3500,                 loss: 0.3893
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 1191.55,                last time consumption/overall running time: 180.5348s / 33322.6848 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.4279
env0_second_0:                 episode reward: 1.0500,                 loss: 0.4231
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 1245.3,                last time consumption/overall running time: 185.7482s / 33508.4330 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.4114
env0_second_0:                 episode reward: 0.6500,                 loss: 0.4254
env1_first_0:                 episode reward: 3.9000,                 loss: nan
env1_second_0:                 episode reward: -3.9000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 1190.45,                last time consumption/overall running time: 184.3286s / 33692.7617 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.4191
env0_second_0:                 episode reward: 2.4500,                 loss: 0.4157
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 1156.0,                last time consumption/overall running time: 174.9981s / 33867.7598 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.3979
env0_second_0:                 episode reward: -0.4500,                 loss: 0.4116
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 1200.45,                last time consumption/overall running time: 182.1089s / 34049.8686 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.4267
env0_second_0:                 episode reward: 0.8000,                 loss: 0.4302
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 1089.95,                last time consumption/overall running time: 154.2442s / 34204.1128 s
env0_first_0:                 episode reward: -4.9000,                 loss: 0.3995
env0_second_0:                 episode reward: 4.9000,                 loss: 0.4010
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 1232.5,                last time consumption/overall running time: 172.3593s / 34376.4721 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.3815
env0_second_0:                 episode reward: -0.6000,                 loss: 0.4164
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 1212.4,                last time consumption/overall running time: 164.2473s / 34540.7194 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.3618
env0_second_0:                 episode reward: -1.5500,                 loss: 0.3654
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 1173.75,                last time consumption/overall running time: 159.3548s / 34700.0742 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.4595
env0_second_0:                 episode reward: -0.2500,                 loss: 0.4535
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 1206.4,                last time consumption/overall running time: 169.4388s / 34869.5130 s
env0_first_0:                 episode reward: 4.1500,                 loss: 0.4472
env0_second_0:                 episode reward: -4.1500,                 loss: 0.4483
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 1295.45,                last time consumption/overall running time: 176.3549s / 35045.8679 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.3870
env0_second_0:                 episode reward: -3.7000,                 loss: 0.4051
env1_first_0:                 episode reward: 2.3000,                 loss: nan
env1_second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 1235.1,                last time consumption/overall running time: 172.0819s / 35217.9498 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3728
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3618
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 1196.3,                last time consumption/overall running time: 162.2737s / 35380.2234 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.4015
env0_second_0:                 episode reward: -0.4500,                 loss: 0.4044
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 1347.4,                last time consumption/overall running time: 182.1407s / 35562.3641 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.4311
env0_second_0:                 episode reward: 1.0000,                 loss: 0.4262
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 1187.85,                last time consumption/overall running time: 160.5184s / 35722.8826 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.3776
env0_second_0:                 episode reward: -2.5000,                 loss: 0.3724
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 1261.2,                last time consumption/overall running time: 175.8238s / 35898.7064 s
env0_first_0:                 episode reward: 6.2000,                 loss: 0.3676
env0_second_0:                 episode reward: -6.2000,                 loss: 0.3764
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 1245.65,                last time consumption/overall running time: 170.9815s / 36069.6879 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.4182
env0_second_0:                 episode reward: -0.7500,                 loss: 0.4233
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 1188.8,                last time consumption/overall running time: 162.6537s / 36232.3416 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.3891
env0_second_0:                 episode reward: -0.8000,                 loss: 0.3817
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 1197.95,                last time consumption/overall running time: 173.2335s / 36405.5751 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.4041
env0_second_0:                 episode reward: -0.1500,                 loss: 0.4106
env1_first_0:                 episode reward: 3.7000,                 loss: nan
env1_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 1194.05,                last time consumption/overall running time: 167.2034s / 36572.7785 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.3659
env0_second_0:                 episode reward: 3.0500,                 loss: 0.3926
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 1143.2,                last time consumption/overall running time: 151.4615s / 36724.2400 s
env0_first_0:                 episode reward: 4.4500,                 loss: 0.4212
env0_second_0:                 episode reward: -4.4500,                 loss: 0.4208
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 1303.15,                last time consumption/overall running time: 175.0612s / 36899.3012 s
env0_first_0:                 episode reward: 3.9000,                 loss: 0.3750
env0_second_0:                 episode reward: -3.9000,                 loss: 0.3804
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 1251.4,                last time consumption/overall running time: 165.3993s / 37064.7005 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.3831
env0_second_0:                 episode reward: -2.0000,                 loss: 0.3792
env1_first_0:                 episode reward: 1.9000,                 loss: nan
env1_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 1251.6,                last time consumption/overall running time: 163.8630s / 37228.5635 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.3773
env0_second_0:                 episode reward: -3.0000,                 loss: 0.3862
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 1261.7,                last time consumption/overall running time: 182.2820s / 37410.8455 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.3697
env0_second_0:                 episode reward: -1.3500,                 loss: 0.3586
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 1145.85,                last time consumption/overall running time: 157.5889s / 37568.4344 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.4010
env0_second_0:                 episode reward: -2.5000,                 loss: 0.4129
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 1226.15,                last time consumption/overall running time: 165.0384s / 37733.4729 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.3653
env0_second_0:                 episode reward: 0.5000,                 loss: 0.3756
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 1248.55,                last time consumption/overall running time: 161.4027s / 37894.8756 s
env0_first_0:                 episode reward: 5.6000,                 loss: 0.3994
env0_second_0:                 episode reward: -5.6000,                 loss: 0.4070
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 1137.6,                last time consumption/overall running time: 165.7699s / 38060.6455 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.3856
env0_second_0:                 episode reward: -1.6500,                 loss: 0.3946
env1_first_0:                 episode reward: 5.6500,                 loss: nan
env1_second_0:                 episode reward: -5.6500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 1233.4,                last time consumption/overall running time: 169.1547s / 38229.8002 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.4521
env0_second_0:                 episode reward: -1.5500,                 loss: 0.4303
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 1152.1,                last time consumption/overall running time: 160.0239s / 38389.8241 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.4053
env0_second_0:                 episode reward: -1.2000,                 loss: 0.4054
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 1201.7,                last time consumption/overall running time: 173.7512s / 38563.5752 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.4193
env0_second_0:                 episode reward: -1.4000,                 loss: 0.4256
env1_first_0:                 episode reward: 6.1000,                 loss: nan
env1_second_0:                 episode reward: -6.1000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 1276.0,                last time consumption/overall running time: 174.4844s / 38738.0597 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.4220
env0_second_0:                 episode reward: 2.4500,                 loss: 0.3879
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 1206.75,                last time consumption/overall running time: 163.0310s / 38901.0906 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3858
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3827
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 1212.4,                last time consumption/overall running time: 164.4609s / 39065.5515 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.3926
env0_second_0:                 episode reward: -3.2000,                 loss: 0.3950
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 1267.45,                last time consumption/overall running time: 173.3396s / 39238.8911 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.3989
env0_second_0:                 episode reward: -3.3000,                 loss: 0.4179
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 1237.4,                last time consumption/overall running time: 162.4822s / 39401.3734 s
env0_first_0:                 episode reward: 1.7500,                 loss: 0.3828
env0_second_0:                 episode reward: -1.7500,                 loss: 0.4000
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 1275.4,                last time consumption/overall running time: 167.8206s / 39569.1940 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.3711
env0_second_0:                 episode reward: -1.6500,                 loss: 0.3816
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 1190.6,                last time consumption/overall running time: 164.1292s / 39733.3232 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.3977
env0_second_0:                 episode reward: 3.1000,                 loss: 0.3968
env1_first_0:                 episode reward: 2.3000,                 loss: nan
env1_second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 1245.95,                last time consumption/overall running time: 170.4598s / 39903.7830 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.3894
env0_second_0:                 episode reward: -2.9000,                 loss: 0.3954
env1_first_0:                 episode reward: 5.3000,                 loss: nan
env1_second_0:                 episode reward: -5.3000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 1203.05,                last time consumption/overall running time: 163.7142s / 40067.4972 s
env0_first_0:                 episode reward: 3.2000,                 loss: 0.3716
env0_second_0:                 episode reward: -3.2000,                 loss: 0.3857
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 1310.5,                last time consumption/overall running time: 181.7469s / 40249.2440 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.4114
env0_second_0:                 episode reward: 2.6500,                 loss: 0.4025
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 1196.85,                last time consumption/overall running time: 159.5643s / 40408.8084 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.4008
env0_second_0:                 episode reward: 1.4000,                 loss: 0.4127
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 1147.75,                last time consumption/overall running time: 154.9807s / 40563.7891 s
env0_first_0:                 episode reward: 5.7000,                 loss: 0.3735
env0_second_0:                 episode reward: -5.7000,                 loss: 0.3663
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 1190.2,                last time consumption/overall running time: 157.7924s / 40721.5815 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.4254
env0_second_0:                 episode reward: -0.7000,                 loss: 0.4245
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 1221.3,                last time consumption/overall running time: 168.6375s / 40890.2189 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.3947
env0_second_0:                 episode reward: -0.9000,                 loss: 0.3912
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 1171.65,                last time consumption/overall running time: 168.4377s / 41058.6567 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.4084
env0_second_0:                 episode reward: -0.4500,                 loss: 0.4009
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 1275.95,                last time consumption/overall running time: 172.0347s / 41230.6914 s
env0_first_0:                 episode reward: 3.3500,                 loss: 0.4021
env0_second_0:                 episode reward: -3.3500,                 loss: 0.3954
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 1201.45,                last time consumption/overall running time: 164.5298s / 41395.2212 s
env0_first_0:                 episode reward: 5.2000,                 loss: 0.4144
env0_second_0:                 episode reward: -5.2000,                 loss: 0.4029
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 1190.0,                last time consumption/overall running time: 154.2029s / 41549.4241 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.4081
env0_second_0:                 episode reward: -0.1000,                 loss: 0.4242
env1_first_0:                 episode reward: 6.3000,                 loss: nan
env1_second_0:                 episode reward: -6.3000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 1232.35,                last time consumption/overall running time: 170.1050s / 41719.5291 s
env0_first_0:                 episode reward: 5.7000,                 loss: 0.3584
env0_second_0:                 episode reward: -5.7000,                 loss: 0.3569
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 1220.6,                last time consumption/overall running time: 169.9267s / 41889.4558 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.3759
env0_second_0:                 episode reward: -1.5000,                 loss: 0.3715
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 1189.9,                last time consumption/overall running time: 159.3902s / 42048.8460 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.4445
env0_second_0:                 episode reward: -2.0500,                 loss: 0.4565
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 1246.95,                last time consumption/overall running time: 165.0864s / 42213.9323 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.3892
env0_second_0:                 episode reward: -3.6000,                 loss: 0.4091
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 1210.0,                last time consumption/overall running time: 164.7309s / 42378.6633 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.4071
env0_second_0:                 episode reward: 1.1500,                 loss: 0.4072
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 1303.5,                last time consumption/overall running time: 177.7244s / 42556.3877 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.3836
env0_second_0:                 episode reward: -1.8000,                 loss: 0.4003
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 1252.75,                last time consumption/overall running time: 176.8140s / 42733.2016 s
env0_first_0:                 episode reward: 4.9000,                 loss: 0.4026
env0_second_0:                 episode reward: -4.9000,                 loss: 0.4093
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 1200.3,                last time consumption/overall running time: 163.7578s / 42896.9594 s
env0_first_0:                 episode reward: 4.3500,                 loss: 0.3935
env0_second_0:                 episode reward: -4.3500,                 loss: 0.3976
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 1134.3,                last time consumption/overall running time: 153.8130s / 43050.7724 s
env0_first_0:                 episode reward: 5.0000,                 loss: 0.3829
env0_second_0:                 episode reward: -5.0000,                 loss: 0.3746
env1_first_0:                 episode reward: 4.5000,                 loss: nan
env1_second_0:                 episode reward: -4.5000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 1261.0,                last time consumption/overall running time: 172.8366s / 43223.6091 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.3784
env0_second_0:                 episode reward: 1.3000,                 loss: 0.3751
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 1291.85,                last time consumption/overall running time: 170.6206s / 43394.2297 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.4120
env0_second_0:                 episode reward: -1.9500,                 loss: 0.4277
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 1204.05,                last time consumption/overall running time: 165.1507s / 43559.3804 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.4095
env0_second_0:                 episode reward: -3.5500,                 loss: 0.4113
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 1115.5,                last time consumption/overall running time: 150.0640s / 43709.4444 s
env0_first_0:                 episode reward: 6.1000,                 loss: 0.3381
env0_second_0:                 episode reward: -6.1000,                 loss: 0.3657
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 1335.5,                last time consumption/overall running time: 180.3673s / 43889.8117 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.3927
env0_second_0:                 episode reward: 1.6500,                 loss: 0.3785
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 1194.7,                last time consumption/overall running time: 164.5931s / 44054.4047 s
env0_first_0:                 episode reward: 5.3000,                 loss: 0.4171
env0_second_0:                 episode reward: -5.3000,                 loss: 0.4021
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 1215.25,                last time consumption/overall running time: 161.5843s / 44215.9891 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.4148
env0_second_0:                 episode reward: 0.8500,                 loss: 0.4182
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 1158.5,                last time consumption/overall running time: 167.2783s / 44383.2674 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.3873
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3941
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 1223.95,                last time consumption/overall running time: 168.9403s / 44552.2077 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.4367
env0_second_0:                 episode reward: -1.4500,                 loss: 0.4428
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 1133.45,                last time consumption/overall running time: 154.9767s / 44707.1844 s
env0_first_0:                 episode reward: 5.2500,                 loss: 0.4126
env0_second_0:                 episode reward: -5.2500,                 loss: 0.4004
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 1243.25,                last time consumption/overall running time: 165.5261s / 44872.7105 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.3937
env0_second_0:                 episode reward: -0.5500,                 loss: 0.3806
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 1261.0,                last time consumption/overall running time: 180.5528s / 45053.2633 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.3927
env0_second_0:                 episode reward: 2.2500,                 loss: 0.3817
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 1244.3,                last time consumption/overall running time: 172.1438s / 45225.4071 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.4102
env0_second_0:                 episode reward: -1.3500,                 loss: 0.4122
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 1241.9,                last time consumption/overall running time: 170.9278s / 45396.3350 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.4297
env0_second_0:                 episode reward: -1.3000,                 loss: 0.4432
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 1261.2,                last time consumption/overall running time: 178.0016s / 45574.3366 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.3732
env0_second_0:                 episode reward: 1.6500,                 loss: 0.3771
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 1245.25,                last time consumption/overall running time: 164.8226s / 45739.1591 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.4112
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4070
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 1208.2,                last time consumption/overall running time: 163.7059s / 45902.8651 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.4501
env0_second_0:                 episode reward: 2.8500,                 loss: 0.4450
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 1218.0,                last time consumption/overall running time: 165.0604s / 46067.9254 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.4036
env0_second_0:                 episode reward: -2.7500,                 loss: 0.3881
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 1228.45,                last time consumption/overall running time: 170.3592s / 46238.2847 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.3888
env0_second_0:                 episode reward: -1.6500,                 loss: 0.4062
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 1191.3,                last time consumption/overall running time: 158.2005s / 46396.4852 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.3446
env0_second_0:                 episode reward: 0.4500,                 loss: 0.3416
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 1249.4,                last time consumption/overall running time: 171.0304s / 46567.5156 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.4033
env0_second_0:                 episode reward: -3.3000,                 loss: 0.4117
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 1246.5,                last time consumption/overall running time: 187.3638s / 46754.8793 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.4058
env0_second_0:                 episode reward: -3.5500,                 loss: 0.3896
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 1264.2,                last time consumption/overall running time: 167.1022s / 46921.9816 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.4031
env0_second_0:                 episode reward: -1.5500,                 loss: 0.4083
env1_first_0:                 episode reward: 3.3500,                 loss: nan
env1_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 1249.65,                last time consumption/overall running time: 167.2288s / 47089.2104 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.3634
env0_second_0:                 episode reward: 1.7500,                 loss: 0.3603
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 1249.8,                last time consumption/overall running time: 167.5879s / 47256.7983 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.4558
env0_second_0:                 episode reward: 2.2500,                 loss: 0.4599
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 1242.6,                last time consumption/overall running time: 163.6713s / 47420.4696 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.3993
env0_second_0:                 episode reward: 1.5500,                 loss: 0.4096
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 1124.3,                last time consumption/overall running time: 156.7041s / 47577.1737 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.3933
env0_second_0:                 episode reward: -2.5500,                 loss: 0.4021
env1_first_0:                 episode reward: 3.6500,                 loss: nan
env1_second_0:                 episode reward: -3.6500,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 1243.15,                last time consumption/overall running time: 171.2261s / 47748.3998 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.3751
env0_second_0:                 episode reward: -3.0500,                 loss: 0.3730
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 1228.85,                last time consumption/overall running time: 178.7785s / 47927.1783 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.4303