pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [85, 42]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 2, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'batch_size': 32, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220114_0533/slimevolley_SlimeVolley-v0_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220114_0533/slimevolley_SlimeVolley-v0_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 630.0,                last time consumption/overall running time: 4.8801s / 4.8801 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0115
env0_second_0:                 episode reward: 2.0000,                 loss: -0.0115
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 559.1,                last time consumption/overall running time: 65.8767s / 70.7567 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0104
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 533.7,                last time consumption/overall running time: 63.2551s / 134.0118 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.1473
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1458
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 591.7,                last time consumption/overall running time: 69.4837s / 203.4955 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.1862
env0_second_0:                 episode reward: -0.5500,                 loss: 0.1799
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 569.45,                last time consumption/overall running time: 67.5142s / 271.0098 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.1998
env0_second_0:                 episode reward: -0.1000,                 loss: 0.1898
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 565.05,                last time consumption/overall running time: 66.8771s / 337.8869 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.1966
env0_second_0:                 episode reward: -0.7500,                 loss: 0.1897
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 569.1,                last time consumption/overall running time: 66.4975s / 404.3844 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.1830
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1737
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 547.7,                last time consumption/overall running time: 64.7415s / 469.1259 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.1937
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1877
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 529.25,                last time consumption/overall running time: 62.9233s / 532.0492 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.1895
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1899
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 558.55,                last time consumption/overall running time: 64.7815s / 596.8307 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.1759
env0_second_0:                 episode reward: 1.3000,                 loss: 0.1692
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 564.95,                last time consumption/overall running time: 66.7364s / 663.5671 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2236
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2144
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 626.2,                last time consumption/overall running time: 72.9488s / 736.5159 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2068
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1964
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 591.9,                last time consumption/overall running time: 70.0506s / 806.5665 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.1877
env0_second_0:                 episode reward: -0.3500,                 loss: 0.1897
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 579.2,                last time consumption/overall running time: 69.0840s / 875.6505 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2100
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2076
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 578.7,                last time consumption/overall running time: 68.6899s / 944.3404 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2172
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2310
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 553.95,                last time consumption/overall running time: 65.3005s / 1009.6409 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.1816
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1899
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 530.8,                last time consumption/overall running time: 64.4947s / 1074.1356 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2400
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2472
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 556.8,                last time consumption/overall running time: 66.5428s / 1140.6784 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2267
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2304
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 542.25,                last time consumption/overall running time: 64.3593s / 1205.0376 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2183
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2298
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 569.55,                last time consumption/overall running time: 67.6250s / 1272.6626 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2071
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2147
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 581.6,                last time consumption/overall running time: 69.2073s / 1341.8699 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2145
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2110
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 554.8,                last time consumption/overall running time: 66.4157s / 1408.2856 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2112
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2129
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 572.35,                last time consumption/overall running time: 67.7072s / 1475.9928 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2267
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2337
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 573.7,                last time consumption/overall running time: 68.5890s / 1544.5818 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2440
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2452
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 581.65,                last time consumption/overall running time: 69.5404s / 1614.1222 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2497
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2508
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 540.35,                last time consumption/overall running time: 65.2238s / 1679.3460 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2052
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2035
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 547.9,                last time consumption/overall running time: 65.5749s / 1744.9209 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2305
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2323
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 607.4,                last time consumption/overall running time: 71.1218s / 1816.0427 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2539
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2616
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 558.1,                last time consumption/overall running time: 66.1406s / 1882.1833 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2314
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2377
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 629.65,                last time consumption/overall running time: 73.4756s / 1955.6589 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2428
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2480
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 595.35,                last time consumption/overall running time: 70.6495s / 2026.3084 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2408
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2443
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 586.75,                last time consumption/overall running time: 69.8011s / 2096.1095 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2270
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2258
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 589.6,                last time consumption/overall running time: 69.6517s / 2165.7612 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2402
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2381
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 561.65,                last time consumption/overall running time: 67.3678s / 2233.1290 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2472
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2451
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 544.3,                last time consumption/overall running time: 65.2891s / 2298.4182 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2336
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2343
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 525.8,                last time consumption/overall running time: 62.7496s / 2361.1678 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2364
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2201
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 606.75,                last time consumption/overall running time: 71.2062s / 2432.3740 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2106
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2136
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 576.2,                last time consumption/overall running time: 67.4091s / 2499.7831 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2129
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2084
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 594.15,                last time consumption/overall running time: 70.2967s / 2570.0797 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2409
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2432
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 581.6,                last time consumption/overall running time: 68.7730s / 2638.8527 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2194
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2190
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 544.25,                last time consumption/overall running time: 64.7145s / 2703.5673 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2433
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2353
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 596.7,                last time consumption/overall running time: 70.4561s / 2774.0234 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2555
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2501
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 575.05,                last time consumption/overall running time: 68.3984s / 2842.4218 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2430
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2366
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 572.85,                last time consumption/overall running time: 68.2407s / 2910.6625 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2595
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2625
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 591.75,                last time consumption/overall running time: 70.2909s / 2980.9534 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2524
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2434
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 573.8,                last time consumption/overall running time: 68.5725s / 3049.5259 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2594
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2543
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 526.75,                last time consumption/overall running time: 62.9555s / 3112.4814 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2744
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2680
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 577.65,                last time consumption/overall running time: 68.7891s / 3181.2705 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2294
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2266
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 571.1,                last time consumption/overall running time: 68.0881s / 3249.3586 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2364
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2266
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 584.05,                last time consumption/overall running time: 69.5253s / 3318.8839 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2328
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2322
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 566.15,                last time consumption/overall running time: 67.1524s / 3386.0363 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2720
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2674
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 595.65,                last time consumption/overall running time: 69.9527s / 3455.9890 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2313
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2305
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 590.25,                last time consumption/overall running time: 70.1910s / 3526.1800 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2281
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2246
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 592.3,                last time consumption/overall running time: 70.6076s / 3596.7876 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2432
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2447
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 545.1,                last time consumption/overall running time: 64.9697s / 3661.7573 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2440
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2420
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 508.35,                last time consumption/overall running time: 61.0337s / 3722.7910 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2595
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2561
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 599.4,                last time consumption/overall running time: 72.0933s / 3794.8843 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2300
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2314
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 564.15,                last time consumption/overall running time: 67.3305s / 3862.2148 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2456
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2417
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 557.85,                last time consumption/overall running time: 66.8227s / 3929.0376 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.2361
env0_second_0:                 episode reward: -1.2500,                 loss: 0.2334
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 538.0,                last time consumption/overall running time: 65.2345s / 3994.2721 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2643
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2628
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 577.5,                last time consumption/overall running time: 69.6403s / 4063.9124 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2667
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2579
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 595.1,                last time consumption/overall running time: 70.4866s / 4134.3990 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2457
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2419
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 571.15,                last time consumption/overall running time: 68.0451s / 4202.4442 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2794
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2695
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 562.85,                last time consumption/overall running time: 67.2939s / 4269.7381 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2344
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2350
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 588.1,                last time consumption/overall running time: 69.9894s / 4339.7275 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2756
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2749
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 551.9,                last time consumption/overall running time: 65.9408s / 4405.6683 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.2524
env0_second_0:                 episode reward: 1.3000,                 loss: 0.2572
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 548.7,                last time consumption/overall running time: 65.6617s / 4471.3300 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2261
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2331
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 552.2,                last time consumption/overall running time: 65.7533s / 4537.0832 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2261
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2298
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 563.05,                last time consumption/overall running time: 67.3699s / 4604.4532 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2518
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2557
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 579.45,                last time consumption/overall running time: 68.7758s / 4673.2289 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2599
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2525
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 582.0,                last time consumption/overall running time: 69.7621s / 4742.9911 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2516
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2450
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 558.0,                last time consumption/overall running time: 67.0679s / 4810.0589 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2327
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2301
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 574.0,                last time consumption/overall running time: 68.5217s / 4878.5806 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2559
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2466
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 599.85,                last time consumption/overall running time: 70.6185s / 4949.1992 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2579
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2543
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 555.75,                last time consumption/overall running time: 66.5542s / 5015.7534 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2662
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2687
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 600.2,                last time consumption/overall running time: 71.5211s / 5087.2745 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2505
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2473
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 571.5,                last time consumption/overall running time: 68.4222s / 5155.6967 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2633
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2605
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 601.45,                last time consumption/overall running time: 71.7552s / 5227.4519 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2538
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2507
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 584.1,                last time consumption/overall running time: 68.8507s / 5296.3026 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2394
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2340
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 594.15,                last time consumption/overall running time: 69.8958s / 5366.1984 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2419
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2480
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 546.55,                last time consumption/overall running time: 66.3363s / 5432.5348 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2748
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2730
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 617.65,                last time consumption/overall running time: 73.4850s / 5506.0197 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2586
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2507
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 574.65,                last time consumption/overall running time: 68.3632s / 5574.3829 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2625
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2639
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 543.75,                last time consumption/overall running time: 65.1771s / 5639.5600 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2423
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2384
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 603.55,                last time consumption/overall running time: 71.9428s / 5711.5028 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2520
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2599
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 572.5,                last time consumption/overall running time: 68.4405s / 5779.9433 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2334
env0_second_0:                 episode reward: 1.2500,                 loss: 0.2283
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 601.85,                last time consumption/overall running time: 71.1552s / 5851.0985 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2762
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2697
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 557.4,                last time consumption/overall running time: 67.6826s / 5918.7811 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2655
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2588
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 572.6,                last time consumption/overall running time: 68.0890s / 5986.8701 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2635
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2585
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 611.75,                last time consumption/overall running time: 73.1736s / 6060.0437 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2548
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2543
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 587.0,                last time consumption/overall running time: 69.9224s / 6129.9661 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2480
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2465
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 560.85,                last time consumption/overall running time: 66.8323s / 6196.7984 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2311
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2362
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 562.5,                last time consumption/overall running time: 67.2774s / 6264.0758 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2749
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2845
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 568.3,                last time consumption/overall running time: 68.3668s / 6332.4426 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2470
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2399
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 571.5,                last time consumption/overall running time: 67.9346s / 6400.3772 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2624
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2597
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 580.8,                last time consumption/overall running time: 69.4139s / 6469.7911 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2491
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2500
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 611.95,                last time consumption/overall running time: 72.3626s / 6542.1537 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2560
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2527
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 564.55,                last time consumption/overall running time: 68.1329s / 6610.2866 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2779
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2728
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 557.4,                last time consumption/overall running time: 67.0515s / 6677.3381 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2656
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2683
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 566.6,                last time consumption/overall running time: 66.9840s / 6744.3221 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2632
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2699
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 593.65,                last time consumption/overall running time: 70.7720s / 6815.0941 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2607
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2588
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 586.0,                last time consumption/overall running time: 69.4808s / 6884.5748 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2559
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2430
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 560.6,                last time consumption/overall running time: 67.6667s / 6952.2415 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2580
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2581
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 572.85,                last time consumption/overall running time: 68.6725s / 7020.9140 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2719
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2719
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 575.35,                last time consumption/overall running time: 68.3397s / 7089.2537 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2628
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2635
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 578.65,                last time consumption/overall running time: 68.2819s / 7157.5356 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2716
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2702
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 533.05,                last time consumption/overall running time: 64.6286s / 7222.1642 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2629
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2691
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 562.55,                last time consumption/overall running time: 68.4660s / 7290.6301 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.2533
env0_second_0:                 episode reward: 1.4000,                 loss: 0.2664
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 573.1,                last time consumption/overall running time: 68.5597s / 7359.1898 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2719
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2776
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 522.9,                last time consumption/overall running time: 62.6212s / 7421.8110 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2591
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2589
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 560.45,                last time consumption/overall running time: 66.9026s / 7488.7136 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2648
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2662
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 561.5,                last time consumption/overall running time: 67.5904s / 7556.3041 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2564
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2638
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 572.1,                last time consumption/overall running time: 68.0258s / 7624.3298 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2583
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2587
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 566.15,                last time consumption/overall running time: 67.7332s / 7692.0630 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2475
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2518
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 548.4,                last time consumption/overall running time: 66.3277s / 7758.3908 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2832
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2863
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 518.95,                last time consumption/overall running time: 61.7388s / 7820.1296 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2733
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2826
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 535.6,                last time consumption/overall running time: 65.1586s / 7885.2882 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2522
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2495
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 581.05,                last time consumption/overall running time: 68.6951s / 7953.9833 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2683
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2623
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 560.4,                last time consumption/overall running time: 67.3549s / 8021.3382 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2529
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2589
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 574.05,                last time consumption/overall running time: 68.4532s / 8089.7913 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2728
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2671
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 589.95,                last time consumption/overall running time: 70.1321s / 8159.9235 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2543
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2476
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 597.35,                last time consumption/overall running time: 71.1551s / 8231.0785 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2534
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2587
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 588.45,                last time consumption/overall running time: 69.6878s / 8300.7663 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2530
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2466
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 581.15,                last time consumption/overall running time: 69.4148s / 8370.1811 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2491
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2504
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 553.15,                last time consumption/overall running time: 66.4006s / 8436.5817 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2780
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2716
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 550.25,                last time consumption/overall running time: 65.5876s / 8502.1693 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2566
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2632
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 565.5,                last time consumption/overall running time: 67.3522s / 8569.5215 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2679
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2550
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 579.55,                last time consumption/overall running time: 68.9531s / 8638.4746 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2668
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2624
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 567.4,                last time consumption/overall running time: 67.7318s / 8706.2064 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.2274
env0_second_0:                 episode reward: -1.1500,                 loss: 0.2276
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 557.3,                last time consumption/overall running time: 66.4906s / 8772.6970 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2866
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2839
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 555.5,                last time consumption/overall running time: 66.8126s / 8839.5096 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2654
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2658
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 586.65,                last time consumption/overall running time: 69.9579s / 8909.4674 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2340
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2342
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 602.3,                last time consumption/overall running time: 71.7850s / 8981.2524 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2592
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2625
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 596.25,                last time consumption/overall running time: 71.4659s / 9052.7183 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2508
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2535
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 548.15,                last time consumption/overall running time: 65.6648s / 9118.3831 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2635
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2636
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 597.15,                last time consumption/overall running time: 71.8110s / 9190.1941 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2646
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2550
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 555.6,                last time consumption/overall running time: 67.2105s / 9257.4046 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2595
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2645
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 596.35,                last time consumption/overall running time: 71.5823s / 9328.9869 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2846
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2830
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 573.6,                last time consumption/overall running time: 67.7048s / 9396.6917 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2737
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2752
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 605.25,                last time consumption/overall running time: 70.9950s / 9467.6866 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2837
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2781
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 580.95,                last time consumption/overall running time: 69.2089s / 9536.8955 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2539
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2416
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 562.8,                last time consumption/overall running time: 68.0130s / 9604.9086 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2290
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2196
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 536.5,                last time consumption/overall running time: 64.4138s / 9669.3224 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2625
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2519
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 553.75,                last time consumption/overall running time: 66.4467s / 9735.7691 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2854
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2901
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 619.8,                last time consumption/overall running time: 73.4821s / 9809.2511 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2449
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2452
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 594.2,                last time consumption/overall running time: 70.4143s / 9879.6654 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2463
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2474
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 576.25,                last time consumption/overall running time: 68.5946s / 9948.2600 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2634
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2679
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 566.2,                last time consumption/overall running time: 68.4029s / 10016.6629 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2630
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2678
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 581.2,                last time consumption/overall running time: 69.2638s / 10085.9268 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2374
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2409
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 582.8,                last time consumption/overall running time: 69.6719s / 10155.5987 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2563
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2589
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 570.95,                last time consumption/overall running time: 68.4202s / 10224.0189 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2570
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2532
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 564.7,                last time consumption/overall running time: 67.5121s / 10291.5310 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2624
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2703
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 556.15,                last time consumption/overall running time: 67.0241s / 10358.5551 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2694
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2684
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 621.9,                last time consumption/overall running time: 73.5360s / 10432.0911 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2669
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2664
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 545.9,                last time consumption/overall running time: 65.0150s / 10497.1061 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2366
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2413
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 520.35,                last time consumption/overall running time: 62.9284s / 10560.0345 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2441
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2451
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 552.4,                last time consumption/overall running time: 65.8720s / 10625.9065 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2643
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2641
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 603.55,                last time consumption/overall running time: 72.1196s / 10698.0262 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2575
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2670
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 579.7,                last time consumption/overall running time: 69.2351s / 10767.2613 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2658
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2690
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 594.3,                last time consumption/overall running time: 70.6355s / 10837.8968 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2562
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2619
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 573.25,                last time consumption/overall running time: 68.2621s / 10906.1589 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2660
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2681
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 568.95,                last time consumption/overall running time: 69.4049s / 10975.5638 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2408
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2395
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 547.1,                last time consumption/overall running time: 66.2882s / 11041.8520 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2588
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2639
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 571.05,                last time consumption/overall running time: 67.7589s / 11109.6109 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2540
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2515
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 534.3,                last time consumption/overall running time: 64.4492s / 11174.0601 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2411
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2483
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 585.3,                last time consumption/overall running time: 69.5509s / 11243.6110 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2661
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2648
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 564.15,                last time consumption/overall running time: 67.9867s / 11311.5977 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2450
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2440
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 588.0,                last time consumption/overall running time: 69.8178s / 11381.4155 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2616
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2613
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 562.35,                last time consumption/overall running time: 67.4075s / 11448.8230 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2701
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2740
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 582.9,                last time consumption/overall running time: 68.9794s / 11517.8025 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2635
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2666
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 583.75,                last time consumption/overall running time: 70.0594s / 11587.8619 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2566
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2508
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 578.45,                last time consumption/overall running time: 68.5528s / 11656.4148 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2558
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2575
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 584.55,                last time consumption/overall running time: 69.3664s / 11725.7812 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2592
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2629
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 555.3,                last time consumption/overall running time: 66.9845s / 11792.7656 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2568
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2555
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 547.85,                last time consumption/overall running time: 65.9600s / 11858.7257 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2527
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2600
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 576.5,                last time consumption/overall running time: 68.6300s / 11927.3557 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2461
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2581
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 583.8,                last time consumption/overall running time: 70.1729s / 11997.5285 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2310
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2237
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 582.25,                last time consumption/overall running time: 69.7346s / 12067.2631 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2680
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2585
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 600.5,                last time consumption/overall running time: 71.0562s / 12138.3194 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2303
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2393
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 569.3,                last time consumption/overall running time: 67.8943s / 12206.2137 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2648
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2687
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 593.0,                last time consumption/overall running time: 71.8305s / 12278.0442 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2616
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2687
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 554.45,                last time consumption/overall running time: 67.1882s / 12345.2325 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2499
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2515
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 582.7,                last time consumption/overall running time: 68.2070s / 12413.4394 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2554
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2664
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 521.45,                last time consumption/overall running time: 62.9527s / 12476.3921 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2589
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2711
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 587.45,                last time consumption/overall running time: 70.6248s / 12547.0169 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2567
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2663
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 560.05,                last time consumption/overall running time: 66.5167s / 12613.5336 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2704
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2687
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 567.5,                last time consumption/overall running time: 67.0000s / 12680.5336 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2423
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2565
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 597.35,                last time consumption/overall running time: 71.0158s / 12751.5494 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2710
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2773
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 584.85,                last time consumption/overall running time: 70.0980s / 12821.6475 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2603
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2657
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 556.45,                last time consumption/overall running time: 67.0816s / 12888.7290 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2342
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2508
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 583.85,                last time consumption/overall running time: 69.1241s / 12957.8531 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2531
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2494
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 565.15,                last time consumption/overall running time: 67.5392s / 13025.3923 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2571
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2566
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 611.25,                last time consumption/overall running time: 72.4029s / 13097.7951 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2594
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2623
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 550.1,                last time consumption/overall running time: 65.6518s / 13163.4469 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2406
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2424
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 549.1,                last time consumption/overall running time: 65.5963s / 13229.0432 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2776
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2715
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 560.2,                last time consumption/overall running time: 68.1379s / 13297.1811 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2738
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2819
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 584.4,                last time consumption/overall running time: 70.2248s / 13367.4059 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2618
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2708
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 556.75,                last time consumption/overall running time: 66.8615s / 13434.2674 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2703
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2705
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 553.75,                last time consumption/overall running time: 66.3736s / 13500.6410 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.2682
env0_second_0:                 episode reward: 1.7000,                 loss: 0.2712
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 592.65,                last time consumption/overall running time: 70.6167s / 13571.2577 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2502
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2484
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 541.55,                last time consumption/overall running time: 65.1068s / 13636.3645 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2667
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2608
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 569.2,                last time consumption/overall running time: 68.3970s / 13704.7615 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2571
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2556
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 536.95,                last time consumption/overall running time: 64.1353s / 13768.8969 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2529
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2520
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 574.55,                last time consumption/overall running time: 68.1391s / 13837.0360 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2573
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2649
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 583.75,                last time consumption/overall running time: 69.6369s / 13906.6729 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2353
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2541
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 593.2,                last time consumption/overall running time: 70.9575s / 13977.6304 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2501
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2571
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 576.85,                last time consumption/overall running time: 69.7718s / 14047.4022 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2331
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2344
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 595.55,                last time consumption/overall running time: 71.0261s / 14118.4283 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2762
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2815
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 589.4,                last time consumption/overall running time: 69.4833s / 14187.9116 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2602
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2597
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 556.2,                last time consumption/overall running time: 67.2138s / 14255.1254 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2811
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2784
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 593.8,                last time consumption/overall running time: 71.5263s / 14326.6517 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2511
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2640
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 558.85,                last time consumption/overall running time: 67.3216s / 14393.9733 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2351
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2370
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 547.6,                last time consumption/overall running time: 65.0353s / 14459.0086 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2659
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2705
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 550.45,                last time consumption/overall running time: 65.4796s / 14524.4882 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2355
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2453
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 592.25,                last time consumption/overall running time: 70.6592s / 14595.1475 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2671
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2686
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 593.95,                last time consumption/overall running time: 70.7051s / 14665.8526 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2603
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2636
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 616.5,                last time consumption/overall running time: 72.0002s / 14737.8529 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2784
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2800
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 599.45,                last time consumption/overall running time: 70.6425s / 14808.4954 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2746
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2858
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 575.25,                last time consumption/overall running time: 68.3321s / 14876.8275 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2565
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2613
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 594.55,                last time consumption/overall running time: 71.2597s / 14948.0872 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2669
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2722
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 601.05,                last time consumption/overall running time: 70.8723s / 15018.9594 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2378
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2401
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 511.05,                last time consumption/overall running time: 61.8769s / 15080.8363 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2488
env0_second_0:                 episode reward: 1.2000,                 loss: 0.2549
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 551.6,                last time consumption/overall running time: 65.2878s / 15146.1241 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2417
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2492
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 537.45,                last time consumption/overall running time: 65.4399s / 15211.5640 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2438
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2447
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 558.9,                last time consumption/overall running time: 66.9682s / 15278.5322 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2584
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2644
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 560.05,                last time consumption/overall running time: 68.0919s / 15346.6242 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2837
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2871
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 526.85,                last time consumption/overall running time: 63.7499s / 15410.3741 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2610
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2533
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 577.5,                last time consumption/overall running time: 68.7528s / 15479.1269 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2999
env0_second_0:                 episode reward: 0.9000,                 loss: 0.3056
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 594.3,                last time consumption/overall running time: 69.8137s / 15548.9406 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2786
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2826
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 506.5,                last time consumption/overall running time: 62.0779s / 15611.0186 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.2670
env0_second_0:                 episode reward: -1.2000,                 loss: 0.2624
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 602.8,                last time consumption/overall running time: 71.6397s / 15682.6582 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2724
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2792
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 549.15,                last time consumption/overall running time: 67.4477s / 15750.1060 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2444
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2479
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 563.0,                last time consumption/overall running time: 68.0459s / 15818.1518 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2616
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2677
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 547.3,                last time consumption/overall running time: 65.1948s / 15883.3467 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2704
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2677
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 550.95,                last time consumption/overall running time: 64.8644s / 15948.2111 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2768
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2737
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 562.75,                last time consumption/overall running time: 66.7965s / 16015.0076 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2604
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2582
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 536.85,                last time consumption/overall running time: 64.6631s / 16079.6707 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2443
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2436
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 530.0,                last time consumption/overall running time: 64.9599s / 16144.6306 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2713
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2761
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 552.35,                last time consumption/overall running time: 66.3811s / 16211.0117 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2507
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2596
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 619.7,                last time consumption/overall running time: 74.0006s / 16285.0124 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2654
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2655
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 589.45,                last time consumption/overall running time: 70.1157s / 16355.1281 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2406
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2339
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 588.0,                last time consumption/overall running time: 69.8001s / 16424.9282 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2677
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2633
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 551.55,                last time consumption/overall running time: 65.8151s / 16490.7433 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2292
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2427
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 605.75,                last time consumption/overall running time: 71.9585s / 16562.7018 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2597
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2570
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 588.55,                last time consumption/overall running time: 70.6555s / 16633.3573 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2603
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2630
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 561.55,                last time consumption/overall running time: 67.0260s / 16700.3833 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.2851
env0_second_0:                 episode reward: 1.3000,                 loss: 0.2895
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 575.3,                last time consumption/overall running time: 68.7269s / 16769.1102 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2833
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2764
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 581.8,                last time consumption/overall running time: 69.6490s / 16838.7592 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2688
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2683
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 573.35,                last time consumption/overall running time: 68.9737s / 16907.7329 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2592
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2716
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 539.5,                last time consumption/overall running time: 64.8847s / 16972.6177 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2502
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2501
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 634.95,                last time consumption/overall running time: 74.5476s / 17047.1653 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2749
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2731
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 526.5,                last time consumption/overall running time: 63.7434s / 17110.9087 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2612
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2717
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 563.35,                last time consumption/overall running time: 67.2126s / 17178.1213 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2532
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2563
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 559.35,                last time consumption/overall running time: 67.3454s / 17245.4667 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2427
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2383
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 549.3,                last time consumption/overall running time: 66.2877s / 17311.7544 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2439
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2445
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 550.65,                last time consumption/overall running time: 66.1446s / 17377.8990 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2436
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2528
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 562.7,                last time consumption/overall running time: 67.9186s / 17445.8177 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2468
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2552
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 576.1,                last time consumption/overall running time: 69.2545s / 17515.0722 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2561
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2593
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 559.1,                last time consumption/overall running time: 67.3599s / 17582.4320 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2563
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2570
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 585.6,                last time consumption/overall running time: 70.2165s / 17652.6486 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2648
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2715
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 580.35,                last time consumption/overall running time: 68.4585s / 17721.1070 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2545
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2589
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 563.5,                last time consumption/overall running time: 67.1687s / 17788.2757 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2691
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2838
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 585.3,                last time consumption/overall running time: 70.3400s / 17858.6157 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2501
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2546
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 568.95,                last time consumption/overall running time: 67.6510s / 17926.2667 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2333
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2499
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 546.15,                last time consumption/overall running time: 66.7418s / 17993.0085 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2572
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2639
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 578.8,                last time consumption/overall running time: 69.4958s / 18062.5043 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2447
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2506
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 589.45,                last time consumption/overall running time: 69.7932s / 18132.2975 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2525
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2539
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 584.05,                last time consumption/overall running time: 69.6671s / 18201.9646 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2555
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2500
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 577.7,                last time consumption/overall running time: 68.4019s / 18270.3665 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2488
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2626
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 560.8,                last time consumption/overall running time: 66.9287s / 18337.2952 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2612
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2650
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 587.1,                last time consumption/overall running time: 69.5715s / 18406.8666 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.2625
env0_second_0:                 episode reward: 1.3000,                 loss: 0.2760
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 575.05,                last time consumption/overall running time: 69.3432s / 18476.2098 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2530
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2618
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 564.35,                last time consumption/overall running time: 68.2624s / 18544.4722 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2578
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2559
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 593.15,                last time consumption/overall running time: 70.6181s / 18615.0903 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2548
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2615
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 560.75,                last time consumption/overall running time: 66.7962s / 18681.8866 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2483
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2560
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 532.65,                last time consumption/overall running time: 64.6109s / 18746.4975 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2273
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2411
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 586.4,                last time consumption/overall running time: 69.3303s / 18815.8278 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2682
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2763
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 595.45,                last time consumption/overall running time: 71.1062s / 18886.9340 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2148
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2191
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 576.4,                last time consumption/overall running time: 69.5606s / 18956.4946 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2615
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2720
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 582.5,                last time consumption/overall running time: 69.5813s / 19026.0759 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2664
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2807
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 579.85,                last time consumption/overall running time: 69.1695s / 19095.2454 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2482
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2439
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 577.75,                last time consumption/overall running time: 68.9191s / 19164.1646 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2673
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2812
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 594.2,                last time consumption/overall running time: 70.6675s / 19234.8321 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2579
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2679
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 567.05,                last time consumption/overall running time: 68.2534s / 19303.0855 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2572
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2648
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 546.85,                last time consumption/overall running time: 65.2518s / 19368.3373 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2541
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2568
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 590.6,                last time consumption/overall running time: 69.5657s / 19437.9030 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.2344
env0_second_0:                 episode reward: -1.1500,                 loss: 0.2445
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5721/10000 (57.2100%),                 avg. length: 607.5,                last time consumption/overall running time: 71.1599s / 19509.0629 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2639
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2691
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5741/10000 (57.4100%),                 avg. length: 594.65,                last time consumption/overall running time: 71.5720s / 19580.6349 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2482
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2572
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 5761/10000 (57.6100%),                 avg. length: 605.35,                last time consumption/overall running time: 71.9468s / 19652.5816 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.2347
env0_second_0:                 episode reward: -1.2500,                 loss: 0.2356
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 5781/10000 (57.8100%),                 avg. length: 580.55,                last time consumption/overall running time: 68.8963s / 19721.4779 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2722
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2732
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5801/10000 (58.0100%),                 avg. length: 588.3,                last time consumption/overall running time: 70.0803s / 19791.5582 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2368
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2482
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5821/10000 (58.2100%),                 avg. length: 608.0,                last time consumption/overall running time: 71.5591s / 19863.1173 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2758
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2677
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 5841/10000 (58.4100%),                 avg. length: 580.25,                last time consumption/overall running time: 68.6172s / 19931.7345 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2396
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2520
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 5861/10000 (58.6100%),                 avg. length: 568.7,                last time consumption/overall running time: 67.4550s / 19999.1895 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2527
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2503
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 5881/10000 (58.8100%),                 avg. length: 562.3,                last time consumption/overall running time: 67.0896s / 20066.2791 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2434
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2567
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5901/10000 (59.0100%),                 avg. length: 585.1,                last time consumption/overall running time: 69.5286s / 20135.8077 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2658
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2771
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5921/10000 (59.2100%),                 avg. length: 593.6,                last time consumption/overall running time: 69.9910s / 20205.7986 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2519
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2520
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5941/10000 (59.4100%),                 avg. length: 550.25,                last time consumption/overall running time: 67.5721s / 20273.3707 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2655
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2674
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5961/10000 (59.6100%),                 avg. length: 595.95,                last time consumption/overall running time: 70.6047s / 20343.9754 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2484
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2435
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5981/10000 (59.8100%),                 avg. length: 571.85,                last time consumption/overall running time: 69.4867s / 20413.4621 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2107
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2132
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 6001/10000 (60.0100%),                 avg. length: 588.2,                last time consumption/overall running time: 70.8278s / 20484.2898 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2484
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2674
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6021/10000 (60.2100%),                 avg. length: 586.3,                last time consumption/overall running time: 70.3589s / 20554.6487 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2450
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2612
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6041/10000 (60.4100%),                 avg. length: 574.9,                last time consumption/overall running time: 68.4660s / 20623.1147 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2549
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2565
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6061/10000 (60.6100%),                 avg. length: 536.7,                last time consumption/overall running time: 64.4327s / 20687.5473 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2334
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2403
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6081/10000 (60.8100%),                 avg. length: 550.2,                last time consumption/overall running time: 66.2056s / 20753.7529 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2707
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2872
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 6101/10000 (61.0100%),                 avg. length: 562.55,                last time consumption/overall running time: 67.1824s / 20820.9353 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2646
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2718
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6121/10000 (61.2100%),                 avg. length: 598.75,                last time consumption/overall running time: 70.9600s / 20891.8953 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2403
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2481
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 6141/10000 (61.4100%),                 avg. length: 574.55,                last time consumption/overall running time: 69.7731s / 20961.6684 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2485
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2498
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6161/10000 (61.6100%),                 avg. length: 583.4,                last time consumption/overall running time: 69.0407s / 21030.7091 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2344
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2409
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6181/10000 (61.8100%),                 avg. length: 553.3,                last time consumption/overall running time: 67.4236s / 21098.1327 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2322
env0_second_0:                 episode reward: 1.2000,                 loss: 0.2302
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6201/10000 (62.0100%),                 avg. length: 545.6,                last time consumption/overall running time: 65.9662s / 21164.0989 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2620
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2671
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 6221/10000 (62.2100%),                 avg. length: 556.05,                last time consumption/overall running time: 66.5616s / 21230.6604 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2672
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2743
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6241/10000 (62.4100%),                 avg. length: 589.3,                last time consumption/overall running time: 70.6093s / 21301.2697 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2559
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2589
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6261/10000 (62.6100%),                 avg. length: 543.25,                last time consumption/overall running time: 64.9492s / 21366.2189 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2349
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2470
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6281/10000 (62.8100%),                 avg. length: 567.7,                last time consumption/overall running time: 68.2193s / 21434.4382 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2519
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2562
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 6301/10000 (63.0100%),                 avg. length: 540.4,                last time consumption/overall running time: 65.1313s / 21499.5695 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2394
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2595
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 6321/10000 (63.2100%),                 avg. length: 538.5,                last time consumption/overall running time: 64.3049s / 21563.8744 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2460
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2594
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6341/10000 (63.4100%),                 avg. length: 594.15,                last time consumption/overall running time: 69.6532s / 21633.5275 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2378
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2458
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6361/10000 (63.6100%),                 avg. length: 554.85,                last time consumption/overall running time: 66.1737s / 21699.7013 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2428
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2459
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6381/10000 (63.8100%),                 avg. length: 573.2,                last time consumption/overall running time: 68.8941s / 21768.5953 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2396
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2527
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6401/10000 (64.0100%),                 avg. length: 538.65,                last time consumption/overall running time: 65.4597s / 21834.0550 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2663
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2691
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6421/10000 (64.2100%),                 avg. length: 539.85,                last time consumption/overall running time: 64.8899s / 21898.9449 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2373
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2462
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6441/10000 (64.4100%),                 avg. length: 541.25,                last time consumption/overall running time: 65.3594s / 21964.3042 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2450
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2524
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 6461/10000 (64.6100%),                 avg. length: 557.65,                last time consumption/overall running time: 66.1121s / 22030.4163 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2706
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2678
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6481/10000 (64.8100%),                 avg. length: 590.2,                last time consumption/overall running time: 69.5923s / 22100.0086 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2564
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2643
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6501/10000 (65.0100%),                 avg. length: 569.05,                last time consumption/overall running time: 68.8220s / 22168.8306 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2343
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2441
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6521/10000 (65.2100%),                 avg. length: 596.6,                last time consumption/overall running time: 70.8333s / 22239.6639 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2547
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2504
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 6541/10000 (65.4100%),                 avg. length: 531.55,                last time consumption/overall running time: 63.2935s / 22302.9574 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2542
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2614
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6561/10000 (65.6100%),                 avg. length: 566.25,                last time consumption/overall running time: 68.5284s / 22371.4858 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2512
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2557
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6581/10000 (65.8100%),                 avg. length: 594.2,                last time consumption/overall running time: 70.8365s / 22442.3222 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2442
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2514
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 6601/10000 (66.0100%),                 avg. length: 614.45,                last time consumption/overall running time: 72.8841s / 22515.2063 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.2643
env0_second_0:                 episode reward: -1.1500,                 loss: 0.2604
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6621/10000 (66.2100%),                 avg. length: 619.8,                last time consumption/overall running time: 74.5953s / 22589.8016 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2794
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2739
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6641/10000 (66.4100%),                 avg. length: 577.2,                last time consumption/overall running time: 68.7283s / 22658.5299 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2342
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2438
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 6661/10000 (66.6100%),                 avg. length: 548.1,                last time consumption/overall running time: 65.7409s / 22724.2708 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2617
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2620
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6681/10000 (66.8100%),                 avg. length: 571.5,                last time consumption/overall running time: 69.0828s / 22793.3536 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2397
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2440
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6701/10000 (67.0100%),                 avg. length: 590.1,                last time consumption/overall running time: 69.9539s / 22863.3075 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2484
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2551
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6721/10000 (67.2100%),                 avg. length: 566.5,                last time consumption/overall running time: 68.2973s / 22931.6047 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2643
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2772
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6741/10000 (67.4100%),                 avg. length: 575.5,                last time consumption/overall running time: 68.4276s / 23000.0323 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2360
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2417
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6761/10000 (67.6100%),                 avg. length: 553.2,                last time consumption/overall running time: 66.4759s / 23066.5082 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2476
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2521
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6781/10000 (67.8100%),                 avg. length: 561.35,                last time consumption/overall running time: 68.3206s / 23134.8288 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2369
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2568
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6801/10000 (68.0100%),                 avg. length: 560.5,                last time consumption/overall running time: 67.5362s / 23202.3650 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2706
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2874
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6821/10000 (68.2100%),                 avg. length: 609.7,                last time consumption/overall running time: 73.2672s / 23275.6322 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2662
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2699
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6841/10000 (68.4100%),                 avg. length: 560.8,                last time consumption/overall running time: 67.4593s / 23343.0915 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2767
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2737
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 6861/10000 (68.6100%),                 avg. length: 580.5,                last time consumption/overall running time: 69.2389s / 23412.3304 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2528
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2687
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6881/10000 (68.8100%),                 avg. length: 578.05,                last time consumption/overall running time: 69.1172s / 23481.4476 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2374
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2450
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6901/10000 (69.0100%),                 avg. length: 556.6,                last time consumption/overall running time: 67.2522s / 23548.6998 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2494
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2514
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6921/10000 (69.2100%),                 avg. length: 573.85,                last time consumption/overall running time: 68.2331s / 23616.9328 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2397
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2450
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6941/10000 (69.4100%),                 avg. length: 557.45,                last time consumption/overall running time: 67.1650s / 23684.0978 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2179
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2262
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6961/10000 (69.6100%),                 avg. length: 569.7,                last time consumption/overall running time: 68.8882s / 23752.9860 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2551
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2614
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6981/10000 (69.8100%),                 avg. length: 557.45,                last time consumption/overall running time: 66.8120s / 23819.7980 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2470
env0_second_0:                 episode reward: 1.2000,                 loss: 0.2661
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7001/10000 (70.0100%),                 avg. length: 563.4,                last time consumption/overall running time: 67.8913s / 23887.6893 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2370
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2520
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 7021/10000 (70.2100%),                 avg. length: 577.0,                last time consumption/overall running time: 68.0357s / 23955.7250 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2708
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2808
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 7041/10000 (70.4100%),                 avg. length: 583.9,                last time consumption/overall running time: 69.3194s / 24025.0444 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2570
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2558
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7061/10000 (70.6100%),                 avg. length: 559.6,                last time consumption/overall running time: 66.4527s / 24091.4971 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2678
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2659
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 7081/10000 (70.8100%),                 avg. length: 572.45,                last time consumption/overall running time: 67.2146s / 24158.7117 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2575
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2579
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7101/10000 (71.0100%),                 avg. length: 554.05,                last time consumption/overall running time: 66.6252s / 24225.3369 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2702
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2769
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7121/10000 (71.2100%),                 avg. length: 582.0,                last time consumption/overall running time: 70.5165s / 24295.8534 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2501
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2598
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7141/10000 (71.4100%),                 avg. length: 524.1,                last time consumption/overall running time: 63.1344s / 24358.9878 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2299
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2466
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 7161/10000 (71.6100%),                 avg. length: 549.65,                last time consumption/overall running time: 66.2070s / 24425.1948 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2636
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2734
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7181/10000 (71.8100%),                 avg. length: 605.75,                last time consumption/overall running time: 71.6804s / 24496.8752 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2638
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2625
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7201/10000 (72.0100%),                 avg. length: 591.55,                last time consumption/overall running time: 70.0723s / 24566.9474 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2578
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2532
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7221/10000 (72.2100%),                 avg. length: 609.95,                last time consumption/overall running time: 73.4087s / 24640.3561 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2508
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2618
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 7241/10000 (72.4100%),                 avg. length: 586.75,                last time consumption/overall running time: 69.3593s / 24709.7154 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2559
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2587
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7261/10000 (72.6100%),                 avg. length: 564.65,                last time consumption/overall running time: 67.6824s / 24777.3978 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2456
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2365
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7281/10000 (72.8100%),                 avg. length: 519.4,                last time consumption/overall running time: 62.7320s / 24840.1297 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.2435
env0_second_0:                 episode reward: -1.1000,                 loss: 0.2507
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7301/10000 (73.0100%),                 avg. length: 598.95,                last time consumption/overall running time: 69.9527s / 24910.0824 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2626
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2619
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7321/10000 (73.2100%),                 avg. length: 600.25,                last time consumption/overall running time: 71.1950s / 24981.2775 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2468
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2406
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7341/10000 (73.4100%),                 avg. length: 553.4,                last time consumption/overall running time: 65.8206s / 25047.0980 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2505
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2600
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7361/10000 (73.6100%),                 avg. length: 599.55,                last time consumption/overall running time: 70.6548s / 25117.7528 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2417
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2353
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7381/10000 (73.8100%),                 avg. length: 578.1,                last time consumption/overall running time: 69.2758s / 25187.0287 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2646
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2672
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7401/10000 (74.0100%),                 avg. length: 579.6,                last time consumption/overall running time: 69.3755s / 25256.4042 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2556
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2531
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 7421/10000 (74.2100%),                 avg. length: 579.3,                last time consumption/overall running time: 69.8034s / 25326.2075 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2537
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2420
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 7441/10000 (74.4100%),                 avg. length: 592.5,                last time consumption/overall running time: 70.2472s / 25396.4547 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2462
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2398
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7461/10000 (74.6100%),                 avg. length: 573.85,                last time consumption/overall running time: 68.6731s / 25465.1279 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2420
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2392
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7481/10000 (74.8100%),                 avg. length: 564.15,                last time consumption/overall running time: 67.4862s / 25532.6140 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2331
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2398
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7501/10000 (75.0100%),                 avg. length: 532.65,                last time consumption/overall running time: 64.3602s / 25596.9742 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2772
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2719
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7521/10000 (75.2100%),                 avg. length: 582.1,                last time consumption/overall running time: 69.6599s / 25666.6341 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2564
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2568
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 7541/10000 (75.4100%),                 avg. length: 579.55,                last time consumption/overall running time: 69.2625s / 25735.8966 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2414
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2437
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7561/10000 (75.6100%),                 avg. length: 565.2,                last time consumption/overall running time: 67.0917s / 25802.9883 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2485
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2593
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7581/10000 (75.8100%),                 avg. length: 545.75,                last time consumption/overall running time: 66.6141s / 25869.6024 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2706
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2594
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7601/10000 (76.0100%),                 avg. length: 623.6,                last time consumption/overall running time: 74.5295s / 25944.1319 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2688
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2650
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7621/10000 (76.2100%),                 avg. length: 596.35,                last time consumption/overall running time: 71.6771s / 26015.8090 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2449
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2435
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 7641/10000 (76.4100%),                 avg. length: 536.35,                last time consumption/overall running time: 65.4247s / 26081.2336 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2266
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2293
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 7661/10000 (76.6100%),                 avg. length: 549.7,                last time consumption/overall running time: 66.4052s / 26147.6388 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.2612
env0_second_0:                 episode reward: -1.5000,                 loss: 0.2479
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7681/10000 (76.8100%),                 avg. length: 537.95,                last time consumption/overall running time: 65.2871s / 26212.9259 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2411
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2333
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7701/10000 (77.0100%),                 avg. length: 554.15,                last time consumption/overall running time: 66.8164s / 26279.7423 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2666
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2577
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 7721/10000 (77.2100%),                 avg. length: 605.25,                last time consumption/overall running time: 72.0144s / 26351.7566 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2478
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2552
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7741/10000 (77.4100%),                 avg. length: 574.9,                last time consumption/overall running time: 68.5333s / 26420.2899 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2441
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2489
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7761/10000 (77.6100%),                 avg. length: 558.95,                last time consumption/overall running time: 66.9761s / 26487.2660 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2566
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2693
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7781/10000 (77.8100%),                 avg. length: 554.55,                last time consumption/overall running time: 65.8085s / 26553.0745 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2391
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2412
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 7801/10000 (78.0100%),                 avg. length: 571.5,                last time consumption/overall running time: 69.8396s / 26622.9141 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2595
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2498
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7821/10000 (78.2100%),                 avg. length: 590.95,                last time consumption/overall running time: 70.0665s / 26692.9806 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2849
env0_second_0:                 episode reward: 1.2000,                 loss: 0.2860
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7841/10000 (78.4100%),                 avg. length: 573.5,                last time consumption/overall running time: 68.8751s / 26761.8557 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2421
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2522
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7861/10000 (78.6100%),                 avg. length: 561.4,                last time consumption/overall running time: 67.8782s / 26829.7339 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2233
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2204
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7881/10000 (78.8100%),                 avg. length: 588.05,                last time consumption/overall running time: 69.9272s / 26899.6611 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2714
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2834
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7901/10000 (79.0100%),                 avg. length: 575.6,                last time consumption/overall running time: 67.9014s / 26967.5625 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2385
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2457
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7921/10000 (79.2100%),                 avg. length: 583.05,                last time consumption/overall running time: 69.8991s / 27037.4616 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2380
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2478
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7941/10000 (79.4100%),                 avg. length: 575.7,                last time consumption/overall running time: 68.9711s / 27106.4327 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2676
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2702
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7961/10000 (79.6100%),                 avg. length: 526.3,                last time consumption/overall running time: 63.8793s / 27170.3119 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2475
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2403
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7981/10000 (79.8100%),                 avg. length: 581.25,                last time consumption/overall running time: 69.0315s / 27239.3434 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2448
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2510
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 8001/10000 (80.0100%),                 avg. length: 583.35,                last time consumption/overall running time: 70.3748s / 27309.7182 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2549
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2583
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 8021/10000 (80.2100%),                 avg. length: 574.4,                last time consumption/overall running time: 67.9039s / 27377.6220 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2403
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2465
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8041/10000 (80.4100%),                 avg. length: 572.3,                last time consumption/overall running time: 67.4380s / 27445.0600 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2264
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2190
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 8061/10000 (80.6100%),                 avg. length: 559.45,                last time consumption/overall running time: 67.0721s / 27512.1321 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2445
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2539
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8081/10000 (80.8100%),                 avg. length: 563.5,                last time consumption/overall running time: 67.7843s / 27579.9164 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2615
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2720
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8101/10000 (81.0100%),                 avg. length: 551.55,                last time consumption/overall running time: 66.0213s / 27645.9378 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2519
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2592
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8121/10000 (81.2100%),                 avg. length: 583.3,                last time consumption/overall running time: 68.6763s / 27714.6140 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2553
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2663
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8141/10000 (81.4100%),                 avg. length: 585.55,                last time consumption/overall running time: 70.1294s / 27784.7434 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2569
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2594
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8161/10000 (81.6100%),                 avg. length: 590.4,                last time consumption/overall running time: 70.6250s / 27855.3684 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2417
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2412
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 8181/10000 (81.8100%),                 avg. length: 561.55,                last time consumption/overall running time: 67.1560s / 27922.5244 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2808
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2736
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8201/10000 (82.0100%),                 avg. length: 548.1,                last time consumption/overall running time: 65.3105s / 27987.8348 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2630
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2664
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8221/10000 (82.2100%),                 avg. length: 542.15,                last time consumption/overall running time: 65.7040s / 28053.5389 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2586
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2659
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8241/10000 (82.4100%),                 avg. length: 563.0,                last time consumption/overall running time: 68.0920s / 28121.6309 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2381
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2450
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8261/10000 (82.6100%),                 avg. length: 568.2,                last time consumption/overall running time: 68.7055s / 28190.3364 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2601
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2680
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8281/10000 (82.8100%),                 avg. length: 607.95,                last time consumption/overall running time: 72.5464s / 28262.8828 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2479
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2505
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8301/10000 (83.0100%),                 avg. length: 548.5,                last time consumption/overall running time: 66.0877s / 28328.9705 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2360
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2495
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8321/10000 (83.2100%),                 avg. length: 556.0,                last time consumption/overall running time: 66.9602s / 28395.9307 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2405
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2446
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 8341/10000 (83.4100%),                 avg. length: 568.7,                last time consumption/overall running time: 67.0322s / 28462.9630 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2523
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2585
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8361/10000 (83.6100%),                 avg. length: 574.0,                last time consumption/overall running time: 68.4661s / 28531.4291 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2387
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2429
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 8381/10000 (83.8100%),                 avg. length: 544.6,                last time consumption/overall running time: 66.3275s / 28597.7566 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2337
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2384
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 8401/10000 (84.0100%),                 avg. length: 575.8,                last time consumption/overall running time: 69.0066s / 28666.7631 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.2612
env0_second_0:                 episode reward: -1.2000,                 loss: 0.2728
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8421/10000 (84.2100%),                 avg. length: 576.3,                last time consumption/overall running time: 69.4461s / 28736.2092 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2428
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2412
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8441/10000 (84.4100%),                 avg. length: 557.35,                last time consumption/overall running time: 67.1109s / 28803.3201 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2317
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2465
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8461/10000 (84.6100%),                 avg. length: 568.15,                last time consumption/overall running time: 67.5013s / 28870.8215 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2305
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2392
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 8481/10000 (84.8100%),                 avg. length: 598.25,                last time consumption/overall running time: 70.4628s / 28941.2842 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2451
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2523
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8501/10000 (85.0100%),                 avg. length: 543.1,                last time consumption/overall running time: 64.2804s / 29005.5647 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2610
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2698
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 8521/10000 (85.2100%),                 avg. length: 557.85,                last time consumption/overall running time: 66.8009s / 29072.3656 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2587
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2651
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8541/10000 (85.4100%),                 avg. length: 612.15,                last time consumption/overall running time: 73.1089s / 29145.4745 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2385
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2562
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 8561/10000 (85.6100%),                 avg. length: 614.55,                last time consumption/overall running time: 72.2256s / 29217.7001 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2482
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2670
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8581/10000 (85.8100%),                 avg. length: 605.8,                last time consumption/overall running time: 71.0880s / 29288.7881 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2405
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2480
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8601/10000 (86.0100%),                 avg. length: 597.6,                last time consumption/overall running time: 70.8704s / 29359.6586 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2532
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2586
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8621/10000 (86.2100%),                 avg. length: 579.3,                last time consumption/overall running time: 68.6470s / 29428.3056 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2523
env0_second_0:                 episode reward: 1.2000,                 loss: 0.2632
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 8641/10000 (86.4100%),                 avg. length: 582.65,                last time consumption/overall running time: 69.2044s / 29497.5100 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2413
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2532
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8661/10000 (86.6100%),                 avg. length: 559.65,                last time consumption/overall running time: 67.2854s / 29564.7954 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2418
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2655
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 8681/10000 (86.8100%),                 avg. length: 517.65,                last time consumption/overall running time: 63.2672s / 29628.0627 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2488
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2438
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 8701/10000 (87.0100%),                 avg. length: 508.6,                last time consumption/overall running time: 61.5621s / 29689.6247 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.2610
env0_second_0:                 episode reward: 1.2000,                 loss: 0.2682
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 8721/10000 (87.2100%),                 avg. length: 544.9,                last time consumption/overall running time: 65.0351s / 29754.6599 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2346
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2432
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8741/10000 (87.4100%),                 avg. length: 530.35,                last time consumption/overall running time: 63.8862s / 29818.5461 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2327
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2305
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8761/10000 (87.6100%),                 avg. length: 546.7,                last time consumption/overall running time: 66.4410s / 29884.9871 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2557
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2634
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8781/10000 (87.8100%),                 avg. length: 545.8,                last time consumption/overall running time: 66.2885s / 29951.2756 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2549
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2539
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 8801/10000 (88.0100%),                 avg. length: 566.85,                last time consumption/overall running time: 67.1853s / 30018.4610 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2567
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2608
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8821/10000 (88.2100%),                 avg. length: 544.35,                last time consumption/overall running time: 64.9425s / 30083.4035 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2408
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2469
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8841/10000 (88.4100%),                 avg. length: 541.3,                last time consumption/overall running time: 64.7342s / 30148.1377 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2509
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2521
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8861/10000 (88.6100%),                 avg. length: 577.9,                last time consumption/overall running time: 69.7449s / 30217.8826 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2339
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2522
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8881/10000 (88.8100%),                 avg. length: 590.55,                last time consumption/overall running time: 70.0938s / 30287.9764 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2384
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2350
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 8901/10000 (89.0100%),                 avg. length: 544.8,                last time consumption/overall running time: 65.9626s / 30353.9390 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2471
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2502
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8921/10000 (89.2100%),                 avg. length: 576.65,                last time consumption/overall running time: 68.5767s / 30422.5156 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2479
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2475
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8941/10000 (89.4100%),                 avg. length: 584.1,                last time consumption/overall running time: 69.4942s / 30492.0098 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2683
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2723
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 8961/10000 (89.6100%),                 avg. length: 563.25,                last time consumption/overall running time: 67.4135s / 30559.4233 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2574
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2726
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 8981/10000 (89.8100%),                 avg. length: 597.4,                last time consumption/overall running time: 71.4348s / 30630.8582 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2442
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2461
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9001/10000 (90.0100%),                 avg. length: 611.45,                last time consumption/overall running time: 72.7100s / 30703.5682 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2405
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2430
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9021/10000 (90.2100%),                 avg. length: 540.6,                last time consumption/overall running time: 64.4561s / 30768.0242 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2523
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2555
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 9041/10000 (90.4100%),                 avg. length: 567.1,                last time consumption/overall running time: 68.2658s / 30836.2900 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2348
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2449
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 9061/10000 (90.6100%),                 avg. length: 550.4,                last time consumption/overall running time: 65.8608s / 30902.1509 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2308
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2351
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 9081/10000 (90.8100%),                 avg. length: 557.75,                last time consumption/overall running time: 66.4630s / 30968.6139 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2477
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2517
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9101/10000 (91.0100%),                 avg. length: 562.6,                last time consumption/overall running time: 68.1155s / 31036.7293 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2206
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2246
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9121/10000 (91.2100%),                 avg. length: 580.25,                last time consumption/overall running time: 69.1676s / 31105.8970 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2569
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2609
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9141/10000 (91.4100%),                 avg. length: 568.65,                last time consumption/overall running time: 68.1320s / 31174.0289 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2173
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2146
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9161/10000 (91.6100%),                 avg. length: 573.95,                last time consumption/overall running time: 68.1636s / 31242.1925 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2472
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2459
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9181/10000 (91.8100%),                 avg. length: 564.1,                last time consumption/overall running time: 67.5793s / 31309.7718 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2514
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2716
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 9201/10000 (92.0100%),                 avg. length: 560.6,                last time consumption/overall running time: 66.0433s / 31375.8151 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.2328
env0_second_0:                 episode reward: -1.7000,                 loss: 0.2485
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 9221/10000 (92.2100%),                 avg. length: 551.45,                last time consumption/overall running time: 67.0804s / 31442.8955 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2195
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2375
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 9241/10000 (92.4100%),                 avg. length: 600.15,                last time consumption/overall running time: 71.4156s / 31514.3111 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2269
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2370
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 9261/10000 (92.6100%),                 avg. length: 589.45,                last time consumption/overall running time: 70.0537s / 31584.3648 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2539
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2624
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9281/10000 (92.8100%),                 avg. length: 554.15,                last time consumption/overall running time: 66.9414s / 31651.3062 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2139
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2361
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 9301/10000 (93.0100%),                 avg. length: 526.5,                last time consumption/overall running time: 62.9126s / 31714.2188 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2261
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2280
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9321/10000 (93.2100%),                 avg. length: 561.8,                last time consumption/overall running time: 68.0030s / 31782.2218 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2403
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2414
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 9341/10000 (93.4100%),                 avg. length: 545.25,                last time consumption/overall running time: 65.7156s / 31847.9374 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2470
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2548
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 9361/10000 (93.6100%),                 avg. length: 572.15,                last time consumption/overall running time: 68.0432s / 31915.9806 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2588
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2756
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 9381/10000 (93.8100%),                 avg. length: 565.55,                last time consumption/overall running time: 67.3620s / 31983.3425 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2372
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2318
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9401/10000 (94.0100%),                 avg. length: 558.2,                last time consumption/overall running time: 67.0446s / 32050.3872 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2179
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2323
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9421/10000 (94.2100%),                 avg. length: 581.15,                last time consumption/overall running time: 69.0849s / 32119.4721 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2437
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2508
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9441/10000 (94.4100%),                 avg. length: 569.05,                last time consumption/overall running time: 67.7732s / 32187.2452 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2241
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2250
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 9461/10000 (94.6100%),                 avg. length: 572.85,                last time consumption/overall running time: 69.0548s / 32256.3000 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2501
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2441
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9481/10000 (94.8100%),                 avg. length: 545.45,                last time consumption/overall running time: 65.2112s / 32321.5113 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2385
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2415
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 9501/10000 (95.0100%),                 avg. length: 548.15,                last time consumption/overall running time: 65.2652s / 32386.7765 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2154
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2141
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9521/10000 (95.2100%),                 avg. length: 566.15,                last time consumption/overall running time: 67.3597s / 32454.1363 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2357
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2393
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9541/10000 (95.4100%),                 avg. length: 560.2,                last time consumption/overall running time: 66.8945s / 32521.0307 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.2733
env0_second_0:                 episode reward: -1.2500,                 loss: 0.2757
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 9561/10000 (95.6100%),                 avg. length: 521.5,                last time consumption/overall running time: 63.4467s / 32584.4775 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2204
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2317
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 9581/10000 (95.8100%),                 avg. length: 598.15,                last time consumption/overall running time: 71.4565s / 32655.9339 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2542
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2626
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9601/10000 (96.0100%),                 avg. length: 536.85,                last time consumption/overall running time: 64.3624s / 32720.2963 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2093
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2341
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 9621/10000 (96.2100%),                 avg. length: 501.95,                last time consumption/overall running time: 61.7589s / 32782.0552 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2466
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2514
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9641/10000 (96.4100%),                 avg. length: 552.55,                last time consumption/overall running time: 66.2494s / 32848.3045 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2390
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2559
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9661/10000 (96.6100%),                 avg. length: 537.35,                last time consumption/overall running time: 63.6916s / 32911.9961 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2267
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2354
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 9681/10000 (96.8100%),                 avg. length: 549.35,                last time consumption/overall running time: 65.9827s / 32977.9788 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2709
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2715
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 9701/10000 (97.0100%),                 avg. length: 578.35,                last time consumption/overall running time: 68.4628s / 33046.4417 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2565
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2632
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9721/10000 (97.2100%),                 avg. length: 571.3,                last time consumption/overall running time: 67.0232s / 33113.4649 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.2148
env0_second_0:                 episode reward: 1.2500,                 loss: 0.2241
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9741/10000 (97.4100%),                 avg. length: 578.1,                last time consumption/overall running time: 68.0507s / 33181.5156 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2756
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2823
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9761/10000 (97.6100%),                 avg. length: 584.9,                last time consumption/overall running time: 70.1132s / 33251.6288 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2327
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2480
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9781/10000 (97.8100%),                 avg. length: 571.15,                last time consumption/overall running time: 68.2368s / 33319.8656 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2480
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2419
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 9801/10000 (98.0100%),                 avg. length: 546.1,                last time consumption/overall running time: 66.5600s / 33386.4256 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2537
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2525
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 9821/10000 (98.2100%),                 avg. length: 580.85,                last time consumption/overall running time: 69.8932s / 33456.3188 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2305
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2237
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 9841/10000 (98.4100%),                 avg. length: 577.5,                last time consumption/overall running time: 68.3273s / 33524.6461 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2176
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2316
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 9861/10000 (98.6100%),                 avg. length: 541.6,                last time consumption/overall running time: 64.7947s / 33589.4407 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2380
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2434
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 9881/10000 (98.8100%),                 avg. length: 563.55,                last time consumption/overall running time: 67.5761s / 33657.0168 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2260
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2166
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 9901/10000 (99.0100%),                 avg. length: 586.55,                last time consumption/overall running time: 69.7049s / 33726.7217 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2701
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2727Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
Load SlimeVolley-v0 environment in type slimevolley.
Env observation space: Box(-3.4028234663852886e+38, 3.4028234663852886e+38, (12,), float32) action space: Discrete(6)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/container.py:141: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/zihan/research/MARS/mars/rl/agents/nash_ppo.py:181: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1641801999604/work/torch/csrc/utils/tensor_new.cpp:210.)
  s,a,r,s_prime,prob_a,done_mask =    torch.tensor(s_lst, dtype=torch.float).to(self.device), torch.tensor(a_lst).to(self.device), \
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)

env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 9921/10000 (99.2100%),                 avg. length: 570.1,                last time consumption/overall running time: 68.4526s / 33795.1743 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2391
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2368
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9941/10000 (99.4100%),                 avg. length: 593.35,                last time consumption/overall running time: 70.6362s / 33865.8105 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2446
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2452
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 9961/10000 (99.6100%),                 avg. length: 624.8,                last time consumption/overall running time: 73.7516s / 33939.5621 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2597
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2626
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9981/10000 (99.8100%),                 avg. length: 560.95,                last time consumption/overall running time: 66.6549s / 34006.2169 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2077
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2029
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
