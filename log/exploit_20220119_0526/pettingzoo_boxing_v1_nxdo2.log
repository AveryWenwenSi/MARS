pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 91
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7fa1c3258390>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [array([0.   , 0.126, 0.   , 0.   , 0.316, 0.   , 0.   , 0.   , 0.048, 0.   , 0.271, 0.084, 0.   , 0.049, 0.058, 0.   , 0.029, 0.014, 0.   , 0.005])
 array([0.   , 0.   , 0.006, 0.   , 0.   , 0.   , 0.   , 0.018, 0.023, 0.   , 0.02 , 0.256, 0.004, 0.058, 0.   , 0.072, 0.059, 0.375, 0.109])]
Load checkpoints (policy family):  [list(['21', '98', '187', '246', '298', '376', '445', '565', '653', '833', '1113', '1983', '2211', '2560', '2898', '3197', '3474', '7265', '7833', '7985'])
 list(['47', '149', '208', '272', '322', '397', '476', '614', '676', '854', '1156', '2015', '2232', '2581', '2919', '3218', '3495', '7291', '7854'])]
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220119_0526/pettingzoo_boxing_v1_nxdo2/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 80, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220119_0526_exploit/pettingzoo_boxing_v1_nxdo2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0526_exploit/pettingzoo_boxing_v1_nxdo2.
Episode: 1/10000 (0.0100%),                 avg. length: 374.0,                last time consumption/overall running time: 6.6758s / 6.6758 s
first_0:                 episode reward: 96.0000,                 loss: nan
second_0:                 episode reward: -96.0000,                 loss: 0.2218
Episode: 21/10000 (0.2100%),                 avg. length: 1576.9,                last time consumption/overall running time: 606.9773s / 613.6531 s
first_0:                 episode reward: 11.1500,                 loss: nan
second_0:                 episode reward: -11.1500,                 loss: 0.0246
Episode: 41/10000 (0.4100%),                 avg. length: 1456.2,                last time consumption/overall running time: 584.4823s / 1198.1354 s
first_0:                 episode reward: 2.2500,                 loss: nan
second_0:                 episode reward: -2.2500,                 loss: 0.0269
Episode: 61/10000 (0.6100%),                 avg. length: 1315.35,                last time consumption/overall running time: 537.2902s / 1735.4256 s
first_0:                 episode reward: -0.7500,                 loss: nan
second_0:                 episode reward: 0.7500,                 loss: 0.0406
Episode: 81/10000 (0.8100%),                 avg. length: 1320.45,                last time consumption/overall running time: 544.9116s / 2280.3372 s
first_0:                 episode reward: -31.2500,                 loss: nan
second_0:                 episode reward: 31.2500,                 loss: 0.0611
Episode: 101/10000 (1.0100%),                 avg. length: 1294.85,                last time consumption/overall running time: 539.4455s / 2819.7827 s
first_0:                 episode reward: -12.1000,                 loss: nan
second_0:                 episode reward: 12.1000,                 loss: 0.0665
Episode: 121/10000 (1.2100%),                 avg. length: 1278.1,                last time consumption/overall running time: 531.9130s / 3351.6957 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0778
Episode: 141/10000 (1.4100%),                 avg. length: 1548.7,                last time consumption/overall running time: 645.8724s / 3997.5681 s
first_0:                 episode reward: -37.8500,                 loss: nan
second_0:                 episode reward: 37.8500,                 loss: 0.0733
Episode: 161/10000 (1.6100%),                 avg. length: 1503.7,                last time consumption/overall running time: 626.0269s / 4623.5949 s
first_0:                 episode reward: -6.7500,                 loss: nan
second_0:                 episode reward: 6.7500,                 loss: 0.0768
Episode: 181/10000 (1.8100%),                 avg. length: 1359.65,                last time consumption/overall running time: 566.0589s / 5189.6538 s
first_0:                 episode reward: -12.4500,                 loss: nan
second_0:                 episode reward: 12.4500,                 loss: 0.0816
Episode: 201/10000 (2.0100%),                 avg. length: 1370.25,                last time consumption/overall running time: 568.4818s / 5758.1357 s
first_0:                 episode reward: 7.4500,                 loss: nan
second_0:                 episode reward: -7.4500,                 loss: 0.0751
Episode: 221/10000 (2.2100%),                 avg. length: 1182.45,                last time consumption/overall running time: 491.8754s / 6250.0111 s
first_0:                 episode reward: -26.8500,                 loss: nan
second_0:                 episode reward: 26.8500,                 loss: 0.0777
Episode: 241/10000 (2.4100%),                 avg. length: 1350.9,                last time consumption/overall running time: 567.0376s / 6817.0487 s
first_0:                 episode reward: -39.9500,                 loss: nan
second_0:                 episode reward: 39.9500,                 loss: 0.0897
Episode: 261/10000 (2.6100%),                 avg. length: 1504.35,                last time consumption/overall running time: 632.4502s / 7449.4989 s
first_0:                 episode reward: -35.7500,                 loss: nan
second_0:                 episode reward: 35.7500,                 loss: 0.1175
Episode: 281/10000 (2.8100%),                 avg. length: 1602.1,                last time consumption/overall running time: 673.9429s / 8123.4417 s
first_0:                 episode reward: -7.8500,                 loss: nan
second_0:                 episode reward: 7.8500,                 loss: 0.1205
Episode: 301/10000 (3.0100%),                 avg. length: 1498.85,                last time consumption/overall running time: 617.5378s / 8740.9795 s
first_0:                 episode reward: -16.0500,                 loss: nan
second_0:                 episode reward: 16.0500,                 loss: 0.1206
Episode: 321/10000 (3.2100%),                 avg. length: 1305.6,                last time consumption/overall running time: 534.3959s / 9275.3754 s
first_0:                 episode reward: -29.8000,                 loss: nan
second_0:                 episode reward: 29.8000,                 loss: 0.0973
Episode: 341/10000 (3.4100%),                 avg. length: 1165.3,                last time consumption/overall running time: 478.4147s / 9753.7901 s
first_0:                 episode reward: -33.7000,                 loss: nan
second_0:                 episode reward: 33.7000,                 loss: 0.1058
Episode: 361/10000 (3.6100%),                 avg. length: 1348.8,                last time consumption/overall running time: 550.3107s / 10304.1008 s
first_0:                 episode reward: -25.2500,                 loss: nan
second_0:                 episode reward: 25.2500,                 loss: 0.1202
Episode: 381/10000 (3.8100%),                 avg. length: 1280.95,                last time consumption/overall running time: 522.0093s / 10826.1101 s
first_0:                 episode reward: -58.5000,                 loss: nan
second_0:                 episode reward: 58.5000,                 loss: 0.1209
Episode: 401/10000 (4.0100%),                 avg. length: 1587.75,                last time consumption/overall running time: 650.2709s / 11476.3810 s
first_0:                 episode reward: -13.8000,                 loss: nan
second_0:                 episode reward: 13.8000,                 loss: 0.1032
Episode: 421/10000 (4.2100%),                 avg. length: 1125.65,                last time consumption/overall running time: 462.5199s / 11938.9009 s
first_0:                 episode reward: -16.0500,                 loss: nan
second_0:                 episode reward: 16.0500,                 loss: 0.0870
Episode: 441/10000 (4.4100%),                 avg. length: 1507.85,                last time consumption/overall running time: 620.0507s / 12558.9516 s
first_0:                 episode reward: -30.1000,                 loss: nan
second_0:                 episode reward: 30.1000,                 loss: 0.0761
Episode: 461/10000 (4.6100%),                 avg. length: 1318.4,                last time consumption/overall running time: 540.8882s / 13099.8398 s
first_0:                 episode reward: -23.8500,                 loss: nan
second_0:                 episode reward: 23.8500,                 loss: 0.0677
Episode: 481/10000 (4.8100%),                 avg. length: 1344.1,                last time consumption/overall running time: 553.8072s / 13653.6470 s
first_0:                 episode reward: -21.7500,                 loss: nan
second_0:                 episode reward: 21.7500,                 loss: 0.0755
Episode: 501/10000 (5.0100%),                 avg. length: 989.7,                last time consumption/overall running time: 404.4235s / 14058.0705 s
first_0:                 episode reward: -18.2000,                 loss: nan
second_0:                 episode reward: 18.2000,                 loss: 0.0795
Episode: 521/10000 (5.2100%),                 avg. length: 1558.85,                last time consumption/overall running time: 635.9466s / 14694.0171 s
first_0:                 episode reward: -12.7500,                 loss: nan
second_0:                 episode reward: 12.7500,                 loss: 0.0818
Episode: 541/10000 (5.4100%),                 avg. length: 1291.6,                last time consumption/overall running time: 536.4242s / 15230.4413 s
first_0:                 episode reward: -42.3500,                 loss: nan
second_0:                 episode reward: 42.3500,                 loss: 0.0834
Episode: 561/10000 (5.6100%),                 avg. length: 1191.3,                last time consumption/overall running time: 496.9130s / 15727.3543 s
first_0:                 episode reward: -48.3000,                 loss: nan
second_0:                 episode reward: 48.3000,                 loss: 0.0902
Episode: 581/10000 (5.8100%),                 avg. length: 1035.45,                last time consumption/overall running time: 436.1599s / 16163.5142 s
first_0:                 episode reward: -49.6500,                 loss: nan
second_0:                 episode reward: 49.6500,                 loss: 0.1108
Episode: 601/10000 (6.0100%),                 avg. length: 1023.5,                last time consumption/overall running time: 429.8238s / 16593.3380 s
first_0:                 episode reward: -22.4000,                 loss: nan
second_0:                 episode reward: 22.4000,                 loss: 0.1285
Episode: 621/10000 (6.2100%),                 avg. length: 989.0,                last time consumption/overall running time: 416.9461s / 17010.2842 s
first_0:                 episode reward: -49.7500,                 loss: nan
second_0:                 episode reward: 49.7500,                 loss: 0.1311
Episode: 641/10000 (6.4100%),                 avg. length: 920.65,                last time consumption/overall running time: 386.2235s / 17396.5076 s
first_0:                 episode reward: -60.4000,                 loss: nan
second_0:                 episode reward: 60.4000,                 loss: 0.1188
Episode: 661/10000 (6.6100%),                 avg. length: 831.0,                last time consumption/overall running time: 346.6107s / 17743.1184 s
first_0:                 episode reward: -68.5500,                 loss: nan
second_0:                 episode reward: 68.5500,                 loss: 0.1158
Episode: 681/10000 (6.8100%),                 avg. length: 839.05,                last time consumption/overall running time: 349.5427s / 18092.6611 s
first_0:                 episode reward: -55.8000,                 loss: nan
second_0:                 episode reward: 55.8000,                 loss: 0.0992
Episode: 701/10000 (7.0100%),                 avg. length: 638.2,                last time consumption/overall running time: 266.5210s / 18359.1821 s
first_0:                 episode reward: -62.6500,                 loss: nan
second_0:                 episode reward: 62.6500,                 loss: 0.1013
Episode: 721/10000 (7.2100%),                 avg. length: 728.05,                last time consumption/overall running time: 304.0562s / 18663.2383 s
first_0:                 episode reward: -79.3500,                 loss: nan
second_0:                 episode reward: 79.3500,                 loss: 0.0955
Episode: 741/10000 (7.4100%),                 avg. length: 812.15,                last time consumption/overall running time: 339.3694s / 19002.6077 s
first_0:                 episode reward: -48.8000,                 loss: nan
second_0:                 episode reward: 48.8000,                 loss: 0.0956
Episode: 761/10000 (7.6100%),                 avg. length: 954.25,                last time consumption/overall running time: 396.2703s / 19398.8780 s
first_0:                 episode reward: -54.6500,                 loss: nan
second_0:                 episode reward: 54.6500,                 loss: 0.0963
Episode: 781/10000 (7.8100%),                 avg. length: 728.55,                last time consumption/overall running time: 300.9219s / 19699.7999 s
first_0:                 episode reward: -82.1000,                 loss: nan
second_0:                 episode reward: 82.1000,                 loss: 0.0971
Episode: 801/10000 (8.0100%),                 avg. length: 570.5,                last time consumption/overall running time: 236.6985s / 19936.4985 s
first_0:                 episode reward: -69.5500,                 loss: nan
second_0:                 episode reward: 69.5500,                 loss: 0.0944
Episode: 821/10000 (8.2100%),                 avg. length: 538.8,                last time consumption/overall running time: 221.3919s / 20157.8904 s
first_0:                 episode reward: -82.3000,                 loss: nan
second_0:                 episode reward: 82.3000,                 loss: 0.1037
Episode: 841/10000 (8.4100%),                 avg. length: 897.4,                last time consumption/overall running time: 371.8686s / 20529.7590 s
first_0:                 episode reward: -54.2000,                 loss: nan
second_0:                 episode reward: 54.2000,                 loss: 0.1073
Episode: 861/10000 (8.6100%),                 avg. length: 921.85,                last time consumption/overall running time: 382.1103s / 20911.8693 s
first_0:                 episode reward: -61.5500,                 loss: nan
second_0:                 episode reward: 61.5500,                 loss: 0.1031
Episode: 881/10000 (8.8100%),                 avg. length: 947.85,                last time consumption/overall running time: 392.4984s / 21304.3677 s
first_0:                 episode reward: -68.0500,                 loss: nan
second_0:                 episode reward: 68.0500,                 loss: 0.0887
Episode: 901/10000 (9.0100%),                 avg. length: 837.7,                last time consumption/overall running time: 345.2367s / 21649.6043 s
first_0:                 episode reward: -79.7500,                 loss: nan
second_0:                 episode reward: 79.7500,                 loss: 0.0931
Episode: 921/10000 (9.2100%),                 avg. length: 821.55,                last time consumption/overall running time: 339.5251s / 21989.1295 s
first_0:                 episode reward: -63.8000,                 loss: nan
second_0:                 episode reward: 63.8000,                 loss: 0.0959
Episode: 941/10000 (9.4100%),                 avg. length: 861.7,                last time consumption/overall running time: 355.6550s / 22344.7844 s
first_0:                 episode reward: -66.1000,                 loss: nan
second_0:                 episode reward: 66.1000,                 loss: 0.0956
Episode: 961/10000 (9.6100%),                 avg. length: 815.7,                last time consumption/overall running time: 337.4318s / 22682.2162 s
first_0:                 episode reward: -72.9500,                 loss: nan
second_0:                 episode reward: 72.9500,                 loss: 0.0918
Episode: 981/10000 (9.8100%),                 avg. length: 737.65,                last time consumption/overall running time: 302.6942s / 22984.9104 s
first_0:                 episode reward: -57.3500,                 loss: nan
second_0:                 episode reward: 57.3500,                 loss: 0.0909
Episode: 1001/10000 (10.0100%),                 avg. length: 562.35,                last time consumption/overall running time: 230.0937s / 23215.0041 s
first_0:                 episode reward: -77.4500,                 loss: nan
second_0:                 episode reward: 77.4500,                 loss: 0.0937
Episode: 1021/10000 (10.2100%),                 avg. length: 747.9,                last time consumption/overall running time: 306.2773s / 23521.2814 s
first_0:                 episode reward: -71.9000,                 loss: nan
second_0:                 episode reward: 71.9000,                 loss: 0.1024
Episode: 1041/10000 (10.4100%),                 avg. length: 847.25,                last time consumption/overall running time: 347.7772s / 23869.0585 s
first_0:                 episode reward: -60.0500,                 loss: nan
second_0:                 episode reward: 60.0500,                 loss: 0.0989
Episode: 1061/10000 (10.6100%),                 avg. length: 718.65,                last time consumption/overall running time: 297.2666s / 24166.3251 s
first_0:                 episode reward: -82.9000,                 loss: nan
second_0:                 episode reward: 82.9000,                 loss: 0.0915
Episode: 1081/10000 (10.8100%),                 avg. length: 631.45,                last time consumption/overall running time: 261.6963s / 24428.0214 s
first_0:                 episode reward: -68.4000,                 loss: nan
second_0:                 episode reward: 68.4000,                 loss: 0.0944
Episode: 1101/10000 (11.0100%),                 avg. length: 679.45,                last time consumption/overall running time: 280.2014s / 24708.2228 s
first_0:                 episode reward: -73.3500,                 loss: nan
second_0:                 episode reward: 73.3500,                 loss: 0.1038
Episode: 1121/10000 (11.2100%),                 avg. length: 818.95,                last time consumption/overall running time: 336.2062s / 25044.4290 s
first_0:                 episode reward: -76.4500,                 loss: nan
second_0:                 episode reward: 76.4500,                 loss: 0.1030
Episode: 1141/10000 (11.4100%),                 avg. length: 628.5,                last time consumption/overall running time: 258.8050s / 25303.2340 s
first_0:                 episode reward: -77.5000,                 loss: nan
second_0:                 episode reward: 77.5000,                 loss: 0.0995
Episode: 1161/10000 (11.6100%),                 avg. length: 789.05,                last time consumption/overall running time: 320.4106s / 25623.6446 s
first_0:                 episode reward: -66.7500,                 loss: nan
second_0:                 episode reward: 66.7500,                 loss: 0.0948
Episode: 1181/10000 (11.8100%),                 avg. length: 571.4,                last time consumption/overall running time: 237.3531s / 25860.9978 s
first_0:                 episode reward: -63.0000,                 loss: nan
second_0:                 episode reward: 63.0000,                 loss: 0.0899
Episode: 1201/10000 (12.0100%),                 avg. length: 947.8,                last time consumption/overall running time: 392.9525s / 26253.9503 s
first_0:                 episode reward: -60.0500,                 loss: nan
second_0:                 episode reward: 60.0500,                 loss: 0.0938
Episode: 1221/10000 (12.2100%),                 avg. length: 682.85,                last time consumption/overall running time: 281.9350s / 26535.8853 s
first_0:                 episode reward: -79.2000,                 loss: nan
second_0:                 episode reward: 79.2000,                 loss: 0.0878
Episode: 1241/10000 (12.4100%),                 avg. length: 507.6,                last time consumption/overall running time: 210.6468s / 26746.5321 s
first_0:                 episode reward: -93.4000,                 loss: nan
second_0:                 episode reward: 93.4000,                 loss: 0.0853
Episode: 1261/10000 (12.6100%),                 avg. length: 562.25,                last time consumption/overall running time: 234.2106s / 26980.7428 s
first_0:                 episode reward: -73.9500,                 loss: nan
second_0:                 episode reward: 73.9500,                 loss: 0.0885
Episode: 1281/10000 (12.8100%),                 avg. length: 614.85,                last time consumption/overall running time: 255.5043s / 27236.2471 s
first_0:                 episode reward: -69.1000,                 loss: nan
second_0:                 episode reward: 69.1000,                 loss: 0.0903
Episode: 1301/10000 (13.0100%),                 avg. length: 752.2,                last time consumption/overall running time: 312.5992s / 27548.8463 s
first_0:                 episode reward: -74.1000,                 loss: nan
second_0:                 episode reward: 74.1000,                 loss: 0.0927
Episode: 1321/10000 (13.2100%),                 avg. length: 830.0,                last time consumption/overall running time: 345.5547s / 27894.4010 s
first_0:                 episode reward: -53.4500,                 loss: nan
second_0:                 episode reward: 53.4500,                 loss: 0.0919
Episode: 1341/10000 (13.4100%),                 avg. length: 861.2,                last time consumption/overall running time: 358.7262s / 28253.1272 s
first_0:                 episode reward: -67.6500,                 loss: nan
second_0:                 episode reward: 67.6500,                 loss: 0.0884
Episode: 1361/10000 (13.6100%),                 avg. length: 684.6,                last time consumption/overall running time: 282.8907s / 28536.0179 s
first_0:                 episode reward: -82.8500,                 loss: nan
second_0:                 episode reward: 82.8500,                 loss: 0.0819
Episode: 1381/10000 (13.8100%),                 avg. length: 780.8,                last time consumption/overall running time: 323.1756s / 28859.1935 s
first_0:                 episode reward: -79.3000,                 loss: nan
second_0:                 episode reward: 79.3000,                 loss: 0.0772
Episode: 1401/10000 (14.0100%),                 avg. length: 631.35,                last time consumption/overall running time: 257.4766s / 29116.6700 s
first_0:                 episode reward: -93.7000,                 loss: nan
second_0:                 episode reward: 93.7000,                 loss: 0.0697
Episode: 1421/10000 (14.2100%),                 avg. length: 758.85,                last time consumption/overall running time: 294.6795s / 29411.3496 s
first_0:                 episode reward: -59.1500,                 loss: nan
second_0:                 episode reward: 59.1500,                 loss: 0.0651
Episode: 1441/10000 (14.4100%),                 avg. length: 851.9,                last time consumption/overall running time: 330.7890s / 29742.1385 s
first_0:                 episode reward: -70.8500,                 loss: nan
second_0:                 episode reward: 70.8500,                 loss: 0.0638
Episode: 1461/10000 (14.6100%),                 avg. length: 783.25,                last time consumption/overall running time: 305.3528s / 30047.4914 s
first_0:                 episode reward: -71.3500,                 loss: nan
second_0:                 episode reward: 71.3500,                 loss: 0.0606
Episode: 1481/10000 (14.8100%),                 avg. length: 772.7,                last time consumption/overall running time: 299.9683s / 30347.4597 s
first_0:                 episode reward: -55.0500,                 loss: nan
second_0:                 episode reward: 55.0500,                 loss: 0.0582
Episode: 1501/10000 (15.0100%),                 avg. length: 809.1,                last time consumption/overall running time: 314.4036s / 30661.8633 s
first_0:                 episode reward: -89.6500,                 loss: nan
second_0:                 episode reward: 89.6500,                 loss: 0.0555
Episode: 1521/10000 (15.2100%),                 avg. length: 601.45,                last time consumption/overall running time: 234.5419s / 30896.4052 s
first_0:                 episode reward: -82.5000,                 loss: nan
second_0:                 episode reward: 82.5000,                 loss: 0.0561
Episode: 1541/10000 (15.4100%),                 avg. length: 998.55,                last time consumption/overall running time: 388.5814s / 31284.9866 s
first_0:                 episode reward: -63.1000,                 loss: nan
second_0:                 episode reward: 63.1000,                 loss: 0.0596
Episode: 1561/10000 (15.6100%),                 avg. length: 886.4,                last time consumption/overall running time: 345.8464s / 31630.8330 s
first_0:                 episode reward: -73.0500,                 loss: nan
second_0:                 episode reward: 73.0500,                 loss: 0.0588
Episode: 1581/10000 (15.8100%),                 avg. length: 713.4,                last time consumption/overall running time: 280.4504s / 31911.2833 s
first_0:                 episode reward: -87.4000,                 loss: nan
second_0:                 episode reward: 87.4000,                 loss: 0.0566
Episode: 1601/10000 (16.0100%),                 avg. length: 768.25,                last time consumption/overall running time: 300.5980s / 32211.8813 s
first_0:                 episode reward: -74.3500,                 loss: nan
second_0:                 episode reward: 74.3500,                 loss: 0.0605
Episode: 1621/10000 (16.2100%),                 avg. length: 688.6,                last time consumption/overall running time: 269.1178s / 32480.9991 s
first_0:                 episode reward: -72.3000,                 loss: nan
second_0:                 episode reward: 72.3000,                 loss: 0.0624
Episode: 1641/10000 (16.4100%),                 avg. length: 705.6,                last time consumption/overall running time: 277.1337s / 32758.1329 s
first_0:                 episode reward: -71.8500,                 loss: nan
second_0:                 episode reward: 71.8500,                 loss: 0.0639
Episode: 1661/10000 (16.6100%),                 avg. length: 703.05,                last time consumption/overall running time: 277.2749s / 33035.4077 s
first_0:                 episode reward: -81.6500,                 loss: nan
second_0:                 episode reward: 81.6500,                 loss: 0.0628
Episode: 1681/10000 (16.8100%),                 avg. length: 758.45,                last time consumption/overall running time: 298.6423s / 33334.0501 s
first_0:                 episode reward: -66.1500,                 loss: nan
second_0:                 episode reward: 66.1500,                 loss: 0.0608
Episode: 1701/10000 (17.0100%),                 avg. length: 770.9,                last time consumption/overall running time: 300.7207s / 33634.7707 s
first_0:                 episode reward: -69.8000,                 loss: nan
second_0:                 episode reward: 69.8000,                 loss: 0.0649
Episode: 1721/10000 (17.2100%),                 avg. length: 735.85,                last time consumption/overall running time: 288.8940s / 33923.6648 s
first_0:                 episode reward: -65.1000,                 loss: nan
second_0:                 episode reward: 65.1000,                 loss: 0.0660
Episode: 1741/10000 (17.4100%),                 avg. length: 621.15,                last time consumption/overall running time: 242.9403s / 34166.6051 s
first_0:                 episode reward: -66.6500,                 loss: nan
second_0:                 episode reward: 66.6500,                 loss: 0.0671
Episode: 1761/10000 (17.6100%),                 avg. length: 707.0,                last time consumption/overall running time: 277.1339s / 34443.7389 s
first_0:                 episode reward: -55.1500,                 loss: nan
second_0:                 episode reward: 55.1500,                 loss: 0.0661
Episode: 1781/10000 (17.8100%),                 avg. length: 415.7,                last time consumption/overall running time: 162.8582s / 34606.5971 s
first_0:                 episode reward: -79.1000,                 loss: nan
second_0:                 episode reward: 79.1000,                 loss: 0.0667
Episode: 1801/10000 (18.0100%),                 avg. length: 633.95,                last time consumption/overall running time: 249.5168s / 34856.1139 s
first_0:                 episode reward: -71.9500,                 loss: nan
second_0:                 episode reward: 71.9500,                 loss: 0.0625
Episode: 1821/10000 (18.2100%),                 avg. length: 529.05,                last time consumption/overall running time: 208.7739s / 35064.8878 s
first_0:                 episode reward: -83.1500,                 loss: nan
second_0:                 episode reward: 83.1500,                 loss: 0.0615
Episode: 1841/10000 (18.4100%),                 avg. length: 718.65,                last time consumption/overall running time: 283.6286s / 35348.5165 s
first_0:                 episode reward: -81.1000,                 loss: nan
second_0:                 episode reward: 81.1000,                 loss: 0.0613
Episode: 1861/10000 (18.6100%),                 avg. length: 840.3,                last time consumption/overall running time: 331.1950s / 35679.7114 s
first_0:                 episode reward: -78.2500,                 loss: nan
second_0:                 episode reward: 78.2500,                 loss: 0.0590
Episode: 1881/10000 (18.8100%),                 avg. length: 608.45,                last time consumption/overall running time: 239.8969s / 35919.6083 s
first_0:                 episode reward: -80.2500,                 loss: nan
second_0:                 episode reward: 80.2500,                 loss: 0.0535
Episode: 1901/10000 (19.0100%),                 avg. length: 921.05,                last time consumption/overall running time: 361.7615s / 36281.3698 s
first_0:                 episode reward: -53.4500,                 loss: nan
second_0:                 episode reward: 53.4500,                 loss: 0.0560