pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
random seed: 91
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7eff9c1f3780>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [array([0.013, 0.013, 0.013, ..., 0.013, 0.013, 0.013]) array([0.014, 0.014, 0.014, ..., 0.014, 0.014, 0.014])]
Load checkpoints (policy family):  [list(['29', '100', '194', '242', '284', '330', '378', '422', '465', '507', '549', '636', '685', '752', '818', '906', '968', '1010', '1056', '1103', '1192', '1252', '1377', '1425', '1510', '1612', '1704', '1770', '1828', '1970', '2055', '2146', '2262', '2353', '2434', '2541', '2647', '2794', '2886', '3024', '3124', '3237', '3323', '3414', '3530', '3642', '3745', '3844', '3957', '4062', '4164', '4273', '4406', '4578', '4699', '4864', '4983', '5161', '5316', '5475', '5617', '5765', '5891', '6112', '6278', '6420', '6554', '6718', '6894', '7035', '7243', '7419', '7646', '7797', '7977'])
 list(['50', '141', '215', '263', '305', '351', '399', '443', '486', '528', '605', '659', '713', '776', '841', '935', '989', '1035', '1082', '1138', '1221', '1297', '1401', '1485', '1552', '1639', '1732', '1799', '1875', '2007', '2089', '2191', '2296', '2388', '2503', '2610', '2725', '2847', '2926', '3083', '3175', '3280', '3370', '3477', '3579', '3689', '3793', '3907', '4012', '4113', '4221', '4339', '4460', '4644', '4755', '4926', '5041', '5221', '5386', '5556', '5680', '5828', '5955', '6213', '6344', '6487', '6623', '6812', '6964', '7106', '7316', '7514', '7720', '7872'])]
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220119_0526/pettingzoo_pong_v2_fictitious_selfplay2/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 30, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220119_0526_exploit/pettingzoo_pong_v2_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0526_exploit/pettingzoo_pong_v2_fictitious_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 906.0,                last time consumption/overall running time: 77.7759s / 77.7759 s
first_0:                 episode reward: 19.0000,                 loss: nan
second_0:                 episode reward: -19.0000,                 loss: 0.0109
Episode: 21/10000 (0.2100%),                 avg. length: 1161.05,                last time consumption/overall running time: 609.7522s / 687.5281 s
first_0:                 episode reward: 14.6000,                 loss: nan
second_0:                 episode reward: -14.6000,                 loss: 0.0037
Episode: 41/10000 (0.4100%),                 avg. length: 2135.15,                last time consumption/overall running time: 1163.3926s / 1850.9207 s
first_0:                 episode reward: 12.1500,                 loss: nan
second_0:                 episode reward: -12.1500,                 loss: 0.0069
Episode: 61/10000 (0.6100%),                 avg. length: 3376.5,                last time consumption/overall running time: 1882.3331s / 3733.2538 s
first_0:                 episode reward: -22.1000,                 loss: nan
second_0:                 episode reward: 22.1000,                 loss: 0.0072
Episode: 81/10000 (0.8100%),                 avg. length: 3391.8,                last time consumption/overall running time: 1902.0650s / 5635.3188 s
first_0:                 episode reward: -11.0000,                 loss: nan
second_0:                 episode reward: 11.0000,                 loss: 0.0057
Episode: 101/10000 (1.0100%),                 avg. length: 3132.35,                last time consumption/overall running time: 1757.2063s / 7392.5251 s
first_0:                 episode reward: -14.2000,                 loss: nan
second_0:                 episode reward: 14.2000,                 loss: 0.0045
Episode: 121/10000 (1.2100%),                 avg. length: 2983.6,                last time consumption/overall running time: 1673.7822s / 9066.3073 s
first_0:                 episode reward: -11.4000,                 loss: nan
second_0:                 episode reward: 11.4000,                 loss: 0.0043
Episode: 141/10000 (1.4100%),                 avg. length: 3436.2,                last time consumption/overall running time: 1925.9587s / 10992.2660 s
first_0:                 episode reward: -9.7500,                 loss: nan
second_0:                 episode reward: 9.7500,                 loss: 0.0039
Episode: 161/10000 (1.6100%),                 avg. length: 2898.4,                last time consumption/overall running time: 1622.9014s / 12615.1674 s
first_0:                 episode reward: -12.7000,                 loss: nan
second_0:                 episode reward: 12.7000,                 loss: 0.0041
Episode: 181/10000 (1.8100%),                 avg. length: 2640.6,                last time consumption/overall running time: 1480.2104s / 14095.3778 s
first_0:                 episode reward: -14.8000,                 loss: nan
second_0:                 episode reward: 14.8000,                 loss: 0.0038
Episode: 201/10000 (2.0100%),                 avg. length: 3235.9,                last time consumption/overall running time: 1807.7681s / 15903.1460 s
first_0:                 episode reward: -28.5000,                 loss: nan
second_0:                 episode reward: 28.5000,                 loss: 0.0046
Episode: 221/10000 (2.2100%),                 avg. length: 3816.2,                last time consumption/overall running time: 2137.5295s / 18040.6754 s
first_0:                 episode reward: -46.0000,                 loss: nan
second_0:                 episode reward: 46.0000,                 loss: 0.0056
Episode: 241/10000 (2.4100%),                 avg. length: 3852.7,                last time consumption/overall running time: 2152.8181s / 20193.4935 s
first_0:                 episode reward: -38.3000,                 loss: nan
second_0:                 episode reward: 38.3000,                 loss: 0.0064
Episode: 261/10000 (2.6100%),                 avg. length: 3227.1,                last time consumption/overall running time: 1803.5921s / 21997.0856 s
first_0:                 episode reward: -13.1500,                 loss: nan
second_0:                 episode reward: 13.1500,                 loss: 0.0056
Episode: 281/10000 (2.8100%),                 avg. length: 3138.35,                last time consumption/overall running time: 1754.3051s / 23751.3907 s
first_0:                 episode reward: -10.6000,                 loss: nan
second_0:                 episode reward: 10.6000,                 loss: 0.0047
Episode: 301/10000 (3.0100%),                 avg. length: 2770.2,                last time consumption/overall running time: 1548.1080s / 25299.4987 s
first_0:                 episode reward: -11.1500,                 loss: nan
second_0:                 episode reward: 11.1500,                 loss: 0.0034
Episode: 321/10000 (3.2100%),                 avg. length: 3121.35,                last time consumption/overall running time: 1744.0901s / 27043.5888 s
first_0:                 episode reward: -14.8000,                 loss: nan
second_0:                 episode reward: 14.8000,                 loss: 0.0032
Episode: 341/10000 (3.4100%),                 avg. length: 3400.9,                last time consumption/overall running time: 1903.7910s / 28947.3798 s
first_0:                 episode reward: -16.4500,                 loss: nan
second_0:                 episode reward: 16.4500,                 loss: 0.0034
Episode: 361/10000 (3.6100%),                 avg. length: 2910.95,                last time consumption/overall running time: 1632.6496s / 30580.0294 s
first_0:                 episode reward: -12.1500,                 loss: nan
second_0:                 episode reward: 12.1500,                 loss: 0.0035
Episode: 381/10000 (3.8100%),                 avg. length: 2839.5,                last time consumption/overall running time: 1585.5496s / 32165.5790 s
first_0:                 episode reward: -14.0500,                 loss: nan
second_0:                 episode reward: 14.0500,                 loss: 0.0030
Episode: 401/10000 (4.0100%),                 avg. length: 2942.8,                last time consumption/overall running time: 1645.8153s / 33811.3944 s
first_0:                 episode reward: -13.3000,                 loss: nan
second_0:                 episode reward: 13.3000,                 loss: 0.0027
Episode: 421/10000 (4.2100%),                 avg. length: 2934.55,                last time consumption/overall running time: 1641.0775s / 35452.4718 s
first_0:                 episode reward: -12.6500,                 loss: nan
second_0:                 episode reward: 12.6500,                 loss: 0.0031
Episode: 441/10000 (4.4100%),                 avg. length: 2643.6,                last time consumption/overall running time: 1476.5469s / 36929.0188 s
first_0:                 episode reward: -18.1000,                 loss: nan
second_0:                 episode reward: 18.1000,                 loss: 0.0037
Episode: 461/10000 (4.6100%),                 avg. length: 3961.9,                last time consumption/overall running time: 2213.7146s / 39142.7334 s
first_0:                 episode reward: -57.5500,                 loss: nan
second_0:                 episode reward: 57.5500,                 loss: 0.0050
Episode: 481/10000 (4.8100%),                 avg. length: 3358.45,                last time consumption/overall running time: 1876.5081s / 41019.2415 s
first_0:                 episode reward: -13.2000,                 loss: nan
second_0:                 episode reward: 13.2000,                 loss: 0.0074
Episode: 501/10000 (5.0100%),                 avg. length: 3249.0,                last time consumption/overall running time: 1811.7824s / 42831.0239 s
first_0:                 episode reward: -25.6000,                 loss: nan
second_0:                 episode reward: 25.6000,                 loss: 0.0049
Episode: 521/10000 (5.2100%),                 avg. length: 3318.55,                last time consumption/overall running time: 1853.7753s / 44684.7992 s
first_0:                 episode reward: -17.3500,                 loss: nan
second_0:                 episode reward: 17.3500,                 loss: 0.0051
Episode: 541/10000 (5.4100%),                 avg. length: 4118.4,                last time consumption/overall running time: 2301.2545s / 46986.0537 s
first_0:                 episode reward: -45.3500,                 loss: nan
second_0:                 episode reward: 45.3500,                 loss: 0.0057
Episode: 561/10000 (5.6100%),                 avg. length: 3373.9,                last time consumption/overall running time: 1883.5385s / 48869.5921 s
first_0:                 episode reward: -21.6000,                 loss: nan
second_0:                 episode reward: 21.6000,                 loss: 0.0059
Episode: 581/10000 (5.8100%),                 avg. length: 3374.3,                last time consumption/overall running time: 1794.0649s / 50663.6571 s
first_0:                 episode reward: -23.4000,                 loss: nan
second_0:                 episode reward: 23.4000,                 loss: 0.0050
Episode: 601/10000 (6.0100%),                 avg. length: 2950.0,                last time consumption/overall running time: 1553.8180s / 52217.4751 s
first_0:                 episode reward: -12.9500,                 loss: nan
second_0:                 episode reward: 12.9500,                 loss: 0.0046
Episode: 621/10000 (6.2100%),                 avg. length: 2729.05,                last time consumption/overall running time: 1416.5759s / 53634.0510 s
first_0:                 episode reward: -14.7000,                 loss: nan
second_0:                 episode reward: 14.7000,                 loss: 0.0040
Episode: 641/10000 (6.4100%),                 avg. length: 3120.35,                last time consumption/overall running time: 1563.7372s / 55197.7882 s
first_0:                 episode reward: -10.6500,                 loss: nan
second_0:                 episode reward: 10.6500,                 loss: 0.0033
Episode: 661/10000 (6.6100%),                 avg. length: 2812.8,                last time consumption/overall running time: 1409.1653s / 56606.9535 s
first_0:                 episode reward: -12.5000,                 loss: nan
second_0:                 episode reward: 12.5000,                 loss: 0.0033
Episode: 681/10000 (6.8100%),                 avg. length: 3102.25,                last time consumption/overall running time: 1549.8186s / 58156.7721 s
first_0:                 episode reward: -23.5000,                 loss: nan
second_0:                 episode reward: 23.5000,                 loss: 0.0040
Episode: 701/10000 (7.0100%),                 avg. length: 2601.8,                last time consumption/overall running time: 1304.9342s / 59461.7063 s
first_0:                 episode reward: -13.7500,                 loss: nan
second_0:                 episode reward: 13.7500,                 loss: 0.0042
Episode: 721/10000 (7.2100%),                 avg. length: 3755.95,                last time consumption/overall running time: 1880.4825s / 61342.1889 s
first_0:                 episode reward: -36.4000,                 loss: nan
second_0:                 episode reward: 36.4000,                 loss: 0.0045
Episode: 741/10000 (7.4100%),                 avg. length: 3121.0,                last time consumption/overall running time: 1562.8430s / 62905.0319 s
first_0:                 episode reward: -18.3000,                 loss: nan
second_0:                 episode reward: 18.3000,                 loss: 0.0055
Episode: 761/10000 (7.6100%),                 avg. length: 3044.3,                last time consumption/overall running time: 1516.1377s / 64421.1696 s
first_0:                 episode reward: -19.6000,                 loss: nan
second_0:                 episode reward: 19.6000,                 loss: 0.0047
Episode: 781/10000 (7.8100%),                 avg. length: 3550.2,                last time consumption/overall running time: 1659.9904s / 66081.1599 s
first_0:                 episode reward: -21.5000,                 loss: nan
second_0:                 episode reward: 21.5000,                 loss: 0.0049
Episode: 801/10000 (8.0100%),                 avg. length: 3809.3,                last time consumption/overall running time: 1783.6474s / 67864.8073 s
first_0:                 episode reward: -40.5500,                 loss: nan
second_0:                 episode reward: 40.5500,                 loss: 0.0048
Episode: 821/10000 (8.2100%),                 avg. length: 3107.9,                last time consumption/overall running time: 1452.6331s / 69317.4404 s
first_0:                 episode reward: -21.7500,                 loss: nan
second_0:                 episode reward: 21.7500,                 loss: 0.0058
Episode: 841/10000 (8.4100%),                 avg. length: 2843.7,                last time consumption/overall running time: 1330.2111s / 70647.6514 s
first_0:                 episode reward: -17.0500,                 loss: nan
second_0:                 episode reward: 17.0500,                 loss: 0.0049
Episode: 861/10000 (8.6100%),                 avg. length: 2667.45,                last time consumption/overall running time: 1248.1333s / 71895.7847 s
first_0:                 episode reward: -14.1000,                 loss: nan
second_0:                 episode reward: 14.1000,                 loss: 0.0043
Episode: 881/10000 (8.8100%),                 avg. length: 3239.8,                last time consumption/overall running time: 1513.5498s / 73409.3345 s
first_0:                 episode reward: -15.6500,                 loss: nan
second_0:                 episode reward: 15.6500,                 loss: 0.0040
Episode: 901/10000 (9.0100%),                 avg. length: 3143.3,                last time consumption/overall running time: 1460.8330s / 74870.1675 s
first_0:                 episode reward: -19.6000,                 loss: nan
second_0:                 episode reward: 19.6000,                 loss: 0.0043
Episode: 921/10000 (9.2100%),                 avg. length: 3419.6,                last time consumption/overall running time: 1443.8673s / 76314.0348 s
first_0:                 episode reward: -23.5500,                 loss: nan
second_0:                 episode reward: 23.5500,                 loss: 0.0043
Episode: 941/10000 (9.4100%),                 avg. length: 2940.9,                last time consumption/overall running time: 1200.1885s / 77514.2233 s
first_0:                 episode reward: -14.9500,                 loss: nan
second_0:                 episode reward: 14.9500,                 loss: 0.0044
Episode: 961/10000 (9.6100%),                 avg. length: 3243.5,                last time consumption/overall running time: 1311.1323s / 78825.3555 s
first_0:                 episode reward: -18.3500,                 loss: nan
second_0:                 episode reward: 18.3500,                 loss: 0.0050
Episode: 981/10000 (9.8100%),                 avg. length: 2884.4,                last time consumption/overall running time: 1102.3700s / 79927.7255 s
first_0:                 episode reward: -12.7500,                 loss: nan
second_0:                 episode reward: 12.7500,                 loss: 0.0046
Episode: 1001/10000 (10.0100%),                 avg. length: 2449.35,                last time consumption/overall running time: 935.2746s / 80863.0001 s
first_0:                 episode reward: -15.5000,                 loss: nan
second_0:                 episode reward: 15.5000,                 loss: 0.0034
Episode: 1021/10000 (10.2100%),                 avg. length: 2660.9,                last time consumption/overall running time: 1015.0608s / 81878.0609 s
first_0:                 episode reward: -14.2000,                 loss: nan
second_0:                 episode reward: 14.2000,                 loss: 0.0030
Episode: 1041/10000 (10.4100%),                 avg. length: 2973.25,                last time consumption/overall running time: 1140.4982s / 83018.5591 s
first_0:                 episode reward: -12.9500,                 loss: nan
second_0:                 episode reward: 12.9500,                 loss: 0.0031
Episode: 1061/10000 (10.6100%),                 avg. length: 3786.65,                last time consumption/overall running time: 1443.4123s / 84461.9714 s
first_0:                 episode reward: -39.2500,                 loss: nan
second_0:                 episode reward: 39.2500,                 loss: 0.0046
Episode: 1081/10000 (10.8100%),                 avg. length: 3193.95,                last time consumption/overall running time: 1217.5574s / 85679.5288 s
first_0:                 episode reward: -17.6500,                 loss: nan
second_0:                 episode reward: 17.6500,                 loss: 0.0056
Episode: 1101/10000 (11.0100%),                 avg. length: 2606.8,                last time consumption/overall running time: 997.4425s / 86676.9713 s
first_0:                 episode reward: -19.5000,                 loss: nan
second_0:                 episode reward: 19.5000,                 loss: 0.0037
Episode: 1121/10000 (11.2100%),                 avg. length: 2943.85,                last time consumption/overall running time: 1125.3168s / 87802.2882 s
first_0:                 episode reward: -24.5000,                 loss: nan
second_0:                 episode reward: 24.5000,                 loss: 0.0039
Episode: 1141/10000 (11.4100%),                 avg. length: 3362.2,                last time consumption/overall running time: 1226.1435s / 89028.4317 s
first_0:                 episode reward: -23.8000,                 loss: nan
second_0:                 episode reward: 23.8000,                 loss: 0.0059
Episode: 1161/10000 (11.6100%),                 avg. length: 3222.4,                last time consumption/overall running time: 1145.1499s / 90173.5816 s
first_0:                 episode reward: -20.4500,                 loss: nan
second_0:                 episode reward: 20.4500,                 loss: 0.0049
Episode: 1181/10000 (11.8100%),                 avg. length: 2639.55,                last time consumption/overall running time: 940.3447s / 91113.9263 s
first_0:                 episode reward: -16.8000,                 loss: nan
second_0:                 episode reward: 16.8000,                 loss: 0.0040
Episode: 1201/10000 (12.0100%),                 avg. length: 2758.3,                last time consumption/overall running time: 982.4227s / 92096.3490 s
first_0:                 episode reward: -13.0000,                 loss: nan
second_0:                 episode reward: 13.0000,                 loss: 0.0042
Episode: 1221/10000 (12.2100%),                 avg. length: 3425.8,                last time consumption/overall running time: 1217.1984s / 93313.5474 s
first_0:                 episode reward: -18.2000,                 loss: nan
second_0:                 episode reward: 18.2000,                 loss: 0.0040
Episode: 1241/10000 (12.4100%),                 avg. length: 3103.5,                last time consumption/overall running time: 1100.3083s / 94413.8557 s
first_0:                 episode reward: -14.0000,                 loss: nan
second_0:                 episode reward: 14.0000,                 loss: 0.0047
Episode: 1261/10000 (12.6100%),                 avg. length: 2843.05,                last time consumption/overall running time: 1009.0895s / 95422.9452 s
first_0:                 episode reward: -16.1000,                 loss: nan
second_0:                 episode reward: 16.1000,                 loss: 0.0037
Episode: 1281/10000 (12.8100%),                 avg. length: 2841.3,                last time consumption/overall running time: 1011.3678s / 96434.3130 s
first_0:                 episode reward: -11.8500,                 loss: nan
second_0:                 episode reward: 11.8500,                 loss: 0.0034
Episode: 1301/10000 (13.0100%),                 avg. length: 3668.7,                last time consumption/overall running time: 1304.0455s / 97738.3585 s
first_0:                 episode reward: -31.8500,                 loss: nan
second_0:                 episode reward: 31.8500,                 loss: 0.0042
Episode: 1321/10000 (13.2100%),                 avg. length: 3352.0,                last time consumption/overall running time: 1190.9660s / 98929.3246 s
first_0:                 episode reward: -18.1500,                 loss: nan
second_0:                 episode reward: 18.1500,                 loss: 0.0056
Episode: 1341/10000 (13.4100%),                 avg. length: 3241.05,                last time consumption/overall running time: 1151.2634s / 100080.5879 s
first_0:                 episode reward: -24.6500,                 loss: nan
second_0:                 episode reward: 24.6500,                 loss: 0.0046
Episode: 1361/10000 (13.6100%),                 avg. length: 3209.5,                last time consumption/overall running time: 1137.5469s / 101218.1348 s
first_0:                 episode reward: -27.0000,                 loss: nan
second_0:                 episode reward: 27.0000,                 loss: 0.0056
Episode: 1381/10000 (13.8100%),                 avg. length: 3478.1,                last time consumption/overall running time: 1233.7258s / 102451.8606 s
first_0:                 episode reward: -25.6000,                 loss: nan
second_0:                 episode reward: 25.6000,                 loss: 0.0050
Episode: 1401/10000 (14.0100%),                 avg. length: 3251.9,                last time consumption/overall running time: 1155.8669s / 103607.7275 s
first_0:                 episode reward: -28.8000,                 loss: nan
second_0:                 episode reward: 28.8000,                 loss: 0.0049
Episode: 1421/10000 (14.2100%),                 avg. length: 2926.2,                last time consumption/overall running time: 1038.8817s / 104646.6092 s
first_0:                 episode reward: -11.8500,                 loss: nan
second_0:                 episode reward: 11.8500,                 loss: 0.0053
Episode: 1441/10000 (14.4100%),                 avg. length: 2525.95,                last time consumption/overall running time: 897.9390s / 105544.5482 s
first_0:                 episode reward: -13.8000,                 loss: nan
second_0:                 episode reward: 13.8000,                 loss: 0.0043
Episode: 1461/10000 (14.6100%),                 avg. length: 3062.25,                last time consumption/overall running time: 1086.1105s / 106630.6587 s
first_0:                 episode reward: -12.3500,                 loss: nan
second_0:                 episode reward: 12.3500,                 loss: 0.0035
Episode: 1481/10000 (14.8100%),                 avg. length: 3400.35,                last time consumption/overall running time: 1207.7634s / 107838.4221 s
first_0:                 episode reward: -25.6500,                 loss: nan
second_0:                 episode reward: 25.6500,                 loss: 0.0041
Episode: 1501/10000 (15.0100%),                 avg. length: 3455.9,                last time consumption/overall running time: 1225.1152s / 109063.5372 s
first_0:                 episode reward: -31.9500,                 loss: nan
second_0:                 episode reward: 31.9500,                 loss: 0.0054
Episode: 1521/10000 (15.2100%),                 avg. length: 2837.55,                last time consumption/overall running time: 1002.6008s / 110066.1380 s
first_0:                 episode reward: -12.2000,                 loss: nan
second_0:                 episode reward: 12.2000,                 loss: 0.0055
Episode: 1541/10000 (15.4100%),                 avg. length: 3213.5,                last time consumption/overall running time: 1134.1830s / 111200.3210 s
first_0:                 episode reward: -10.8500,                 loss: nan
second_0:                 episode reward: 10.8500,                 loss: 0.0041
Episode: 1561/10000 (15.6100%),                 avg. length: 3164.25,                last time consumption/overall running time: 1119.2190s / 112319.5400 s
first_0:                 episode reward: -14.0500,                 loss: nan
second_0:                 episode reward: 14.0500,                 loss: 0.0034
Episode: 1581/10000 (15.8100%),                 avg. length: 2789.65,                last time consumption/overall running time: 984.9509s / 113304.4909 s
first_0:                 episode reward: -16.2000,                 loss: nan
second_0:                 episode reward: 16.2000,                 loss: 0.0038
Episode: 1601/10000 (16.0100%),                 avg. length: 3219.3,                last time consumption/overall running time: 1137.7188s / 114442.2098 s
first_0:                 episode reward: -24.6500,                 loss: nan
second_0:                 episode reward: 24.6500,                 loss: 0.0043
Episode: 1621/10000 (16.2100%),                 avg. length: 2774.2,                last time consumption/overall running time: 948.9105s / 115391.1203 s
first_0:                 episode reward: -16.0500,                 loss: nan
second_0:                 episode reward: 16.0500,                 loss: 0.0053
Episode: 1641/10000 (16.4100%),                 avg. length: 3583.35,                last time consumption/overall running time: 1178.4523s / 116569.5725 s
first_0:                 episode reward: -29.4000,                 loss: nan
second_0:                 episode reward: 29.4000,                 loss: 0.0054
Episode: 1661/10000 (16.6100%),                 avg. length: 3047.85,                last time consumption/overall running time: 1002.7370s / 117572.3096 s
first_0:                 episode reward: -13.7000,                 loss: nan
second_0:                 episode reward: 13.7000,                 loss: 0.0051
Episode: 1681/10000 (16.8100%),                 avg. length: 3138.4,                last time consumption/overall running time: 1034.7532s / 118607.0628 s
first_0:                 episode reward: -25.2000,                 loss: nan
second_0:                 episode reward: 25.2000,                 loss: 0.0035
Episode: 1701/10000 (17.0100%),                 avg. length: 3665.65,                last time consumption/overall running time: 1207.9652s / 119815.0280 s
first_0:                 episode reward: -27.4000,                 loss: nan
second_0:                 episode reward: 27.4000,                 loss: 0.0055
Episode: 1721/10000 (17.2100%),                 avg. length: 3017.7,                last time consumption/overall running time: 916.5401s / 120731.5681 s
first_0:                 episode reward: -15.0500,                 loss: nan
second_0:                 episode reward: 15.0500,                 loss: 0.0059
Episode: 1741/10000 (17.4100%),                 avg. length: 2890.05,                last time consumption/overall running time: 881.0685s / 121612.6366 s
first_0:                 episode reward: -13.7500,                 loss: nan
second_0:                 episode reward: 13.7500,                 loss: 0.0048
Episode: 1761/10000 (17.6100%),                 avg. length: 3688.9,                last time consumption/overall running time: 1121.9173s / 122734.5539 s
first_0:                 episode reward: -43.9000,                 loss: nan
second_0:                 episode reward: 43.9000,                 loss: 0.0047
Episode: 1781/10000 (17.8100%),                 avg. length: 3397.65,                last time consumption/overall running time: 1029.0607s / 123763.6146 s
first_0:                 episode reward: -17.1000,                 loss: nan
second_0:                 episode reward: 17.1000,                 loss: 0.0063
Episode: 1801/10000 (18.0100%),                 avg. length: 3297.25,                last time consumption/overall running time: 1000.4990s / 124764.1135 s
first_0:                 episode reward: -30.4000,                 loss: nan
second_0:                 episode reward: 30.4000,                 loss: 0.0051
Episode: 1821/10000 (18.2100%),                 avg. length: 3271.75,                last time consumption/overall running time: 987.1711s / 125751.2847 s
first_0:                 episode reward: -14.2500,                 loss: nan
second_0:                 episode reward: 14.2500,                 loss: 0.0057
Episode: 1841/10000 (18.4100%),                 avg. length: 3091.5,                last time consumption/overall running time: 933.0547s / 126684.3394 s
first_0:                 episode reward: -12.6000,                 loss: nan
second_0:                 episode reward: 12.6000,                 loss: 0.0041
Episode: 1861/10000 (18.6100%),                 avg. length: 3585.0,                last time consumption/overall running time: 1081.8779s / 127766.2173 s