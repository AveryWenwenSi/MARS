/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
surround_v1 pettingzoo
Load surround_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(5)
random seed: 91
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f4209f234e0>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=256, bias=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=256, bias=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=5, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=256, bias=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=256, bias=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=5, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  ./data/model/20220119_0526/pettingzoo_surround_v1_nash_dqn_exploiter/8000_0
Arguments:  {'env_name': 'surround_v1', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'exploiter_update_itr': 3}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220119_0526/pettingzoo_surround_v1_nash_dqn_exploiter/8000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220119_0526_exploit/pettingzoo_surround_v1_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0526_exploit/pettingzoo_surround_v1_nash_dqn_exploiter.
Traceback (most recent call last):
  File "general_exploit.py", line 49, in <module>
    launch_rollout(parser_args.env, parser_args.method, parser_args.load_id, parser_args.save_id)
  File "general_exploit.py", line 41, in launch_rollout
    rollout(env, model, exploitation_args, save_id = load_id+'_exploit') # save results of exploitation in a separate folder
  File "/home/zihan/research/MARS/mars/rollout.py", line 21, in rollout
    rollout_normal(env, model, save_id, args)
  File "/home/zihan/research/MARS/mars/rollout.py", line 45, in rollout_normal
    obs_to_store)  # action: (agent, env, action_dim)
  File "/home/zihan/research/MARS/mars/rl/agents/multiagent.py", line 137, in choose_action
    nash_actions = self.agents[i].choose_action(np.expand_dims(state, 0), Greedy=greedy)  # (envs, state_dim) to (1, envs, state_dim), 1 for one-side observation
  File "/home/zihan/research/MARS/mars/rl/agents/nash_dqn_exploiter.py", line 77, in choose_action
    q_values = self.normal_nashQ(state).detach().cpu().numpy()  # needs state: (batch, agents*state_dim)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zihan/research/MARS/mars/rl/agents/dqn.py", line 186, in forward
    return self.net(x)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zihan/research/MARS/mars/rl/common/networks.py", line 69, in forward
    x = self.body(x)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/container.py", line 141, in forward
    input = module(input)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/nn/functional.py", line 1958, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`
pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
surround_v1 pettingzoo
Load surround_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(5)
random seed: 91
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f56c754a198>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=256, bias=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=256, bias=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=5, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=256, bias=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=256, bias=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=5, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  ./data/model/20220119_0526/pettingzoo_surround_v1_nash_dqn_exploiter/8000_0
Arguments:  {'env_name': 'surround_v1', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'exploiter_update_itr': 3}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220119_0526/pettingzoo_surround_v1_nash_dqn_exploiter/8000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220119_0526_exploit/pettingzoo_surround_v1_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0526_exploit/pettingzoo_surround_v1_nash_dqn_exploiter.
Episode: 1/10000 (0.0100%),                 avg. length: 1567.0,                last time consumption/overall running time: 25.4008s / 25.4008 s
first_0:                 episode reward: 5.0000,                 loss: nan
second_0:                 episode reward: -5.0000,                 loss: 0.0029
Episode: 21/10000 (0.2100%),                 avg. length: 1658.7,                last time consumption/overall running time: 607.4587s / 632.8595 s
first_0:                 episode reward: -0.0500,                 loss: nan
second_0:                 episode reward: 0.0500,                 loss: 0.0031
Episode: 41/10000 (0.4100%),                 avg. length: 1797.05,                last time consumption/overall running time: 681.5070s / 1314.3664 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0037
Episode: 61/10000 (0.6100%),                 avg. length: 1760.65,                last time consumption/overall running time: 678.5844s / 1992.9508 s
first_0:                 episode reward: -3.2000,                 loss: nan
second_0:                 episode reward: 3.2000,                 loss: 0.0037
Episode: 81/10000 (0.8100%),                 avg. length: 1848.2,                last time consumption/overall running time: 716.1112s / 2709.0620 s
first_0:                 episode reward: -1.2500,                 loss: nan
second_0:                 episode reward: 1.2500,                 loss: 0.0041
Episode: 101/10000 (1.0100%),                 avg. length: 1846.45,                last time consumption/overall running time: 715.5199s / 3424.5820 s
first_0:                 episode reward: -2.4500,                 loss: nan
second_0:                 episode reward: 2.4500,                 loss: 0.0034
Episode: 121/10000 (1.2100%),                 avg. length: 1712.25,                last time consumption/overall running time: 663.7177s / 4088.2997 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0029
Episode: 141/10000 (1.4100%),                 avg. length: 1814.9,                last time consumption/overall running time: 702.0877s / 4790.3874 s
first_0:                 episode reward: -2.8000,                 loss: nan
second_0:                 episode reward: 2.8000,                 loss: 0.0025
Episode: 161/10000 (1.6100%),                 avg. length: 1696.2,                last time consumption/overall running time: 660.4525s / 5450.8399 s
first_0:                 episode reward: -2.9500,                 loss: nan
second_0:                 episode reward: 2.9500,                 loss: 0.0025
Episode: 181/10000 (1.8100%),                 avg. length: 1604.6,                last time consumption/overall running time: 624.8754s / 6075.7153 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0023
Episode: 201/10000 (2.0100%),                 avg. length: 1665.7,                last time consumption/overall running time: 644.4697s / 6720.1850 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0023
Episode: 221/10000 (2.2100%),                 avg. length: 1613.15,                last time consumption/overall running time: 631.2458s / 7351.4307 s
first_0:                 episode reward: -3.0500,                 loss: nan
second_0:                 episode reward: 3.0500,                 loss: 0.0024
Episode: 241/10000 (2.4100%),                 avg. length: 1800.0,                last time consumption/overall running time: 704.3053s / 8055.7361 s
first_0:                 episode reward: -2.2500,                 loss: nan
second_0:                 episode reward: 2.2500,                 loss: 0.0024
Episode: 261/10000 (2.6100%),                 avg. length: 1588.1,                last time consumption/overall running time: 680.0017s / 8735.7378 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0023
Episode: 281/10000 (2.8100%),                 avg. length: 1695.45,                last time consumption/overall running time: 658.8473s / 9394.5851 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0022
Episode: 301/10000 (3.0100%),                 avg. length: 1646.25,                last time consumption/overall running time: 637.2174s / 10031.8025 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0023
Episode: 321/10000 (3.2100%),                 avg. length: 1752.6,                last time consumption/overall running time: 678.4882s / 10710.2907 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0023
Episode: 341/10000 (3.4100%),                 avg. length: 1637.2,                last time consumption/overall running time: 633.7818s / 11344.0724 s
first_0:                 episode reward: -4.9500,                 loss: nan
second_0:                 episode reward: 4.9500,                 loss: 0.0031
Episode: 361/10000 (3.6100%),                 avg. length: 1794.6,                last time consumption/overall running time: 694.1922s / 12038.2646 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0042
Episode: 381/10000 (3.8100%),                 avg. length: 1769.0,                last time consumption/overall running time: 689.1144s / 12727.3789 s
first_0:                 episode reward: -2.6500,                 loss: nan
second_0:                 episode reward: 2.6500,                 loss: 0.0040
Episode: 401/10000 (4.0100%),                 avg. length: 1866.9,                last time consumption/overall running time: 724.6977s / 13452.0767 s
first_0:                 episode reward: -2.1000,                 loss: nan
second_0:                 episode reward: 2.1000,                 loss: 0.0034
Episode: 421/10000 (4.2100%),                 avg. length: 1706.1,                last time consumption/overall running time: 662.3276s / 14114.4043 s
first_0:                 episode reward: -2.8500,                 loss: nan
second_0:                 episode reward: 2.8500,                 loss: 0.0040
Episode: 441/10000 (4.4100%),                 avg. length: 1765.1,                last time consumption/overall running time: 682.3556s / 14796.7598 s
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0064
Episode: 461/10000 (4.6100%),                 avg. length: 1668.4,                last time consumption/overall running time: 643.7701s / 15440.5299 s
first_0:                 episode reward: -3.7500,                 loss: nan
second_0:                 episode reward: 3.7500,                 loss: 0.0055
Episode: 481/10000 (4.8100%),                 avg. length: 1732.2,                last time consumption/overall running time: 669.3334s / 16109.8633 s
first_0:                 episode reward: -3.1500,                 loss: nan
second_0:                 episode reward: 3.1500,                 loss: 0.0042
Episode: 501/10000 (5.0100%),                 avg. length: 1682.25,                last time consumption/overall running time: 648.8732s / 16758.7366 s
first_0:                 episode reward: -2.9500,                 loss: nan
second_0:                 episode reward: 2.9500,                 loss: 0.0042
Episode: 521/10000 (5.2100%),                 avg. length: 1771.85,                last time consumption/overall running time: 683.0961s / 17441.8327 s
first_0:                 episode reward: -2.9000,                 loss: nan
second_0:                 episode reward: 2.9000,                 loss: 0.0043
Episode: 541/10000 (5.4100%),                 avg. length: 1759.15,                last time consumption/overall running time: 677.2137s / 18119.0463 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0039
Episode: 561/10000 (5.6100%),                 avg. length: 1730.05,                last time consumption/overall running time: 668.9903s / 18788.0366 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0038
Episode: 581/10000 (5.8100%),                 avg. length: 1803.5,                last time consumption/overall running time: 699.5297s / 19487.5663 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0036
Episode: 601/10000 (6.0100%),                 avg. length: 1715.2,                last time consumption/overall running time: 669.1678s / 20156.7342 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0052
Episode: 621/10000 (6.2100%),                 avg. length: 1788.55,                last time consumption/overall running time: 698.5910s / 20855.3251 s
first_0:                 episode reward: -1.9000,                 loss: nan
second_0:                 episode reward: 1.9000,                 loss: 0.0049
Episode: 641/10000 (6.4100%),                 avg. length: 1664.05,                last time consumption/overall running time: 648.5320s / 21503.8571 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0047
Episode: 661/10000 (6.6100%),                 avg. length: 1664.3,                last time consumption/overall running time: 647.7579s / 22151.6150 s
first_0:                 episode reward: -3.3000,                 loss: nan
second_0:                 episode reward: 3.3000,                 loss: 0.0103
Episode: 681/10000 (6.8100%),                 avg. length: 1641.55,                last time consumption/overall running time: 637.6579s / 22789.2728 s
first_0:                 episode reward: 0.1000,                 loss: nan
second_0:                 episode reward: -0.1000,                 loss: 0.0125
Episode: 701/10000 (7.0100%),                 avg. length: 1631.85,                last time consumption/overall running time: 631.2869s / 23420.5597 s
first_0:                 episode reward: -2.3000,                 loss: nan
second_0:                 episode reward: 2.3000,                 loss: 0.0059
Episode: 721/10000 (7.2100%),                 avg. length: 1825.9,                last time consumption/overall running time: 710.0828s / 24130.6425 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0054
Episode: 741/10000 (7.4100%),                 avg. length: 1714.1,                last time consumption/overall running time: 664.0045s / 24794.6471 s
first_0:                 episode reward: -2.5500,                 loss: nan
second_0:                 episode reward: 2.5500,                 loss: 0.0063
Episode: 761/10000 (7.6100%),                 avg. length: 1721.8,                last time consumption/overall running time: 665.3584s / 25460.0055 s
first_0:                 episode reward: -3.5000,                 loss: nan
second_0:                 episode reward: 3.5000,                 loss: 0.0059
Episode: 781/10000 (7.8100%),                 avg. length: 1788.25,                last time consumption/overall running time: 693.4023s / 26153.4077 s
first_0:                 episode reward: -1.9000,                 loss: nan
second_0:                 episode reward: 1.9000,                 loss: 0.0063
Episode: 801/10000 (8.0100%),                 avg. length: 1712.1,                last time consumption/overall running time: 665.7742s / 26819.1819 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0078
Episode: 821/10000 (8.2100%),                 avg. length: 1804.35,                last time consumption/overall running time: 700.4586s / 27519.6405 s
first_0:                 episode reward: -3.2500,                 loss: nan
second_0:                 episode reward: 3.2500,                 loss: 0.0078
Episode: 841/10000 (8.4100%),                 avg. length: 1685.15,                last time consumption/overall running time: 651.3658s / 28171.0064 s
first_0:                 episode reward: -2.8500,                 loss: nan
second_0:                 episode reward: 2.8500,                 loss: 0.0067
Episode: 861/10000 (8.6100%),                 avg. length: 1760.15,                last time consumption/overall running time: 685.7754s / 28856.7817 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0058
Episode: 881/10000 (8.8100%),                 avg. length: 1698.15,                last time consumption/overall running time: 666.5900s / 29523.3717 s
first_0:                 episode reward: -2.8000,                 loss: nan
second_0:                 episode reward: 2.8000,                 loss: 0.0070
Episode: 901/10000 (9.0100%),                 avg. length: 1893.0,                last time consumption/overall running time: 737.9518s / 30261.3235 s
first_0:                 episode reward: -2.8500,                 loss: nan
second_0:                 episode reward: 2.8500,                 loss: 0.0077
Episode: 921/10000 (9.2100%),                 avg. length: 1835.05,                last time consumption/overall running time: 717.5961s / 30978.9197 s
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0101
Episode: 941/10000 (9.4100%),                 avg. length: 1816.55,                last time consumption/overall running time: 706.0831s / 31685.0027 s
first_0:                 episode reward: -2.1500,                 loss: nan
second_0:                 episode reward: 2.1500,                 loss: 0.0117
Episode: 961/10000 (9.6100%),                 avg. length: 1660.15,                last time consumption/overall running time: 642.6231s / 32327.6258 s
first_0:                 episode reward: -4.9500,                 loss: nan
second_0:                 episode reward: 4.9500,                 loss: 0.0050
Episode: 981/10000 (9.8100%),                 avg. length: 1788.55,                last time consumption/overall running time: 700.2507s / 33027.8765 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0056
Episode: 1001/10000 (10.0100%),                 avg. length: 1559.2,                last time consumption/overall running time: 607.8191s / 33635.6956 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0066
Episode: 1021/10000 (10.2100%),                 avg. length: 1665.55,                last time consumption/overall running time: 644.4781s / 34280.1737 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0059
Episode: 1041/10000 (10.4100%),                 avg. length: 1854.95,                last time consumption/overall running time: 719.9298s / 35000.1035 s
first_0:                 episode reward: -0.9500,                 loss: nan
second_0:                 episode reward: 0.9500,                 loss: 0.0092
Episode: 1061/10000 (10.6100%),                 avg. length: 1739.0,                last time consumption/overall running time: 672.8920s / 35672.9955 s
first_0:                 episode reward: -1.1500,                 loss: nan
second_0:                 episode reward: 1.1500,                 loss: 0.0090
Episode: 1081/10000 (10.8100%),                 avg. length: 1657.3,                last time consumption/overall running time: 640.8561s / 36313.8517 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0078
Episode: 1101/10000 (11.0100%),                 avg. length: 1689.55,                last time consumption/overall running time: 652.5484s / 36966.4001 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0075
Episode: 1121/10000 (11.2100%),                 avg. length: 1736.25,                last time consumption/overall running time: 671.4405s / 37637.8406 s
first_0:                 episode reward: 0.2500,                 loss: nan
second_0:                 episode reward: -0.2500,                 loss: 0.0065
Episode: 1141/10000 (11.4100%),                 avg. length: 1759.95,                last time consumption/overall running time: 682.4436s / 38320.2843 s
first_0:                 episode reward: -0.6000,                 loss: nan
second_0:                 episode reward: 0.6000,                 loss: 0.0052
Episode: 1161/10000 (11.6100%),                 avg. length: 1611.3,                last time consumption/overall running time: 626.5177s / 38946.8020 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0046
Episode: 1181/10000 (11.8100%),                 avg. length: 1742.55,                last time consumption/overall running time: 675.4593s / 39622.2613 s
first_0:                 episode reward: -2.0000,                 loss: nan
second_0:                 episode reward: 2.0000,                 loss: 0.0053
Episode: 1201/10000 (12.0100%),                 avg. length: 1759.35,                last time consumption/overall running time: 681.8080s / 40304.0693 s
first_0:                 episode reward: -1.3000,                 loss: nan
second_0:                 episode reward: 1.3000,                 loss: 0.0059
Episode: 1221/10000 (12.2100%),                 avg. length: 1552.5,                last time consumption/overall running time: 600.1193s / 40904.1886 s
first_0:                 episode reward: -6.1000,                 loss: nan
second_0:                 episode reward: 6.1000,                 loss: 0.0055
Episode: 1241/10000 (12.4100%),                 avg. length: 1681.75,                last time consumption/overall running time: 649.4993s / 41553.6880 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0063
Episode: 1261/10000 (12.6100%),                 avg. length: 1678.8,                last time consumption/overall running time: 652.7247s / 42206.4126 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0067
Episode: 1281/10000 (12.8100%),                 avg. length: 1559.95,                last time consumption/overall running time: 603.8073s / 42810.2199 s
first_0:                 episode reward: -5.7000,                 loss: nan
second_0:                 episode reward: 5.7000,                 loss: 0.0044
Episode: 1301/10000 (13.0100%),                 avg. length: 1620.25,                last time consumption/overall running time: 629.4013s / 43439.6212 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0033
Episode: 1321/10000 (13.2100%),                 avg. length: 1679.6,                last time consumption/overall running time: 656.3015s / 44095.9227 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0030
Episode: 1341/10000 (13.4100%),                 avg. length: 1667.9,                last time consumption/overall running time: 652.6861s / 44748.6088 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0030
Episode: 1361/10000 (13.6100%),                 avg. length: 1702.75,                last time consumption/overall running time: 661.5053s / 45410.1141 s
first_0:                 episode reward: -4.9500,                 loss: nan
second_0:                 episode reward: 4.9500,                 loss: 0.0037
Episode: 1381/10000 (13.8100%),                 avg. length: 1760.65,                last time consumption/overall running time: 684.7173s / 46094.8315 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0039
Episode: 1401/10000 (14.0100%),                 avg. length: 1733.25,                last time consumption/overall running time: 673.5720s / 46768.4035 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0029
Episode: 1421/10000 (14.2100%),                 avg. length: 1788.85,                last time consumption/overall running time: 691.9101s / 47460.3136 s
first_0:                 episode reward: -3.5500,                 loss: nan
second_0:                 episode reward: 3.5500,                 loss: 0.0035
Episode: 1441/10000 (14.4100%),                 avg. length: 1670.85,                last time consumption/overall running time: 646.7067s / 48107.0203 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0059
Episode: 1461/10000 (14.6100%),                 avg. length: 1566.55,                last time consumption/overall running time: 604.1758s / 48711.1962 s
first_0:                 episode reward: -6.2000,                 loss: nan
second_0:                 episode reward: 6.2000,                 loss: 0.0044
Episode: 1481/10000 (14.8100%),                 avg. length: 1697.8,                last time consumption/overall running time: 652.9147s / 49364.1109 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0041
Episode: 1501/10000 (15.0100%),                 avg. length: 1615.55,                last time consumption/overall running time: 626.5131s / 49990.6240 s
first_0:                 episode reward: -5.8000,                 loss: nan
second_0:                 episode reward: 5.8000,                 loss: 0.0027
Episode: 1521/10000 (15.2100%),                 avg. length: 1704.45,                last time consumption/overall running time: 662.2133s / 50652.8372 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0026
Episode: 1541/10000 (15.4100%),                 avg. length: 1633.3,                last time consumption/overall running time: 637.0971s / 51289.9344 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0032
Episode: 1561/10000 (15.6100%),                 avg. length: 1678.75,                last time consumption/overall running time: 658.4185s / 51948.3528 s
first_0:                 episode reward: -5.2000,                 loss: nan
second_0:                 episode reward: 5.2000,                 loss: 0.0031
Episode: 1581/10000 (15.8100%),                 avg. length: 1632.65,                last time consumption/overall running time: 636.9130s / 52585.2659 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0035
Episode: 1601/10000 (16.0100%),                 avg. length: 1717.6,                last time consumption/overall running time: 667.9632s / 53253.2291 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0030
Episode: 1621/10000 (16.2100%),                 avg. length: 1691.75,                last time consumption/overall running time: 655.3904s / 53908.6195 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0026
Episode: 1641/10000 (16.4100%),                 avg. length: 1531.95,                last time consumption/overall running time: 593.5863s / 54502.2059 s
first_0:                 episode reward: -6.6000,                 loss: nan
second_0:                 episode reward: 6.6000,                 loss: 0.0024
Episode: 1661/10000 (16.6100%),                 avg. length: 1647.8,                last time consumption/overall running time: 637.6943s / 55139.9001 s
first_0:                 episode reward: -5.3500,                 loss: nan
second_0:                 episode reward: 5.3500,                 loss: 0.0025
Episode: 1681/10000 (16.8100%),                 avg. length: 1634.75,                last time consumption/overall running time: 635.1163s / 55775.0165 s
first_0:                 episode reward: -5.5000,                 loss: nan
second_0:                 episode reward: 5.5000,                 loss: 0.0029
Episode: 1701/10000 (17.0100%),                 avg. length: 1734.15,                last time consumption/overall running time: 675.8519s / 56450.8684 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0026
Episode: 1721/10000 (17.2100%),                 avg. length: 1695.1,                last time consumption/overall running time: 655.7588s / 57106.6272 s
first_0:                 episode reward: -5.1000,                 loss: nan
second_0:                 episode reward: 5.1000,                 loss: 0.0025
Episode: 1741/10000 (17.4100%),                 avg. length: 1656.6,                last time consumption/overall running time: 645.9034s / 57752.5306 s
first_0:                 episode reward: -5.2500,                 loss: nan
second_0:                 episode reward: 5.2500,                 loss: 0.0029
Episode: 1761/10000 (17.6100%),                 avg. length: 1651.5,                last time consumption/overall running time: 642.2312s / 58394.7617 s
first_0:                 episode reward: -5.2000,                 loss: nan
second_0:                 episode reward: 5.2000,                 loss: 0.0048
Episode: 1781/10000 (17.8100%),                 avg. length: 1793.75,                last time consumption/overall running time: 694.8819s / 59089.6437 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0035
Episode: 1801/10000 (18.0100%),                 avg. length: 1638.35,                last time consumption/overall running time: 637.9881s / 59727.6317 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0028
Episode: 1821/10000 (18.2100%),                 avg. length: 1656.45,                last time consumption/overall running time: 643.4186s / 60371.0504 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0025
Episode: 1841/10000 (18.4100%),                 avg. length: 1597.85,                last time consumption/overall running time: 622.6319s / 60993.6823 s
first_0:                 episode reward: -5.9500,                 loss: nan
second_0:                 episode reward: 5.9500,                 loss: 0.0026
Episode: 1861/10000 (18.6100%),                 avg. length: 1665.6,                last time consumption/overall running time: 648.0135s / 61641.6958 s
first_0:                 episode reward: -5.7500,                 loss: nan
second_0:                 episode reward: 5.7500,                 loss: 0.0024
Episode: 1881/10000 (18.8100%),                 avg. length: 1621.35,                last time consumption/overall running time: 627.3442s / 62269.0400 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0024
Episode: 1901/10000 (19.0100%),                 avg. length: 1510.1,                last time consumption/overall running time: 585.0694s / 62854.1094 s
first_0:                 episode reward: -6.3000,                 loss: nan
second_0:                 episode reward: 6.3000,                 loss: 0.0023
Episode: 1921/10000 (19.2100%),                 avg. length: 1654.4,                last time consumption/overall running time: 641.5302s / 63495.6396 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0022
Episode: 1941/10000 (19.4100%),                 avg. length: 1658.1,                last time consumption/overall running time: 642.6613s / 64138.3010 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0022
Episode: 1961/10000 (19.6100%),                 avg. length: 1593.05,                last time consumption/overall running time: 615.6948s / 64753.9958 s
first_0:                 episode reward: -5.3500,                 loss: nan
second_0:                 episode reward: 5.3500,                 loss: 0.0021
Episode: 1981/10000 (19.8100%),                 avg. length: 1829.1,                last time consumption/overall running time: 710.6346s / 65464.6304 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0022
Episode: 2001/10000 (20.0100%),                 avg. length: 1575.6,                last time consumption/overall running time: 613.1749s / 66077.8053 s
first_0:                 episode reward: -5.6500,                 loss: nan
second_0:                 episode reward: 5.6500,                 loss: 0.0022
Episode: 2021/10000 (20.2100%),                 avg. length: 1607.4,                last time consumption/overall running time: 624.4927s / 66702.2980 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0022
Episode: 2041/10000 (20.4100%),                 avg. length: 1532.4,                last time consumption/overall running time: 594.0280s / 67296.3259 s
first_0:                 episode reward: -6.0000,                 loss: nan
second_0:                 episode reward: 6.0000,                 loss: 0.0022
Episode: 2061/10000 (20.6100%),                 avg. length: 1595.15,                last time consumption/overall running time: 618.6652s / 67914.9911 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0023
Episode: 2081/10000 (20.8100%),                 avg. length: 1568.45,                last time consumption/overall running time: 601.5298s / 68516.5209 s
first_0:                 episode reward: -6.5500,                 loss: nan
second_0:                 episode reward: 6.5500,                 loss: 0.0022
Episode: 2101/10000 (21.0100%),                 avg. length: 1608.7,                last time consumption/overall running time: 577.2767s / 69093.7976 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0022
Episode: 2121/10000 (21.2100%),                 avg. length: 1681.45,                last time consumption/overall running time: 606.7132s / 69700.5108 s
first_0:                 episode reward: -5.6500,                 loss: nan
second_0:                 episode reward: 5.6500,                 loss: 0.0021
Episode: 2141/10000 (21.4100%),                 avg. length: 1692.8,                last time consumption/overall running time: 607.5676s / 70308.0784 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0020
Episode: 2161/10000 (21.6100%),                 avg. length: 1566.6,                last time consumption/overall running time: 565.7202s / 70873.7985 s
first_0:                 episode reward: -6.2500,                 loss: nan
second_0:                 episode reward: 6.2500,                 loss: 0.0022
Episode: 2181/10000 (21.8100%),                 avg. length: 1663.15,                last time consumption/overall running time: 601.2362s / 71475.0347 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0021
Episode: 2201/10000 (22.0100%),                 avg. length: 1722.6,                last time consumption/overall running time: 621.5458s / 72096.5805 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0021
Episode: 2221/10000 (22.2100%),                 avg. length: 1635.95,                last time consumption/overall running time: 591.2557s / 72687.8362 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0022
Episode: 2241/10000 (22.4100%),                 avg. length: 1751.85,                last time consumption/overall running time: 633.4528s / 73321.2891 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0022
Episode: 2261/10000 (22.6100%),                 avg. length: 1675.8,                last time consumption/overall running time: 605.9299s / 73927.2189 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0021
Episode: 2281/10000 (22.8100%),                 avg. length: 1582.85,                last time consumption/overall running time: 572.8596s / 74500.0785 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0021
Episode: 2301/10000 (23.0100%),                 avg. length: 1748.45,                last time consumption/overall running time: 631.2022s / 75131.2807 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0021
Episode: 2321/10000 (23.2100%),                 avg. length: 1628.6,                last time consumption/overall running time: 588.8007s / 75720.0814 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0021
Episode: 2341/10000 (23.4100%),                 avg. length: 1637.75,                last time consumption/overall running time: 590.5480s / 76310.6294 s
first_0:                 episode reward: -5.3500,                 loss: nan
second_0:                 episode reward: 5.3500,                 loss: 0.0021
Episode: 2361/10000 (23.6100%),                 avg. length: 1628.05,                last time consumption/overall running time: 587.0470s / 76897.6764 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0021
Episode: 2381/10000 (23.8100%),                 avg. length: 1652.7,                last time consumption/overall running time: 597.8964s / 77495.5729 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0022
Episode: 2401/10000 (24.0100%),                 avg. length: 1629.95,                last time consumption/overall running time: 590.6077s / 78086.1805 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0022
Episode: 2421/10000 (24.2100%),                 avg. length: 1488.0,                last time consumption/overall running time: 537.5391s / 78623.7196 s
first_0:                 episode reward: -7.0000,                 loss: nan
second_0:                 episode reward: 7.0000,                 loss: 0.0022
Episode: 2441/10000 (24.4100%),                 avg. length: 1683.7,                last time consumption/overall running time: 606.4952s / 79230.2149 s
first_0:                 episode reward: -5.4500,                 loss: nan
second_0:                 episode reward: 5.4500,                 loss: 0.0021
Episode: 2461/10000 (24.6100%),                 avg. length: 1657.4,                last time consumption/overall running time: 595.4473s / 79825.6621 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0022
Episode: 2481/10000 (24.8100%),                 avg. length: 1638.65,                last time consumption/overall running time: 589.2757s / 80414.9378 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0022
Episode: 2501/10000 (25.0100%),                 avg. length: 1651.5,                last time consumption/overall running time: 595.7998s / 81010.7376 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0022
Episode: 2521/10000 (25.2100%),                 avg. length: 1658.7,                last time consumption/overall running time: 599.0615s / 81609.7991 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0023
Episode: 2541/10000 (25.4100%),                 avg. length: 1557.05,                last time consumption/overall running time: 563.4642s / 82173.2634 s
first_0:                 episode reward: -5.5000,                 loss: nan
second_0:                 episode reward: 5.5000,                 loss: 0.0023
Episode: 2561/10000 (25.6100%),                 avg. length: 1639.5,                last time consumption/overall running time: 594.2299s / 82767.4933 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0024
Episode: 2581/10000 (25.8100%),                 avg. length: 1512.3,                last time consumption/overall running time: 547.4792s / 83314.9725 s
first_0:                 episode reward: -6.7500,                 loss: nan
second_0:                 episode reward: 6.7500,                 loss: 0.0023
Episode: 2601/10000 (26.0100%),                 avg. length: 1701.65,                last time consumption/overall running time: 616.8361s / 83931.8086 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0022
Episode: 2621/10000 (26.2100%),                 avg. length: 1612.0,                last time consumption/overall running time: 585.7141s / 84517.5227 s
first_0:                 episode reward: -5.6500,                 loss: nan
second_0:                 episode reward: 5.6500,                 loss: 0.0022
Episode: 2641/10000 (26.4100%),                 avg. length: 1697.3,                last time consumption/overall running time: 613.8827s / 85131.4053 s
first_0:                 episode reward: -4.9500,                 loss: nan
second_0:                 episode reward: 4.9500,                 loss: 0.0023
Episode: 2661/10000 (26.6100%),                 avg. length: 1553.5,                last time consumption/overall running time: 562.1757s / 85693.5810 s
first_0:                 episode reward: -6.0000,                 loss: nan
second_0:                 episode reward: 6.0000,                 loss: 0.0022
Episode: 2681/10000 (26.8100%),                 avg. length: 1586.0,                last time consumption/overall running time: 574.1072s / 86267.6882 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0023
Episode: 2701/10000 (27.0100%),                 avg. length: 1771.7,                last time consumption/overall running time: 642.9974s / 86910.6856 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0023
Episode: 2721/10000 (27.2100%),                 avg. length: 1714.3,                last time consumption/overall running time: 621.9166s / 87532.6022 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0023
Episode: 2741/10000 (27.4100%),                 avg. length: 1678.5,                last time consumption/overall running time: 607.6181s / 88140.2202 s
first_0:                 episode reward: -5.1000,                 loss: nan
second_0:                 episode reward: 5.1000,                 loss: 0.0024
Episode: 2761/10000 (27.6100%),                 avg. length: 1633.9,                last time consumption/overall running time: 592.7159s / 88732.9362 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0026
Episode: 2781/10000 (27.8100%),                 avg. length: 1665.5,                last time consumption/overall running time: 603.9619s / 89336.8981 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0028
Episode: 2801/10000 (28.0100%),                 avg. length: 1621.55,                last time consumption/overall running time: 588.8064s / 89925.7045 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0025
Episode: 2821/10000 (28.2100%),                 avg. length: 1623.7,                last time consumption/overall running time: 591.4704s / 90517.1748 s
first_0:                 episode reward: -5.8000,                 loss: nan
second_0:                 episode reward: 5.8000,                 loss: 0.0024
Episode: 2841/10000 (28.4100%),                 avg. length: 1474.1,                last time consumption/overall running time: 538.3254s / 91055.5002 s
first_0:                 episode reward: -6.5000,                 loss: nan
second_0:                 episode reward: 6.5000,                 loss: 0.0023
Episode: 2861/10000 (28.6100%),                 avg. length: 1631.05,                last time consumption/overall running time: 593.7953s / 91649.2955 s
first_0:                 episode reward: -5.3000,                 loss: nan
second_0:                 episode reward: 5.3000,                 loss: 0.0023
Episode: 2881/10000 (28.8100%),                 avg. length: 1661.65,                last time consumption/overall running time: 605.0819s / 92254.3774 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0024
Episode: 2901/10000 (29.0100%),                 avg. length: 1767.85,                last time consumption/overall running time: 644.8619s / 92899.2394 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0025
Episode: 2921/10000 (29.2100%),                 avg. length: 1608.9,                last time consumption/overall running time: 585.8215s / 93485.0609 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0025
Episode: 2941/10000 (29.4100%),                 avg. length: 1686.0,                last time consumption/overall running time: 610.1655s / 94095.2264 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0025
Episode: 2961/10000 (29.6100%),                 avg. length: 1832.45,                last time consumption/overall running time: 663.5709s / 94758.7973 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0026
Episode: 2981/10000 (29.8100%),                 avg. length: 1597.0,                last time consumption/overall running time: 580.7013s / 95339.4986 s
first_0:                 episode reward: -6.2000,                 loss: nan
second_0:                 episode reward: 6.2000,                 loss: 0.0025
Episode: 3001/10000 (30.0100%),                 avg. length: 1583.85,                last time consumption/overall running time: 575.9855s / 95915.4840 s
first_0:                 episode reward: -5.9500,                 loss: nan
second_0:                 episode reward: 5.9500,                 loss: 0.0023
Episode: 3021/10000 (30.2100%),                 avg. length: 1657.7,                last time consumption/overall running time: 600.4747s / 96515.9587 s
first_0:                 episode reward: -5.1000,                 loss: nan
second_0:                 episode reward: 5.1000,                 loss: 0.0024
Episode: 3041/10000 (30.4100%),                 avg. length: 1682.2,                last time consumption/overall running time: 608.3107s / 97124.2694 s
first_0:                 episode reward: -4.9500,                 loss: nan
second_0:                 episode reward: 4.9500,                 loss: 0.0024
Episode: 3061/10000 (30.6100%),                 avg. length: 1620.2,                last time consumption/overall running time: 585.9749s / 97710.2443 s
first_0:                 episode reward: -5.8000,                 loss: nan
second_0:                 episode reward: 5.8000,                 loss: 0.0025
Episode: 3081/10000 (30.8100%),                 avg. length: 1766.15,                last time consumption/overall running time: 640.5719s / 98350.8162 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0024
Episode: 3101/10000 (31.0100%),                 avg. length: 1584.8,                last time consumption/overall running time: 573.5954s / 98924.4116 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0024
Episode: 3121/10000 (31.2100%),                 avg. length: 1731.95,                last time consumption/overall running time: 627.9008s / 99552.3124 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0026
Episode: 3141/10000 (31.4100%),                 avg. length: 1712.3,                last time consumption/overall running time: 620.9258s / 100173.2382 s
first_0:                 episode reward: -4.9500,                 loss: nan
second_0:                 episode reward: 4.9500,                 loss: 0.0025
Episode: 3161/10000 (31.6100%),                 avg. length: 1658.65,                last time consumption/overall running time: 600.4044s / 100773.6426 s
first_0:                 episode reward: -5.3000,                 loss: nan
second_0:                 episode reward: 5.3000,                 loss: 0.0025
Episode: 3181/10000 (31.8100%),                 avg. length: 1681.45,                last time consumption/overall running time: 605.9227s / 101379.5653 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0025
Episode: 3201/10000 (32.0100%),                 avg. length: 1559.6,                last time consumption/overall running time: 564.9305s / 101944.4958 s
first_0:                 episode reward: -5.2000,                 loss: nan
second_0:                 episode reward: 5.2000,                 loss: 0.0024
Episode: 3221/10000 (32.2100%),                 avg. length: 1636.8,                last time consumption/overall running time: 592.6322s / 102537.1280 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0025
Episode: 3241/10000 (32.4100%),                 avg. length: 1615.25,                last time consumption/overall running time: 586.7081s / 103123.8361 s
first_0:                 episode reward: -5.5000,                 loss: nan
second_0:                 episode reward: 5.5000,                 loss: 0.0026
Episode: 3261/10000 (32.6100%),                 avg. length: 1783.3,                last time consumption/overall running time: 648.1628s / 103771.9989 s
first_0:                 episode reward: -3.9500,                 loss: nan
second_0:                 episode reward: 3.9500,                 loss: 0.0026
Episode: 3281/10000 (32.8100%),                 avg. length: 1612.05,                last time consumption/overall running time: 584.3913s / 104356.3902 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0025
Episode: 3301/10000 (33.0100%),                 avg. length: 1562.05,                last time consumption/overall running time: 568.8668s / 104925.2570 s
first_0:                 episode reward: -6.4500,                 loss: nan
second_0:                 episode reward: 6.4500,                 loss: 0.0025
Episode: 3321/10000 (33.2100%),                 avg. length: 1686.9,                last time consumption/overall running time: 613.2556s / 105538.5125 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0024
Episode: 3341/10000 (33.4100%),                 avg. length: 1643.55,                last time consumption/overall running time: 595.6699s / 106134.1825 s
first_0:                 episode reward: -5.4500,                 loss: nan
second_0:                 episode reward: 5.4500,                 loss: 0.0025
Episode: 3361/10000 (33.6100%),                 avg. length: 1647.05,                last time consumption/overall running time: 596.7185s / 106730.9010 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0026
Episode: 3381/10000 (33.8100%),                 avg. length: 1610.45,                last time consumption/overall running time: 585.2307s / 107316.1317 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0026
Episode: 3401/10000 (34.0100%),                 avg. length: 1728.05,                last time consumption/overall running time: 629.9416s / 107946.0733 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0026
Episode: 3421/10000 (34.2100%),                 avg. length: 1579.1,                last time consumption/overall running time: 573.3504s / 108519.4237 s
first_0:                 episode reward: -5.7000,                 loss: nan
second_0:                 episode reward: 5.7000,                 loss: 0.0026
Episode: 3441/10000 (34.4100%),                 avg. length: 1639.9,                last time consumption/overall running time: 595.2699s / 109114.6936 s
first_0:                 episode reward: -5.7000,                 loss: nan
second_0:                 episode reward: 5.7000,                 loss: 0.0025
Episode: 3461/10000 (34.6100%),                 avg. length: 1632.4,                last time consumption/overall running time: 592.0654s / 109706.7591 s
first_0:                 episode reward: -5.4500,                 loss: nan
second_0:                 episode reward: 5.4500,                 loss: 0.0025
Episode: 3481/10000 (34.8100%),                 avg. length: 1627.0,                last time consumption/overall running time: 593.8632s / 110300.6223 s
first_0:                 episode reward: -5.3500,                 loss: nan
second_0:                 episode reward: 5.3500,                 loss: 0.0025
Episode: 3501/10000 (35.0100%),                 avg. length: 1664.65,                last time consumption/overall running time: 605.5134s / 110906.1357 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0025
Episode: 3521/10000 (35.2100%),                 avg. length: 1730.3,                last time consumption/overall running time: 629.9108s / 111536.0465 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0026
Episode: 3541/10000 (35.4100%),                 avg. length: 1755.05,                last time consumption/overall running time: 635.7324s / 112171.7789 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0027
Episode: 3561/10000 (35.6100%),                 avg. length: 1820.85,                last time consumption/overall running time: 658.0142s / 112829.7931 s
first_0:                 episode reward: -3.0000,                 loss: nan
second_0:                 episode reward: 3.0000,                 loss: 0.0027
Episode: 3581/10000 (35.8100%),                 avg. length: 1702.9,                last time consumption/overall running time: 616.9447s / 113446.7378 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0026
Episode: 3601/10000 (36.0100%),                 avg. length: 1619.25,                last time consumption/overall running time: 586.1108s / 114032.8487 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0026
Episode: 3621/10000 (36.2100%),                 avg. length: 1755.85,                last time consumption/overall running time: 637.7840s / 114670.6327 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0025
Episode: 3641/10000 (36.4100%),                 avg. length: 1547.2,                last time consumption/overall running time: 561.7306s / 115232.3633 s
first_0:                 episode reward: -6.0000,                 loss: nan
second_0:                 episode reward: 6.0000,                 loss: 0.0026
Episode: 3661/10000 (36.6100%),                 avg. length: 1667.9,                last time consumption/overall running time: 603.7927s / 115836.1560 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0027
Episode: 3681/10000 (36.8100%),                 avg. length: 1618.45,                last time consumption/overall running time: 589.2463s / 116425.4023 s
first_0:                 episode reward: -5.3500,                 loss: nan
second_0:                 episode reward: 5.3500,                 loss: 0.0026
Episode: 3701/10000 (37.0100%),                 avg. length: 1630.05,                last time consumption/overall running time: 592.2509s / 117017.6532 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0024
Episode: 3721/10000 (37.2100%),                 avg. length: 1544.65,                last time consumption/overall running time: 560.2747s / 117577.9279 s
first_0:                 episode reward: -6.0000,                 loss: nan
second_0:                 episode reward: 6.0000,                 loss: 0.0024
Episode: 3741/10000 (37.4100%),                 avg. length: 1739.45,                last time consumption/overall running time: 631.5189s / 118209.4467 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0025
Episode: 3761/10000 (37.6100%),                 avg. length: 1721.75,                last time consumption/overall running time: 622.8128s / 118832.2595 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0026
Episode: 3781/10000 (37.8100%),                 avg. length: 1501.15,                last time consumption/overall running time: 545.1758s / 119377.4353 s
first_0:                 episode reward: -6.5000,                 loss: nan
second_0:                 episode reward: 6.5000,                 loss: 0.0028
Episode: 3801/10000 (38.0100%),                 avg. length: 1559.15,                last time consumption/overall running time: 565.1208s / 119942.5561 s
first_0:                 episode reward: -6.1500,                 loss: nan
second_0:                 episode reward: 6.1500,                 loss: 0.0026
Episode: 3821/10000 (38.2100%),                 avg. length: 1628.0,                last time consumption/overall running time: 591.1136s / 120533.6698 s
first_0:                 episode reward: -5.6500,                 loss: nan
second_0:                 episode reward: 5.6500,                 loss: 0.0025
Episode: 3841/10000 (38.4100%),                 avg. length: 1650.8,                last time consumption/overall running time: 600.0200s / 121133.6898 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0025
Episode: 3861/10000 (38.6100%),                 avg. length: 1721.4,                last time consumption/overall running time: 624.9582s / 121758.6480 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0027
Episode: 3881/10000 (38.8100%),                 avg. length: 1775.3,                last time consumption/overall running time: 643.9790s / 122402.6270 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0028
Episode: 3901/10000 (39.0100%),                 avg. length: 1638.55,                last time consumption/overall running time: 590.5072s / 122993.1342 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0028
Episode: 3921/10000 (39.2100%),                 avg. length: 1721.1,                last time consumption/overall running time: 620.8817s / 123614.0159 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0032
Episode: 3941/10000 (39.4100%),                 avg. length: 1645.5,                last time consumption/overall running time: 591.8301s / 124205.8460 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0031
Episode: 3961/10000 (39.6100%),                 avg. length: 1618.3,                last time consumption/overall running time: 583.9682s / 124789.8142 s
first_0:                 episode reward: -5.3000,                 loss: nan
second_0:                 episode reward: 5.3000,                 loss: 0.0028
Episode: 3981/10000 (39.8100%),                 avg. length: 1675.8,                last time consumption/overall running time: 606.4007s / 125396.2149 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0028
Episode: 4001/10000 (40.0100%),                 avg. length: 1665.3,                last time consumption/overall running time: 599.1021s / 125995.3170 s
first_0:                 episode reward: -5.2500,                 loss: nan
second_0:                 episode reward: 5.2500,                 loss: 0.0028
Episode: 4021/10000 (40.2100%),                 avg. length: 1638.7,                last time consumption/overall running time: 590.3183s / 126585.6353 s
first_0:                 episode reward: -5.4500,                 loss: nan
second_0:                 episode reward: 5.4500,                 loss: 0.0028
Episode: 4041/10000 (40.4100%),                 avg. length: 1722.7,                last time consumption/overall running time: 621.1439s / 127206.7792 s
first_0:                 episode reward: -5.0000,                 loss: nan
second_0:                 episode reward: 5.0000,                 loss: 0.0026
Episode: 4061/10000 (40.6100%),                 avg. length: 1799.9,                last time consumption/overall running time: 649.5355s / 127856.3147 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0029
Episode: 4081/10000 (40.8100%),                 avg. length: 1679.3,                last time consumption/overall running time: 603.6701s / 128459.9847 s
first_0:                 episode reward: -4.9500,                 loss: nan
second_0:                 episode reward: 4.9500,                 loss: 0.0028
Episode: 4101/10000 (41.0100%),                 avg. length: 1638.55,                last time consumption/overall running time: 588.3254s / 129048.3102 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0025
Episode: 4121/10000 (41.2100%),                 avg. length: 1621.8,                last time consumption/overall running time: 585.4261s / 129633.7363 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0026
Episode: 4141/10000 (41.4100%),                 avg. length: 1622.45,                last time consumption/overall running time: 585.7185s / 130219.4548 s
first_0:                 episode reward: -5.4500,                 loss: nan
second_0:                 episode reward: 5.4500,                 loss: 0.0029
Episode: 4161/10000 (41.6100%),                 avg. length: 1533.95,                last time consumption/overall running time: 552.0768s / 130771.5316 s
first_0:                 episode reward: -6.7000,                 loss: nan
second_0:                 episode reward: 6.7000,                 loss: 0.0030
Episode: 4181/10000 (41.8100%),                 avg. length: 1658.45,                last time consumption/overall running time: 598.1158s / 131369.6474 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0031
Episode: 4201/10000 (42.0100%),                 avg. length: 1563.15,                last time consumption/overall running time: 569.2139s / 131938.8614 s
first_0:                 episode reward: -6.1500,                 loss: nan
second_0:                 episode reward: 6.1500,                 loss: 0.0031
Episode: 4221/10000 (42.2100%),                 avg. length: 1509.9,                last time consumption/overall running time: 543.7116s / 132482.5729 s
first_0:                 episode reward: -6.6000,                 loss: nan
second_0:                 episode reward: 6.6000,                 loss: 0.0029
Episode: 4241/10000 (42.4100%),                 avg. length: 1570.05,                last time consumption/overall running time: 568.3608s / 133050.9337 s
first_0:                 episode reward: -6.2000,                 loss: nan
second_0:                 episode reward: 6.2000,                 loss: 0.0026
Episode: 4261/10000 (42.6100%),                 avg. length: 1610.25,                last time consumption/overall running time: 587.0998s / 133638.0336 s
first_0:                 episode reward: -5.2500,                 loss: nan
second_0:                 episode reward: 5.2500,                 loss: 0.0025
Episode: 4281/10000 (42.8100%),                 avg. length: 1779.45,                last time consumption/overall running time: 626.8682s / 134264.9018 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0025
Episode: 4301/10000 (43.0100%),                 avg. length: 1650.0,                last time consumption/overall running time: 557.8407s / 134822.7426 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0027
Episode: 4321/10000 (43.2100%),                 avg. length: 1452.1,                last time consumption/overall running time: 488.3760s / 135311.1186 s
first_0:                 episode reward: -6.9500,                 loss: nan
second_0:                 episode reward: 6.9500,                 loss: 0.0030
Episode: 4341/10000 (43.4100%),                 avg. length: 1618.1,                last time consumption/overall running time: 544.2506s / 135855.3692 s
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0031
Episode: 4361/10000 (43.6100%),                 avg. length: 1692.85,                last time consumption/overall running time: 568.7016s / 136424.0707 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0033
Episode: 4381/10000 (43.8100%),                 avg. length: 1600.05,                last time consumption/overall running time: 536.8707s / 136960.9415 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0029
Episode: 4401/10000 (44.0100%),                 avg. length: 1539.65,                last time consumption/overall running time: 520.3012s / 137481.2427 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0029
Episode: 4421/10000 (44.2100%),                 avg. length: 1543.6,                last time consumption/overall running time: 519.7384s / 138000.9811 s
first_0:                 episode reward: -6.4500,                 loss: nan
second_0:                 episode reward: 6.4500,                 loss: 0.0027
Episode: 4441/10000 (44.4100%),                 avg. length: 1709.25,                last time consumption/overall running time: 575.0790s / 138576.0600 s
first_0:                 episode reward: -5.2500,                 loss: nan
second_0:                 episode reward: 5.2500,                 loss: 0.0028
Episode: 4461/10000 (44.6100%),                 avg. length: 1545.85,                last time consumption/overall running time: 524.9219s / 139100.9820 s
first_0:                 episode reward: -5.9000,                 loss: nan
second_0:                 episode reward: 5.9000,                 loss: 0.0026
Episode: 4481/10000 (44.8100%),                 avg. length: 1609.15,                last time consumption/overall running time: 542.1133s / 139643.0952 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0027
Episode: 4501/10000 (45.0100%),                 avg. length: 1740.95,                last time consumption/overall running time: 585.3921s / 140228.4873 s
first_0:                 episode reward: -3.7000,                 loss: nan
second_0:                 episode reward: 3.7000,                 loss: 0.0028
Episode: 4521/10000 (45.2100%),                 avg. length: 1611.9,                last time consumption/overall running time: 542.5788s / 140771.0660 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0030
Episode: 4541/10000 (45.4100%),                 avg. length: 1633.8,                last time consumption/overall running time: 549.8484s / 141320.9145 s
first_0:                 episode reward: -5.5000,                 loss: nan
second_0:                 episode reward: 5.5000,                 loss: 0.0028
Episode: 4561/10000 (45.6100%),                 avg. length: 1656.2,                last time consumption/overall running time: 558.5574s / 141879.4718 s
first_0:                 episode reward: -4.6500,                 loss: nan
second_0:                 episode reward: 4.6500,                 loss: 0.0029
Episode: 4581/10000 (45.8100%),                 avg. length: 1533.0,                last time consumption/overall running time: 518.0052s / 142397.4770 s
first_0:                 episode reward: -6.3500,                 loss: nan
second_0:                 episode reward: 6.3500,                 loss: 0.0030
Episode: 4601/10000 (46.0100%),                 avg. length: 1563.1,                last time consumption/overall running time: 528.0503s / 142925.5273 s
first_0:                 episode reward: -5.7000,                 loss: nan
second_0:                 episode reward: 5.7000,                 loss: 0.0030
Episode: 4621/10000 (46.2100%),                 avg. length: 1650.15,                last time consumption/overall running time: 556.3159s / 143481.8432 s
first_0:                 episode reward: -5.7500,                 loss: nan
second_0:                 episode reward: 5.7500,                 loss: 0.0028
Episode: 4641/10000 (46.4100%),                 avg. length: 1623.65,                last time consumption/overall running time: 547.5612s / 144029.4044 s
first_0:                 episode reward: -5.7000,                 loss: nan
second_0:                 episode reward: 5.7000,                 loss: 0.0026
Episode: 4661/10000 (46.6100%),                 avg. length: 1535.25,                last time consumption/overall running time: 517.5058s / 144546.9102 s
first_0:                 episode reward: -6.0500,                 loss: nan
second_0:                 episode reward: 6.0500,                 loss: 0.0026
Episode: 4681/10000 (46.8100%),                 avg. length: 1639.45,                last time consumption/overall running time: 551.4045s / 145098.3147 s
first_0:                 episode reward: -5.4500,                 loss: nan
second_0:                 episode reward: 5.4500,                 loss: 0.0027
Episode: 4701/10000 (47.0100%),                 avg. length: 1665.35,                last time consumption/overall running time: 560.0442s / 145658.3588 s
first_0:                 episode reward: -5.1000,                 loss: nan
second_0:                 episode reward: 5.1000,                 loss: 0.0027
Episode: 4721/10000 (47.2100%),                 avg. length: 1629.35,                last time consumption/overall running time: 547.9179s / 146206.2768 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0028
Episode: 4741/10000 (47.4100%),                 avg. length: 1532.4,                last time consumption/overall running time: 516.2298s / 146722.5065 s
first_0:                 episode reward: -6.2500,                 loss: nan
second_0:                 episode reward: 6.2500,                 loss: 0.0027
Episode: 4761/10000 (47.6100%),                 avg. length: 1634.0,                last time consumption/overall running time: 550.2416s / 147272.7481 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0027
Episode: 4781/10000 (47.8100%),                 avg. length: 1769.0,                last time consumption/overall running time: 596.2802s / 147869.0283 s
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0025
Episode: 4801/10000 (48.0100%),                 avg. length: 1863.85,                last time consumption/overall running time: 625.8895s / 148494.9178 s
first_0:                 episode reward: -3.2500,                 loss: nan
second_0:                 episode reward: 3.2500,                 loss: 0.0025
Episode: 4821/10000 (48.2100%),                 avg. length: 1686.4,                last time consumption/overall running time: 568.3020s / 149063.2199 s
first_0:                 episode reward: -3.9500,                 loss: nan
second_0:                 episode reward: 3.9500,                 loss: 0.0028
Episode: 4841/10000 (48.4100%),                 avg. length: 1723.75,                last time consumption/overall running time: 582.1977s / 149645.4176 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0028
Episode: 4861/10000 (48.6100%),                 avg. length: 1648.7,                last time consumption/overall running time: 553.7977s / 150199.2152 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0027
Episode: 4881/10000 (48.8100%),                 avg. length: 1636.25,                last time consumption/overall running time: 550.7487s / 150749.9639 s
first_0:                 episode reward: -5.1000,                 loss: nan
second_0:                 episode reward: 5.1000,                 loss: 0.0029
Episode: 4901/10000 (49.0100%),                 avg. length: 1712.5,                last time consumption/overall running time: 576.4353s / 151326.3992 s
first_0:                 episode reward: -4.5500,                 loss: nan
second_0:                 episode reward: 4.5500,                 loss: 0.0029
Episode: 4921/10000 (49.2100%),                 avg. length: 1853.45,                last time consumption/overall running time: 625.2866s / 151951.6859 s
first_0:                 episode reward: -3.8500,                 loss: nan
second_0:                 episode reward: 3.8500,                 loss: 0.0031
Episode: 4941/10000 (49.4100%),                 avg. length: 1629.55,                last time consumption/overall running time: 546.7626s / 152498.4484 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0032
Episode: 4961/10000 (49.6100%),                 avg. length: 1690.8,                last time consumption/overall running time: 568.2744s / 153066.7228 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0030
Episode: 4981/10000 (49.8100%),                 avg. length: 1706.95,                last time consumption/overall running time: 576.4785s / 153643.2013 s
first_0:                 episode reward: -3.7500,                 loss: nan
second_0:                 episode reward: 3.7500,                 loss: 0.0030
Episode: 5001/10000 (50.0100%),                 avg. length: 1791.05,                last time consumption/overall running time: 604.4617s / 154247.6630 s
first_0:                 episode reward: -2.9000,                 loss: nan
second_0:                 episode reward: 2.9000,                 loss: 0.0031
Episode: 5021/10000 (50.2100%),                 avg. length: 1698.75,                last time consumption/overall running time: 571.6437s / 154819.3067 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0036
Episode: 5041/10000 (50.4100%),                 avg. length: 1814.6,                last time consumption/overall running time: 607.9649s / 155427.2716 s
first_0:                 episode reward: -3.7500,                 loss: nan
second_0:                 episode reward: 3.7500,                 loss: 0.0031
Episode: 5061/10000 (50.6100%),                 avg. length: 1605.1,                last time consumption/overall running time: 537.4871s / 155964.7588 s
first_0:                 episode reward: -5.7000,                 loss: nan
second_0:                 episode reward: 5.7000,                 loss: 0.0028
Episode: 5081/10000 (50.8100%),                 avg. length: 1836.5,                last time consumption/overall running time: 620.5747s / 156585.3334 s
first_0:                 episode reward: -2.6500,                 loss: nan
second_0:                 episode reward: 2.6500,                 loss: 0.0030
Episode: 5101/10000 (51.0100%),                 avg. length: 1708.75,                last time consumption/overall running time: 575.5746s / 157160.9080 s
first_0:                 episode reward: -5.0500,                 loss: nan
second_0:                 episode reward: 5.0500,                 loss: 0.0028
Episode: 5121/10000 (51.2100%),                 avg. length: 1634.2,                last time consumption/overall running time: 550.2179s / 157711.1259 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0026
Episode: 5141/10000 (51.4100%),                 avg. length: 1767.25,                last time consumption/overall running time: 596.8854s / 158308.0113 s
first_0:                 episode reward: -3.9500,                 loss: nan
second_0:                 episode reward: 3.9500,                 loss: 0.0026
Episode: 5161/10000 (51.6100%),                 avg. length: 1644.4,                last time consumption/overall running time: 555.7970s / 158863.8083 s
first_0:                 episode reward: -2.5000,                 loss: nan
second_0:                 episode reward: 2.5000,                 loss: 0.0026
Episode: 5181/10000 (51.8100%),                 avg. length: 1711.75,                last time consumption/overall running time: 575.7780s / 159439.5863 s
first_0:                 episode reward: -2.4500,                 loss: nan
second_0:                 episode reward: 2.4500,                 loss: 0.0026
Episode: 5201/10000 (52.0100%),                 avg. length: 1714.4,                last time consumption/overall running time: 577.1571s / 160016.7434 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0026
Episode: 5221/10000 (52.2100%),                 avg. length: 1627.4,                last time consumption/overall running time: 549.0568s / 160565.8002 s
first_0:                 episode reward: -5.6000,                 loss: nan
second_0:                 episode reward: 5.6000,                 loss: 0.0027
Episode: 5241/10000 (52.4100%),                 avg. length: 1601.15,                last time consumption/overall running time: 538.0764s / 161103.8767 s
first_0:                 episode reward: -5.9000,                 loss: nan
second_0:                 episode reward: 5.9000,                 loss: 0.0026
Episode: 5261/10000 (52.6100%),                 avg. length: 1581.15,                last time consumption/overall running time: 530.8769s / 161634.7535 s
first_0:                 episode reward: -6.2000,                 loss: nan
second_0:                 episode reward: 6.2000,                 loss: 0.0025
Episode: 5281/10000 (52.8100%),                 avg. length: 1647.9,                last time consumption/overall running time: 554.1631s / 162188.9166 s
first_0:                 episode reward: -5.2000,                 loss: nan
second_0:                 episode reward: 5.2000,                 loss: 0.0025
Episode: 5301/10000 (53.0100%),                 avg. length: 1725.8,                last time consumption/overall running time: 582.6705s / 162771.5870 s
first_0:                 episode reward: -4.7500,                 loss: nan
second_0:                 episode reward: 4.7500,                 loss: 0.0026
Episode: 5321/10000 (53.2100%),                 avg. length: 1709.15,                last time consumption/overall running time: 577.9204s / 163349.5074 s
first_0:                 episode reward: -4.8500,                 loss: nan
second_0:                 episode reward: 4.8500,                 loss: 0.0026
Episode: 5341/10000 (53.4100%),                 avg. length: 1732.05,                last time consumption/overall running time: 582.1816s / 163931.6890 s
first_0:                 episode reward: -4.4500,                 loss: nan
second_0:                 episode reward: 4.4500,                 loss: 0.0026
Episode: 5361/10000 (53.6100%),                 avg. length: 1620.25,                last time consumption/overall running time: 544.9404s / 164476.6294 s
first_0:                 episode reward: -3.9500,                 loss: nan
second_0:                 episode reward: 3.9500,                 loss: 0.0025
Episode: 5381/10000 (53.8100%),                 avg. length: 1592.0,                last time consumption/overall running time: 534.4621s / 165011.0915 s
first_0:                 episode reward: -6.0500,                 loss: nan
second_0:                 episode reward: 6.0500,                 loss: 0.0026
Episode: 5401/10000 (54.0100%),                 avg. length: 1802.65,                last time consumption/overall running time: 608.0004s / 165619.0919 s
first_0:                 episode reward: -3.6000,                 loss: nan
second_0:                 episode reward: 3.6000,                 loss: 0.0026
Episode: 5421/10000 (54.2100%),                 avg. length: 1655.75,                last time consumption/overall running time: 555.5684s / 166174.6603 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0027
Episode: 5441/10000 (54.4100%),                 avg. length: 1713.35,                last time consumption/overall running time: 576.8279s / 166751.4882 s
first_0:                 episode reward: -4.9000,                 loss: nan
second_0:                 episode reward: 4.9000,                 loss: 0.0027
Episode: 5461/10000 (54.6100%),                 avg. length: 1720.75,                last time consumption/overall running time: 577.8081s / 167329.2963 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0029
Episode: 5481/10000 (54.8100%),                 avg. length: 1718.45,                last time consumption/overall running time: 579.7909s / 167909.0872 s
first_0:                 episode reward: -4.7000,                 loss: nan
second_0:                 episode reward: 4.7000,                 loss: 0.0029
Episode: 5501/10000 (55.0100%),                 avg. length: 1799.35,                last time consumption/overall running time: 604.6792s / 168513.7664 s
first_0:                 episode reward: -4.1500,                 loss: nan
second_0:                 episode reward: 4.1500,                 loss: 0.0028
Episode: 5521/10000 (55.2100%),                 avg. length: 1736.0,                last time consumption/overall running time: 580.1019s / 169093.8683 s
first_0:                 episode reward: -3.5500,                 loss: nan
second_0:                 episode reward: 3.5500,                 loss: 0.0029
Episode: 5541/10000 (55.4100%),                 avg. length: 1709.15,                last time consumption/overall running time: 573.3323s / 169667.2005 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0030
Episode: 5561/10000 (55.6100%),                 avg. length: 1709.0,                last time consumption/overall running time: 572.4347s / 170239.6353 s
first_0:                 episode reward: -3.9500,                 loss: nan
second_0:                 episode reward: 3.9500,                 loss: 0.0030
Episode: 5581/10000 (55.8100%),                 avg. length: 1781.6,                last time consumption/overall running time: 597.0107s / 170836.6460 s
first_0:                 episode reward: -2.9500,                 loss: nan
second_0:                 episode reward: 2.9500,                 loss: 0.0027
Episode: 5601/10000 (56.0100%),                 avg. length: 1743.25,                last time consumption/overall running time: 588.7629s / 171425.4088 s
first_0:                 episode reward: -3.3500,                 loss: nan
second_0:                 episode reward: 3.3500,                 loss: 0.0029
Episode: 5621/10000 (56.2100%),                 avg. length: 1691.25,                last time consumption/overall running time: 564.3879s / 171989.7967 s
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0028
Episode: 5641/10000 (56.4100%),                 avg. length: 1830.5,                last time consumption/overall running time: 609.8804s / 172599.6771 s
first_0:                 episode reward: -3.4500,                 loss: nan
second_0:                 episode reward: 3.4500,                 loss: 0.0029
Episode: 5661/10000 (56.6100%),                 avg. length: 1644.45,                last time consumption/overall running time: 549.3435s / 173149.0206 s
first_0:                 episode reward: -4.6000,                 loss: nan
second_0:                 episode reward: 4.6000,                 loss: 0.0028
Episode: 5681/10000 (56.8100%),                 avg. length: 1627.35,                last time consumption/overall running time: 544.0403s / 173693.0610 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0029