pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
tennis_v2 pettingzoo
Load tennis_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 91
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f8743cbe150>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [array([0.026, 0.026, 0.026, ..., 0.026, 0.026, 0.026]) array([0.027, 0.027, 0.027, ..., 0.027, 0.027, 0.027])]
Load checkpoints (policy family):  [list(['21', '317', '417', '638', '1247', '1396', '1441', '1485', '1565', '1608', '1688', '1747', '1812', '1857', '1931', '1991', '2103', '2189', '2245', '2356', '2421', '2496', '2625', '2681', '2760', '2910', '2964', '3071', '3139', '3231', '3294', '3368', '3434', '3563', '3648', '3737', '3868', '3954'])
 list(['42', '338', '487', '744', '1292', '1417', '1462', '1506', '1587', '1638', '1716', '1788', '1834', '1902', '1952', '2030', '2138', '2223', '2294', '2377', '2474', '2519', '2657', '2727', '2884', '2937', '3000', '3110', '3198', '3262', '3336', '3401', '3468', '3598', '3684', '3781', '3906'])]
Arguments:  {'env_name': 'tennis_v2', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220119_0526/pettingzoo_tennis_v2_fictitious_selfplay2/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 50, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220119_0526_exploit/pettingzoo_tennis_v2_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0526_exploit/pettingzoo_tennis_v2_fictitious_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 1657.0,                last time consumption/overall running time: 26.6929s / 26.6929 s
first_0:                 episode reward: 23.0000,                 loss: nan
second_0:                 episode reward: -23.0000,                 loss: 0.0047
Episode: 21/10000 (0.2100%),                 avg. length: 2884.8,                last time consumption/overall running time: 1530.3532s / 1557.0461 s
first_0:                 episode reward: 11.6000,                 loss: nan
second_0:                 episode reward: -11.6000,                 loss: 0.0062
Episode: 41/10000 (0.4100%),                 avg. length: 2748.6,                last time consumption/overall running time: 1649.1567s / 3206.2028 s
first_0:                 episode reward: 7.9500,                 loss: nan
second_0:                 episode reward: -7.9500,                 loss: 0.0074
Episode: 61/10000 (0.6100%),                 avg. length: 3479.0,                last time consumption/overall running time: 2082.8812s / 5289.0840 s
first_0:                 episode reward: 10.0500,                 loss: nan
second_0:                 episode reward: -10.0500,                 loss: 0.0059
Episode: 81/10000 (0.8100%),                 avg. length: 7750.1,                last time consumption/overall running time: 4651.1579s / 9940.2419 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0055
Episode: 101/10000 (1.0100%),                 avg. length: 8319.8,                last time consumption/overall running time: 4992.1670s / 14932.4089 s
first_0:                 episode reward: -11.0500,                 loss: nan
second_0:                 episode reward: 11.0500,                 loss: 0.0070
Episode: 121/10000 (1.2100%),                 avg. length: 7972.3,                last time consumption/overall running time: 4811.1899s / 19743.5988 s
first_0:                 episode reward: 50.8000,                 loss: nan
second_0:                 episode reward: -50.8000,                 loss: 0.0082
Episode: 141/10000 (1.4100%),                 avg. length: 8981.1,                last time consumption/overall running time: 5401.7128s / 25145.3116 s
first_0:                 episode reward: 48.7500,                 loss: nan
second_0:                 episode reward: -48.7500,                 loss: 0.0086
Episode: 161/10000 (1.6100%),                 avg. length: 7104.3,                last time consumption/overall running time: 4267.8146s / 29413.1262 s
first_0:                 episode reward: 27.9000,                 loss: nan
second_0:                 episode reward: -27.9000,                 loss: 0.0100
Episode: 181/10000 (1.8100%),                 avg. length: 9239.6,                last time consumption/overall running time: 5538.0133s / 34951.1395 s
first_0:                 episode reward: 55.6000,                 loss: nan
second_0:                 episode reward: -55.6000,                 loss: 0.0135
Episode: 201/10000 (2.0100%),                 avg. length: 7242.75,                last time consumption/overall running time: 4344.9173s / 39296.0569 s
first_0:                 episode reward: 67.9500,                 loss: nan
second_0:                 episode reward: -67.9500,                 loss: 0.0165
Episode: 221/10000 (2.2100%),                 avg. length: 7698.1,                last time consumption/overall running time: 4612.6034s / 43908.6602 s
first_0:                 episode reward: 59.1500,                 loss: nan
second_0:                 episode reward: -59.1500,                 loss: 0.0176
Episode: 241/10000 (2.4100%),                 avg. length: 8396.5,                last time consumption/overall running time: 5019.1406s / 48927.8009 s
first_0:                 episode reward: 78.6000,                 loss: nan
second_0:                 episode reward: -78.6000,                 loss: 0.0144
Episode: 261/10000 (2.6100%),                 avg. length: 7675.5,                last time consumption/overall running time: 4581.0697s / 53508.8705 s
first_0:                 episode reward: 69.7500,                 loss: nan
second_0:                 episode reward: -69.7500,                 loss: 0.0138
Episode: 281/10000 (2.8100%),                 avg. length: 7434.9,                last time consumption/overall running time: 4451.6271s / 57960.4977 s
first_0:                 episode reward: 40.9500,                 loss: nan
second_0:                 episode reward: -40.9500,                 loss: 0.0146
Episode: 301/10000 (3.0100%),                 avg. length: 6452.25,                last time consumption/overall running time: 3867.3207s / 61827.8184 s
first_0:                 episode reward: 35.7000,                 loss: nan
second_0:                 episode reward: -35.7000,                 loss: 0.0166
Episode: 321/10000 (3.2100%),                 avg. length: 7852.8,                last time consumption/overall running time: 4692.7993s / 66520.6177 s
first_0:                 episode reward: 63.2000,                 loss: nan
second_0:                 episode reward: -63.2000,                 loss: 0.0162
Episode: 341/10000 (3.4100%),                 avg. length: 5615.7,                last time consumption/overall running time: 3380.5725s / 69901.1903 s
first_0:                 episode reward: 13.8500,                 loss: nan
second_0:                 episode reward: -13.8500,                 loss: 0.0149
Episode: 361/10000 (3.6100%),                 avg. length: 7734.9,                last time consumption/overall running time: 4635.8881s / 74537.0783 s
first_0:                 episode reward: 74.7000,                 loss: nan
second_0:                 episode reward: -74.7000,                 loss: 0.0125
Episode: 381/10000 (3.8100%),                 avg. length: 7920.0,                last time consumption/overall running time: 4743.0668s / 79280.1451 s
first_0:                 episode reward: 69.2000,                 loss: nan
second_0:                 episode reward: -69.2000,                 loss: 0.0124
Episode: 401/10000 (4.0100%),                 avg. length: 7040.5,                last time consumption/overall running time: 4203.3926s / 83483.5377 s
first_0:                 episode reward: 36.4500,                 loss: nan
second_0:                 episode reward: -36.4500,                 loss: 0.0155
Episode: 421/10000 (4.2100%),                 avg. length: 6690.65,                last time consumption/overall running time: 4028.9209s / 87512.4586 s
first_0:                 episode reward: 19.1500,                 loss: nan
second_0:                 episode reward: -19.1500,                 loss: 0.0140
Episode: 441/10000 (4.4100%),                 avg. length: 6704.95,                last time consumption/overall running time: 4027.9660s / 91540.4246 s
first_0:                 episode reward: 49.2500,                 loss: nan
second_0:                 episode reward: -49.2500,                 loss: 0.0128
Episode: 461/10000 (4.6100%),                 avg. length: 7596.0,                last time consumption/overall running time: 4576.3234s / 96116.7480 s
first_0:                 episode reward: 94.5000,                 loss: nan
second_0:                 episode reward: -94.5000,                 loss: 0.0189
Episode: 481/10000 (4.8100%),                 avg. length: 6046.35,                last time consumption/overall running time: 3627.9735s / 99744.7215 s
first_0:                 episode reward: 74.0500,                 loss: nan
second_0:                 episode reward: -74.0500,                 loss: 0.0242
Episode: 501/10000 (5.0100%),                 avg. length: 6736.3,                last time consumption/overall running time: 4036.6033s / 103781.3248 s
first_0:                 episode reward: 72.0500,                 loss: nan
second_0:                 episode reward: -72.0500,                 loss: 0.0300
Episode: 521/10000 (5.2100%),                 avg. length: 6516.95,                last time consumption/overall running time: 3901.9907s / 107683.3155 s
first_0:                 episode reward: 23.8500,                 loss: nan
second_0:                 episode reward: -23.8500,                 loss: 0.0273
Episode: 541/10000 (5.4100%),                 avg. length: 6255.65,                last time consumption/overall running time: 3765.1205s / 111448.4360 s
first_0:                 episode reward: 24.9500,                 loss: nan
second_0:                 episode reward: -24.9500,                 loss: 0.0204
Episode: 561/10000 (5.6100%),                 avg. length: 6346.0,                last time consumption/overall running time: 3797.8603s / 115246.2963 s
first_0:                 episode reward: 19.1000,                 loss: nan
second_0:                 episode reward: -19.1000,                 loss: 0.0144
Episode: 581/10000 (5.8100%),                 avg. length: 7250.35,                last time consumption/overall running time: 4352.7885s / 119599.0847 s
first_0:                 episode reward: 60.1000,                 loss: nan
second_0:                 episode reward: -60.1000,                 loss: 0.0137
Episode: 601/10000 (6.0100%),                 avg. length: 7482.35,                last time consumption/overall running time: 4478.5142s / 124077.5989 s
first_0:                 episode reward: 28.2500,                 loss: nan
second_0:                 episode reward: -28.2500,                 loss: 0.0186
Episode: 621/10000 (6.2100%),                 avg. length: 7405.8,                last time consumption/overall running time: 4450.9021s / 128528.5010 s
first_0:                 episode reward: 41.0000,                 loss: nan
second_0:                 episode reward: -41.0000,                 loss: 0.0247
Episode: 641/10000 (6.4100%),                 avg. length: 6265.15,                last time consumption/overall running time: 3774.8008s / 132303.3018 s
first_0:                 episode reward: 57.3500,                 loss: nan
second_0:                 episode reward: -57.3500,                 loss: 0.0229
Episode: 661/10000 (6.6100%),                 avg. length: 6292.65,                last time consumption/overall running time: 3783.9733s / 136087.2751 s
first_0:                 episode reward: 21.5500,                 loss: nan
second_0:                 episode reward: -21.5500,                 loss: 0.0240
Episode: 681/10000 (6.8100%),                 avg. length: 5946.15,                last time consumption/overall running time: 3584.0142s / 139671.2892 s
first_0:                 episode reward: 19.5000,                 loss: nan
second_0:                 episode reward: -19.5000,                 loss: 0.0268
Episode: 701/10000 (7.0100%),                 avg. length: 5512.9,                last time consumption/overall running time: 3310.7708s / 142982.0601 s
first_0:                 episode reward: 27.5500,                 loss: nan
second_0:                 episode reward: -27.5500,                 loss: 0.0215
Episode: 721/10000 (7.2100%),                 avg. length: 5325.65,                last time consumption/overall running time: 3190.5775s / 146172.6376 s
first_0:                 episode reward: 41.6000,                 loss: nan
second_0:                 episode reward: -41.6000,                 loss: 0.0181
Episode: 741/10000 (7.4100%),                 avg. length: 4829.7,                last time consumption/overall running time: 2904.5675s / 149077.2051 s
first_0:                 episode reward: 31.3500,                 loss: nan
second_0:                 episode reward: -31.3500,                 loss: 0.0181
Episode: 761/10000 (7.6100%),                 avg. length: 6774.25,                last time consumption/overall running time: 4043.4168s / 153120.6219 s
first_0:                 episode reward: 57.7000,                 loss: nan
second_0:                 episode reward: -57.7000,                 loss: 0.0202
Episode: 781/10000 (7.8100%),                 avg. length: 5149.2,                last time consumption/overall running time: 3083.7944s / 156204.4163 s
first_0:                 episode reward: 59.2500,                 loss: nan
second_0:                 episode reward: -59.2500,                 loss: 0.0236
Episode: 801/10000 (8.0100%),                 avg. length: 4188.95,                last time consumption/overall running time: 2503.2597s / 158707.6760 s
first_0:                 episode reward: 18.4000,                 loss: nan
second_0:                 episode reward: -18.4000,                 loss: 0.0220
Episode: 821/10000 (8.2100%),                 avg. length: 4789.8,                last time consumption/overall running time: 2873.2825s / 161580.9585 s
first_0:                 episode reward: 7.6500,                 loss: nan
second_0:                 episode reward: -7.6500,                 loss: 0.0167
Episode: 841/10000 (8.4100%),                 avg. length: 5330.75,                last time consumption/overall running time: 3203.0020s / 164783.9605 s
first_0:                 episode reward: 36.1500,                 loss: nan
second_0:                 episode reward: -36.1500,                 loss: 0.0142
Episode: 861/10000 (8.6100%),                 avg. length: 5352.7,                last time consumption/overall running time: 3237.3952s / 168021.3557 s
first_0:                 episode reward: 14.9000,                 loss: nan
second_0:                 episode reward: -14.9000,                 loss: 0.0142
Episode: 881/10000 (8.8100%),                 avg. length: 7574.15,                last time consumption/overall running time: 4528.1897s / 172549.5454 s
first_0:                 episode reward: 42.8000,                 loss: nan
second_0:                 episode reward: -42.8000,                 loss: 0.0162
Episode: 901/10000 (9.0100%),                 avg. length: 5499.65,                last time consumption/overall running time: 3319.1153s / 175868.6608 s
first_0:                 episode reward: 43.7000,                 loss: nan
second_0:                 episode reward: -43.7000,                 loss: 0.0244
Episode: 921/10000 (9.2100%),                 avg. length: 7550.15,                last time consumption/overall running time: 4557.6865s / 180426.3472 s
first_0:                 episode reward: 69.3000,                 loss: nan
second_0:                 episode reward: -69.3000,                 loss: 0.0325
Episode: 941/10000 (9.4100%),                 avg. length: 5615.95,                last time consumption/overall running time: 3381.9332s / 183808.2804 s
first_0:                 episode reward: 46.9000,                 loss: nan
second_0:                 episode reward: -46.9000,                 loss: 0.0324
Episode: 961/10000 (9.6100%),                 avg. length: 5622.55,                last time consumption/overall running time: 3405.6627s / 187213.9430 s
first_0:                 episode reward: 30.8500,                 loss: nan
second_0:                 episode reward: -30.8500,                 loss: 0.0263
Episode: 981/10000 (9.8100%),                 avg. length: 5623.95,                last time consumption/overall running time: 3392.9778s / 190606.9208 s
first_0:                 episode reward: 51.6000,                 loss: nan
second_0:                 episode reward: -51.6000,                 loss: 0.0272
Episode: 1001/10000 (10.0100%),                 avg. length: 6008.05,                last time consumption/overall running time: 3615.4929s / 194222.4137 s
first_0:                 episode reward: 62.7000,                 loss: nan
second_0:                 episode reward: -62.7000,                 loss: 0.0223
Episode: 1021/10000 (10.2100%),                 avg. length: 6309.7,                last time consumption/overall running time: 3825.6569s / 198048.0706 s
first_0:                 episode reward: 48.0500,                 loss: nan
second_0:                 episode reward: -48.0500,                 loss: 0.0301
Episode: 1041/10000 (10.4100%),                 avg. length: 5033.05,                last time consumption/overall running time: 3037.7586s / 201085.8292 s
first_0:                 episode reward: 27.3500,                 loss: nan
second_0:                 episode reward: -27.3500,                 loss: 0.0259
Episode: 1061/10000 (10.6100%),                 avg. length: 5031.5,                last time consumption/overall running time: 3002.1909s / 204088.0201 s
first_0:                 episode reward: 56.5500,                 loss: nan
second_0:                 episode reward: -56.5500,                 loss: 0.0250
Episode: 1081/10000 (10.8100%),                 avg. length: 5643.15,                last time consumption/overall running time: 3397.2069s / 207485.2270 s
first_0:                 episode reward: 40.0000,                 loss: nan
second_0:                 episode reward: -40.0000,                 loss: 0.0245
Episode: 1101/10000 (11.0100%),                 avg. length: 4929.55,                last time consumption/overall running time: 2979.0340s / 210464.2610 s
first_0:                 episode reward: 28.0500,                 loss: nan
second_0:                 episode reward: -28.0500,                 loss: 0.0161
Episode: 1121/10000 (11.2100%),                 avg. length: 6275.35,                last time consumption/overall running time: 3765.1807s / 214229.4417 s
first_0:                 episode reward: 24.0500,                 loss: nan
second_0:                 episode reward: -24.0500,                 loss: 0.0167
Episode: 1141/10000 (11.4100%),                 avg. length: 7085.75,                last time consumption/overall running time: 4245.3158s / 218474.7576 s
first_0:                 episode reward: -18.9500,                 loss: nan
second_0:                 episode reward: 18.9500,                 loss: 0.0180
Episode: 1161/10000 (11.6100%),                 avg. length: 6469.1,                last time consumption/overall running time: 3888.3458s / 222363.1034 s
first_0:                 episode reward: 28.9500,                 loss: nan
second_0:                 episode reward: -28.9500,                 loss: 0.0128
Episode: 1181/10000 (11.8100%),                 avg. length: 6244.4,                last time consumption/overall running time: 3752.5015s / 226115.6049 s
first_0:                 episode reward: 13.4500,                 loss: nan
second_0:                 episode reward: -13.4500,                 loss: 0.0118
Episode: 1201/10000 (12.0100%),                 avg. length: 5997.45,                last time consumption/overall running time: 3624.7048s / 229740.3097 s
first_0:                 episode reward: -0.5000,                 loss: nan
second_0:                 episode reward: 0.5000,                 loss: 0.0108
Episode: 1221/10000 (12.2100%),                 avg. length: 6463.4,                last time consumption/overall running time: 3884.3484s / 233624.6581 s
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.0100
Episode: 1241/10000 (12.4100%),                 avg. length: 7412.15,                last time consumption/overall running time: 4469.4425s / 238094.1005 s
first_0:                 episode reward: 51.2500,                 loss: nan
second_0:                 episode reward: -51.2500,                 loss: 0.0119
Episode: 1261/10000 (12.6100%),                 avg. length: 8567.15,                last time consumption/overall running time: 5141.4817s / 243235.5822 s
first_0:                 episode reward: 106.6500,                 loss: nan
second_0:                 episode reward: -106.6500,                 loss: 0.0230
Episode: 1281/10000 (12.8100%),                 avg. length: 7364.75,                last time consumption/overall running time: 4440.0296s / 247675.6118 s
first_0:                 episode reward: 100.0000,                 loss: nan
second_0:                 episode reward: -100.0000,                 loss: 0.0325
Episode: 1301/10000 (13.0100%),                 avg. length: 6690.15,                last time consumption/overall running time: 4013.4806s / 251689.0924 s
first_0:                 episode reward: 56.3500,                 loss: nan
second_0:                 episode reward: -56.3500,                 loss: 0.0321
Episode: 1321/10000 (13.2100%),                 avg. length: 7765.4,                last time consumption/overall running time: 4648.6783s / 256337.7707 s
first_0:                 episode reward: 23.7500,                 loss: nan
second_0:                 episode reward: -23.7500,                 loss: 0.0176
Episode: 1341/10000 (13.4100%),                 avg. length: 7080.2,                last time consumption/overall running time: 4273.1298s / 260610.9005 s
first_0:                 episode reward: 47.4500,                 loss: nan
second_0:                 episode reward: -47.4500,                 loss: 0.0135
Episode: 1361/10000 (13.6100%),                 avg. length: 6588.35,                last time consumption/overall running time: 3941.4962s / 264552.3967 s
first_0:                 episode reward: 45.2500,                 loss: nan
second_0:                 episode reward: -45.2500,                 loss: 0.0120
Episode: 1381/10000 (13.8100%),                 avg. length: 7970.7,                last time consumption/overall running time: 4785.2303s / 269337.6270 s
first_0:                 episode reward: 17.6000,                 loss: nan
second_0:                 episode reward: -17.6000,                 loss: 0.0143
Episode: 1401/10000 (14.0100%),                 avg. length: 6188.0,                last time consumption/overall running time: 3721.8877s / 273059.5147 s
first_0:                 episode reward: 28.6000,                 loss: nan
second_0:                 episode reward: -28.6000,                 loss: 0.0260
Episode: 1421/10000 (14.2100%),                 avg. length: 7620.6,                last time consumption/overall running time: 4593.4280s / 277652.9428 s
first_0:                 episode reward: -9.3000,                 loss: nan
second_0:                 episode reward: 9.3000,                 loss: 0.0120
Episode: 1441/10000 (14.4100%),                 avg. length: 7385.6,                last time consumption/overall running time: 4448.8002s / 282101.7430 s
first_0:                 episode reward: 19.1500,                 loss: nan
second_0:                 episode reward: -19.1500,                 loss: 0.0087
Episode: 1461/10000 (14.6100%),                 avg. length: 7006.25,                last time consumption/overall running time: 4203.5949s / 286305.3379 s
first_0:                 episode reward: 4.5500,                 loss: nan
second_0:                 episode reward: -4.5500,                 loss: 0.0065
Episode: 1481/10000 (14.8100%),                 avg. length: 6447.5,                last time consumption/overall running time: 3870.9169s / 290176.2547 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0083
Episode: 1501/10000 (15.0100%),                 avg. length: 8259.3,                last time consumption/overall running time: 4944.4066s / 295120.6613 s
first_0:                 episode reward: -2.7000,                 loss: nan
second_0:                 episode reward: 2.7000,                 loss: 0.0062
Episode: 1521/10000 (15.2100%),                 avg. length: 7203.3,                last time consumption/overall running time: 4342.2374s / 299462.8987 s
first_0:                 episode reward: -31.4000,                 loss: nan
second_0:                 episode reward: 31.4000,                 loss: 0.0071
Episode: 1541/10000 (15.4100%),                 avg. length: 8252.25,                last time consumption/overall running time: 4956.2813s / 304419.1800 s
first_0:                 episode reward: -17.3500,                 loss: nan
second_0:                 episode reward: 17.3500,                 loss: 0.0059
Episode: 1561/10000 (15.6100%),                 avg. length: 8969.45,                last time consumption/overall running time: 5400.4539s / 309819.6339 s
first_0:                 episode reward: -23.5000,                 loss: nan
second_0:                 episode reward: 23.5000,                 loss: 0.0064
Episode: 1581/10000 (15.8100%),                 avg. length: 7142.2,                last time consumption/overall running time: 4309.9154s / 314129.5493 s
first_0:                 episode reward: -0.3000,                 loss: nan
second_0:                 episode reward: 0.3000,                 loss: 0.0053
Episode: 1601/10000 (16.0100%),                 avg. length: 7086.85,                last time consumption/overall running time: 4285.2952s / 318414.8444 s
first_0:                 episode reward: -13.5500,                 loss: nan
second_0:                 episode reward: 13.5500,                 loss: 0.0142
Episode: 1621/10000 (16.2100%),                 avg. length: 7465.25,                last time consumption/overall running time: 4465.8655s / 322880.7099 s
first_0:                 episode reward: 6.9500,                 loss: nan
second_0:                 episode reward: -6.9500,                 loss: 0.0100
Episode: 1641/10000 (16.4100%),                 avg. length: 7309.4,                last time consumption/overall running time: 4402.5075s / 327283.2174 s
first_0:                 episode reward: -15.7000,                 loss: nan
second_0:                 episode reward: 15.7000,                 loss: 0.0081
Episode: 1661/10000 (16.6100%),                 avg. length: 5743.75,                last time consumption/overall running time: 3458.5214s / 330741.7389 s
first_0:                 episode reward: -34.3000,                 loss: nan
second_0:                 episode reward: 34.3000,                 loss: 0.0258
Episode: 1681/10000 (16.8100%),                 avg. length: 4690.45,                last time consumption/overall running time: 2817.8429s / 333559.5817 s
first_0:                 episode reward: 17.2000,                 loss: nan
second_0:                 episode reward: -17.2000,                 loss: 0.0347
Episode: 1701/10000 (17.0100%),                 avg. length: 5324.95,                last time consumption/overall running time: 3191.9859s / 336751.5677 s
first_0:                 episode reward: 35.9500,                 loss: nan
second_0:                 episode reward: -35.9500,                 loss: 0.0230
Episode: 1721/10000 (17.2100%),                 avg. length: 4173.6,                last time consumption/overall running time: 2511.5700s / 339263.1376 s
first_0:                 episode reward: 11.9000,                 loss: nan
second_0:                 episode reward: -11.9000,                 loss: 0.0177
Episode: 1741/10000 (17.4100%),                 avg. length: 4820.85,                last time consumption/overall running time: 2899.4114s / 342162.5491 s
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0140
Episode: 1761/10000 (17.6100%),                 avg. length: 4926.1,                last time consumption/overall running time: 2967.7424s / 345130.2915 s
first_0:                 episode reward: -6.1000,                 loss: nan
second_0:                 episode reward: 6.1000,                 loss: 0.0139
Episode: 1781/10000 (17.8100%),                 avg. length: 5150.95,                last time consumption/overall running time: 3115.7899s / 348246.0814 s
first_0:                 episode reward: 10.5500,                 loss: nan
second_0:                 episode reward: -10.5500,                 loss: 0.0148
Episode: 1801/10000 (18.0100%),                 avg. length: 7473.9,                last time consumption/overall running time: 4498.6145s / 352744.6960 s
first_0:                 episode reward: 49.9500,                 loss: nan
second_0:                 episode reward: -49.9500,                 loss: 0.0132
Episode: 1821/10000 (18.2100%),                 avg. length: 5463.65,                last time consumption/overall running time: 3301.5045s / 356046.2005 s
first_0:                 episode reward: 8.9500,                 loss: nan
second_0:                 episode reward: -8.9500,                 loss: 0.0223
Episode: 1841/10000 (18.4100%),                 avg. length: 4069.0,                last time consumption/overall running time: 2446.8561s / 358493.0566 s
first_0:                 episode reward: 13.2000,                 loss: nan
second_0:                 episode reward: -13.2000,                 loss: 0.0336
Episode: 1861/10000 (18.6100%),                 avg. length: 4284.4,                last time consumption/overall running time: 2570.5641s / 361063.6207 s
first_0:                 episode reward: 23.7000,                 loss: nan
second_0:                 episode reward: -23.7000,                 loss: 0.0287
Episode: 1881/10000 (18.8100%),                 avg. length: 5593.85,                last time consumption/overall running time: 3359.2072s / 364422.8279 s
first_0:                 episode reward: 7.7500,                 loss: nan
second_0:                 episode reward: -7.7500,                 loss: 0.0151
Episode: 1901/10000 (19.0100%),                 avg. length: 5280.55,                last time consumption/overall running time: 3182.6432s / 367605.4711 s
first_0:                 episode reward: -17.7500,                 loss: nan
second_0:                 episode reward: 17.7500,                 loss: 0.0121
Episode: 1921/10000 (19.2100%),                 avg. length: 5170.65,                last time consumption/overall running time: 3091.0858s / 370696.5569 s
first_0:                 episode reward: 35.5000,                 loss: nan
second_0:                 episode reward: -35.5000,                 loss: 0.0093
Episode: 1941/10000 (19.4100%),                 avg. length: 6796.7,                last time consumption/overall running time: 4109.0479s / 374805.6048 s
first_0:                 episode reward: 41.3000,                 loss: nan
second_0:                 episode reward: -41.3000,                 loss: 0.0089
Episode: 1961/10000 (19.6100%),                 avg. length: 5586.45,                last time consumption/overall running time: 3400.7258s / 378206.3306 s
first_0:                 episode reward: -3.3500,                 loss: nan
second_0:                 episode reward: 3.3500,                 loss: 0.0126
Episode: 1981/10000 (19.8100%),                 avg. length: 6514.85,                last time consumption/overall running time: 3925.1478s / 382131.4784 s
first_0:                 episode reward: 29.4500,                 loss: nan
second_0:                 episode reward: -29.4500,                 loss: 0.0086
Episode: 2001/10000 (20.0100%),                 avg. length: 7923.3,                last time consumption/overall running time: 4778.9611s / 386910.4395 s
first_0:                 episode reward: 36.8000,                 loss: nan
second_0:                 episode reward: -36.8000,                 loss: 0.0073
Episode: 2021/10000 (20.2100%),                 avg. length: 7240.8,                last time consumption/overall running time: 4379.5796s / 391290.0191 s
first_0:                 episode reward: -5.9000,                 loss: nan
second_0:                 episode reward: 5.9000,                 loss: 0.0094
Episode: 2041/10000 (20.4100%),                 avg. length: 7653.7,                last time consumption/overall running time: 4604.9241s / 395894.9432 s
first_0:                 episode reward: -19.5000,                 loss: nan
second_0:                 episode reward: 19.5000,                 loss: 0.0079
Episode: 2061/10000 (20.6100%),                 avg. length: 7168.7,                last time consumption/overall running time: 4320.1998s / 400215.1430 s
first_0:                 episode reward: 4.8000,                 loss: nan
second_0:                 episode reward: -4.8000,                 loss: 0.0067
Episode: 2081/10000 (20.8100%),                 avg. length: 7848.65,                last time consumption/overall running time: 4726.3908s / 404941.5338 s
first_0:                 episode reward: -10.4500,                 loss: nan
second_0:                 episode reward: 10.4500,                 loss: 0.0059
Episode: 2101/10000 (21.0100%),                 avg. length: 6412.5,                last time consumption/overall running time: 3871.9142s / 408813.4480 s
first_0:                 episode reward: -11.2000,                 loss: nan
second_0:                 episode reward: 11.2000,                 loss: 0.0060
Episode: 2121/10000 (21.2100%),                 avg. length: 8614.15,                last time consumption/overall running time: 5165.3991s / 413978.8471 s
first_0:                 episode reward: -33.2500,                 loss: nan
second_0:                 episode reward: 33.2500,                 loss: 0.0073
Episode: 2141/10000 (21.4100%),                 avg. length: 8019.05,                last time consumption/overall running time: 4841.1961s / 418820.0432 s
first_0:                 episode reward: -14.6000,                 loss: nan
second_0:                 episode reward: 14.6000,                 loss: 0.0075
Episode: 2161/10000 (21.6100%),                 avg. length: 6884.85,                last time consumption/overall running time: 4132.1152s / 422952.1585 s
first_0:                 episode reward: -3.3500,                 loss: nan
second_0:                 episode reward: 3.3500,                 loss: 0.0090
Episode: 2181/10000 (21.8100%),                 avg. length: 7941.15,                last time consumption/overall running time: 4792.7854s / 427744.9439 s
first_0:                 episode reward: -10.8500,                 loss: nan
second_0:                 episode reward: 10.8500,                 loss: 0.0072
Episode: 2201/10000 (22.0100%),                 avg. length: 6960.75,                last time consumption/overall running time: 4183.3404s / 431928.2843 s
first_0:                 episode reward: 3.9000,                 loss: nan
second_0:                 episode reward: -3.9000,                 loss: 0.0126
Episode: 2221/10000 (22.2100%),                 avg. length: 7772.5,                last time consumption/overall running time: 4694.0472s / 436622.3315 s
first_0:                 episode reward: 10.4500,                 loss: nan
second_0:                 episode reward: -10.4500,                 loss: 0.0110
Episode: 2241/10000 (22.4100%),                 avg. length: 6453.85,                last time consumption/overall running time: 3873.0563s / 440495.3878 s
first_0:                 episode reward: 27.9000,                 loss: nan
second_0:                 episode reward: -27.9000,                 loss: 0.0200
Episode: 2261/10000 (22.6100%),                 avg. length: 7001.9,                last time consumption/overall running time: 4225.6352s / 444721.0230 s
first_0:                 episode reward: -37.6500,                 loss: nan
second_0:                 episode reward: 37.6500,                 loss: 0.0137
Episode: 2281/10000 (22.8100%),                 avg. length: 6331.0,                last time consumption/overall running time: 3831.0879s / 448552.1110 s
first_0:                 episode reward: -16.5500,                 loss: nan
second_0:                 episode reward: 16.5500,                 loss: 0.0101
Episode: 2301/10000 (23.0100%),                 avg. length: 6792.6,                last time consumption/overall running time: 4064.7041s / 452616.8151 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0122
Episode: 2321/10000 (23.2100%),                 avg. length: 6346.9,                last time consumption/overall running time: 3813.5005s / 456430.3156 s
first_0:                 episode reward: 9.2000,                 loss: nan
second_0:                 episode reward: -9.2000,                 loss: 0.0124
Episode: 2341/10000 (23.4100%),                 avg. length: 6760.25,                last time consumption/overall running time: 4085.5063s / 460515.8219 s
first_0:                 episode reward: 11.5000,                 loss: nan
second_0:                 episode reward: -11.5000,                 loss: 0.0162
Episode: 2361/10000 (23.6100%),                 avg. length: 7499.1,                last time consumption/overall running time: 4513.0119s / 465028.8338 s
first_0:                 episode reward: -23.9000,                 loss: nan
second_0:                 episode reward: 23.9000,                 loss: 0.0105
Episode: 2381/10000 (23.8100%),                 avg. length: 6752.85,                last time consumption/overall running time: 4075.0576s / 469103.8914 s
first_0:                 episode reward: 0.3500,                 loss: nan
second_0:                 episode reward: -0.3500,                 loss: 0.0118
Episode: 2401/10000 (24.0100%),                 avg. length: 6587.0,                last time consumption/overall running time: 4000.8100s / 473104.7014 s
first_0:                 episode reward: 32.2500,                 loss: nan
second_0:                 episode reward: -32.2500,                 loss: 0.0219
Episode: 2421/10000 (24.2100%),                 avg. length: 6079.1,                last time consumption/overall running time: 3656.9158s / 476761.6172 s