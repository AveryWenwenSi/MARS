pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 91
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f5b72e96e48>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=128, bias=True)
      (1): ReLU()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ReLU()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): ReLU()
      (6): Linear(in_features=128, out_features=128, bias=True)
      (7): ReLU()
      (8): Linear(in_features=128, out_features=18, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Load meta strategy:  [array([0.016, 0.016, 0.016, ..., 0.016, 0.016, 0.016]) array([0.017, 0.017, 0.017, ..., 0.017, 0.017, 0.017])]
Load checkpoints (policy family):  [list(['21', '126', '182', '228', '282', '356', '444', '601', '648', '694', '827', '907', '949', '991', '1082', '1243', '1288', '1331', '1499', '1558', '1620', '1709', '1788', '1893', '1964', '2113', '2202', '2376', '2442', '2502', '2567', '2704', '2775', '2938', '3008', '3091', '3390', '3466', '3657', '3804', '4280', '4379', '4466', '4564', '4713', '4872', '4999', '5095', '5227', '5409', '5514', '6172', '6299', '6419', '6569', '6871', '6992', '7450', '7600', '7762', '7990'])
 list(['67', '161', '205', '249', '334', '380', '501', '622', '673', '720', '885', '928', '970', '1017', '1103', '1264', '1309', '1352', '1520', '1596', '1661', '1743', '1844', '1918', '1990', '2140', '2240', '2405', '2472', '2533', '2670', '2737', '2813', '2973', '3045', '3179', '3428', '3505', '3760', '4238', '4337', '4423', '4510', '4668', '4826', '4927', '5047', '5167', '5277', '5463', '5615', '6225', '6353', '6478', '6625', '6928', '7050', '7509', '7660', '7832'])]
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220119_0526/pettingzoo_boxing_v1_fictitious_selfplay2/', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False, 'selfplay_score_delta': 80, 'trainable_agent_idx': 0, 'opponent_idx': 1}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220119_0526_exploit/pettingzoo_boxing_v1_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0526_exploit/pettingzoo_boxing_v1_fictitious_selfplay2.
Episode: 1/10000 (0.0100%),                 avg. length: 1784.0,                last time consumption/overall running time: 33.4239s / 33.4239 s
first_0:                 episode reward: 20.0000,                 loss: nan
second_0:                 episode reward: -20.0000,                 loss: 0.0702
Episode: 21/10000 (0.2100%),                 avg. length: 761.5,                last time consumption/overall running time: 294.9976s / 328.4215 s
first_0:                 episode reward: 70.4500,                 loss: nan
second_0:                 episode reward: -70.4500,                 loss: 0.0614
Episode: 41/10000 (0.4100%),                 avg. length: 856.9,                last time consumption/overall running time: 341.2537s / 669.6752 s
first_0:                 episode reward: 69.3000,                 loss: nan
second_0:                 episode reward: -69.3000,                 loss: 0.1115
Episode: 61/10000 (0.6100%),                 avg. length: 1188.05,                last time consumption/overall running time: 486.0766s / 1155.7518 s
first_0:                 episode reward: 57.9000,                 loss: nan
second_0:                 episode reward: -57.9000,                 loss: 0.1565
Episode: 81/10000 (0.8100%),                 avg. length: 976.1,                last time consumption/overall running time: 406.1614s / 1561.9133 s
first_0:                 episode reward: 57.5500,                 loss: nan
second_0:                 episode reward: -57.5500,                 loss: 0.1603
Episode: 101/10000 (1.0100%),                 avg. length: 974.85,                last time consumption/overall running time: 407.9440s / 1969.8572 s
first_0:                 episode reward: 53.1500,                 loss: nan
second_0:                 episode reward: -53.1500,                 loss: 0.1850
Episode: 121/10000 (1.2100%),                 avg. length: 1348.3,                last time consumption/overall running time: 569.5634s / 2539.4206 s
first_0:                 episode reward: 34.2000,                 loss: nan
second_0:                 episode reward: -34.2000,                 loss: 0.1725
Episode: 141/10000 (1.4100%),                 avg. length: 1230.25,                last time consumption/overall running time: 517.8974s / 3057.3180 s
first_0:                 episode reward: 44.7500,                 loss: nan
second_0:                 episode reward: -44.7500,                 loss: 0.1355
Episode: 161/10000 (1.6100%),                 avg. length: 1381.55,                last time consumption/overall running time: 580.9327s / 3638.2508 s
first_0:                 episode reward: 39.4000,                 loss: nan
second_0:                 episode reward: -39.4000,                 loss: 0.1134
Episode: 181/10000 (1.8100%),                 avg. length: 1286.15,                last time consumption/overall running time: 541.6266s / 4179.8774 s
first_0:                 episode reward: 41.7000,                 loss: nan
second_0:                 episode reward: -41.7000,                 loss: 0.1075
Episode: 201/10000 (2.0100%),                 avg. length: 1587.5,                last time consumption/overall running time: 669.3226s / 4849.2000 s
first_0:                 episode reward: 15.4500,                 loss: nan
second_0:                 episode reward: -15.4500,                 loss: 0.0909
Episode: 221/10000 (2.2100%),                 avg. length: 1556.8,                last time consumption/overall running time: 655.6035s / 5504.8035 s
first_0:                 episode reward: 13.9000,                 loss: nan
second_0:                 episode reward: -13.9000,                 loss: 0.0676
Episode: 241/10000 (2.4100%),                 avg. length: 1416.75,                last time consumption/overall running time: 597.2644s / 6102.0679 s
first_0:                 episode reward: 36.1500,                 loss: nan
second_0:                 episode reward: -36.1500,                 loss: 0.0378
Episode: 261/10000 (2.6100%),                 avg. length: 1469.8,                last time consumption/overall running time: 617.2347s / 6719.3027 s
first_0:                 episode reward: 26.0000,                 loss: nan
second_0:                 episode reward: -26.0000,                 loss: 0.0329
Episode: 281/10000 (2.8100%),                 avg. length: 1220.5,                last time consumption/overall running time: 515.6238s / 7234.9265 s
first_0:                 episode reward: 46.6000,                 loss: nan
second_0:                 episode reward: -46.6000,                 loss: 0.0474
Episode: 301/10000 (3.0100%),                 avg. length: 1421.9,                last time consumption/overall running time: 597.9820s / 7832.9085 s
first_0:                 episode reward: 41.4000,                 loss: nan
second_0:                 episode reward: -41.4000,                 loss: 0.0720
Episode: 321/10000 (3.2100%),                 avg. length: 1252.2,                last time consumption/overall running time: 526.7526s / 8359.6611 s
first_0:                 episode reward: 51.2500,                 loss: nan
second_0:                 episode reward: -51.2500,                 loss: 0.0850
Episode: 341/10000 (3.4100%),                 avg. length: 1283.9,                last time consumption/overall running time: 540.1924s / 8899.8535 s
first_0:                 episode reward: 48.3000,                 loss: nan
second_0:                 episode reward: -48.3000,                 loss: 0.0869
Episode: 361/10000 (3.6100%),                 avg. length: 1387.0,                last time consumption/overall running time: 584.2452s / 9484.0987 s
first_0:                 episode reward: 31.8000,                 loss: nan
second_0:                 episode reward: -31.8000,                 loss: 0.0903
Episode: 381/10000 (3.8100%),                 avg. length: 1228.5,                last time consumption/overall running time: 518.6565s / 10002.7552 s
first_0:                 episode reward: 51.0500,                 loss: nan
second_0:                 episode reward: -51.0500,                 loss: 0.0863
Episode: 401/10000 (4.0100%),                 avg. length: 1391.2,                last time consumption/overall running time: 585.6530s / 10588.4083 s
first_0:                 episode reward: 39.3000,                 loss: nan
second_0:                 episode reward: -39.3000,                 loss: 0.0942
Episode: 421/10000 (4.2100%),                 avg. length: 1223.95,                last time consumption/overall running time: 514.0334s / 11102.4417 s
first_0:                 episode reward: 46.8000,                 loss: nan
second_0:                 episode reward: -46.8000,                 loss: 0.1010
Episode: 441/10000 (4.4100%),                 avg. length: 1325.45,                last time consumption/overall running time: 558.1038s / 11660.5454 s
first_0:                 episode reward: 58.5500,                 loss: nan
second_0:                 episode reward: -58.5500,                 loss: 0.1185
Episode: 461/10000 (4.6100%),                 avg. length: 1136.65,                last time consumption/overall running time: 479.4290s / 12139.9744 s
first_0:                 episode reward: 47.1000,                 loss: nan
second_0:                 episode reward: -47.1000,                 loss: 0.1128
Episode: 481/10000 (4.8100%),                 avg. length: 1158.2,                last time consumption/overall running time: 487.1578s / 12627.1322 s
first_0:                 episode reward: 53.5000,                 loss: nan
second_0:                 episode reward: -53.5000,                 loss: 0.1192
Episode: 501/10000 (5.0100%),                 avg. length: 919.5,                last time consumption/overall running time: 386.7465s / 13013.8788 s
first_0:                 episode reward: 64.0000,                 loss: nan
second_0:                 episode reward: -64.0000,                 loss: 0.1430
Episode: 521/10000 (5.2100%),                 avg. length: 1101.2,                last time consumption/overall running time: 464.7414s / 13478.6201 s
first_0:                 episode reward: 55.9000,                 loss: nan
second_0:                 episode reward: -55.9000,                 loss: 0.1614
Episode: 541/10000 (5.4100%),                 avg. length: 1155.9,                last time consumption/overall running time: 489.7203s / 13968.3405 s
first_0:                 episode reward: 50.9500,                 loss: nan
second_0:                 episode reward: -50.9500,                 loss: 0.1668
Episode: 561/10000 (5.6100%),                 avg. length: 1199.85,                last time consumption/overall running time: 504.9397s / 14473.2802 s
first_0:                 episode reward: 40.9000,                 loss: nan
second_0:                 episode reward: -40.9000,                 loss: 0.1704
Episode: 581/10000 (5.8100%),                 avg. length: 967.2,                last time consumption/overall running time: 407.3039s / 14880.5840 s
first_0:                 episode reward: 62.4000,                 loss: nan
second_0:                 episode reward: -62.4000,                 loss: 0.1676
Episode: 601/10000 (6.0100%),                 avg. length: 858.4,                last time consumption/overall running time: 360.4259s / 15241.0099 s
first_0:                 episode reward: 70.5000,                 loss: nan
second_0:                 episode reward: -70.5000,                 loss: 0.2033
Episode: 621/10000 (6.2100%),                 avg. length: 1274.95,                last time consumption/overall running time: 538.2786s / 15779.2885 s
first_0:                 episode reward: 51.8000,                 loss: nan
second_0:                 episode reward: -51.8000,                 loss: 0.2066
Episode: 641/10000 (6.4100%),                 avg. length: 1088.2,                last time consumption/overall running time: 459.4153s / 16238.7037 s
first_0:                 episode reward: 65.2000,                 loss: nan
second_0:                 episode reward: -65.2000,                 loss: 0.2038
Episode: 661/10000 (6.6100%),                 avg. length: 1067.0,                last time consumption/overall running time: 449.8760s / 16688.5798 s
first_0:                 episode reward: 54.4000,                 loss: nan
second_0:                 episode reward: -54.4000,                 loss: 0.2313
Episode: 681/10000 (6.8100%),                 avg. length: 881.35,                last time consumption/overall running time: 371.7557s / 17060.3354 s
first_0:                 episode reward: 63.8000,                 loss: nan
second_0:                 episode reward: -63.8000,                 loss: 0.2523
Episode: 701/10000 (7.0100%),                 avg. length: 1427.85,                last time consumption/overall running time: 601.6239s / 17661.9593 s
first_0:                 episode reward: 40.4500,                 loss: nan
second_0:                 episode reward: -40.4500,                 loss: 0.2348
Episode: 721/10000 (7.2100%),                 avg. length: 1097.5,                last time consumption/overall running time: 462.7694s / 18124.7287 s
first_0:                 episode reward: 48.5500,                 loss: nan
second_0:                 episode reward: -48.5500,                 loss: 0.2150
Episode: 741/10000 (7.4100%),                 avg. length: 1264.25,                last time consumption/overall running time: 533.2753s / 18658.0041 s
first_0:                 episode reward: 48.5500,                 loss: nan
second_0:                 episode reward: -48.5500,                 loss: 0.2042
Episode: 761/10000 (7.6100%),                 avg. length: 1424.25,                last time consumption/overall running time: 598.8744s / 19256.8785 s
first_0:                 episode reward: 36.5000,                 loss: nan
second_0:                 episode reward: -36.5000,                 loss: 0.1704
Episode: 781/10000 (7.8100%),                 avg. length: 1112.9,                last time consumption/overall running time: 467.5193s / 19724.3978 s
first_0:                 episode reward: 50.1000,                 loss: nan
second_0:                 episode reward: -50.1000,                 loss: 0.1652
Episode: 801/10000 (8.0100%),                 avg. length: 1226.05,                last time consumption/overall running time: 517.4588s / 20241.8566 s
first_0:                 episode reward: 38.5500,                 loss: nan
second_0:                 episode reward: -38.5500,                 loss: 0.1715
Episode: 821/10000 (8.2100%),                 avg. length: 1454.8,                last time consumption/overall running time: 612.4382s / 20854.2948 s
first_0:                 episode reward: 18.3000,                 loss: nan
second_0:                 episode reward: -18.3000,                 loss: 0.1327
Episode: 841/10000 (8.4100%),                 avg. length: 1221.3,                last time consumption/overall running time: 515.5252s / 21369.8201 s
first_0:                 episode reward: 31.8500,                 loss: nan
second_0:                 episode reward: -31.8500,                 loss: 0.1030
Episode: 861/10000 (8.6100%),                 avg. length: 1509.8,                last time consumption/overall running time: 636.8284s / 22006.6485 s
first_0:                 episode reward: 12.1500,                 loss: nan
second_0:                 episode reward: -12.1500,                 loss: 0.0827
Episode: 881/10000 (8.8100%),                 avg. length: 1273.8,                last time consumption/overall running time: 536.7191s / 22543.3675 s
first_0:                 episode reward: 41.3500,                 loss: nan
second_0:                 episode reward: -41.3500,                 loss: 0.0713
Episode: 901/10000 (9.0100%),                 avg. length: 1118.45,                last time consumption/overall running time: 472.4310s / 23015.7986 s
first_0:                 episode reward: 45.5000,                 loss: nan
second_0:                 episode reward: -45.5000,                 loss: 0.0862
Episode: 921/10000 (9.2100%),                 avg. length: 1414.8,                last time consumption/overall running time: 597.8990s / 23613.6976 s
first_0:                 episode reward: 39.4500,                 loss: nan
second_0:                 episode reward: -39.4500,                 loss: 0.0995
Episode: 941/10000 (9.4100%),                 avg. length: 1438.4,                last time consumption/overall running time: 608.0846s / 24221.7822 s
first_0:                 episode reward: 20.5500,                 loss: nan
second_0:                 episode reward: -20.5500,                 loss: 0.0975
Episode: 961/10000 (9.6100%),                 avg. length: 1409.55,                last time consumption/overall running time: 595.8539s / 24817.6361 s
first_0:                 episode reward: 26.8500,                 loss: nan
second_0:                 episode reward: -26.8500,                 loss: 0.0849
Episode: 981/10000 (9.8100%),                 avg. length: 1253.85,                last time consumption/overall running time: 530.3276s / 25347.9637 s
first_0:                 episode reward: 46.6000,                 loss: nan
second_0:                 episode reward: -46.6000,                 loss: 0.0937
Episode: 1001/10000 (10.0100%),                 avg. length: 1287.25,                last time consumption/overall running time: 542.8183s / 25890.7820 s
first_0:                 episode reward: 31.1000,                 loss: nan
second_0:                 episode reward: -31.1000,                 loss: 0.1015
Episode: 1021/10000 (10.2100%),                 avg. length: 1314.15,                last time consumption/overall running time: 552.6934s / 26443.4753 s
first_0:                 episode reward: 36.8500,                 loss: nan
second_0:                 episode reward: -36.8500,                 loss: 0.1022
Episode: 1041/10000 (10.4100%),                 avg. length: 1354.2,                last time consumption/overall running time: 571.6470s / 27015.1223 s
first_0:                 episode reward: 28.0500,                 loss: nan
second_0:                 episode reward: -28.0500,                 loss: 0.1104
Episode: 1061/10000 (10.6100%),                 avg. length: 1045.15,                last time consumption/overall running time: 441.3031s / 27456.4254 s
first_0:                 episode reward: 48.2500,                 loss: nan
second_0:                 episode reward: -48.2500,                 loss: 0.1069
Episode: 1081/10000 (10.8100%),                 avg. length: 1384.7,                last time consumption/overall running time: 584.3820s / 28040.8075 s
first_0:                 episode reward: 22.0000,                 loss: nan
second_0:                 episode reward: -22.0000,                 loss: 0.1102
Episode: 1101/10000 (11.0100%),                 avg. length: 1117.0,                last time consumption/overall running time: 471.6760s / 28512.4835 s
first_0:                 episode reward: 38.8500,                 loss: nan
second_0:                 episode reward: -38.8500,                 loss: 0.1258
Episode: 1121/10000 (11.2100%),                 avg. length: 919.75,                last time consumption/overall running time: 389.3307s / 28901.8142 s
first_0:                 episode reward: 46.3500,                 loss: nan
second_0:                 episode reward: -46.3500,                 loss: 0.1262
Episode: 1141/10000 (11.4100%),                 avg. length: 1327.2,                last time consumption/overall running time: 560.9278s / 29462.7420 s
first_0:                 episode reward: 30.7500,                 loss: nan
second_0:                 episode reward: -30.7500,                 loss: 0.1465
Episode: 1161/10000 (11.6100%),                 avg. length: 1249.9,                last time consumption/overall running time: 527.1839s / 29989.9259 s
first_0:                 episode reward: 15.5500,                 loss: nan
second_0:                 episode reward: -15.5500,                 loss: 0.1372
Episode: 1181/10000 (11.8100%),                 avg. length: 1304.9,                last time consumption/overall running time: 547.4487s / 30537.3745 s
first_0:                 episode reward: 18.2000,                 loss: nan
second_0:                 episode reward: -18.2000,                 loss: 0.1383
Episode: 1201/10000 (12.0100%),                 avg. length: 1215.3,                last time consumption/overall running time: 513.3098s / 31050.6843 s
first_0:                 episode reward: 35.0000,                 loss: nan
second_0:                 episode reward: -35.0000,                 loss: 0.1311
Episode: 1221/10000 (12.2100%),                 avg. length: 1241.95,                last time consumption/overall running time: 525.1561s / 31575.8404 s
first_0:                 episode reward: 28.9000,                 loss: nan
second_0:                 episode reward: -28.9000,                 loss: 0.1240
Episode: 1241/10000 (12.4100%),                 avg. length: 1377.85,                last time consumption/overall running time: 582.3145s / 32158.1549 s
first_0:                 episode reward: 17.8000,                 loss: nan
second_0:                 episode reward: -17.8000,                 loss: 0.1188
Episode: 1261/10000 (12.6100%),                 avg. length: 1051.9,                last time consumption/overall running time: 444.6625s / 32602.8173 s
first_0:                 episode reward: 33.3000,                 loss: nan
second_0:                 episode reward: -33.3000,                 loss: 0.1254
Episode: 1281/10000 (12.8100%),                 avg. length: 1177.7,                last time consumption/overall running time: 498.8406s / 33101.6579 s
first_0:                 episode reward: 28.3000,                 loss: nan
second_0:                 episode reward: -28.3000,                 loss: 0.1328
Episode: 1301/10000 (13.0100%),                 avg. length: 1189.1,                last time consumption/overall running time: 503.7303s / 33605.3882 s
first_0:                 episode reward: 11.9500,                 loss: nan
second_0:                 episode reward: -11.9500,                 loss: 0.1327
Episode: 1321/10000 (13.2100%),                 avg. length: 1095.6,                last time consumption/overall running time: 462.6211s / 34068.0093 s
first_0:                 episode reward: 36.9000,                 loss: nan
second_0:                 episode reward: -36.9000,                 loss: 0.1539
Episode: 1341/10000 (13.4100%),                 avg. length: 1180.8,                last time consumption/overall running time: 498.5365s / 34566.5458 s
first_0:                 episode reward: 10.8500,                 loss: nan
second_0:                 episode reward: -10.8500,                 loss: 0.1460