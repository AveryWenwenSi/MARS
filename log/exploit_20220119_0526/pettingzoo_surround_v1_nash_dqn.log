pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
surround_v1 pettingzoo
Load surround_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(5)
random seed: 91
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f0c307c8dd8>
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=256, bias=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=256, bias=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=5, bias=True)
    )
  )
)
DQNBase(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): ReLU()
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): ReLU()
      (4): Linear(in_features=256, out_features=256, bias=True)
      (5): ReLU()
      (6): Linear(in_features=256, out_features=256, bias=True)
      (7): ReLU()
      (8): Linear(in_features=256, out_features=5, bias=True)
    )
  )
)
Agents No. [0] (index starting from 0) are not learnable.
Agent No. [0] loads model from:  ./data/model/20220119_0526/pettingzoo_surround_v1_nash_dqn/6000_0
Arguments:  {'env_name': 'surround_v1', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': True, 'load_model_idx': False, 'load_model_full_path': './data/model/20220119_0526/pettingzoo_surround_v1_nash_dqn/6000_0', 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'against_baseline': False}
Save models to : /home/zihan/research/MARS/data/model/20220119_0526_exploit/pettingzoo_surround_v1_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0526_exploit/pettingzoo_surround_v1_nash_dqn.
Episode: 1/10000 (0.0100%),                 avg. length: 1863.0,                last time consumption/overall running time: 81.5833s / 81.5833 s
first_0:                 episode reward: 2.0000,                 loss: nan
second_0:                 episode reward: -2.0000,                 loss: 0.0030
Episode: 21/10000 (0.2100%),                 avg. length: 1654.95,                last time consumption/overall running time: 500.1810s / 581.7642 s
first_0:                 episode reward: 0.7000,                 loss: nan
second_0:                 episode reward: -0.7000,                 loss: 0.0037
Episode: 41/10000 (0.4100%),                 avg. length: 1799.15,                last time consumption/overall running time: 562.8831s / 1144.6473 s
first_0:                 episode reward: -0.6500,                 loss: nan
second_0:                 episode reward: 0.6500,                 loss: 0.0050
Episode: 61/10000 (0.6100%),                 avg. length: 1766.85,                last time consumption/overall running time: 562.5019s / 1707.1493 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0040
Episode: 81/10000 (0.8100%),                 avg. length: 1796.55,                last time consumption/overall running time: 573.9159s / 2281.0652 s
first_0:                 episode reward: -1.9500,                 loss: nan
second_0:                 episode reward: 1.9500,                 loss: 0.0033
Episode: 101/10000 (1.0100%),                 avg. length: 1670.3,                last time consumption/overall running time: 541.1942s / 2822.2593 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0025
Episode: 121/10000 (1.2100%),                 avg. length: 1810.75,                last time consumption/overall running time: 581.6985s / 3403.9578 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0021
Episode: 141/10000 (1.4100%),                 avg. length: 1668.1,                last time consumption/overall running time: 536.7370s / 3940.6948 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0022
Episode: 161/10000 (1.6100%),                 avg. length: 1757.2,                last time consumption/overall running time: 571.6831s / 4512.3778 s
first_0:                 episode reward: -2.2000,                 loss: nan
second_0:                 episode reward: 2.2000,                 loss: 0.0022
Episode: 181/10000 (1.8100%),                 avg. length: 1599.65,                last time consumption/overall running time: 512.4446s / 5024.8225 s
first_0:                 episode reward: -5.7500,                 loss: nan
second_0:                 episode reward: 5.7500,                 loss: 0.0022
Episode: 201/10000 (2.0100%),                 avg. length: 1672.55,                last time consumption/overall running time: 536.1923s / 5561.0148 s
first_0:                 episode reward: -5.2000,                 loss: nan
second_0:                 episode reward: 5.2000,                 loss: 0.0020
Episode: 221/10000 (2.2100%),                 avg. length: 1743.1,                last time consumption/overall running time: 557.7040s / 6118.7188 s
first_0:                 episode reward: -3.9500,                 loss: nan
second_0:                 episode reward: 3.9500,                 loss: 0.0021
Episode: 241/10000 (2.4100%),                 avg. length: 1572.05,                last time consumption/overall running time: 484.0017s / 6602.7205 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0020
Episode: 261/10000 (2.6100%),                 avg. length: 1671.95,                last time consumption/overall running time: 510.6317s / 7113.3522 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0020
Episode: 281/10000 (2.8100%),                 avg. length: 1603.65,                last time consumption/overall running time: 489.2646s / 7602.6167 s
first_0:                 episode reward: -5.8000,                 loss: nan
second_0:                 episode reward: 5.8000,                 loss: 0.0020
Episode: 301/10000 (3.0100%),                 avg. length: 1683.55,                last time consumption/overall running time: 518.1385s / 8120.7552 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0022
Episode: 321/10000 (3.2100%),                 avg. length: 1683.1,                last time consumption/overall running time: 518.4943s / 8639.2495 s
first_0:                 episode reward: -2.5000,                 loss: nan
second_0:                 episode reward: 2.5000,                 loss: 0.0021
Episode: 341/10000 (3.4100%),                 avg. length: 1671.4,                last time consumption/overall running time: 517.3222s / 9156.5717 s
first_0:                 episode reward: -4.5000,                 loss: nan
second_0:                 episode reward: 4.5000,                 loss: 0.0021
Episode: 361/10000 (3.6100%),                 avg. length: 1640.15,                last time consumption/overall running time: 504.3140s / 9660.8858 s
first_0:                 episode reward: -4.9500,                 loss: nan
second_0:                 episode reward: 4.9500,                 loss: 0.0021
Episode: 381/10000 (3.8100%),                 avg. length: 1840.25,                last time consumption/overall running time: 562.9958s / 10223.8816 s
first_0:                 episode reward: -2.5000,                 loss: nan
second_0:                 episode reward: 2.5000,                 loss: 0.0020
Episode: 401/10000 (4.0100%),                 avg. length: 1829.9,                last time consumption/overall running time: 560.5882s / 10784.4699 s
first_0:                 episode reward: -2.3000,                 loss: nan
second_0:                 episode reward: 2.3000,                 loss: 0.0023
Episode: 421/10000 (4.2100%),                 avg. length: 1710.35,                last time consumption/overall running time: 518.4964s / 11302.9662 s
first_0:                 episode reward: -5.1500,                 loss: nan
second_0:                 episode reward: 5.1500,                 loss: 0.0026
Episode: 441/10000 (4.4100%),                 avg. length: 1674.0,                last time consumption/overall running time: 514.6303s / 11817.5965 s
first_0:                 episode reward: -2.4000,                 loss: nan
second_0:                 episode reward: 2.4000,                 loss: 0.0026
Episode: 461/10000 (4.6100%),                 avg. length: 1699.2,                last time consumption/overall running time: 521.5844s / 12339.1809 s
first_0:                 episode reward: -3.5000,                 loss: nan
second_0:                 episode reward: 3.5000,                 loss: 0.0025
Episode: 481/10000 (4.8100%),                 avg. length: 1800.15,                last time consumption/overall running time: 553.5199s / 12892.7008 s
first_0:                 episode reward: -1.7000,                 loss: nan
second_0:                 episode reward: 1.7000,                 loss: 0.0024
Episode: 501/10000 (5.0100%),                 avg. length: 1664.5,                last time consumption/overall running time: 512.4859s / 13405.1867 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0028
Episode: 521/10000 (5.2100%),                 avg. length: 1832.6,                last time consumption/overall running time: 566.7873s / 13971.9740 s
first_0:                 episode reward: 0.6500,                 loss: nan
second_0:                 episode reward: -0.6500,                 loss: 0.0052
Episode: 541/10000 (5.4100%),                 avg. length: 1847.4,                last time consumption/overall running time: 569.1968s / 14541.1708 s
first_0:                 episode reward: -0.4500,                 loss: nan
second_0:                 episode reward: 0.4500,                 loss: 0.0070
Episode: 561/10000 (5.6100%),                 avg. length: 1626.9,                last time consumption/overall running time: 501.2565s / 15042.4272 s
first_0:                 episode reward: -4.0500,                 loss: nan
second_0:                 episode reward: 4.0500,                 loss: 0.0053
Episode: 581/10000 (5.8100%),                 avg. length: 1854.9,                last time consumption/overall running time: 570.3243s / 15612.7516 s
first_0:                 episode reward: -1.9000,                 loss: nan
second_0:                 episode reward: 1.9000,                 loss: 0.0051
Episode: 601/10000 (6.0100%),                 avg. length: 1773.9,                last time consumption/overall running time: 549.5069s / 16162.2584 s
first_0:                 episode reward: -2.4000,                 loss: nan
second_0:                 episode reward: 2.4000,                 loss: 0.0055
Episode: 621/10000 (6.2100%),                 avg. length: 1736.85,                last time consumption/overall running time: 534.1167s / 16696.3752 s
first_0:                 episode reward: -3.7500,                 loss: nan
second_0:                 episode reward: 3.7500,                 loss: 0.0079
Episode: 641/10000 (6.4100%),                 avg. length: 1841.6,                last time consumption/overall running time: 563.8840s / 17260.2591 s
first_0:                 episode reward: -3.1000,                 loss: nan
second_0:                 episode reward: 3.1000,                 loss: 0.0085
Episode: 661/10000 (6.6100%),                 avg. length: 1859.1,                last time consumption/overall running time: 569.9939s / 17830.2531 s
first_0:                 episode reward: -0.9000,                 loss: nan
second_0:                 episode reward: 0.9000,                 loss: 0.0065
Episode: 681/10000 (6.8100%),                 avg. length: 1776.95,                last time consumption/overall running time: 544.0445s / 18374.2976 s
first_0:                 episode reward: -2.9500,                 loss: nan
second_0:                 episode reward: 2.9500,                 loss: 0.0060
Episode: 701/10000 (7.0100%),                 avg. length: 1608.8,                last time consumption/overall running time: 495.6730s / 18869.9705 s
first_0:                 episode reward: -5.8000,                 loss: nan
second_0:                 episode reward: 5.8000,                 loss: 0.0069
Episode: 721/10000 (7.2100%),                 avg. length: 1822.2,                last time consumption/overall running time: 560.3877s / 19430.3582 s
first_0:                 episode reward: -1.7500,                 loss: nan
second_0:                 episode reward: 1.7500,                 loss: 0.0076
Episode: 741/10000 (7.4100%),                 avg. length: 1790.1,                last time consumption/overall running time: 547.0517s / 19977.4099 s
first_0:                 episode reward: -0.8000,                 loss: nan
second_0:                 episode reward: 0.8000,                 loss: 0.0078
Episode: 761/10000 (7.6100%),                 avg. length: 1703.2,                last time consumption/overall running time: 521.5262s / 20498.9361 s
first_0:                 episode reward: -3.6500,                 loss: nan
second_0:                 episode reward: 3.6500,                 loss: 0.0088
Episode: 781/10000 (7.8100%),                 avg. length: 1674.35,                last time consumption/overall running time: 516.4234s / 21015.3595 s
first_0:                 episode reward: -2.2500,                 loss: nan
second_0:                 episode reward: 2.2500,                 loss: 0.0113
Episode: 801/10000 (8.0100%),                 avg. length: 1778.45,                last time consumption/overall running time: 545.2122s / 21560.5717 s
first_0:                 episode reward: -0.5500,                 loss: nan
second_0:                 episode reward: 0.5500,                 loss: 0.0097
Episode: 821/10000 (8.2100%),                 avg. length: 1723.2,                last time consumption/overall running time: 521.6094s / 22082.1812 s
first_0:                 episode reward: -1.6000,                 loss: nan
second_0:                 episode reward: 1.6000,                 loss: 0.0101
Episode: 841/10000 (8.4100%),                 avg. length: 1770.75,                last time consumption/overall running time: 545.4361s / 22627.6173 s
first_0:                 episode reward: -4.2500,                 loss: nan
second_0:                 episode reward: 4.2500,                 loss: 0.0160
Episode: 861/10000 (8.6100%),                 avg. length: 1772.25,                last time consumption/overall running time: 547.3951s / 23175.0124 s
first_0:                 episode reward: -1.8500,                 loss: nan
second_0:                 episode reward: 1.8500,                 loss: 0.0117
Episode: 881/10000 (8.8100%),                 avg. length: 1768.2,                last time consumption/overall running time: 545.1069s / 23720.1193 s
first_0:                 episode reward: 0.7500,                 loss: nan
second_0:                 episode reward: -0.7500,                 loss: 0.0105
Episode: 901/10000 (9.0100%),                 avg. length: 1716.8,                last time consumption/overall running time: 526.6651s / 24246.7843 s
first_0:                 episode reward: -2.5500,                 loss: nan
second_0:                 episode reward: 2.5500,                 loss: 0.0087
Episode: 921/10000 (9.2100%),                 avg. length: 1645.7,                last time consumption/overall running time: 506.0196s / 24752.8040 s
first_0:                 episode reward: -5.3000,                 loss: nan
second_0:                 episode reward: 5.3000,                 loss: 0.0107
Episode: 941/10000 (9.4100%),                 avg. length: 1790.2,                last time consumption/overall running time: 546.0573s / 25298.8613 s
first_0:                 episode reward: -1.1000,                 loss: nan
second_0:                 episode reward: 1.1000,                 loss: 0.0113
Episode: 961/10000 (9.6100%),                 avg. length: 1698.45,                last time consumption/overall running time: 519.7637s / 25818.6250 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0117
Episode: 981/10000 (9.8100%),                 avg. length: 1727.5,                last time consumption/overall running time: 525.9204s / 26344.5454 s
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0104
Episode: 1001/10000 (10.0100%),                 avg. length: 1684.4,                last time consumption/overall running time: 517.7446s / 26862.2901 s
first_0:                 episode reward: -4.1000,                 loss: nan
second_0:                 episode reward: 4.1000,                 loss: 0.0100
Episode: 1021/10000 (10.2100%),                 avg. length: 1674.2,                last time consumption/overall running time: 507.9883s / 27370.2783 s
first_0:                 episode reward: -2.6500,                 loss: nan
second_0:                 episode reward: 2.6500,                 loss: 0.0081
Episode: 1041/10000 (10.4100%),                 avg. length: 1765.5,                last time consumption/overall running time: 542.5004s / 27912.7787 s
first_0:                 episode reward: -1.0500,                 loss: nan
second_0:                 episode reward: 1.0500,                 loss: 0.0063
Episode: 1061/10000 (10.6100%),                 avg. length: 1656.25,                last time consumption/overall running time: 507.6453s / 28420.4240 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0061
Episode: 1081/10000 (10.8100%),                 avg. length: 1569.95,                last time consumption/overall running time: 474.7352s / 28895.1592 s
first_0:                 episode reward: -5.5500,                 loss: nan
second_0:                 episode reward: 5.5500,                 loss: 0.0076
Episode: 1101/10000 (11.0100%),                 avg. length: 1831.85,                last time consumption/overall running time: 563.2143s / 29458.3735 s
first_0:                 episode reward: -1.4000,                 loss: nan
second_0:                 episode reward: 1.4000,                 loss: 0.0103
Episode: 1121/10000 (11.2100%),                 avg. length: 1772.1,                last time consumption/overall running time: 538.7143s / 29997.0878 s
first_0:                 episode reward: 0.4000,                 loss: nan
second_0:                 episode reward: -0.4000,                 loss: 0.0091
Episode: 1141/10000 (11.4100%),                 avg. length: 1720.6,                last time consumption/overall running time: 523.2107s / 30520.2985 s
first_0:                 episode reward: -3.3000,                 loss: nan
second_0:                 episode reward: 3.3000,                 loss: 0.0102
Episode: 1161/10000 (11.6100%),                 avg. length: 1917.9,                last time consumption/overall running time: 584.3286s / 31104.6271 s
first_0:                 episode reward: -2.3000,                 loss: nan
second_0:                 episode reward: 2.3000,                 loss: 0.0112
Episode: 1181/10000 (11.8100%),                 avg. length: 1733.65,                last time consumption/overall running time: 528.0143s / 31632.6414 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0064
Episode: 1201/10000 (12.0100%),                 avg. length: 1737.3,                last time consumption/overall running time: 529.2131s / 32161.8545 s
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0062
Episode: 1221/10000 (12.2100%),                 avg. length: 1610.3,                last time consumption/overall running time: 492.3925s / 32654.2470 s
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0047
Episode: 1241/10000 (12.4100%),                 avg. length: 1688.65,                last time consumption/overall running time: 514.5858s / 33168.8328 s
first_0:                 episode reward: -4.4000,                 loss: nan
second_0:                 episode reward: 4.4000,                 loss: 0.0029
Episode: 1261/10000 (12.6100%),                 avg. length: 1721.2,                last time consumption/overall running time: 523.5563s / 33692.3891 s
first_0:                 episode reward: -3.9000,                 loss: nan
second_0:                 episode reward: 3.9000,                 loss: 0.0035
Episode: 1281/10000 (12.8100%),                 avg. length: 1820.4,                last time consumption/overall running time: 552.6489s / 34245.0380 s
first_0:                 episode reward: -4.0000,                 loss: nan
second_0:                 episode reward: 4.0000,                 loss: 0.0038
Episode: 1301/10000 (13.0100%),                 avg. length: 1651.9,                last time consumption/overall running time: 498.5002s / 34743.5382 s
first_0:                 episode reward: -5.1000,                 loss: nan
second_0:                 episode reward: 5.1000,                 loss: 0.0029
Episode: 1321/10000 (13.2100%),                 avg. length: 1658.55,                last time consumption/overall running time: 501.3478s / 35244.8861 s
first_0:                 episode reward: -5.3000,                 loss: nan
second_0:                 episode reward: 5.3000,                 loss: 0.0025
Episode: 1341/10000 (13.4100%),                 avg. length: 1794.55,                last time consumption/overall running time: 548.1390s / 35793.0250 s
first_0:                 episode reward: -3.4500,                 loss: nan
second_0:                 episode reward: 3.4500,                 loss: 0.0023
Episode: 1361/10000 (13.6100%),                 avg. length: 1617.7,                last time consumption/overall running time: 486.5739s / 36279.5989 s
first_0:                 episode reward: -5.8500,                 loss: nan
second_0:                 episode reward: 5.8500,                 loss: 0.0023
Episode: 1381/10000 (13.8100%),                 avg. length: 1788.1,                last time consumption/overall running time: 539.1817s / 36818.7806 s
first_0:                 episode reward: -4.2000,                 loss: nan
second_0:                 episode reward: 4.2000,                 loss: 0.0023
Episode: 1401/10000 (14.0100%),                 avg. length: 1637.05,                last time consumption/overall running time: 481.7390s / 37300.5196 s
first_0:                 episode reward: -5.7000,                 loss: nan
second_0:                 episode reward: 5.7000,                 loss: 0.0023
Episode: 1421/10000 (14.2100%),                 avg. length: 1515.2,                last time consumption/overall running time: 430.7023s / 37731.2219 s
first_0:                 episode reward: -6.0500,                 loss: nan