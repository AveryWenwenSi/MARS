pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [23, 24]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=128, bias=True)
      (1): Tanh()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): Tanh()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): Tanh()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=128, bias=True)
      (1): Tanh()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): Tanh()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): Tanh()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 2, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 1000000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 50000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'Tanh', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220324_0417/slimevolley_SlimeVolley-v0_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20220324_0417/slimevolley_SlimeVolley-v0_nash_dqn.
Episode: 1/50000 (0.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 6.3183s / 6.3183 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0051
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0064
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 21/50000 (0.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 192.8122s / 199.1305 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0069
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0070
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 41/50000 (0.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 195.5430s / 394.6735 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0099
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0095
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 61/50000 (0.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 199.3531s / 594.0266 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0136
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0138
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 81/50000 (0.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 202.6481s / 796.6747 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0158
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0152
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 101/50000 (0.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 204.2396s / 1000.9144 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0159
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0158
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 121/50000 (0.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 208.6949s / 1209.6092 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0150
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0156
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 141/50000 (0.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 210.9464s / 1420.5556 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0145
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0153
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 161/50000 (0.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 215.2078s / 1635.7634 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0146
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0154
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 181/50000 (0.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 217.8311s / 1853.5946 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0149
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0157
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 201/50000 (0.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 221.2523s / 2074.8469 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0148
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0160
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 221/50000 (0.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 225.4500s / 2300.2969 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0151
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0160
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 241/50000 (0.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 229.0407s / 2529.3376 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0156
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0160
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 261/50000 (0.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 232.8565s / 2762.1941 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0156
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0161
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 281/50000 (0.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 239.3605s / 3001.5546 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0155
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0159
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 301/50000 (0.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 241.1480s / 3242.7026 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0153
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0165
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 321/50000 (0.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 246.2526s / 3488.9553 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0153
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0161
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 341/50000 (0.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 250.2435s / 3739.1987 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0154
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0159
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 361/50000 (0.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 250.6910s / 3989.8897 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0156
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0158
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 381/50000 (0.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 250.7523s / 4240.6420 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0158
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0156
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 401/50000 (0.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 251.2939s / 4491.9358 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0162
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0158
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 421/50000 (0.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 251.7671s / 4743.7029 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0157
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0160
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 441/50000 (0.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 251.1492s / 4994.8521 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0151
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0162
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 461/50000 (0.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 250.9610s / 5245.8131 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0154
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0158
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 481/50000 (0.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 251.7770s / 5497.5901 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0153
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0158
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 501/50000 (1.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 250.6164s / 5748.2065 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0146
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0154
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 521/50000 (1.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 249.9166s / 5998.1231 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0149
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0152
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 541/50000 (1.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 250.9690s / 6249.0921 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0150
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0152
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 561/50000 (1.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 250.6647s / 6499.7568 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0153
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0149
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 581/50000 (1.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 249.9310s / 6749.6879 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0151
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0148
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 601/50000 (1.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 250.6126s / 7000.3004 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0148
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0152
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 621/50000 (1.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 250.2402s / 7250.5407 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0141
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0146
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 641/50000 (1.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 251.6726s / 7502.2132 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0142
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0149
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 661/50000 (1.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 252.6946s / 7754.9078 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0144
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0145
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 681/50000 (1.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 251.9434s / 8006.8512 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0140
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0142
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 701/50000 (1.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 252.3624s / 8259.2136 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0139
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0140
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 721/50000 (1.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 252.6433s / 8511.8569 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0135
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0141
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 741/50000 (1.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 251.4184s / 8763.2753 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0138
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0141
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 761/50000 (1.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 250.8431s / 9014.1184 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0134
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0142
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 781/50000 (1.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 252.6466s / 9266.7650 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0129
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0140
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 801/50000 (1.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 251.9603s / 9518.7253 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0129
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0141
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 821/50000 (1.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 251.4744s / 9770.1997 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0129
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0142
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 841/50000 (1.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 251.2329s / 10021.4327 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0130
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0140
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 861/50000 (1.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 252.0295s / 10273.4622 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0124
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0137
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 881/50000 (1.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 251.3798s / 10524.8420 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0123
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0135
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 901/50000 (1.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 251.6187s / 10776.4607 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0120
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0135
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 921/50000 (1.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 252.6354s / 11029.0961 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0130
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 941/50000 (1.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 250.8896s / 11279.9857 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0121
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0128
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 961/50000 (1.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 250.6553s / 11530.6410 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0124
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0129
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 981/50000 (1.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 253.6755s / 11784.3165 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0121
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0130
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1001/50000 (2.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 253.0703s / 12037.3868 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0123
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0131
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1021/50000 (2.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 251.0122s / 12288.3990 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0123
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0125
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1041/50000 (2.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 252.4535s / 12540.8524 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0124
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0125
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1061/50000 (2.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 252.1265s / 12792.9790 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0124
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0127
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1081/50000 (2.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 251.4602s / 13044.4392 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0121
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0127
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1101/50000 (2.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 251.7637s / 13296.2029 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0123
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0121
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1121/50000 (2.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 252.7121s / 13548.9150 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0121
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0123
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1141/50000 (2.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 253.3473s / 13802.2623 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0121
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1161/50000 (2.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 252.7976s / 14055.0599 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1181/50000 (2.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 252.5125s / 14307.5724 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0119
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1201/50000 (2.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 252.8159s / 14560.3883 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0122
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1221/50000 (2.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 253.4422s / 14813.8305 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0122
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1241/50000 (2.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 253.4847s / 15067.3152 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1261/50000 (2.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 252.6916s / 15320.0068 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0119
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1281/50000 (2.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 253.5042s / 15573.5111 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1301/50000 (2.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 252.5531s / 15826.0642 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0115
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1321/50000 (2.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 253.1344s / 16079.1986 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0113
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0114
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1341/50000 (2.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 253.9920s / 16333.1906 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0115
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1361/50000 (2.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 252.8756s / 16586.0662 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0116
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1381/50000 (2.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 252.7305s / 16838.7967 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0122
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1401/50000 (2.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 254.6615s / 17093.4582 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0121
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0114
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1421/50000 (2.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 255.3763s / 17348.8345 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1441/50000 (2.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 255.8023s / 17604.6368 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0122
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1461/50000 (2.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 256.8226s / 17861.4593 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1481/50000 (2.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 256.2147s / 18117.6740 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0116
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0116
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1501/50000 (3.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 258.6761s / 18376.3501 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0116
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0114
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1521/50000 (3.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 256.4387s / 18632.7888 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0116
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0114
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1541/50000 (3.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 256.5808s / 18889.3696 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0113
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1561/50000 (3.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 255.4366s / 19144.8062 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0110
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0111
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1581/50000 (3.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 256.5008s / 19401.3070 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0113
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1601/50000 (3.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 254.4559s / 19655.7629 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1621/50000 (3.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 255.0993s / 19910.8622 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1641/50000 (3.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 255.3423s / 20166.2045 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0104
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0104
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1661/50000 (3.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 255.6390s / 20421.8435 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0102
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1681/50000 (3.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 257.3908s / 20679.2342 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0102
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1701/50000 (3.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 256.0268s / 20935.2611 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0104
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0102
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1721/50000 (3.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 255.6523s / 21190.9134 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0103
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0105
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1741/50000 (3.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 256.2097s / 21447.1231 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0104
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0103
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1761/50000 (3.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 256.4927s / 21703.6157 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0104
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0103
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1781/50000 (3.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 257.1501s / 21960.7659 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0106
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0105
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1801/50000 (3.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 258.0381s / 22218.8040 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0110
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0108
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1821/50000 (3.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 256.0301s / 22474.8341 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0109
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1841/50000 (3.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 257.0065s / 22731.8406 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0110
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1861/50000 (3.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 257.1123s / 22988.9529 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0104
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1881/50000 (3.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 257.2721s / 23246.2251 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1901/50000 (3.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 258.1686s / 23504.3937 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0107
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1921/50000 (3.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 260.1960s / 23764.5897 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0105
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1941/50000 (3.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 259.1717s / 24023.7614 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1961/50000 (3.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 258.2880s / 24282.0493 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0108
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0112
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1981/50000 (3.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 258.3230s / 24540.3723 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2001/50000 (4.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 259.2989s / 24799.6713 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0104
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0114
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2021/50000 (4.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 260.1442s / 25059.8155 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0103
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2041/50000 (4.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 259.4687s / 25319.2842 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2061/50000 (4.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 258.1291s / 25577.4133 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2081/50000 (4.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 260.5236s / 25837.9369 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2101/50000 (4.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 259.6592s / 26097.5961 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0100
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0106
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2121/50000 (4.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 258.9743s / 26356.5705 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0099
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2141/50000 (4.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 259.8703s / 26616.4407 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0100
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2161/50000 (4.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 258.3410s / 26874.7818 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0095
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0103
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2181/50000 (4.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 258.2929s / 27133.0747 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0097
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2201/50000 (4.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 258.3945s / 27391.4692 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0097
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2221/50000 (4.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 258.8802s / 27650.3494 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0103
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2241/50000 (4.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 257.8761s / 27908.2254 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0109
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2261/50000 (4.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 258.6223s / 28166.8477 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0104
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2281/50000 (4.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 260.2642s / 28427.1119 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0105
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0106
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 2301/50000 (4.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 257.7515s / 28684.8634 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0104
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0104
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2321/50000 (4.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 258.2443s / 28943.1077 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0105
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0105
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2341/50000 (4.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 258.2985s / 29201.4061 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2361/50000 (4.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 259.2486s / 29460.6547 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2381/50000 (4.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 259.0579s / 29719.7126 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0109
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2401/50000 (4.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 258.9924s / 29978.7050 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0108
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0107
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2421/50000 (4.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 259.1021s / 30237.8071 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0109
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2441/50000 (4.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 258.8612s / 30496.6683 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0105
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2461/50000 (4.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 258.8421s / 30755.5104 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 2481/50000 (4.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 260.4000s / 31015.9104 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0106
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0106
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2501/50000 (5.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 259.5882s / 31275.4986 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0102
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2521/50000 (5.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 262.0147s / 31537.5133 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0109
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0103
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2541/50000 (5.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 260.7011s / 31798.2144 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0112
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2561/50000 (5.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 260.8300s / 32059.0445 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0109
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0104
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2581/50000 (5.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 260.8815s / 32319.9260 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0106
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2601/50000 (5.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 260.0687s / 32579.9947 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0107
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2621/50000 (5.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 258.8284s / 32838.8231 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2641/50000 (5.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 259.2433s / 33098.0664 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0107
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0106
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2661/50000 (5.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 259.7354s / 33357.8018 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0110
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2681/50000 (5.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 259.0482s / 33616.8500 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0110
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2701/50000 (5.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 260.0705s / 33876.9205 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0108
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0111
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 2721/50000 (5.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 259.5571s / 34136.4776 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2741/50000 (5.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 259.1975s / 34395.6752 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0112
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2761/50000 (5.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 259.8722s / 34655.5473 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0115
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2781/50000 (5.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 261.1403s / 34916.6877 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2801/50000 (5.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 260.7249s / 35177.4126 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0112
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0104
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2821/50000 (5.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 260.2858s / 35437.6984 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0101
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2841/50000 (5.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 260.5437s / 35698.2421 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0109
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0104
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2861/50000 (5.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 259.2457s / 35957.4878 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0102
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2881/50000 (5.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 260.2540s / 36217.7418 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0102
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2901/50000 (5.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 260.8469s / 36478.5887 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2921/50000 (5.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 260.2392s / 36738.8278 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0095
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0108
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2941/50000 (5.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 260.5035s / 36999.3314 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0096
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2961/50000 (5.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 260.8204s / 37260.1518 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0096
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2981/50000 (5.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 260.9487s / 37521.1005 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0095
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0109
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3001/50000 (6.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 261.7412s / 37782.8417 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0094
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3021/50000 (6.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 259.8846s / 38042.7263 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0093
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0101
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3041/50000 (6.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 261.7577s / 38304.4840 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0096
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3061/50000 (6.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 263.1491s / 38567.6331 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0097
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3081/50000 (6.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 277.2439s / 38844.8770 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0095
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3101/50000 (6.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 283.9935s / 39128.8704 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0096
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3121/50000 (6.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 261.2205s / 39390.0910 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0098
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3141/50000 (6.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 261.1552s / 39651.2462 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0097
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3161/50000 (6.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 262.4947s / 39913.7409 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0099
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0105
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3181/50000 (6.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 259.8848s / 40173.6257 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0097
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0102
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3201/50000 (6.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 262.2787s / 40435.9044 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0098
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0103
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 3221/50000 (6.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 262.2180s / 40698.1223 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0102
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0101
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3241/50000 (6.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 260.5305s / 40958.6528 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0100
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0101
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3261/50000 (6.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 261.5035s / 41220.1563 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0098
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3281/50000 (6.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 260.9620s / 41481.1183 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0099
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0100
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3301/50000 (6.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 260.8633s / 41741.9816 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0101
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3321/50000 (6.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 261.1397s / 42003.1213 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0103
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3341/50000 (6.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 263.2611s / 42266.3824 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0100
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0102
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3361/50000 (6.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 261.9317s / 42528.3140 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0102
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0104
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3381/50000 (6.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 261.4005s / 42789.7146 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0101
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3401/50000 (6.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 261.3473s / 43051.0619 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0104
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0102
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3421/50000 (6.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 261.2523s / 43312.3142 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0101
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0103
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3441/50000 (6.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 262.7509s / 43575.0652 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0104
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3461/50000 (6.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 261.4662s / 43836.5313 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0098
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0109
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3481/50000 (6.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 261.1469s / 44097.6782 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0099
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0105
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3501/50000 (7.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 261.7510s / 44359.4292 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0104
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3521/50000 (7.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 262.4844s / 44621.9135 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0099
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0096
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3541/50000 (7.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 261.3639s / 44883.2774 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0099
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0099
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3561/50000 (7.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 261.2912s / 45144.5686 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0098
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0100
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3581/50000 (7.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 261.3522s / 45405.9208 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0097
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0100
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3601/50000 (7.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 261.7052s / 45667.6260 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0102
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0102
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3621/50000 (7.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 261.1412s / 45928.7672 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0097
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3641/50000 (7.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 260.5102s / 46189.2775 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0095
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0104
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3661/50000 (7.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 261.0261s / 46450.3036 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0095
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0104
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3681/50000 (7.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 262.6322s / 46712.9357 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0093
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0100
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3701/50000 (7.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 261.5221s / 46974.4578 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0096
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0097
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3721/50000 (7.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 260.6975s / 47235.1553 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0095
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0098
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3741/50000 (7.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 261.4885s / 47496.6437 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0095
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0096
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3761/50000 (7.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 261.5656s / 47758.2094 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0094
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0096
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3781/50000 (7.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 263.0022s / 48021.2116 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0095
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0096
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3801/50000 (7.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 262.3093s / 48283.5208 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0094
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0099
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3821/50000 (7.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 264.2688s / 48547.7897 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0092
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3841/50000 (7.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 263.2908s / 48811.0805 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0091
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0104
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3861/50000 (7.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 262.4728s / 49073.5532 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0091
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3881/50000 (7.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 261.9908s / 49335.5440 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0092
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0104
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3901/50000 (7.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 262.5501s / 49598.0942 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0092
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3921/50000 (7.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 262.4961s / 49860.5903 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0092
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0101
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3941/50000 (7.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 260.6823s / 50121.2726 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0091
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3961/50000 (7.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 262.4977s / 50383.7703 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0093
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0110
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3981/50000 (7.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 263.0724s / 50646.8427 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0097
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4001/50000 (8.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 261.9762s / 50908.8189 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0096
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4021/50000 (8.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 263.7650s / 51172.5839 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0096
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0108
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4041/50000 (8.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 263.1918s / 51435.7756 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0097
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0104
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4061/50000 (8.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 264.1906s / 51699.9662 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0098
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4081/50000 (8.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 262.5489s / 51962.5151 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0097
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4101/50000 (8.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.0372s / 52228.5523 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0097
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0110
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 4121/50000 (8.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 263.4775s / 52492.0298 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0096
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0108
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4141/50000 (8.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 264.4248s / 52756.4546 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0101
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0107
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4161/50000 (8.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 263.2716s / 53019.7262 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0101
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0106
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4181/50000 (8.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 262.6204s / 53282.3466 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0100
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0108
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 4201/50000 (8.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 262.8626s / 53545.2093 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0108
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4221/50000 (8.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 262.9792s / 53808.1885 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0101
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4241/50000 (8.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 264.1676s / 54072.3561 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4261/50000 (8.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 292.4261s / 54364.7821 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4281/50000 (8.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 263.7195s / 54628.5016 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0096
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0103
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4301/50000 (8.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 262.7732s / 54891.2748 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0099
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0103
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4321/50000 (8.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 262.9719s / 55154.2467 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 4341/50000 (8.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 263.5778s / 55417.8245 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0103
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0104
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4361/50000 (8.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 262.0873s / 55679.9117 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0103
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4381/50000 (8.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 263.0204s / 55942.9322 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0101
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4401/50000 (8.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 262.4258s / 56205.3580 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0099
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4421/50000 (8.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 262.6882s / 56468.0463 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0104
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0099
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4441/50000 (8.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 262.9263s / 56730.9726 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0101
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0098
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4461/50000 (8.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 262.8559s / 56993.8284 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0100
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0098
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4481/50000 (8.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 263.6347s / 57257.4631 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0097
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0098
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4501/50000 (9.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.1206s / 57521.5837 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0098
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0101
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4521/50000 (9.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 262.8132s / 57784.3969 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0099
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0098
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4541/50000 (9.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 262.6179s / 58047.0148 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0097
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0100
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4561/50000 (9.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 262.4315s / 58309.4464 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0098
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4581/50000 (9.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 263.6553s / 58573.1017 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0103
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0102
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4601/50000 (9.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.3172s / 58837.4189 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0105
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0103
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4621/50000 (9.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 262.1157s / 59099.5345 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0103
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0102
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4641/50000 (9.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 261.9960s / 59361.5305 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4661/50000 (9.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 263.3447s / 59624.8753 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0104
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0111
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4681/50000 (9.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 262.6893s / 59887.5646 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0109
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4701/50000 (9.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.4886s / 60152.0531 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4721/50000 (9.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 263.7485s / 60415.8016 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0110
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4741/50000 (9.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 262.3453s / 60678.1469 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0110
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0103
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 4761/50000 (9.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 263.6505s / 60941.7974 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4781/50000 (9.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 265.0621s / 61206.8595 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0109
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0106
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4801/50000 (9.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 263.3962s / 61470.2557 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0104
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0105
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4821/50000 (9.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 263.4717s / 61733.7274 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0106
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0108
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4841/50000 (9.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 263.0555s / 61996.7829 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4861/50000 (9.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 263.9326s / 62260.7155 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0105
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0108
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4881/50000 (9.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 263.5148s / 62524.2303 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0109
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4901/50000 (9.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.3980s / 62788.6283 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0109
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0105
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4921/50000 (9.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 265.5363s / 63054.1646 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0107
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4941/50000 (9.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 263.1436s / 63317.3082 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0103
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4961/50000 (9.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 262.8825s / 63580.1907 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0110
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0102
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4981/50000 (9.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 264.9027s / 63845.0935 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5001/50000 (10.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 265.7710s / 64110.8645 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0107
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5021/50000 (10.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 265.3646s / 64376.2291 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0108
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5041/50000 (10.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.3344s / 64642.5635 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0103
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5061/50000 (10.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 264.7447s / 64907.3082 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0107
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0110
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5081/50000 (10.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 263.9308s / 65171.2391 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0104
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0109
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5101/50000 (10.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 263.6424s / 65434.8814 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0103
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0104
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5121/50000 (10.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 264.9927s / 65699.8741 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0104
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5141/50000 (10.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2359s / 65966.1100 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5161/50000 (10.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 263.6775s / 66229.7876 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5181/50000 (10.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 263.2928s / 66493.0803 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0101
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0113
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5201/50000 (10.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 263.6945s / 66756.7748 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0100
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0112
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5221/50000 (10.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 264.1649s / 67020.9396 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0100
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0109
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5241/50000 (10.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 265.9398s / 67286.8794 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0102
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0107
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5261/50000 (10.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 264.1161s / 67550.9955 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0103
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0106
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 5281/50000 (10.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2854s / 67817.2809 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5301/50000 (10.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.5838s / 68083.8647 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0100
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0106
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5321/50000 (10.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 264.9047s / 68348.7694 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0097
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0101
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5341/50000 (10.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 264.5190s / 68613.2883 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0104
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0102
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5361/50000 (10.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 264.1119s / 68877.4002 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0100
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0100
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5381/50000 (10.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 263.8914s / 69141.2916 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0100
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0101
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5401/50000 (10.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.9661s / 69406.2577 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0100
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0104
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5421/50000 (10.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 263.8674s / 69670.1251 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0100
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0103
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5441/50000 (10.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 265.2107s / 69935.3358 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0094
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0101
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5461/50000 (10.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.6407s / 70201.9765 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0099
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0102
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5481/50000 (10.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 275.5725s / 70477.5490 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0098
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0104
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5501/50000 (11.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.6144s / 70742.1634 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0099
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0106
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5521/50000 (11.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 263.4926s / 71005.6560 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0099
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5541/50000 (11.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 263.5184s / 71269.1744 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0098
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0110
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 5561/50000 (11.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 264.1585s / 71533.3330 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0097
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0112
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5581/50000 (11.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 265.5566s / 71798.8896 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0099
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5601/50000 (11.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.8432s / 72063.7328 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0099
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0110
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5621/50000 (11.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 264.7080s / 72328.4408 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5641/50000 (11.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 265.1285s / 72593.5693 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0100
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0108
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5661/50000 (11.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.0990s / 72858.6684 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0101
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0110
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5681/50000 (11.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4078s / 73125.0762 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0104
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5701/50000 (11.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.1953s / 73389.2714 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5721/50000 (11.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 265.8834s / 73655.1548 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0102
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0112
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5741/50000 (11.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2407s / 73921.3956 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0105
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0114
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5761/50000 (11.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.5318s / 74186.9274 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0114
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5781/50000 (11.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2374s / 74453.1648 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0100
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5801/50000 (11.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2381s / 74719.4029 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0101
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5821/50000 (11.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.1933s / 74985.5962 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0101
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5841/50000 (11.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4840s / 75252.0802 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0101
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5861/50000 (11.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.1272s / 75517.2074 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0104
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0106
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 5881/50000 (11.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 264.6881s / 75781.8955 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0107
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5901/50000 (11.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.4901s / 76046.3856 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5921/50000 (11.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 263.9366s / 76310.3222 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0106
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0105
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5941/50000 (11.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 265.9526s / 76576.2748 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0104
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5961/50000 (11.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.4064s / 76841.6812 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0107
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5981/50000 (11.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.7525s / 77108.4337 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0107
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6001/50000 (12.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.0594s / 77374.4931 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0105
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0105
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 6021/50000 (12.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.5211s / 77641.0141 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0103
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0105
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6041/50000 (12.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.6475s / 77907.6616 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0107
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6061/50000 (12.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4553s / 78174.1170 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0107
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0108
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6081/50000 (12.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.6421s / 78440.7591 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0108
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0108
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6101/50000 (12.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.9514s / 78705.7105 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0106
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0106
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6121/50000 (12.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 265.9471s / 78971.6576 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0102
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0109
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6141/50000 (12.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 264.7833s / 79236.4409 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0104
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0110
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6161/50000 (12.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.9564s / 79502.3973 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0103
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6181/50000 (12.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 265.3102s / 79767.7075 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0102
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6201/50000 (12.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 265.3057s / 80033.0132 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0104
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0107
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6221/50000 (12.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.0224s / 80299.0356 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0103
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0107
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 6241/50000 (12.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 265.3663s / 80564.4019 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0104
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0105
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6261/50000 (12.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2862s / 80830.6881 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0099
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0105
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6281/50000 (12.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7769s / 81098.4650 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0101
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6301/50000 (12.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2805s / 81366.7455 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0105
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0107
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 6321/50000 (12.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5573s / 81634.3028 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0104
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0110
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6341/50000 (12.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2446s / 81902.5474 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0104
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0111
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6361/50000 (12.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.0704s / 82167.6178 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0098
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0112
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 6381/50000 (12.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4400s / 82434.0577 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0102
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0114
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6401/50000 (12.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.1279s / 82700.1856 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0103
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0116
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6421/50000 (12.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.3570s / 82966.5426 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0100
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6441/50000 (12.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3120s / 83233.8546 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0099
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6461/50000 (12.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8089s / 83501.6635 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0097
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 6481/50000 (12.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8021s / 83770.4656 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0098
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0122
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6501/50000 (13.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9820s / 84037.4477 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0101
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6521/50000 (13.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4096s / 84303.8572 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0101
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6541/50000 (13.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 274.0214s / 84577.8787 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0102
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0116
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 6561/50000 (13.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 299.2461s / 84877.1247 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0099
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0113
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6581/50000 (13.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 265.0489s / 85142.1737 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0104
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 6601/50000 (13.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 265.4850s / 85407.6586 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0104
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6621/50000 (13.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6653s / 85675.3240 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0108
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6641/50000 (13.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8269s / 85943.1508 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0108
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6661/50000 (13.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1892s / 86210.3400 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0110
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6681/50000 (13.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1736s / 86477.5136 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0120
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6701/50000 (13.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 265.7500s / 86743.2636 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6721/50000 (13.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6496s / 87010.9132 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0114
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 6741/50000 (13.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2216s / 87278.1347 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0109
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 6761/50000 (13.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7293s / 87545.8641 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6781/50000 (13.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9476s / 87812.8116 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0109
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6801/50000 (13.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5304s / 88080.3421 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6821/50000 (13.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3462s / 88348.6882 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0112
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6841/50000 (13.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7096s / 88617.3979 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 6861/50000 (13.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2890s / 88883.6869 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0116
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 6881/50000 (13.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.5180s / 89150.2049 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0112
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0120
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6901/50000 (13.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0977s / 89417.3026 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0113
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 6921/50000 (13.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7539s / 89685.0564 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6941/50000 (13.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.4799s / 89954.5363 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0113
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0114
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 6961/50000 (13.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2419s / 90223.7783 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6981/50000 (13.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6778s / 90492.4561 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7001/50000 (14.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1144s / 90760.5705 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7021/50000 (14.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9091s / 91028.4796 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0112
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7041/50000 (14.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1228s / 91295.6024 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0110
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 7061/50000 (14.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2817s / 91563.8841 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0113
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 7081/50000 (14.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0475s / 91830.9317 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0117
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7101/50000 (14.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6656s / 92098.5973 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0112
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0113
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7121/50000 (14.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9679s / 92366.5652 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0112
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7141/50000 (14.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4360s / 92634.0011 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7161/50000 (14.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0588s / 92901.0600 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0115
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7181/50000 (14.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0145s / 93168.0745 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7201/50000 (14.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1596s / 93436.2341 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0116
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0116
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7221/50000 (14.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7518s / 93703.9859 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0112
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0113
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7241/50000 (14.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3314s / 93972.3173 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0116
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7261/50000 (14.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4073s / 94238.7246 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0117
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0114
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7281/50000 (14.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.7513s / 94505.4759 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0117
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 7301/50000 (14.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.5076s / 94774.9835 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0112
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0113
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7321/50000 (14.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8772s / 95042.8606 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0119
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7341/50000 (14.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1625s / 95310.0232 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0111
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7361/50000 (14.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5631s / 95578.5863 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0108
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7381/50000 (14.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2887s / 95844.8750 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0116
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0112
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7401/50000 (14.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6062s / 96112.4812 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7421/50000 (14.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8282s / 96380.3094 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0111
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7441/50000 (14.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8357s / 96647.1451 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0116
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7461/50000 (14.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0693s / 96914.2144 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0110
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 7481/50000 (14.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2932s / 97182.5076 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0109
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0110
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7501/50000 (15.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0645s / 97449.5721 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0109
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0112
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7521/50000 (15.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1476s / 97717.7197 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0110
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7541/50000 (15.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.7193s / 97984.4390 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0106
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0109
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7561/50000 (15.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3259s / 98251.7649 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0106
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0114
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 7581/50000 (15.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6574s / 98519.4223 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0106
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0116
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7601/50000 (15.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2553s / 98785.6776 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0109
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7621/50000 (15.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 265.9881s / 99051.6657 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0112
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0115
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 7641/50000 (15.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4589s / 99318.1246 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0113
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0116
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 7661/50000 (15.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2612s / 99584.3857 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0113
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7681/50000 (15.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2055s / 99851.5912 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0112
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7701/50000 (15.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8178s / 100120.4090 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7721/50000 (15.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3592s / 100388.7682 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 7741/50000 (15.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2321s / 100657.0003 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0113
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7761/50000 (15.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.3224s / 100923.3227 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 7781/50000 (15.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2898s / 101189.6126 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0119
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7801/50000 (15.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.7135s / 101456.3261 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0119
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7821/50000 (15.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 265.8665s / 101722.1925 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0118
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 7841/50000 (15.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 265.5494s / 101987.7419 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0119
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7861/50000 (15.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9620s / 102254.7039 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0117
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7881/50000 (15.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5021s / 102523.2060 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7901/50000 (15.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6810s / 102790.8870 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0120
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 7921/50000 (15.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.3792s / 103060.2661 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0121
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7941/50000 (15.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.3691s / 103329.6353 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0118
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7961/50000 (15.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4309s / 103597.0662 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0117
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0116
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 7981/50000 (15.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9680s / 103864.0342 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0116
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0114
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 8001/50000 (16.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2734s / 104131.3076 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0117
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0116
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 8021/50000 (16.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8839s / 104398.1915 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8041/50000 (16.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4848s / 104664.6762 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0119
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0120
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8061/50000 (16.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0096s / 104932.6858 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8081/50000 (16.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 265.2223s / 105197.9081 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8101/50000 (16.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 265.8572s / 105463.7653 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0121
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0121
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8121/50000 (16.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2118s / 105730.9771 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0124
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8141/50000 (16.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9026s / 105997.8797 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0126
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8161/50000 (16.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.1996s / 106264.0793 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0122
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8181/50000 (16.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3929s / 106531.4722 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0124
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8201/50000 (16.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7293s / 106800.2016 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0122
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8221/50000 (16.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4122s / 107068.6138 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0118
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0121
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8241/50000 (16.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0848s / 107336.6986 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0117
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0126
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8261/50000 (16.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8402s / 107603.5388 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8281/50000 (16.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.0605s / 107869.5993 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8301/50000 (16.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1383s / 108136.7375 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0112
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0119
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8321/50000 (16.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1403s / 108403.8779 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0115
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8341/50000 (16.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.7359s / 108670.6137 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8361/50000 (16.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2504s / 108936.8641 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0114
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8381/50000 (16.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4990s / 109203.3631 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 8401/50000 (16.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.5228s / 109469.8859 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0112
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0111
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 8421/50000 (16.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1120s / 109738.9979 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0113
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0112
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8441/50000 (16.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.6026s / 110005.6005 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0114
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 8461/50000 (16.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4272s / 110272.0276 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0117
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0114
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8481/50000 (16.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 265.8324s / 110537.8601 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0112
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0113
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8501/50000 (17.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.1025s / 110803.9626 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0113
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 8521/50000 (17.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4032s / 111070.3657 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8541/50000 (17.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.5256s / 111336.8914 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0112
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0112
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8561/50000 (17.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.7709s / 111603.6623 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0112
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8581/50000 (17.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9721s / 111870.6344 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0116
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8601/50000 (17.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1076s / 112138.7420 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0116
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8621/50000 (17.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4840s / 112406.2260 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8641/50000 (17.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5170s / 112674.7430 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0110
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8661/50000 (17.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2479s / 112942.9909 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0114
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8681/50000 (17.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6022s / 113210.5931 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0112
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8701/50000 (17.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4902s / 113479.0834 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0112
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0116
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 8721/50000 (17.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.3334s / 113745.4168 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8741/50000 (17.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.7873s / 114012.2041 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0115
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8761/50000 (17.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0579s / 114279.2620 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0113
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8781/50000 (17.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1222s / 114548.3841 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8801/50000 (17.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3913s / 114816.7754 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0110
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0113
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8821/50000 (17.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1772s / 115084.9526 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0110
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0112
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8841/50000 (17.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0563s / 115352.0089 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0110
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0112
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 8861/50000 (17.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1810s / 115620.1899 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0115
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8881/50000 (17.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1496s / 115887.3395 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0114
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8901/50000 (17.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5209s / 116154.8603 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0116
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0111
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 8921/50000 (17.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8297s / 116422.6900 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8941/50000 (17.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7200s / 116691.4100 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0110
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8961/50000 (17.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3995s / 116959.8095 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0111
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 8981/50000 (17.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8655s / 117228.6750 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9001/50000 (18.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7617s / 117496.4367 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0109
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0109
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 9021/50000 (18.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0400s / 117763.4767 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0112
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9041/50000 (18.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0243s / 118030.5010 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0111
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0112
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9061/50000 (18.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1740s / 118298.6750 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0112
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 9081/50000 (18.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8979s / 118565.5729 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0112
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9101/50000 (18.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8823s / 118834.4552 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0116
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0113
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9121/50000 (18.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3135s / 119102.7687 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0114
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0112
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9141/50000 (18.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7459s / 119370.5146 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0117
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9161/50000 (18.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1081s / 119637.6227 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0111
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 9181/50000 (18.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9955s / 119904.6181 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0117
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0112
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 9201/50000 (18.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2746s / 120171.8927 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0116
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9221/50000 (18.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3728s / 120439.2655 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0112
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9241/50000 (18.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7250s / 120706.9905 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0116
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0111
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9261/50000 (18.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.5098s / 120973.5003 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0115
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9281/50000 (18.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6167s / 121242.1171 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0110
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 9301/50000 (18.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.7459s / 121508.8629 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0116
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9321/50000 (18.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6369s / 121776.4998 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 9341/50000 (18.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0406s / 122043.5404 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0115
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0116
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 9361/50000 (18.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1679s / 122311.7083 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9381/50000 (18.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5511s / 122579.2593 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 9401/50000 (18.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0573s / 122847.3166 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0111
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 9421/50000 (18.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4827s / 123115.7993 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0110
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 9441/50000 (18.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5687s / 123383.3680 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 9461/50000 (18.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6718s / 123652.0398 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0112
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9481/50000 (18.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8130s / 123919.8528 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0113
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9501/50000 (19.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4096s / 124187.2624 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0112
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0109
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 9521/50000 (19.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.5722s / 124453.8346 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0112
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9541/50000 (19.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.5666s / 124720.4011 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0112
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0109
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9561/50000 (19.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5798s / 124987.9810 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0113
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9581/50000 (19.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8381s / 125255.8191 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0113
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0112
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9601/50000 (19.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 265.5619s / 125521.3810 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0108
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0112
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9621/50000 (19.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2636s / 125787.6446 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0115
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0114
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9641/50000 (19.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 265.4465s / 126053.0910 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0117
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0116
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 9661/50000 (19.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.3846s / 126319.4756 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0120
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9681/50000 (19.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 265.9768s / 126585.4524 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0117
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9701/50000 (19.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 265.6833s / 126851.1357 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9721/50000 (19.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.1432s / 127117.2788 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0116
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9741/50000 (19.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 265.6999s / 127382.9787 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0118
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9761/50000 (19.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.9708s / 127648.9496 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 9781/50000 (19.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1394s / 127917.0890 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9801/50000 (19.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1317s / 128186.2207 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9821/50000 (19.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1394s / 128455.3601 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0117
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0120
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9841/50000 (19.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8315s / 128724.1916 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0121
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0121
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9861/50000 (19.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7767s / 128991.9683 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0119
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 9881/50000 (19.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.6256s / 129261.5939 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0118
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9901/50000 (19.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1033s / 129530.6972 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0118
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 9921/50000 (19.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9501s / 129798.6473 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0123
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9941/50000 (19.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9929s / 130067.6401 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0113
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 9961/50000 (19.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.0530s / 130333.6932 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0118
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0115
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9981/50000 (19.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.6472s / 130600.3403 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 10001/50000 (20.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0907s / 130868.4310 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0114
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 10021/50000 (20.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3098s / 131136.7408 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 10041/50000 (20.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4782s / 131404.2190 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0120
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 10061/50000 (20.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7841s / 131672.0030 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0118
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0122
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 10081/50000 (20.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8025s / 131939.8055 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 10101/50000 (20.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6132s / 132207.4187 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0120
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 10121/50000 (20.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7769s / 132475.1957 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0117
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 10141/50000 (20.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8541s / 132742.0498 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0119
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 10161/50000 (20.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.4868s / 133011.5365 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0122
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 10181/50000 (20.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2067s / 133278.7432 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0119
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 10201/50000 (20.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6900s / 133547.4332 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0119
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 10221/50000 (20.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2138s / 133814.6471 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0124
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 10241/50000 (20.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8756s / 134083.5226 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0119
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 10261/50000 (20.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6238s / 134352.1465 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0120
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0113
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 10281/50000 (20.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6516s / 134620.7980 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0121
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 10301/50000 (20.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8449s / 134888.6429 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 10321/50000 (20.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.5074s / 135158.1503 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0119
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 10341/50000 (20.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9771s / 135427.1274 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0119
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 10361/50000 (20.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5903s / 135694.7177 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0113
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0119
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 10381/50000 (20.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4820s / 135963.1997 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0116
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 10401/50000 (20.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3644s / 136230.5640 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0113
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0114
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 10421/50000 (20.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2130s / 136499.7771 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 10441/50000 (20.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8465s / 136767.6235 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0115
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 10461/50000 (20.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8449s / 137035.4684 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0116
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0113
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 10481/50000 (20.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1736s / 137303.6420 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0117
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 10501/50000 (21.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4893s / 137572.1313 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0113
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0111
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 10521/50000 (21.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4162s / 137840.5476 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0111
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0112
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 10541/50000 (21.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5593s / 138109.1069 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 10561/50000 (21.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2170s / 138377.3239 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0114
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0112
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 10581/50000 (21.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9009s / 138644.2249 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0114
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 10601/50000 (21.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.6706s / 138910.8954 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0112
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0121
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 10621/50000 (21.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0500s / 139177.9454 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0111
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0117
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 10641/50000 (21.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9255s / 139445.8708 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0112
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0116
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 10661/50000 (21.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.5021s / 139712.3729 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0111
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0115
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 10681/50000 (21.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0405s / 139981.4134 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 10701/50000 (21.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3760s / 140248.7893 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0113
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 10721/50000 (21.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1229s / 140516.9122 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0115
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 10741/50000 (21.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1292s / 140785.0414 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0116
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 10761/50000 (21.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1402s / 141053.1816 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0110
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 10781/50000 (21.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9169s / 141321.0985 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 10801/50000 (21.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9553s / 141589.0538 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0112
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0112
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 10821/50000 (21.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4260s / 141857.4798 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0114
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0115
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 10841/50000 (21.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.7012s / 142127.1810 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0116
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 10861/50000 (21.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0203s / 142395.2013 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0116
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 10881/50000 (21.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0354s / 142663.2367 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 10901/50000 (21.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3487s / 142930.5855 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0118
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0121
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 10921/50000 (21.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8496s / 143197.4350 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0119
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 10941/50000 (21.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4003s / 143464.8353 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 10961/50000 (21.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.1421s / 143730.9774 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0118
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 10981/50000 (21.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5550s / 143998.5324 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0119
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 11001/50000 (22.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2863s / 144265.8187 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0115
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 11021/50000 (22.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7578s / 144534.5765 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0115
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 11041/50000 (22.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0240s / 144802.6005 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0112
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 11061/50000 (22.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6751s / 145070.2756 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0117
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0112
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 11081/50000 (22.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0945s / 145337.3702 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0116
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 11101/50000 (22.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8277s / 145604.1979 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0113
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 11121/50000 (22.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8299s / 145873.0278 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0119
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 11141/50000 (22.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5643s / 146140.5921 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0119
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0112
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 11161/50000 (22.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9645s / 146409.5565 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0119
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0114
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 11181/50000 (22.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1615s / 146677.7181 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0119
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0113
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 11201/50000 (22.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7956s / 146946.5137 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 11221/50000 (22.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.3853s / 147215.8990 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0122
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 11241/50000 (22.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8701s / 147483.7691 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 11261/50000 (22.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9257s / 147751.6948 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0123
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0116
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 11281/50000 (22.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3419s / 148019.0367 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0117
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 11301/50000 (22.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.8520s / 148288.8887 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0123
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 11321/50000 (22.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.7925s / 148558.6812 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0123
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 11341/50000 (22.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5913s / 148826.2726 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0125
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0112
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 11361/50000 (22.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4171s / 149094.6897 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0126
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 11381/50000 (22.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2611s / 149362.9508 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0124
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0109
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 11401/50000 (22.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3393s / 149630.2901 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0110
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 11421/50000 (22.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0726s / 149897.3627 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0123
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0112
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 11441/50000 (22.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0164s / 150164.3791 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0113
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 11461/50000 (22.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5145s / 150432.8937 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0121
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0112
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 11481/50000 (22.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0814s / 150700.9750 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0119
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0114
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 11501/50000 (23.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8044s / 150969.7795 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0122
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0116
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 11521/50000 (23.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7737s / 151237.5532 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0123
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 11541/50000 (23.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0647s / 151505.6179 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 11561/50000 (23.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4732s / 151774.0912 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0121
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0117
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 11581/50000 (23.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0975s / 152043.1886 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0121
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 11601/50000 (23.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2125s / 152312.4011 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 11621/50000 (23.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4776s / 152580.8787 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0119
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 11641/50000 (23.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9043s / 152848.7830 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0118
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 11661/50000 (23.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.5312s / 153115.3142 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 11681/50000 (23.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0237s / 153382.3379 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 11701/50000 (23.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3502s / 153649.6881 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0125
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0123
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 11721/50000 (23.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3524s / 153917.0405 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0125
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 11741/50000 (23.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7816s / 154184.8221 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0126
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0123
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 11761/50000 (23.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6024s / 154453.4245 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0123
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0120
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 11781/50000 (23.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7819s / 154722.2065 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0123
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 11801/50000 (23.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9892s / 154990.1956 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0118
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 11821/50000 (23.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0080s / 155258.2036 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0123
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 11841/50000 (23.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5531s / 155525.7567 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0126
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 11861/50000 (23.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2803s / 155793.0370 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0124
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 11881/50000 (23.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8266s / 156059.8637 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0125
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0120
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 11901/50000 (23.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0063s / 156326.8700 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0125
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 11921/50000 (23.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2456s / 156594.1156 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0126
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0127
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 11941/50000 (23.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4883s / 156862.6039 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0127
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0129
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 11961/50000 (23.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0158s / 157130.6197 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0130
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0126
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 11981/50000 (23.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3319s / 157398.9516 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0127
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0126
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 12001/50000 (24.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9367s / 157666.8884 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0125
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0130
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 12021/50000 (24.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2247s / 157935.1131 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0129
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0131
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 12041/50000 (24.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9293s / 158204.0424 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0129
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0126
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 12061/50000 (24.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5345s / 158472.5769 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0127
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 12081/50000 (24.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9378s / 158740.5147 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0129
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 12101/50000 (24.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9774s / 159008.4921 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0129
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0125
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 12121/50000 (24.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0716s / 159276.5637 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0130
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 12141/50000 (24.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.3164s / 159545.8801 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0129
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0119
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 12161/50000 (24.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7038s / 159814.5838 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0128
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 12181/50000 (24.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0267s / 160083.6105 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0127
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 12201/50000 (24.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1661s / 160351.7766 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0124
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0120
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 12221/50000 (24.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4885s / 160619.2651 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0128
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 12241/50000 (24.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5117s / 160887.7768 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0127
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0121
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 12261/50000 (24.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0060s / 161155.7828 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0127
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0121
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 12281/50000 (24.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5716s / 161424.3544 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0131
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 12301/50000 (24.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4466s / 161691.8010 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0133
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0119
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 12321/50000 (24.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1410s / 161959.9420 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0134
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0122
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 12341/50000 (24.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4970s / 162228.4390 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0129
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 12361/50000 (24.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 274.5892s / 162503.0281 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 12381/50000 (24.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.5905s / 162769.6186 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0125
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 12401/50000 (24.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.7904s / 163036.4090 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0128
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0128
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 12421/50000 (24.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2382s / 163303.6472 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0130
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0123
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 12441/50000 (24.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6254s / 163572.2725 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0127
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0126
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 12461/50000 (24.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2989s / 163840.5715 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0125
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 12481/50000 (24.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6986s / 164109.2701 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0127
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 12501/50000 (25.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1171s / 164377.3871 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0122
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 12521/50000 (25.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5353s / 164645.9225 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0125
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 12541/50000 (25.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0514s / 164912.9739 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0130
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 12561/50000 (25.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5770s / 165180.5509 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0126
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 12581/50000 (25.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1314s / 165448.6823 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0127
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 12601/50000 (25.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4123s / 165717.0946 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0126
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0121
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 12621/50000 (25.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6906s / 165984.7852 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0125
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0119
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 12641/50000 (25.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 265.4128s / 166250.1980 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0124
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0120
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 12661/50000 (25.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9810s / 166519.1790 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0124
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 12681/50000 (25.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4696s / 166786.6486 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0124
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0116
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 12701/50000 (25.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 270.9995s / 167057.6481 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0126
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 12721/50000 (25.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.8071s / 167327.4552 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0121
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0116
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 12741/50000 (25.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0589s / 167594.5141 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0126
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0115
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 12761/50000 (25.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5742s / 167862.0883 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0122
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 12781/50000 (25.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7711s / 168130.8594 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0124
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 12801/50000 (25.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3071s / 168399.1665 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0126
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 12821/50000 (25.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6156s / 168667.7821 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0127
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 12841/50000 (25.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1064s / 168936.8885 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0129
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 12861/50000 (25.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.5499s / 169206.4385 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0133
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0116
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 12881/50000 (25.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.5732s / 169476.0116 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0128
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 12901/50000 (25.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9015s / 169743.9132 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0127
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0115
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 12921/50000 (25.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 270.0899s / 170014.0031 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0129
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 12941/50000 (25.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7388s / 170282.7419 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0128
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0115
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 12961/50000 (25.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2467s / 170549.9886 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0127
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 12981/50000 (25.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3932s / 170817.3818 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0130
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 13001/50000 (26.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.7374s / 171087.1192 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0125
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 13021/50000 (26.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5885s / 171355.7077 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0127
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0121
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 13041/50000 (26.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3243s / 171623.0320 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0123
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 13061/50000 (26.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2675s / 171891.2994 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0124
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 13081/50000 (26.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4089s / 172159.7084 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0121
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0120
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 13101/50000 (26.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8504s / 172428.5588 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0121
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 13121/50000 (26.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8869s / 172697.4457 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0122
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0120
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 13141/50000 (26.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9469s / 172964.3925 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0116
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 13161/50000 (26.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3976s / 173232.7901 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0118
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 13181/50000 (26.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1118s / 173500.9019 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0117
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 13201/50000 (26.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 270.4023s / 173771.3042 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 13221/50000 (26.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2498s / 174039.5540 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0119
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 13241/50000 (26.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8592s / 174308.4132 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0120
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13261/50000 (26.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1679s / 174576.5811 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0119
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 13281/50000 (26.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.3561s / 174845.9372 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 13301/50000 (26.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6404s / 175114.5776 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0119
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0123
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 13321/50000 (26.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0538s / 175383.6314 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0122
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0127
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 13341/50000 (26.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 270.0527s / 175653.6842 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0120
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0120
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 13361/50000 (26.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8310s / 175922.5152 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0118
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 13381/50000 (26.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2794s / 176189.7945 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13401/50000 (26.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 270.7236s / 176460.5181 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0123
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0123
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 13421/50000 (26.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 270.2690s / 176730.7872 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0124
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0128
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 13441/50000 (26.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 270.8883s / 177001.6755 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0124
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0126
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 13461/50000 (26.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0581s / 177269.7336 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0122
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 13481/50000 (26.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8485s / 177538.5821 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0122
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 13501/50000 (27.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6821s / 177806.2642 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 13521/50000 (27.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 270.1061s / 178076.3703 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0124
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0121
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 13541/50000 (27.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3775s / 178344.7478 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0124
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 13561/50000 (27.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1350s / 178612.8828 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0122
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0119
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 13581/50000 (27.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.3631s / 178882.2459 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0123
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 13601/50000 (27.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1707s / 179151.4166 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0116
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 13621/50000 (27.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2938s / 179418.7103 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 13641/50000 (27.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4308s / 179686.1411 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0123
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 13661/50000 (27.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8470s / 179953.9881 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0124
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0121
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13681/50000 (27.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1334s / 180221.1215 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0123
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0123
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 13701/50000 (27.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.3607s / 180490.4822 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0123
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0120
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 13721/50000 (27.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0763s / 180758.5585 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0125
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 13741/50000 (27.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6154s / 181027.1740 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0120
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 13761/50000 (27.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7572s / 181295.9312 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0122
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 13781/50000 (27.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4741s / 181563.4053 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0120
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 13801/50000 (27.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3216s / 181830.7268 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0119
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 13821/50000 (27.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3264s / 182099.0532 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0121
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 13841/50000 (27.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.8140s / 182368.8672 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0123
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 13861/50000 (27.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0030s / 182636.8702 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0118
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0123
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 13881/50000 (27.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5501s / 182905.4202 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0122
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 13901/50000 (27.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9458s / 183172.3660 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0122
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 13921/50000 (27.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4223s / 183438.7883 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0118
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0124
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 13941/50000 (27.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9836s / 183706.7719 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0120
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0126
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 13961/50000 (27.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2707s / 183976.0427 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0114
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0128
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 13981/50000 (27.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4792s / 184244.5219 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0115
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0127
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 14001/50000 (28.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.3633s / 184513.8852 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0126
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 14021/50000 (28.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6657s / 184782.5509 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0119
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0130
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 14041/50000 (28.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9683s / 185050.5192 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0118
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0132
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 14061/50000 (28.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0221s / 185319.5413 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0138
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 14081/50000 (28.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8918s / 185588.4331 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0120
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0134
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 14101/50000 (28.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8116s / 185856.2447 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0121
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0127
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 14121/50000 (28.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1733s / 186124.4180 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0125
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 14141/50000 (28.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 270.8956s / 186395.3136 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0121
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0127
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 14161/50000 (28.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1663s / 186663.4799 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0122
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0130
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 14181/50000 (28.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.9382s / 186933.4181 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0119
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0124
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 14201/50000 (28.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2799s / 187201.6981 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0119
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0130
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 14221/50000 (28.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5780s / 187469.2761 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0125
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 14241/50000 (28.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 270.0702s / 187739.3463 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 14261/50000 (28.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7024s / 188007.0486 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0121
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0127
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 14281/50000 (28.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.3357s / 188276.3843 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0127
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0130
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 14301/50000 (28.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1549s / 188545.5393 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0129
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0126
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 14321/50000 (28.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4585s / 188813.9978 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0128
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0129
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 14341/50000 (28.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8975s / 189081.8953 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0126
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0131
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 14361/50000 (28.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4078s / 189349.3031 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0127
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0131
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 14381/50000 (28.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1268s / 189618.4299 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0127
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0129
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 14401/50000 (28.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2851s / 189887.7150 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0128
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 14421/50000 (28.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1159s / 190155.8308 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 14441/50000 (28.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6732s / 190424.5040 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0124
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0126
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 14461/50000 (28.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7194s / 190693.2235 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0125
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0127
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 14481/50000 (28.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.4279s / 190962.6514 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0126
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0124
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 14501/50000 (29.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8389s / 191230.4903 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0125
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0122
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 14521/50000 (29.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.3633s / 191499.8536 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0125
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 14541/50000 (29.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4029s / 191768.2564 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0117
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 14561/50000 (29.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4263s / 192034.6827 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0123
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0113
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 14581/50000 (29.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.3933s / 192304.0761 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0121
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0115
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 14601/50000 (29.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.9475s / 192574.0236 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0121
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 14621/50000 (29.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3669s / 192842.3905 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 14641/50000 (29.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.7199s / 193112.1104 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 14661/50000 (29.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.3572s / 193381.4676 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0116
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 14681/50000 (29.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4272s / 193649.8948 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0115
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 14701/50000 (29.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5521s / 193918.4469 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 14721/50000 (29.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2075s / 194186.6543 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0125
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0120
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 14741/50000 (29.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9291s / 194455.5834 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 14761/50000 (29.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5050s / 194723.0885 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0128
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0121
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 14781/50000 (29.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5321s / 194990.6206 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0128
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0124
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 14801/50000 (29.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2303s / 195258.8509 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0130
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 14821/50000 (29.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2147s / 195528.0656 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0127
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 14841/50000 (29.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8168s / 195796.8824 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0125
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0125
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 14861/50000 (29.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5159s / 196065.3983 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0128
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0129
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 14881/50000 (29.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8957s / 196333.2940 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0129
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 14901/50000 (29.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3972s / 196600.6912 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0127
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0128
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 14921/50000 (29.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 270.0405s / 196870.7318 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0128
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0131
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 14941/50000 (29.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.3114s / 197140.0432 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0133
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 14961/50000 (29.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4512s / 197408.4944 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0134
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0134
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 14981/50000 (29.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.8835s / 197678.3779 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0129
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0130
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 15001/50000 (30.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1488s / 197946.5267 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0130
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0130
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 15021/50000 (30.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1364s / 198214.6630 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0127
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0131
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 15041/50000 (30.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1019s / 198483.7649 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0130
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0129
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 15061/50000 (30.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6520s / 198751.4169 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0128
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0129
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 15081/50000 (30.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9987s / 199020.4156 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0128
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0133
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 15101/50000 (30.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7883s / 199288.2039 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0127
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0131
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 15121/50000 (30.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9214s / 199556.1252 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0123
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0126
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 15141/50000 (30.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4467s / 199824.5719 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0123
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0127
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 15161/50000 (30.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 270.2839s / 200094.8559 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0123
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 15181/50000 (30.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1935s / 200363.0493 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0123
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 15201/50000 (30.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2219s / 200631.2713 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0120
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0121
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 15221/50000 (30.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4702s / 200899.7415 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0123
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 15241/50000 (30.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9993s / 201167.7408 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0121
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0123
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 15261/50000 (30.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1368s / 201435.8776 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0125
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 15281/50000 (30.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0282s / 201704.9057 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0122
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 15301/50000 (30.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0358s / 201973.9416 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0123
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 15321/50000 (30.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2385s / 202243.1801 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0124
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 15341/50000 (30.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1435s / 202511.3235 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0122
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 15361/50000 (30.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6678s / 202778.9913 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0126
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 15381/50000 (30.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 270.0107s / 203049.0020 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0125
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0127
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 15401/50000 (30.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0675s / 203318.0695 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0128
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0125
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 15421/50000 (30.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6618s / 203585.7313 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0124
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 15441/50000 (30.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0137s / 203854.7450 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0121
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 15461/50000 (30.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9279s / 204123.6729 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0123
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0123
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 15481/50000 (30.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1648s / 204392.8377 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0125
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0126
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 15501/50000 (31.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7054s / 204661.5431 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0124
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0131
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 15521/50000 (31.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8185s / 204929.3616 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0121
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0127
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 15541/50000 (31.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1429s / 205196.5046 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0129
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 15561/50000 (31.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9331s / 205465.4376 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0119
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0127
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 15581/50000 (31.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3388s / 205733.7764 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0130
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 15601/50000 (31.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9808s / 206001.7571 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0125
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0128
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 15621/50000 (31.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4779s / 206269.2350 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0122
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0133
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 15641/50000 (31.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4773s / 206536.7123 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0122
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0133
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 15661/50000 (31.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8886s / 206803.6009 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0132
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 15681/50000 (31.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8667s / 207071.4677 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0122
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0135
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 15701/50000 (31.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4790s / 207339.9467 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0123
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0135
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 15721/50000 (31.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2242s / 207608.1709 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0122
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0130
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 15741/50000 (31.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0809s / 207876.2518 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0127
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0134
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 15761/50000 (31.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.6818s / 208142.9336 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0121
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0132
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 15781/50000 (31.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.3942s / 208412.3278 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0122
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0133
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 15801/50000 (31.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4980s / 208680.8258 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0122
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0128
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 15821/50000 (31.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 270.4979s / 208951.3237 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0126
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 15841/50000 (31.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0853s / 209220.4090 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0128
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0123
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 15861/50000 (31.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9804s / 209489.3894 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0126
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 15881/50000 (31.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7601s / 209758.1494 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0125
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0119
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 15901/50000 (31.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 271.3778s / 210029.5273 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0122
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 15921/50000 (31.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 270.1605s / 210299.6877 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0124
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 15941/50000 (31.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1391s / 210567.8269 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0124
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 15961/50000 (31.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8951s / 210835.7220 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0127
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 15981/50000 (31.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6421s / 211103.3641 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0129
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0123
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 16001/50000 (32.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 270.8397s / 211374.2038 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0127
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 16021/50000 (32.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.9065s / 211644.1103 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0129
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0124
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 16041/50000 (32.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9496s / 211913.0599 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0125
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 16061/50000 (32.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9712s / 212182.0311 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0125
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 16081/50000 (32.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4035s / 212449.4347 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0125
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0123
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 16101/50000 (32.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.6562s / 212716.0908 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0129
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0120
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 16121/50000 (32.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3884s / 212984.4792 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0127
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 16141/50000 (32.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1841s / 213251.6633 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0123
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 16161/50000 (32.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9983s / 213519.6616 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0121
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0118
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 16181/50000 (32.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.5062s / 213789.1679 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0122
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 16201/50000 (32.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3855s / 214056.5534 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0124
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 16221/50000 (32.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1521s / 214325.7055 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0130
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 16241/50000 (32.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 270.2448s / 214595.9503 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0127
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 16261/50000 (32.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0303s / 214862.9806 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0126
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 16281/50000 (32.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4573s / 215130.4379 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0125
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0119
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 16301/50000 (32.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4200s / 215397.8579 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0131
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 16321/50000 (32.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1526s / 215667.0105 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0128
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0122
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 16341/50000 (32.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9552s / 215935.9656 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0124
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 16361/50000 (32.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.4946s / 216205.4603 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0130
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 16381/50000 (32.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9159s / 216474.3761 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 16401/50000 (32.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8929s / 216743.2690 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0124
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0121
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 16421/50000 (32.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 270.0082s / 217013.2772 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0121
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 16441/50000 (32.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3582s / 217281.6353 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0128
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 16461/50000 (32.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2513s / 217549.8866 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0131
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 16481/50000 (32.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5466s / 217818.4332 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0131
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 16501/50000 (33.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.6915s / 218088.1247 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0132
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0123
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 16521/50000 (33.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3922s / 218355.5169 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0129
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 16541/50000 (33.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2476s / 218621.7645 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0134
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0126
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 16561/50000 (33.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.7680s / 218891.5325 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 16581/50000 (33.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6105s / 219160.1430 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0130
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0123
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 16601/50000 (33.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.1268s / 219426.2699 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0126
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 16621/50000 (33.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.0790s / 219692.3488 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0131
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 16641/50000 (33.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1300s / 219959.4788 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0132
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0124
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 16661/50000 (33.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8406s / 220227.3195 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0130
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0126
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 16681/50000 (33.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6572s / 220494.9766 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0128
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0126
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 16701/50000 (33.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.0230s / 220760.9996 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0130
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 16721/50000 (33.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6034s / 221028.6029 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0129
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0130
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 16741/50000 (33.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1435s / 221297.7464 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0128
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0131
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 16761/50000 (33.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4106s / 221565.1570 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0131
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0131
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 16781/50000 (33.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1529s / 221832.3100 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0131
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0129
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 16801/50000 (33.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2754s / 222098.5854 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0129
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0132
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 16821/50000 (33.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.6396s / 222365.2250 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0133
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 16841/50000 (33.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8896s / 222633.1146 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0131
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0132
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 16861/50000 (33.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4473s / 222900.5620 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0130
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0130
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 16881/50000 (33.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1229s / 223169.6849 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0130
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0129
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 16901/50000 (33.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 270.8128s / 223440.4977 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0129
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0129
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 16921/50000 (33.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2384s / 223706.7361 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0127
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0132
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 16941/50000 (33.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 270.0903s / 223976.8264 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0130
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0131
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 16961/50000 (33.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0450s / 224245.8714 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0133
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0132
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 16981/50000 (33.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.8153s / 224515.6867 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0135
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0129
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 17001/50000 (34.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0904s / 224783.7771 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0132
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0132
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 17021/50000 (34.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.7238s / 225050.5010 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0135
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0126
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 17041/50000 (34.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1389s / 225318.6399 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0135
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0130
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 17061/50000 (34.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1639s / 225586.8037 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0135
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0128
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 17081/50000 (34.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8777s / 225855.6814 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0135
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 17101/50000 (34.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4520s / 226124.1335 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0137
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 17121/50000 (34.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9647s / 226392.0982 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0134
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 17141/50000 (34.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5249s / 226660.6230 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0134
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0126
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 17161/50000 (34.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3376s / 226928.9606 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 17181/50000 (34.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8618s / 227197.8224 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0128
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 17201/50000 (34.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9578s / 227466.7802 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0129
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0128
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 17221/50000 (34.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0795s / 227735.8596 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 17241/50000 (34.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1128s / 228003.9724 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0125
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0127
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 17261/50000 (34.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.7073s / 228273.6797 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0127
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0128
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 17281/50000 (34.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0507s / 228542.7304 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0132
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0127
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 17301/50000 (34.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3817s / 228811.1121 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0133
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0127
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 17321/50000 (34.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1795s / 229078.2916 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0126
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0127
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 17341/50000 (34.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 270.1501s / 229348.4417 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0126
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0123
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 17361/50000 (34.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1242s / 229616.5660 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0126
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0126
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 17381/50000 (34.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2234s / 229885.7894 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0123
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0125
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 17401/50000 (34.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7603s / 230153.5497 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0123
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0123
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 17421/50000 (34.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9663s / 230421.5160 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0124
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 17441/50000 (34.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6485s / 230690.1644 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0126
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 17461/50000 (34.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.7550s / 230959.9195 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0118
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 17481/50000 (34.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9516s / 231228.8711 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0127
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0124
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 17501/50000 (35.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2617s / 231497.1329 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0128
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 17521/50000 (35.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6460s / 231765.7789 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0127
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 17541/50000 (35.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1129s / 232032.8918 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0129
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0125
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 17561/50000 (35.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9631s / 232300.8549 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0128
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0126
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 17581/50000 (35.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1535s / 232570.0084 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0123
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 17601/50000 (35.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.4474s / 232839.4558 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0124
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0126
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 17621/50000 (35.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.4996s / 233108.9555 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0126
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0131
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 17641/50000 (35.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4298s / 233377.3852 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0126
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0130
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 17661/50000 (35.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.5235s / 233646.9087 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0133
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 17681/50000 (35.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 265.7419s / 233912.6506 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0130
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 17701/50000 (35.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0978s / 234180.7484 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 17721/50000 (35.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6038s / 234449.3522 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0119
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 17741/50000 (35.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3097s / 234716.6619 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0115
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 17761/50000 (35.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2058s / 234984.8677 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0116
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 17781/50000 (35.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6053s / 235252.4730 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0117
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 17801/50000 (35.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.3798s / 235518.8528 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0117
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0119
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 17821/50000 (35.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7132s / 235786.5660 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0116
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 17841/50000 (35.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8612s / 236054.4272 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0117
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0119
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 17861/50000 (35.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2947s / 236320.7220 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0118
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0112
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 17881/50000 (35.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2082s / 236587.9301 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 17901/50000 (35.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1415s / 236856.0716 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0118
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0117
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 17921/50000 (35.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1556s / 237125.2272 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0118
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 17941/50000 (35.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.7370s / 237394.9642 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0118
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0114
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 17961/50000 (35.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7212s / 237662.6854 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0120
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0118
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 17981/50000 (35.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5970s / 237930.2824 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0119
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0120
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 18001/50000 (36.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2043s / 238196.4867 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0126
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 18021/50000 (36.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1916s / 238464.6783 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0125
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 18041/50000 (36.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8145s / 238733.4928 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0128
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 18061/50000 (36.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8448s / 239002.3376 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0123
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0123
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 18081/50000 (36.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6660s / 239271.0036 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0124
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 18101/50000 (36.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8013s / 239539.8049 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0126
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 18121/50000 (36.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 279.6801s / 239819.4850 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0124
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0120
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 18141/50000 (36.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0274s / 240088.5124 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0122
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 18161/50000 (36.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7962s / 240356.3086 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0126
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 18181/50000 (36.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9855s / 240623.2941 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0124
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0126
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 18201/50000 (36.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.7465s / 240890.0406 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0125
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0125
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 18221/50000 (36.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3231s / 241158.3637 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0130
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 18241/50000 (36.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9517s / 241426.3154 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0122
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 18261/50000 (36.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.5702s / 241692.8856 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0132
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 18281/50000 (36.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3856s / 241960.2712 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0128
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 18301/50000 (36.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2265s / 242226.4978 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0126
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0122
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 18321/50000 (36.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3300s / 242494.8278 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0127
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 18341/50000 (36.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5326s / 242763.3603 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0130
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0121
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 18361/50000 (36.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6237s / 243030.9840 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0129
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 18381/50000 (36.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4145s / 243299.3986 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0127
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 18401/50000 (36.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1332s / 243567.5318 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0128
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0127
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 18421/50000 (36.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8146s / 243835.3464 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0128
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0127
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 18441/50000 (36.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0146s / 244103.3610 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0127
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 18461/50000 (36.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.4874s / 244372.8485 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0130
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0134
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 18481/50000 (36.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0152s / 244640.8637 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0132
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0129
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 18501/50000 (37.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9058s / 244909.7695 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0127
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0131
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 18521/50000 (37.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3559s / 245177.1253 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0130
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 18541/50000 (37.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0880s / 245445.2134 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0127
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0130
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 18561/50000 (37.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.6976s / 245711.9109 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0131
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0132
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 18581/50000 (37.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3189s / 245979.2299 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0132
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0130
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 18601/50000 (37.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2845s / 246247.5144 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0131
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0130
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 18621/50000 (37.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.7384s / 246517.2528 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 18641/50000 (37.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0205s / 246786.2733 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0130
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0126
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 18661/50000 (37.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3405s / 247053.6138 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0130
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0120
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 18681/50000 (37.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8308s / 247321.4446 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0127
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0126
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 18701/50000 (37.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5248s / 247589.9694 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0125
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 18721/50000 (37.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1668s / 247857.1362 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0128
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0123
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 18741/50000 (37.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 265.9509s / 248123.0870 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0125
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 18761/50000 (37.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6265s / 248390.7135 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0128
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 18781/50000 (37.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2025s / 248659.9160 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0125
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0117
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 18801/50000 (37.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.0457s / 248925.9618 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.0127
env0_second_0:                 episode reward: -0.9500,                 loss: 0.0120
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 18821/50000 (37.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 265.5990s / 249191.5608 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0125
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 18841/50000 (37.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2348s / 249457.7956 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0123
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0126
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 18861/50000 (37.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2998s / 249724.0954 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0125
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 18881/50000 (37.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1184s / 249991.2138 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0123
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0130
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 18901/50000 (37.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 264.7869s / 250256.0007 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0125
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0126
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 18921/50000 (37.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.5021s / 250522.5028 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0128
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0132
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 18941/50000 (37.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 265.8593s / 250788.3621 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0126
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 18961/50000 (37.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.0246s / 251053.3866 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0130
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0129
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 18981/50000 (37.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7745s / 251321.1611 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0131
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0129
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 19001/50000 (38.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2692s / 251588.4303 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0131
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 19021/50000 (38.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0992s / 251856.5296 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0130
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0123
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 19041/50000 (38.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7397s / 252124.2692 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0132
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0127
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 19061/50000 (38.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1110s / 252391.3802 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0127
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0128
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 19081/50000 (38.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0972s / 252658.4774 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0135
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0130
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 19101/50000 (38.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9935s / 252925.4710 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0133
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0128
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 19121/50000 (38.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 265.6108s / 253191.0818 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0133
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0128
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 19141/50000 (38.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.3438s / 253457.4257 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0133
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0130
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 19161/50000 (38.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.9958s / 253723.4214 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0134
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0129
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 19181/50000 (38.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1491s / 253990.5706 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0133
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0129
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 19201/50000 (38.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0636s / 254259.6342 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0133
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0127
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 19221/50000 (38.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5544s / 254528.1886 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0137
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0132
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 19241/50000 (38.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5951s / 254795.7837 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0136
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0134
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 19261/50000 (38.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.7300s / 255062.5138 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0135
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0136
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 19281/50000 (38.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4836s / 255328.9974 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0132
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0139
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 19301/50000 (38.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 265.9707s / 255594.9681 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0136
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0136
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 19321/50000 (38.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 265.8114s / 255860.7795 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0134
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0132
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 19341/50000 (38.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3584s / 256128.1379 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0135
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0131
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 19361/50000 (38.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4217s / 256394.5596 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0129
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0130
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 19381/50000 (38.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5780s / 256662.1377 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0132
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0133
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 19401/50000 (38.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8967s / 256929.0343 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0131
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0134
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 19421/50000 (38.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5852s / 257197.6195 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0132
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 19441/50000 (38.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8953s / 257464.5149 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0134
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0128
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 19461/50000 (38.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1650s / 257731.6799 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0135
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0129
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 19481/50000 (38.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2187s / 257999.8985 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0134
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0125
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 19501/50000 (39.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.6140s / 258266.5126 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0138
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0125
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 19521/50000 (39.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0343s / 258533.5469 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0133
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0129
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 19541/50000 (39.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8318s / 258800.3786 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0133
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0125
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 19561/50000 (39.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4322s / 259066.8108 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0138
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0131
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 19581/50000 (39.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3587s / 259334.1695 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0133
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0134
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 19601/50000 (39.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3779s / 259601.5474 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0134
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0131
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 19621/50000 (39.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9595s / 259869.5069 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0132
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0130
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 19641/50000 (39.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5015s / 260137.0084 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0131
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0129
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 19661/50000 (39.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.3762s / 260403.3846 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0130
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0133
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 19681/50000 (39.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6742s / 260671.0589 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0137
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0131
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 19701/50000 (39.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1198s / 260938.1787 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0135
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0129
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 19721/50000 (39.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 265.4938s / 261203.6725 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0134
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0128
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 19741/50000 (39.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0929s / 261470.7653 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0133
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0127
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 19761/50000 (39.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4216s / 261737.1870 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0133
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0128
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 19781/50000 (39.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.4525s / 262003.6395 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0134
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0130
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 19801/50000 (39.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8403s / 262270.4798 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0130
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0136
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 19821/50000 (39.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1950s / 262538.6748 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0130
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0132
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 19841/50000 (39.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.5913s / 262805.2661 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0135
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0131
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 19861/50000 (39.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.6756s / 263071.9417 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0130
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0128
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 19881/50000 (39.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9563s / 263338.8980 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0134
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0131
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 19901/50000 (39.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8898s / 263606.7878 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0131
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0127
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 19921/50000 (39.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 265.7984s / 263872.5862 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0127
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0126
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 19941/50000 (39.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1546s / 264139.7408 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0132
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0126
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 19961/50000 (39.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9210s / 264406.6618 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0136
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0126
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 19981/50000 (39.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4463s / 264674.1081 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0132
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0131
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 20001/50000 (40.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7525s / 264941.8606 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0132
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0129
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 20021/50000 (40.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0450s / 265208.9055 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0134
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0132
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 20041/50000 (40.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9938s / 265475.8994 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0132
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0127
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 20061/50000 (40.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.1228s / 265742.0221 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0132
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0131
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 20081/50000 (40.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6606s / 266009.6827 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0130
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0127
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 20101/50000 (40.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0765s / 266276.7593 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0131
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0125
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 20121/50000 (40.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8863s / 266544.6456 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0130
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 20141/50000 (40.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.7906s / 266811.4361 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0132
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 20161/50000 (40.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.9412s / 267077.3773 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0130
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0127
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 20181/50000 (40.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.6851s / 267344.0625 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0134
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0129
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 20201/50000 (40.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7118s / 267611.7742 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0127
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 20221/50000 (40.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3016s / 267879.0759 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0134
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 20241/50000 (40.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3944s / 268146.4703 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0134
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0128
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 20261/50000 (40.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2116s / 268413.6818 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0127
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0127
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 20281/50000 (40.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0755s / 268680.7573 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0131
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 20301/50000 (40.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5935s / 268948.3508 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0130
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0123
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 20321/50000 (40.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.1165s / 269214.4673 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0119
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 20341/50000 (40.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3164s / 269481.7837 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0125
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 20361/50000 (40.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.6708s / 269748.4545 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0130
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 20381/50000 (40.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1626s / 270016.6171 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0130
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 20401/50000 (40.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8840s / 270283.5011 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0124
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0116
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 20421/50000 (40.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2290s / 270552.7301 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0126
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0115
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 20441/50000 (40.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6460s / 270820.3761 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0126
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 20461/50000 (40.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9270s / 271087.3031 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0124
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 20481/50000 (40.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.6545s / 271353.9576 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0128
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 20501/50000 (41.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4752s / 271621.4329 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0129
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0116
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 20521/50000 (41.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0963s / 271889.5292 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0127
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0116
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 20541/50000 (41.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4870s / 272158.0162 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0124
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0113
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 20561/50000 (41.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8830s / 272425.8991 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0111
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 20581/50000 (41.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6206s / 272693.5198 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0126
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0114
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 20601/50000 (41.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8315s / 272962.3513 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0126
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0116
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 20621/50000 (41.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6659s / 273230.0172 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0132
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0116
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 20641/50000 (41.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8400s / 273496.8572 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0128
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 20661/50000 (41.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1113s / 273764.9685 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0131
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 20681/50000 (41.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1730s / 274033.1415 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0134
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0121
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 20701/50000 (41.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2507s / 274300.3922 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0129
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0125
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 20721/50000 (41.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.7000s / 274570.0922 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0127
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0119
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 20741/50000 (41.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.5970s / 274839.6892 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0122
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 20761/50000 (41.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5282s / 275107.2174 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0120
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0126
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 20781/50000 (41.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3539s / 275375.5713 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0125
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0124
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 20801/50000 (41.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5550s / 275644.1263 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0122
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 20821/50000 (41.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7271s / 275911.8534 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0125
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0120
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 20841/50000 (41.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.9200s / 276178.7734 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0124
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 20861/50000 (41.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0167s / 276446.7901 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0129
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 20881/50000 (41.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7281s / 276714.5182 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0128
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0129
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 20901/50000 (41.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0781s / 276983.5964 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0128
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0127
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 20921/50000 (41.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.8135s / 277253.4098 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0132
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0127
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 20941/50000 (41.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9650s / 277522.3748 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0135
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0129
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 20961/50000 (41.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2769s / 277790.6518 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0135
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0129
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 20981/50000 (41.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3464s / 278058.9982 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0138
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0133
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 21001/50000 (42.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7826s / 278327.7808 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0142
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0129
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 21021/50000 (42.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1866s / 278594.9674 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0133
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0132
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 21041/50000 (42.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8665s / 278863.8338 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0139
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0127
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 21061/50000 (42.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1229s / 279131.9567 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0140
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0128
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 21081/50000 (42.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9232s / 279399.8799 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0138
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0134
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 21101/50000 (42.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 270.2133s / 279670.0932 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0138
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0130
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 21121/50000 (42.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1726s / 279939.2658 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0134
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0131
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 21141/50000 (42.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0879s / 280207.3538 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0140
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0131
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 21161/50000 (42.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 270.1957s / 280477.5494 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0141
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0130
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 21181/50000 (42.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8892s / 280745.4386 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0138
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0130
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 21201/50000 (42.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7845s / 281013.2231 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0139
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0129
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 21221/50000 (42.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.7472s / 281279.9703 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0138
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0129
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 21241/50000 (42.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4090s / 281548.3794 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0138
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0128
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 21261/50000 (42.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8010s / 281816.1804 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0138
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 21281/50000 (42.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8685s / 282084.0489 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0136
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0128
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 21301/50000 (42.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5143s / 282351.5632 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0136
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0127
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 21321/50000 (42.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8260s / 282619.3892 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0134
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0133
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 21341/50000 (42.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1015s / 282888.4906 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0136
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0130
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 21361/50000 (42.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2543s / 283157.7450 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0136
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0132
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 21381/50000 (42.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 270.1221s / 283427.8670 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0132
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0129
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 21401/50000 (42.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7467s / 283696.6137 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0132
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0129
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 21421/50000 (42.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0393s / 283964.6529 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0134
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0126
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 21441/50000 (42.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6183s / 284233.2712 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0137
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0126
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 21461/50000 (42.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7086s / 284501.9798 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0138
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0130
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 21481/50000 (42.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 270.1753s / 284772.1551 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0140
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0130
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 21501/50000 (43.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3285s / 285040.4836 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0137
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0132
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 21521/50000 (43.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.7842s / 285310.2678 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0138
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0132
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 21541/50000 (43.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.4702s / 285579.7379 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0141
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0131
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 21561/50000 (43.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 270.3413s / 285850.0792 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0139
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0131
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 21581/50000 (43.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 278.8681s / 286128.9473 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0142
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0130
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 21601/50000 (43.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 271.4691s / 286400.4164 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0137
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0130
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 21621/50000 (43.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.5888s / 286670.0052 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0135
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0128
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 21641/50000 (43.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.3095s / 286939.3148 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0134
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0124
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 21661/50000 (43.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0332s / 287207.3479 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0136
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0127
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 21681/50000 (43.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8003s / 287475.1483 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0137
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0127
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 21701/50000 (43.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0761s / 287742.2244 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0139
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0126
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 21721/50000 (43.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8216s / 288010.0460 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0137
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0126
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 21741/50000 (43.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8398s / 288277.8858 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0137
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0126
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 21761/50000 (43.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0193s / 288545.9051 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0137
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 21781/50000 (43.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9972s / 288813.9023 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0138
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 21801/50000 (43.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9578s / 289081.8601 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0138
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0127
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 21821/50000 (43.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2449s / 289350.1050 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0137
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 21841/50000 (43.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1474s / 289618.2524 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0138
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 21861/50000 (43.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0850s / 289886.3374 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0136
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0123
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 21881/50000 (43.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0109s / 290154.3484 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0138
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0125
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 21901/50000 (43.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.6972s / 290421.0456 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0138
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0125
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 21921/50000 (43.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0182s / 290689.0638 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0136
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0126
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 21941/50000 (43.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8720s / 290955.9357 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0138
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0125
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 21961/50000 (43.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.6136s / 291225.5493 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0136
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 21981/50000 (43.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8416s / 291494.3909 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0133
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 22001/50000 (44.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.3810s / 291763.7719 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0133
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 22021/50000 (44.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7297s / 292032.5016 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0138
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0124
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 22041/50000 (44.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4120s / 292300.9136 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0132
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0128
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 22061/50000 (44.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6026s / 292568.5162 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0134
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 22081/50000 (44.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5455s / 292837.0617 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0135
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 22101/50000 (44.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4718s / 293105.5335 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0137
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 22121/50000 (44.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5937s / 293373.1271 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0133
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 22141/50000 (44.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9116s / 293642.0387 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0136
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 22161/50000 (44.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.6655s / 293911.7042 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0135
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0127
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 22181/50000 (44.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8497s / 294178.5540 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0140
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0124
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 22201/50000 (44.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8098s / 294447.3638 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0141
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 22221/50000 (44.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0775s / 294716.4413 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0139
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 22241/50000 (44.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0718s / 294983.5131 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0142
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 22261/50000 (44.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9402s / 295251.4533 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0138
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0119
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 22281/50000 (44.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9636s / 295519.4169 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0140
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 22301/50000 (44.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5616s / 295787.9785 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0134
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0125
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 22321/50000 (44.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.4441s / 296057.4227 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0136
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0121
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 22341/50000 (44.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9964s / 296325.4191 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0134
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0120
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 22361/50000 (44.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8296s / 296592.2486 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0135
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 22381/50000 (44.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6123s / 296859.8610 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0135
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0122
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 22401/50000 (44.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 270.8812s / 297130.7422 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0140
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0124
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 22421/50000 (44.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1581s / 297398.9003 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0139
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 22441/50000 (44.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4439s / 297667.3442 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0140
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 22461/50000 (44.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.0841s / 297936.4283 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0136
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0124
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 22481/50000 (44.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0828s / 298204.5111 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0136
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0123
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 22501/50000 (45.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3601s / 298471.8712 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0135
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0122
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 22521/50000 (45.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8371s / 298739.7083 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0136
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0123
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 22541/50000 (45.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7505s / 299008.4588 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0139
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0123
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 22561/50000 (45.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.0655s / 299276.5243 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0136
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 22581/50000 (45.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8968s / 299544.4211 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0133
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 22601/50000 (45.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5944s / 299812.0155 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0132
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0126
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 22621/50000 (45.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 269.8266s / 300081.8421 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0137
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0125
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 22641/50000 (45.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.7149s / 300350.5570 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0134
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0129
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 22661/50000 (45.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3330s / 300618.8900 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0133
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0127
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 22681/50000 (45.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.8540s / 300886.7440 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0131
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 22701/50000 (45.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.6567s / 301154.4007 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0132
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 22721/50000 (45.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 270.2826s / 301424.6833 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0131
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0123
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 22741/50000 (45.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.9539s / 301694.6371 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0131
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0124
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 22761/50000 (45.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.5543s / 301964.1915 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0128
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0125
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 22781/50000 (45.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.9173s / 302234.1088 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0131
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0127
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 22801/50000 (45.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3860s / 302502.4948 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0128
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0130
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 22821/50000 (45.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.7286s / 302769.2234 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0130
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0131
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 22841/50000 (45.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9179s / 303037.1414 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0128
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0128
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 22861/50000 (45.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9133s / 303305.0547 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0131
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0125
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 22881/50000 (45.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2789s / 303574.3336 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0130
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0123
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 22901/50000 (45.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.4628s / 303842.7964 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0134
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0127
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 22921/50000 (45.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3720s / 304111.1684 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0133
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0125
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 22941/50000 (45.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.2985s / 304378.4669 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0136
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0122
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 22961/50000 (45.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.3491s / 304647.8159 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0136
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0127
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 22981/50000 (45.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1245s / 304916.9405 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0134
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0127
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 23001/50000 (46.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5918s / 305184.5323 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0133
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0126
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 23021/50000 (46.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6316s / 305453.1639 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0134
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0130
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 23041/50000 (46.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1381s / 305722.3020 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0131
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0127
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 23061/50000 (46.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1591s / 305989.4611 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0138
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0131
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 23081/50000 (46.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3053s / 306257.7664 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0130
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0131
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 23101/50000 (46.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.9820s / 306526.7484 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0130
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0132
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 23121/50000 (46.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5669s / 306794.3153 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0134
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0130
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 23141/50000 (46.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.4900s / 307061.8054 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0134
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0131
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 23161/50000 (46.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.1099s / 307327.9152 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0134
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0128
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 23181/50000 (46.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3814s / 307596.2966 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0136
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0130
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 23201/50000 (46.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.1871s / 307863.4837 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0135
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0132
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 23221/50000 (46.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0850s / 308130.5688 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0137
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0134
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 23241/50000 (46.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 269.1625s / 308399.7313 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0136
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0129
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 23261/50000 (46.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 269.9628s / 308669.6941 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0132
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0131
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 23281/50000 (46.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7773s / 308937.4714 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0126
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0123
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 23301/50000 (46.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2049s / 309205.6763 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0128
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0123
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 23321/50000 (46.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.5618s / 309474.2381 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0123
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0116
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 23341/50000 (46.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.7204s / 309741.9585 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0128
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0118
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 23361/50000 (46.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.8906s / 310007.8491 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0122
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0115
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 23381/50000 (46.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3988s / 310275.2479 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0123
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0117
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23401/50000 (46.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 266.7136s / 310541.9615 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0120
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0112
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23421/50000 (46.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3280s / 310809.2895 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0124
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0111
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 23441/50000 (46.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.2697s / 311077.5592 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0114
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 23461/50000 (46.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5500s / 311345.1092 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0119
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0116
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 23481/50000 (46.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0846s / 311612.1938 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0122
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0114
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 23501/50000 (47.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 268.8304s / 311881.0241 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0120
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0118
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 23521/50000 (47.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 268.1152s / 312149.1393 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0120
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0113
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 23541/50000 (47.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 267.9827s / 312417.1220 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0121
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0120
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 23561/50000 (47.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 268.6058s / 312685.7278 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0125
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0121
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 23581/50000 (47.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 269.2500s / 312954.9777 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0124
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0122
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 23601/50000 (47.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0204s / 313221.9982 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0126
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0124
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 23621/50000 (47.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 266.2670s / 313488.2652 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0124
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0120
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 23641/50000 (47.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 266.0787s / 313754.3439 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0128
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0116
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 23661/50000 (47.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 266.8564s / 314021.2004 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0130
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0120
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 23681/50000 (47.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 266.3448s / 314287.5452 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0127
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0119
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 23701/50000 (47.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 267.0007s / 314554.5459 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0129
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 23721/50000 (47.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 267.5458s / 314822.0916 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0130
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0120
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 23741/50000 (47.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 268.3600s / 315090.4516 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0129
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0121
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 23761/50000 (47.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 265.6106s / 315356.0622 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0130
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0119