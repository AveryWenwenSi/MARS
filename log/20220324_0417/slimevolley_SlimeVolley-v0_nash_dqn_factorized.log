pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [23, 24]
<SubprocVectorEnv instance>
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=128, bias=True)
      (1): Tanh()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): Tanh()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): Tanh()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
ParallelDQN(
  (net): MLP(
    (body): Sequential(
      (0): Linear(in_features=12, out_features=128, bias=True)
      (1): Tanh()
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): Tanh()
      (4): Linear(in_features=128, out_features=128, bias=True)
      (5): Tanh()
      (6): Linear(in_features=128, out_features=6, bias=True)
    )
  )
)
No agent are not learnable.
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 2, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'NashDQNFactorized', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 1000000}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 50000, 'max_steps_per_episode': 300, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'Tanh', 'output_activation': False}, 'marl_method': 'nash_dqn_factorized', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20220324_0417/slimevolley_SlimeVolley-v0_nash_dqn_factorized. 
 Save logs to: /home/zihan/research/MARS/data/log/20220324_0417/slimevolley_SlimeVolley-v0_nash_dqn_factorized.
Episode: 1/50000 (0.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 8.6804s / 8.6804 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0114
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0109
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 21/50000 (0.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 258.0474s / 266.7279 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0084
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0087
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 41/50000 (0.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 263.4983s / 530.2262 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0134
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0139
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 61/50000 (0.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 264.8605s / 795.0867 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0169
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0184
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 81/50000 (0.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 267.3599s / 1062.4466 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0186
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0189
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 101/50000 (0.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 269.8445s / 1332.2911 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0185
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0192
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 121/50000 (0.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 271.5732s / 1603.8642 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0189
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0186
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 141/50000 (0.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 275.8246s / 1879.6888 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0194
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0196
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 161/50000 (0.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 280.4704s / 2160.1592 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0190
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0201
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 181/50000 (0.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 281.8718s / 2442.0310 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0200
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0214
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 201/50000 (0.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 285.9276s / 2727.9585 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0222
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0218
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 221/50000 (0.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 287.2507s / 3015.2092 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0231
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0227
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 241/50000 (0.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 293.0978s / 3308.3070 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0228
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0233
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 261/50000 (0.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 297.1670s / 3605.4739 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0237
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0232
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 281/50000 (0.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 300.0485s / 3905.5225 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0226
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0241
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 301/50000 (0.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 303.9384s / 4209.4609 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0235
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0255
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 321/50000 (0.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 307.6591s / 4517.1200 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0247
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0268
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 341/50000 (0.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 311.9580s / 4829.0780 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0240
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0247
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 361/50000 (0.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 313.3897s / 5142.4678 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0259
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0265
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 381/50000 (0.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 310.9592s / 5453.4270 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0272
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0273
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 401/50000 (0.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 312.0064s / 5765.4334 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0264
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0271
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 421/50000 (0.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 312.1958s / 6077.6291 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0267
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0280
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 441/50000 (0.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 311.5286s / 6389.1577 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0256
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0267
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 461/50000 (0.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 311.6832s / 6700.8409 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0246
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0272
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 481/50000 (0.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 311.4538s / 7012.2948 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0246
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0275
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 501/50000 (1.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 311.7161s / 7324.0108 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0253
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0272
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 521/50000 (1.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 312.5827s / 7636.5935 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0270
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0261
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 541/50000 (1.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 312.0677s / 7948.6612 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0273
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0262
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 561/50000 (1.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 311.8883s / 8260.5495 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0265
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0273
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 581/50000 (1.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 320.9089s / 8581.4584 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0281
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0280
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 601/50000 (1.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 315.2140s / 8896.6724 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0274
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0287
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 621/50000 (1.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 313.5112s / 9210.1836 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0271
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0297
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 641/50000 (1.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 314.8160s / 9524.9996 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0277
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0292
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 661/50000 (1.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 312.7283s / 9837.7280 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0278
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0293
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 681/50000 (1.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 314.4050s / 10152.1330 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0271
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0290
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 701/50000 (1.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 316.0312s / 10468.1642 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0258
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0293
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 721/50000 (1.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 313.9203s / 10782.0845 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0276
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0293
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 741/50000 (1.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 317.2217s / 11099.3062 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0293
env0_second_0:                 episode reward: -0.7500,                 loss: 0.0294
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 761/50000 (1.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 316.9371s / 11416.2433 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0285
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0282
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 781/50000 (1.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 317.7040s / 11733.9473 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0285
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0313
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 801/50000 (1.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 317.6641s / 12051.6114 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0299
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0308
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 821/50000 (1.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 318.3640s / 12369.9754 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0299
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0305
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 841/50000 (1.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 315.5378s / 12685.5132 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0309
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0300
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 861/50000 (1.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 317.3708s / 13002.8840 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0295
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0302
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 881/50000 (1.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 317.2810s / 13320.1650 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0288
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0311
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 901/50000 (1.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 318.3618s / 13638.5268 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0283
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0298
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 921/50000 (1.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 319.2007s / 13957.7276 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0286
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0306
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 941/50000 (1.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 318.4632s / 14276.1907 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0286
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0316
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 961/50000 (1.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 322.4529s / 14598.6437 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0288
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0304
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 981/50000 (1.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 323.0861s / 14921.7298 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0287
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0312
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1001/50000 (2.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 318.8659s / 15240.5957 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0283
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0315
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1021/50000 (2.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 322.3666s / 15562.9623 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0293
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0322
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1041/50000 (2.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 321.0314s / 15883.9937 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0296
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0325
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1061/50000 (2.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 322.1205s / 16206.1143 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0292
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0316
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 1081/50000 (2.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 322.3110s / 16528.4253 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0298
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0335
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1101/50000 (2.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 320.1603s / 16848.5855 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0291
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0326
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1121/50000 (2.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 322.8522s / 17171.4378 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0308
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0320
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1141/50000 (2.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 321.1461s / 17492.5838 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0295
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0324
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1161/50000 (2.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 319.4295s / 17812.0134 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0296
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0322
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1181/50000 (2.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 320.2316s / 18132.2450 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0302
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0316
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1201/50000 (2.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 321.0861s / 18453.3311 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0308
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0330
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1221/50000 (2.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 323.0628s / 18776.3939 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0312
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0329
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1241/50000 (2.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 321.9390s / 19098.3328 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0314
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0333
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1261/50000 (2.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 322.2449s / 19420.5778 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0325
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0344
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1281/50000 (2.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 322.3524s / 19742.9301 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0331
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0325
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1301/50000 (2.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 323.7727s / 20066.7028 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0300
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0312
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1321/50000 (2.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 321.8295s / 20388.5322 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0288
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0318
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1341/50000 (2.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 322.8573s / 20711.3896 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0298
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0326
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1361/50000 (2.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 321.3781s / 21032.7677 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0301
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0349
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1381/50000 (2.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 321.4498s / 21354.2175 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0297
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0369
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1401/50000 (2.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 325.5973s / 21679.8148 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0297
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0358
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1421/50000 (2.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 322.0336s / 22001.8484 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0309
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0350
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1441/50000 (2.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 321.5089s / 22323.3573 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0313
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0358
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1461/50000 (2.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 323.1933s / 22646.5506 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0310
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0356
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1481/50000 (2.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 326.5725s / 22973.1230 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0314
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0374
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1501/50000 (3.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 322.7220s / 23295.8450 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0329
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0369
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1521/50000 (3.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 322.2836s / 23618.1286 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0320
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0359
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1541/50000 (3.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 323.5403s / 23941.6689 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0306
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0364
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1561/50000 (3.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 322.8066s / 24264.4755 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0318
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0366
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1581/50000 (3.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 323.2605s / 24587.7361 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0310
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0366
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1601/50000 (3.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 336.2367s / 24923.9728 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0309
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0369
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1621/50000 (3.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 324.1470s / 25248.1198 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0305
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0366
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1641/50000 (3.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 324.2981s / 25572.4179 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0305
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0380
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1661/50000 (3.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 323.8468s / 25896.2647 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0314
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0384
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1681/50000 (3.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 321.1760s / 26217.4407 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0318
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0396
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1701/50000 (3.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 320.5214s / 26537.9621 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0318
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0397
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1721/50000 (3.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 321.3586s / 26859.3208 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0328
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0402
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1741/50000 (3.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 328.8389s / 27188.1597 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0322
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0419
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1761/50000 (3.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 327.0254s / 27515.1851 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0333
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0422
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1781/50000 (3.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 323.5712s / 27838.7562 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0332
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0412
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1801/50000 (3.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 321.2022s / 28159.9584 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0332
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0438
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1821/50000 (3.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 324.2532s / 28484.2116 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0337
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0433
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1841/50000 (3.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 322.3699s / 28806.5815 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0330
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0449
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1861/50000 (3.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 321.0927s / 29127.6742 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0336
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0458
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1881/50000 (3.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 325.2227s / 29452.8969 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0339
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0463
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1901/50000 (3.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 326.0243s / 29778.9212 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0340
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0473
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 1921/50000 (3.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 324.6028s / 30103.5240 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0338
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0482
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1941/50000 (3.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 324.7465s / 30428.2705 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0353
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0480
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1961/50000 (3.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 325.9763s / 30754.2468 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0337
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0482
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1981/50000 (3.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 324.9167s / 31079.1634 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0347
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0488
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2001/50000 (4.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 326.2963s / 31405.4597 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0357
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0492
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2021/50000 (4.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 325.4003s / 31730.8600 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0355
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0498
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2041/50000 (4.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 324.6319s / 32055.4919 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0361
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0486
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2061/50000 (4.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 324.3451s / 32379.8370 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0366
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0491
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2081/50000 (4.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 324.6860s / 32704.5230 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0366
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0494
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2101/50000 (4.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 325.6712s / 33030.1942 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0350
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0517
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2121/50000 (4.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 321.9838s / 33352.1781 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0362
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0530
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2141/50000 (4.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 325.9517s / 33678.1298 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0370
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0508
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2161/50000 (4.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 325.6767s / 34003.8064 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0381
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0508
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2181/50000 (4.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 326.3253s / 34330.1318 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0391
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0523
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2201/50000 (4.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 326.0702s / 34656.2019 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0400
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0503
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2221/50000 (4.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 325.4720s / 34981.6739 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0409
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0519
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2241/50000 (4.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 327.7398s / 35309.4137 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0393
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0518
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2261/50000 (4.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 325.8314s / 35635.2451 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0401
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0527
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2281/50000 (4.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 323.2524s / 35958.4975 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0385
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0521
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2301/50000 (4.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 326.2476s / 36284.7451 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0404
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0526
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2321/50000 (4.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 325.3848s / 36610.1299 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0411
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0552
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2341/50000 (4.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 326.4040s / 36936.5339 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0414
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0545
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2361/50000 (4.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 326.6741s / 37263.2080 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0423
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0568
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2381/50000 (4.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 325.1988s / 37588.4068 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0419
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0559
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2401/50000 (4.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 327.9116s / 37916.3184 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0423
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0590
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2421/50000 (4.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 326.7580s / 38243.0764 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0444
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0574
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2441/50000 (4.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 328.8846s / 38571.9610 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0434
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0590
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2461/50000 (4.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 325.9686s / 38897.9296 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0443
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0587
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2481/50000 (4.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 324.3587s / 39222.2882 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0439
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0563
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2501/50000 (5.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.0398s / 39551.3280 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0432
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0576
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2521/50000 (5.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 328.6438s / 39879.9718 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0403
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0592
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2541/50000 (5.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 327.2823s / 40207.2541 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0408
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0605
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2561/50000 (5.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 326.2064s / 40533.4605 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0421
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0614
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2581/50000 (5.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 326.3811s / 40859.8416 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0422
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0615
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2601/50000 (5.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 325.8085s / 41185.6500 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0407
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0619
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2621/50000 (5.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 325.4485s / 41511.0985 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0415
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0643
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2641/50000 (5.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 324.9867s / 41836.0853 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0417
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0614
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2661/50000 (5.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 325.4511s / 42161.5363 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0408
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0647
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2681/50000 (5.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 327.9254s / 42489.4617 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0394
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0621
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2701/50000 (5.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 326.3823s / 42815.8440 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0405
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0617
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2721/50000 (5.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.8553s / 43146.6992 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0401
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0618
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2741/50000 (5.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 326.6739s / 43473.3732 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0404
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0618
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2761/50000 (5.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 324.8476s / 43798.2208 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0402
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0642
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2781/50000 (5.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 329.2578s / 44127.4787 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0424
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0645
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2801/50000 (5.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 330.6809s / 44458.1596 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0404
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0627
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2821/50000 (5.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 325.8941s / 44784.0536 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0407
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0641
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2841/50000 (5.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 327.8956s / 45111.9492 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0393
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0639
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2861/50000 (5.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 327.1765s / 45439.1257 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0406
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0630
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 2881/50000 (5.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 325.6112s / 45764.7369 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0399
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0618
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2901/50000 (5.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 322.7453s / 46087.4822 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0406
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0602
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2921/50000 (5.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 322.8765s / 46410.3587 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0422
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0594
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2941/50000 (5.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 323.9519s / 46734.3106 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0408
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0624
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2961/50000 (5.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 322.9852s / 47057.2958 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0405
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0623
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 2981/50000 (5.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 324.8550s / 47382.1508 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0407
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0631
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3001/50000 (6.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 328.2522s / 47710.4030 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0399
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0613
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3021/50000 (6.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 326.1448s / 48036.5478 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0406
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0601
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3041/50000 (6.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 324.6560s / 48361.2038 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0411
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0622
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3061/50000 (6.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 325.9065s / 48687.1102 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0424
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0642
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3081/50000 (6.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 324.9912s / 49012.1015 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0419
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0637
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3101/50000 (6.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 323.9458s / 49336.0473 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0430
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0657
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3121/50000 (6.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 322.8403s / 49658.8876 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0434
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0653
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3141/50000 (6.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 323.8653s / 49982.7528 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0439
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0642
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3161/50000 (6.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 325.0675s / 50307.8203 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0428
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0701
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3181/50000 (6.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 324.0240s / 50631.8443 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0442
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0703
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3201/50000 (6.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 323.2329s / 50955.0772 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0434
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0720
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3221/50000 (6.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 323.1030s / 51278.1802 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0447
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0736
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3241/50000 (6.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 323.3299s / 51601.5101 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0425
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0740
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3261/50000 (6.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 323.1150s / 51924.6251 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0420
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0725
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3281/50000 (6.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 324.8245s / 52249.4496 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0428
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0746
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3301/50000 (6.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 326.6594s / 52576.1090 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0459
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0762
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3321/50000 (6.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 324.4741s / 52900.5831 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0435
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0764
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3341/50000 (6.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 327.9621s / 53228.5453 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0428
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0762
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3361/50000 (6.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 325.1069s / 53553.6521 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0430
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0786
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3381/50000 (6.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 326.4149s / 53880.0670 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0431
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0753
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3401/50000 (6.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 324.9875s / 54205.0545 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0425
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0739
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3421/50000 (6.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 328.9623s / 54534.0168 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0450
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0751
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3441/50000 (6.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 325.1437s / 54859.1605 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0442
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0738
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3461/50000 (6.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 326.5533s / 55185.7138 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0458
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0743
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3481/50000 (6.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 324.9884s / 55510.7022 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0431
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0790
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3501/50000 (7.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 324.9470s / 55835.6492 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0438
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0799
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3521/50000 (7.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 326.2732s / 56161.9225 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0442
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0798
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3541/50000 (7.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 326.5425s / 56488.4650 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0469
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0773
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3561/50000 (7.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 325.7712s / 56814.2362 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0451
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0783
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 3581/50000 (7.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 324.1460s / 57138.3822 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0446
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0785
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3601/50000 (7.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 323.7939s / 57462.1761 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0447
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0780
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3621/50000 (7.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 325.3187s / 57787.4947 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0427
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0755
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3641/50000 (7.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 326.6047s / 58114.0995 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0451
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0796
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3661/50000 (7.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 328.0512s / 58442.1507 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0474
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0795
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3681/50000 (7.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 326.0191s / 58768.1697 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0452
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0807
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3701/50000 (7.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 325.7132s / 59093.8830 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0469
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0782
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3721/50000 (7.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 325.4464s / 59419.3294 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0458
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0785
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3741/50000 (7.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 326.1824s / 59745.5117 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0447
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0807
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3761/50000 (7.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 326.5948s / 60072.1066 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0451
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0772
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3781/50000 (7.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 323.1892s / 60395.2957 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0453
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0753
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3801/50000 (7.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 323.5223s / 60718.8180 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0438
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0773
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3821/50000 (7.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 327.0324s / 61045.8504 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0448
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0777
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3841/50000 (7.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 325.6766s / 61371.5269 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0452
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0767
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3861/50000 (7.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 325.8107s / 61697.3377 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0462
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0798
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 3881/50000 (7.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 324.7958s / 62022.1334 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0465
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0785
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3901/50000 (7.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 325.7990s / 62347.9324 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0459
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0784
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3921/50000 (7.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 326.2774s / 62674.2099 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0454
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0772
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3941/50000 (7.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 326.2450s / 63000.4549 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0448
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0769
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3961/50000 (7.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 333.8012s / 63334.2561 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0461
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0791
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 3981/50000 (7.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.0408s / 63665.2969 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0466
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0767
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4001/50000 (8.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.3038s / 63994.6007 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0475
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0795
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4021/50000 (8.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 326.6716s / 64321.2723 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0498
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0787
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4041/50000 (8.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 327.4290s / 64648.7013 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0477
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0792
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4061/50000 (8.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 328.6265s / 64977.3278 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0454
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0805
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4081/50000 (8.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 326.9967s / 65304.3245 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0455
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0794
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4101/50000 (8.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 324.8243s / 65629.1488 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0457
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0789
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4121/50000 (8.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 324.2841s / 65953.4329 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0458
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0825
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4141/50000 (8.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 324.3860s / 66277.8189 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0447
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0843
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4161/50000 (8.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 326.8142s / 66604.6331 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0446
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0799
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4181/50000 (8.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 327.5490s / 66932.1821 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0436
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0828
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4201/50000 (8.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 326.8084s / 67258.9905 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0468
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0811
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4221/50000 (8.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 326.9780s / 67585.9686 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0476
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0803
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4241/50000 (8.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 327.8013s / 67913.7698 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0471
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0830
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4261/50000 (8.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 326.1550s / 68239.9248 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0481
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0857
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4281/50000 (8.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 327.4350s / 68567.3598 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0468
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0867
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4301/50000 (8.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 326.7867s / 68894.1466 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0462
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0820
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4321/50000 (8.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 327.1652s / 69221.3118 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0471
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0835
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4341/50000 (8.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 326.7184s / 69548.0302 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0476
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0841
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4361/50000 (8.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 326.2354s / 69874.2656 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0475
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0848
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4381/50000 (8.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 325.9471s / 70200.2127 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0460
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0863
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4401/50000 (8.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 327.2288s / 70527.4415 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0476
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0879
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4421/50000 (8.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 327.3361s / 70854.7777 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0477
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0910
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4441/50000 (8.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 327.6708s / 71182.4485 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0492
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0883
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 4461/50000 (8.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 327.5431s / 71509.9915 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0468
env0_second_0:                 episode reward: -0.4000,                 loss: 0.0861
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 4481/50000 (8.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 326.1292s / 71836.1207 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0470
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0891
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4501/50000 (9.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 327.0318s / 72163.1525 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0473
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0860
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4521/50000 (9.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 327.8255s / 72490.9780 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0486
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0836
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4541/50000 (9.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 325.0895s / 72816.0675 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0480
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0859
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4561/50000 (9.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 326.5352s / 73142.6027 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0488
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0862
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 4581/50000 (9.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 328.6714s / 73471.2741 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0465
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0882
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4601/50000 (9.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 326.4362s / 73797.7104 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0462
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0906
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4621/50000 (9.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 326.9672s / 74124.6776 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0473
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0943
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4641/50000 (9.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 327.3757s / 74452.0533 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0473
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0962
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4661/50000 (9.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 325.1639s / 74777.2172 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0469
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0973
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4681/50000 (9.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 325.5232s / 75102.7405 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0466
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0913
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4701/50000 (9.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 328.1795s / 75430.9199 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0465
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0937
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4721/50000 (9.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 327.2031s / 75758.1230 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0464
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0901
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4741/50000 (9.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 327.4955s / 76085.6185 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0455
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0864
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4761/50000 (9.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 325.8004s / 76411.4189 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0472
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0861
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4781/50000 (9.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 327.7696s / 76739.1884 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0462
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0879
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4801/50000 (9.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.3940s / 77068.5824 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0474
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0900
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4821/50000 (9.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 327.1638s / 77395.7462 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0466
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0898
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4841/50000 (9.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 327.9895s / 77723.7357 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0457
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0905
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4861/50000 (9.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 328.7917s / 78052.5274 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0466
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0885
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4881/50000 (9.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 328.6307s / 78381.1581 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0469
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0883
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4901/50000 (9.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.2840s / 78710.4422 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0458
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0895
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4921/50000 (9.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 329.5833s / 79040.0255 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0451
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0895
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4941/50000 (9.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 329.1935s / 79369.2189 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0450
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0976
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4961/50000 (9.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 327.6095s / 79696.8284 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0446
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0966
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4981/50000 (9.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 327.5571s / 80024.3856 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0439
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0970
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 5001/50000 (10.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.3191s / 80353.7046 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0459
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0990
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 5021/50000 (10.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.0413s / 80684.7459 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0454
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0996
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 5041/50000 (10.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 328.7779s / 81013.5238 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0433
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0989
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 5061/50000 (10.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 329.7293s / 81343.2531 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0456
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0948
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5081/50000 (10.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.1445s / 81674.3977 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0456
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0959
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5101/50000 (10.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 328.3208s / 82002.7185 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0442
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0955
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5121/50000 (10.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 328.5420s / 82331.2604 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0457
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0941
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5141/50000 (10.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 327.8230s / 82659.0834 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0456
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0933
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5161/50000 (10.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 330.4255s / 82989.5089 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0444
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0923
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5181/50000 (10.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 329.5624s / 83319.0713 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0449
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0958
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5201/50000 (10.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 328.6510s / 83647.7223 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0445
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0959
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5221/50000 (10.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 328.7232s / 83976.4454 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0445
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0955
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5241/50000 (10.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.0353s / 84307.4807 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0443
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0982
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5261/50000 (10.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 326.5147s / 84633.9954 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0458
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0990
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5281/50000 (10.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 329.7841s / 84963.7795 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0466
env0_second_0:                 episode reward: -0.3500,                 loss: 0.1002
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 5301/50000 (10.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.4670s / 85293.2464 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0444
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0991
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5321/50000 (10.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 327.7908s / 85621.0372 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0445
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1002
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5341/50000 (10.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 330.2432s / 85951.2804 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0456
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1019
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5361/50000 (10.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.6601s / 86282.9405 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0466
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0989
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5381/50000 (10.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 330.6854s / 86613.6259 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0458
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0985
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5401/50000 (10.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 330.0306s / 86943.6565 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0452
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0995
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5421/50000 (10.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 329.6210s / 87273.2776 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0463
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0954
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5441/50000 (10.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 329.8059s / 87603.0834 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0458
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0978
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5461/50000 (10.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.6598s / 87934.7432 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0457
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1013
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5481/50000 (10.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 330.2271s / 88264.9703 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0469
env0_second_0:                 episode reward: -0.1500,                 loss: 0.1006
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5501/50000 (11.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.7283s / 88594.6987 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0447
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0977
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5521/50000 (11.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.7718s / 88925.4704 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0449
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1002
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 5541/50000 (11.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 330.7136s / 89256.1840 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0440
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0963
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5561/50000 (11.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 330.5663s / 89586.7503 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0443
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0966
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 5581/50000 (11.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 330.8506s / 89917.6009 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0439
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0946
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5601/50000 (11.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.7639s / 90247.3648 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0432
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0997
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5621/50000 (11.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 334.9840s / 90582.3488 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0438
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0970
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5641/50000 (11.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.2601s / 90914.6089 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0438
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0973
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5661/50000 (11.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 330.3849s / 91244.9938 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0437
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0963
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5681/50000 (11.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 330.3607s / 91575.3545 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0443
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0968
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5701/50000 (11.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.0821s / 91906.4365 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0439
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0960
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5721/50000 (11.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.8072s / 92237.2437 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0440
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0968
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5741/50000 (11.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.8197s / 92569.0635 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0439
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0967
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5761/50000 (11.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 329.5231s / 92898.5866 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0434
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0992
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5781/50000 (11.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 327.6901s / 93226.2767 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0434
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0990
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5801/50000 (11.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 330.9759s / 93557.2526 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0435
env0_second_0:                 episode reward: -0.2500,                 loss: 0.1046
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5821/50000 (11.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.6537s / 93887.9063 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0437
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1039
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5841/50000 (11.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.9597s / 94219.8660 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0442
env0_second_0:                 episode reward: -0.2000,                 loss: 0.1015
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5861/50000 (11.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 329.5167s / 94549.3827 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0432
env0_second_0:                 episode reward: -0.2000,                 loss: 0.1038
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5881/50000 (11.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.8693s / 94881.2520 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0433
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1021
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5901/50000 (11.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.1369s / 95213.3889 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0422
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0985
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5921/50000 (11.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.0795s / 95543.4685 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0426
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0955
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 5941/50000 (11.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 329.6436s / 95873.1121 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0414
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0959
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5961/50000 (11.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.3650s / 96204.4772 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0413
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0984
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 5981/50000 (11.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 330.9246s / 96535.4017 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0444
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0949
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6001/50000 (12.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.9871s / 96865.3888 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0454
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0992
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6021/50000 (12.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 329.9439s / 97195.3328 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0461
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0971
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 6041/50000 (12.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 329.8876s / 97525.2204 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0440
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0957
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6061/50000 (12.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 330.4209s / 97855.6413 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0441
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0983
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6081/50000 (12.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 329.7845s / 98185.4258 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0426
env0_second_0:                 episode reward: -0.1500,                 loss: 0.1017
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6101/50000 (12.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.3527s / 98518.7786 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0417
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0973
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6121/50000 (12.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.7215s / 98850.5000 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0432
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0953
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6141/50000 (12.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.6985s / 99183.1986 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0429
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0982
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 6161/50000 (12.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 329.5387s / 99512.7373 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0429
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0985
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6181/50000 (12.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 329.6786s / 99842.4159 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0439
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0951
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 6201/50000 (12.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 330.1099s / 100172.5257 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0433
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0966
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6221/50000 (12.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 328.3014s / 100500.8271 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0447
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1006
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6241/50000 (12.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 329.0605s / 100829.8876 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0445
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0999
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6261/50000 (12.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 328.6463s / 101158.5339 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0450
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0955
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6281/50000 (12.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 329.1392s / 101487.6731 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0433
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0923
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6301/50000 (12.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.9386s / 101819.6118 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0422
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0951
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 6321/50000 (12.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.9353s / 102151.5470 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0430
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0907
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 6341/50000 (12.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 329.8449s / 102481.3919 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0429
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0958
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6361/50000 (12.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.4754s / 102813.8673 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0434
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0976
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6381/50000 (12.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 329.1037s / 103142.9710 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0405
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0977
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6401/50000 (12.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.3244s / 103474.2954 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0406
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0961
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6421/50000 (12.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 328.2849s / 103802.5803 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0403
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0958
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 6441/50000 (12.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 330.2268s / 104132.8071 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0411
env0_second_0:                 episode reward: -0.1000,                 loss: 0.1000
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6461/50000 (12.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 328.8750s / 104461.6821 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0404
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0942
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6481/50000 (12.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 329.6627s / 104791.3448 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0421
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0967
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6501/50000 (13.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.6262s / 105120.9711 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0410
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0976
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 6521/50000 (13.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.4781s / 105451.4492 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0399
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0992
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 6541/50000 (13.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.8926s / 105785.3418 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0401
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1005
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 6561/50000 (13.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 330.8520s / 106116.1938 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0408
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0981
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 6581/50000 (13.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.0716s / 106447.2654 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0414
env0_second_0:                 episode reward: 0.9000,                 loss: 0.1015
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6601/50000 (13.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.2358s / 106776.5012 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0410
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1023
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 6621/50000 (13.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 329.0331s / 107105.5343 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0396
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1018
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 6641/50000 (13.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 329.3669s / 107434.9012 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0401
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1060
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 6661/50000 (13.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 329.0068s / 107763.9080 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0417
env0_second_0:                 episode reward: -0.4500,                 loss: 0.1052
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6681/50000 (13.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.0859s / 108096.9939 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0409
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1044
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 6701/50000 (13.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 330.0155s / 108427.0094 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0415
env0_second_0:                 episode reward: -0.3000,                 loss: 0.1047
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6721/50000 (13.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.8527s / 108757.8621 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0412
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1054
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 6741/50000 (13.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2012s / 109091.0633 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0404
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1036
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6761/50000 (13.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 329.1595s / 109420.2228 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0396
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1029
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6781/50000 (13.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 329.8714s / 109750.0942 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0404
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1055
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 6801/50000 (13.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.2237s / 110079.3179 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0397
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1000
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 6821/50000 (13.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 327.9148s / 110407.2327 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0402
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0976
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6841/50000 (13.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.4382s / 110738.6708 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0395
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0991
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 6861/50000 (13.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 330.0431s / 111068.7139 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0388
env0_second_0:                 episode reward: 0.7000,                 loss: 0.1034
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6881/50000 (13.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 329.8296s / 111398.5435 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0378
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1022
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 6901/50000 (13.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 328.1835s / 111726.7271 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0378
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1020
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 6921/50000 (13.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.8420s / 112057.5690 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0384
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1003
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6941/50000 (13.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 326.4393s / 112384.0083 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0392
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0999
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6961/50000 (13.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 327.5137s / 112711.5220 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0413
env0_second_0:                 episode reward: -0.1500,                 loss: 0.1010
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6981/50000 (13.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 326.9706s / 113038.4927 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0397
env0_second_0:                 episode reward: -0.1000,                 loss: 0.1036
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7001/50000 (14.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.0200s / 113367.5127 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0403
env0_second_0:                 episode reward: 1.0000,                 loss: 0.1042
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 7021/50000 (14.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 328.0279s / 113695.5406 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0414
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1013
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7041/50000 (14.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 329.2083s / 114024.7489 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0407
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1035
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7061/50000 (14.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 328.4684s / 114353.2173 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0406
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1022
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7081/50000 (14.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 328.6488s / 114681.8661 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0401
env0_second_0:                 episode reward: -0.7500,                 loss: 0.1026
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7101/50000 (14.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 327.5776s / 115009.4437 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0416
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1040
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 7121/50000 (14.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 328.8830s / 115338.3267 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0430
env0_second_0:                 episode reward: -0.1000,                 loss: 0.1065
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 7141/50000 (14.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 330.0377s / 115668.3645 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0426
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1045
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 7161/50000 (14.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 330.4471s / 115998.8116 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0434
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1028
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7181/50000 (14.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 328.1953s / 116327.0069 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0422
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1061
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7201/50000 (14.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.7307s / 116656.7377 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0420
env0_second_0:                 episode reward: -0.2000,                 loss: 0.1060
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7221/50000 (14.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 329.1122s / 116985.8499 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0408
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1062
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7241/50000 (14.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 330.0255s / 117315.8753 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0410
env0_second_0:                 episode reward: -0.1000,                 loss: 0.1051
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7261/50000 (14.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 329.8661s / 117645.7415 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0404
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1047
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7281/50000 (14.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 330.8152s / 117976.5567 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0403
env0_second_0:                 episode reward: 0.7000,                 loss: 0.1058
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7301/50000 (14.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 330.9245s / 118307.4812 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0411
env0_second_0:                 episode reward: 0.6500,                 loss: 0.1051
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7321/50000 (14.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 328.7859s / 118636.2671 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0425
env0_second_0:                 episode reward: 0.7500,                 loss: 0.1029
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 7341/50000 (14.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 329.8978s / 118966.1649 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0409
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1041
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 7361/50000 (14.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 330.9892s / 119297.1541 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0425
env0_second_0:                 episode reward: 0.8000,                 loss: 0.1020
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7381/50000 (14.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 337.4588s / 119634.6129 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0426
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1034
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7401/50000 (14.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.8950s / 119964.5079 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0438
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1037
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7421/50000 (14.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.4604s / 120295.9683 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0421
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1028
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7441/50000 (14.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 330.4821s / 120626.4505 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0413
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1053
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7461/50000 (14.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 330.9510s / 120957.4014 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0417
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1098
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7481/50000 (14.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.5648s / 121289.9662 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0430
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1059
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7501/50000 (15.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.1706s / 121621.1368 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0416
env0_second_0:                 episode reward: -0.4000,                 loss: 0.1093
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7521/50000 (15.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.2635s / 121951.4002 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0419
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1092
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7541/50000 (15.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 329.9585s / 122281.3587 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0418
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1097
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7561/50000 (15.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 329.6614s / 122611.0202 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0416
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1131
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7581/50000 (15.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 329.1301s / 122940.1503 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0429
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1073
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7601/50000 (15.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.5581s / 123269.7084 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0432
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1076
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 7621/50000 (15.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.7391s / 123600.4475 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0416
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1069
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7641/50000 (15.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 329.8086s / 123930.2561 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0418
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1046
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 7661/50000 (15.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 329.0676s / 124259.3237 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0432
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1058
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 7681/50000 (15.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 328.7543s / 124588.0780 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0425
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1056
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7701/50000 (15.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.3949s / 124917.4729 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0421
env0_second_0:                 episode reward: -0.2000,                 loss: 0.1068
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 7721/50000 (15.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.8666s / 125248.3395 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0418
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1033
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 7741/50000 (15.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 330.9172s / 125579.2566 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0417
env0_second_0:                 episode reward: 0.6500,                 loss: 0.1032
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7761/50000 (15.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 329.0363s / 125908.2929 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0429
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1076
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 7781/50000 (15.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 330.6206s / 126238.9135 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0432
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1069
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 7801/50000 (15.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.9143s / 126568.8278 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0425
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1028
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 7821/50000 (15.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 328.4257s / 126897.2535 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0415
env0_second_0:                 episode reward: -0.3000,                 loss: 0.1072
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 7841/50000 (15.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 329.4196s / 127226.6731 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0416
env0_second_0:                 episode reward: -0.6000,                 loss: 0.1043
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7861/50000 (15.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 327.9995s / 127554.6726 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0408
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1068
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 7881/50000 (15.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 328.3302s / 127883.0028 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0413
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1038
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 7901/50000 (15.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.5342s / 128212.5369 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0406
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1068
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 7921/50000 (15.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 328.8089s / 128541.3458 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0421
env0_second_0:                 episode reward: -0.1500,                 loss: 0.1008
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 7941/50000 (15.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 329.7325s / 128871.0783 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0403
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1025
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 7961/50000 (15.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 329.9208s / 129200.9991 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0406
env0_second_0:                 episode reward: -0.1500,                 loss: 0.1043
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 7981/50000 (15.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 330.9118s / 129531.9109 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0409
env0_second_0:                 episode reward: 0.7000,                 loss: 0.1063
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8001/50000 (16.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.4809s / 129863.3918 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0400
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1049
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8021/50000 (16.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.8186s / 130195.2104 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0412
env0_second_0:                 episode reward: -0.1000,                 loss: 0.1042
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8041/50000 (16.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.8147s / 130528.0252 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0401
env0_second_0:                 episode reward: -0.1500,                 loss: 0.1053
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 8061/50000 (16.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.2868s / 130860.3119 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0397
env0_second_0:                 episode reward: 0.8500,                 loss: 0.1074
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8081/50000 (16.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.0944s / 131191.4063 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0397
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1021
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 8101/50000 (16.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 329.3682s / 131520.7746 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0422
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1010
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8121/50000 (16.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 329.6972s / 131850.4718 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0404
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1070
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 8141/50000 (16.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 329.2460s / 132179.7178 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0407
env0_second_0:                 episode reward: -0.3000,                 loss: 0.1025
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8161/50000 (16.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 330.7041s / 132510.4219 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0407
env0_second_0:                 episode reward: 0.8000,                 loss: 0.1042
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8181/50000 (16.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.2864s / 132842.7084 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0405
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1045
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 8201/50000 (16.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 330.7248s / 133173.4332 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0397
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1039
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8221/50000 (16.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.0361s / 133504.4693 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0408
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1031
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8241/50000 (16.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.3762s / 133837.8455 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0401
env0_second_0:                 episode reward: -0.2000,                 loss: 0.1031
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8261/50000 (16.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.4074s / 134170.2529 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0405
env0_second_0:                 episode reward: 1.0000,                 loss: 0.1043
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8281/50000 (16.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.0312s / 134502.2841 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0418
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1058
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 8301/50000 (16.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.6497s / 134833.9338 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0422
env0_second_0:                 episode reward: -0.2500,                 loss: 0.1046
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8321/50000 (16.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.7016s / 135164.6354 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0420
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1090
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8341/50000 (16.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.5535s / 135497.1889 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0399
env0_second_0:                 episode reward: -0.1500,                 loss: 0.1076
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8361/50000 (16.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.8252s / 135830.0140 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0410
env0_second_0:                 episode reward: -0.1000,                 loss: 0.1065
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8381/50000 (16.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1547s / 136163.1688 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0403
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1086
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8401/50000 (16.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.3203s / 136495.4890 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0398
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1085
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8421/50000 (16.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 336.8942s / 136832.3833 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.0403
env0_second_0:                 episode reward: -0.4000,                 loss: 0.1104
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8441/50000 (16.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.1819s / 137164.5652 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0403
env0_second_0:                 episode reward: 0.8000,                 loss: 0.1079
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8461/50000 (16.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.5564s / 137499.1216 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0396
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1061
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8481/50000 (16.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 330.0628s / 137829.1844 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0396
env0_second_0:                 episode reward: 0.8000,                 loss: 0.1088
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8501/50000 (17.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.5777s / 138160.7621 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0392
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1070
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8521/50000 (17.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.6660s / 138494.4281 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0398
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1091
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8541/50000 (17.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.4948s / 138825.9228 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0407
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1130
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8561/50000 (17.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.9746s / 139158.8974 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0387
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1092
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 8581/50000 (17.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 336.0864s / 139494.9838 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0392
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1078
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8601/50000 (17.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.3137s / 139827.2975 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0389
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1106
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 8621/50000 (17.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.5473s / 140158.8448 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0381
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1097
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8641/50000 (17.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 330.9285s / 140489.7733 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0383
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1105
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 8661/50000 (17.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.4388s / 140822.2122 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0386
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1099
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 8681/50000 (17.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.4241s / 141153.6363 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0403
env0_second_0:                 episode reward: 1.0000,                 loss: 0.1077
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 8701/50000 (17.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.1904s / 141484.8267 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0396
env0_second_0:                 episode reward: -0.1000,                 loss: 0.1129
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 8721/50000 (17.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.3370s / 141817.1638 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0383
env0_second_0:                 episode reward: -0.2500,                 loss: 0.1144
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 8741/50000 (17.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.9240s / 142149.0878 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0411
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1159
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 8761/50000 (17.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 329.9811s / 142479.0689 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0412
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1151
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 8781/50000 (17.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.6965s / 142811.7654 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0405
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1168
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8801/50000 (17.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.2614s / 143143.0268 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0388
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1212
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 8821/50000 (17.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 334.1505s / 143477.1774 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0383
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1291
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 8841/50000 (17.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.0373s / 143809.2146 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0395
env0_second_0:                 episode reward: 0.9000,                 loss: 0.1370
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8861/50000 (17.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.2761s / 144140.4908 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0401
env0_second_0:                 episode reward: -0.1000,                 loss: 0.1439
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 8881/50000 (17.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.0885s / 144471.5793 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0385
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1406
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 8901/50000 (17.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.3255s / 144802.9048 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0371
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1403
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 8921/50000 (17.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.5212s / 145134.4260 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0371
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1463
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 8941/50000 (17.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 330.3796s / 145464.8056 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0379
env0_second_0:                 episode reward: 0.9500,                 loss: 0.1461
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 8961/50000 (17.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.4363s / 145796.2419 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0403
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1513
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 8981/50000 (17.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.1154s / 146127.3572 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0386
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1440
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 9001/50000 (18.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.5455s / 146458.9028 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0390
env0_second_0:                 episode reward: -0.5000,                 loss: 0.1440
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 9021/50000 (18.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.6930s / 146789.5957 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0390
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1448
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 9041/50000 (18.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.9041s / 147121.4998 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0393
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1395
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9061/50000 (18.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.1500s / 147452.6497 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0395
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1391
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 9081/50000 (18.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.3640s / 147785.0137 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0400
env0_second_0:                 episode reward: -0.1500,                 loss: 0.1371
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 9101/50000 (18.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.6635s / 148117.6772 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0408
env0_second_0:                 episode reward: 0.8000,                 loss: 0.1353
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9121/50000 (18.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.3184s / 148447.9956 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0395
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1350
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9141/50000 (18.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.8888s / 148781.8844 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0393
env0_second_0:                 episode reward: -0.1500,                 loss: 0.1310
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9161/50000 (18.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 333.9863s / 149115.8707 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0401
env0_second_0:                 episode reward: 0.6500,                 loss: 0.1324
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 9181/50000 (18.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 330.3052s / 149446.1759 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0390
env0_second_0:                 episode reward: 0.6500,                 loss: 0.1343
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9201/50000 (18.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 330.9222s / 149777.0982 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0401
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1350
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9221/50000 (18.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.1566s / 150109.2547 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0393
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1287
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 9241/50000 (18.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 330.4990s / 150439.7538 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0401
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1291
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 9261/50000 (18.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.1627s / 150771.9165 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0404
env0_second_0:                 episode reward: -0.5500,                 loss: 0.1292
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9281/50000 (18.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.9828s / 151103.8993 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0400
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1339
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 9301/50000 (18.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 335.0894s / 151438.9887 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0395
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1343
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 9321/50000 (18.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.3510s / 151770.3397 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0383
env0_second_0:                 episode reward: 0.6500,                 loss: 0.1271
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 9341/50000 (18.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 329.3525s / 152099.6922 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0385
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1316
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9361/50000 (18.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.8094s / 152431.5016 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0374
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1343
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 9381/50000 (18.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.7399s / 152764.2415 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0376
env0_second_0:                 episode reward: -0.2500,                 loss: 0.1350
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9401/50000 (18.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.3312s / 153097.5726 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0369
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1429
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 9421/50000 (18.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.8651s / 153431.4377 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0371
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1398
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9441/50000 (18.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2814s / 153764.7192 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0371
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1415
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 9461/50000 (18.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.2473s / 154095.9665 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0377
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1415
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9481/50000 (18.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.3502s / 154429.3167 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0371
env0_second_0:                 episode reward: -0.2500,                 loss: 0.1410
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9501/50000 (19.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2155s / 154762.5322 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0357
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1365
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 9521/50000 (19.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.5519s / 155093.0840 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0368
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1361
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 9541/50000 (19.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.5462s / 155424.6302 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0367
env0_second_0:                 episode reward: -0.1500,                 loss: 0.1320
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 9561/50000 (19.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.7944s / 155757.4247 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0368
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1363
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9581/50000 (19.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.9247s / 156089.3494 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0366
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1331
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9601/50000 (19.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.8585s / 156422.2079 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0362
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1327
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9621/50000 (19.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.4424s / 156753.6503 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0379
env0_second_0:                 episode reward: 0.7000,                 loss: 0.1278
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 9641/50000 (19.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 330.9375s / 157084.5878 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0390
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1272
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 9661/50000 (19.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.7224s / 157419.3102 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0388
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1311
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9681/50000 (19.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.2480s / 157750.5581 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0367
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1308
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 9701/50000 (19.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.4760s / 158082.0342 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0381
env0_second_0:                 episode reward: -0.1500,                 loss: 0.1328
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 9721/50000 (19.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 334.1972s / 158416.2314 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0382
env0_second_0:                 episode reward: -0.1500,                 loss: 0.1360
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 9741/50000 (19.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 330.3505s / 158746.5819 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0386
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1405
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 9761/50000 (19.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.5509s / 159078.1327 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0400
env0_second_0:                 episode reward: -0.4500,                 loss: 0.1434
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 9781/50000 (19.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.5388s / 159409.6715 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0387
env0_second_0:                 episode reward: 0.6500,                 loss: 0.1450
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 9801/50000 (19.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 330.9975s / 159740.6690 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0384
env0_second_0:                 episode reward: -0.6500,                 loss: 0.1445
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9821/50000 (19.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.9500s / 160072.6190 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0376
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1411
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9841/50000 (19.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 330.7998s / 160403.4187 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0389
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1419
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 9861/50000 (19.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 330.1562s / 160733.5749 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0381
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1406
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 9881/50000 (19.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.3846s / 161064.9595 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0384
env0_second_0:                 episode reward: -0.1500,                 loss: 0.1377
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 9901/50000 (19.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.9646s / 161397.9241 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0394
env0_second_0:                 episode reward: 0.9500,                 loss: 0.1331
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 9921/50000 (19.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.7971s / 161729.7212 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0386
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1394
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 9941/50000 (19.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.4676s / 162061.1888 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0369
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1350
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 9961/50000 (19.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 330.3596s / 162391.5484 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0383
env0_second_0:                 episode reward: 0.8000,                 loss: 0.1375
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 9981/50000 (19.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.0211s / 162722.5695 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0380
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1371
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 10001/50000 (20.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 334.2573s / 163056.8268 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0367
env0_second_0:                 episode reward: -0.2500,                 loss: 0.1356
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 10021/50000 (20.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 329.3838s / 163386.2106 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0364
env0_second_0:                 episode reward: -0.6000,                 loss: 0.1372
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 10041/50000 (20.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.8465s / 163718.0571 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0373
env0_second_0:                 episode reward: -0.1500,                 loss: 0.1373
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 10061/50000 (20.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 330.8360s / 164048.8931 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0376
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1351
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 10081/50000 (20.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.8253s / 164380.7184 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0387
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1437
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 10101/50000 (20.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.1847s / 164712.9031 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0393
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1435
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 10121/50000 (20.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.8648s / 165043.7679 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0388
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1431
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 10141/50000 (20.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 334.6283s / 165378.3962 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0380
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1384
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 10161/50000 (20.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 333.0882s / 165711.4844 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0393
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1370
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 10181/50000 (20.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.0897s / 166043.5741 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0399
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1396
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 10201/50000 (20.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.2154s / 166374.7895 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0389
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1344
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 10221/50000 (20.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1754s / 166707.9649 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0363
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1325
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 10241/50000 (20.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.8799s / 167039.8449 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0385
env0_second_0:                 episode reward: 0.8000,                 loss: 0.1298
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 10261/50000 (20.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.6845s / 167372.5294 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0384
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1289
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 10281/50000 (20.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.7975s / 167705.3269 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0385
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1262
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 10301/50000 (20.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2185s / 168038.5455 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0395
env0_second_0:                 episode reward: 1.2000,                 loss: 0.1226
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 10321/50000 (20.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2659s / 168371.8114 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0384
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1183
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 10341/50000 (20.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.3147s / 168705.1261 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0385
env0_second_0:                 episode reward: 0.8500,                 loss: 0.1159
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 10361/50000 (20.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.0619s / 169039.1880 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0384
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1161
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 10381/50000 (20.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.3735s / 169372.5615 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0396
env0_second_0:                 episode reward: 0.7000,                 loss: 0.1169
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 10401/50000 (20.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.9793s / 169705.5408 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0403
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1134
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 10421/50000 (20.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.2757s / 170037.8165 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0392
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1123
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 10441/50000 (20.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.5348s / 170371.3513 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0394
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1133
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 10461/50000 (20.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.4970s / 170703.8483 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0386
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1102
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 10481/50000 (20.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.9260s / 171036.7742 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0403
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1150
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 10501/50000 (21.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 334.8412s / 171371.6155 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0386
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1147
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 10521/50000 (21.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.1734s / 171703.7888 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0381
env0_second_0:                 episode reward: -0.7500,                 loss: 0.1106
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 10541/50000 (21.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 335.7325s / 172039.5213 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0371
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1098
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 10561/50000 (21.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 333.4185s / 172372.9398 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0374
env0_second_0:                 episode reward: 1.1000,                 loss: 0.1074
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 10581/50000 (21.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.3865s / 172705.3263 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0386
env0_second_0:                 episode reward: -0.8000,                 loss: 0.1093
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 10601/50000 (21.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1322s / 173038.4584 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0368
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1155
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 10621/50000 (21.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 334.6340s / 173373.0925 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0384
env0_second_0:                 episode reward: 1.1000,                 loss: 0.1114
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 10641/50000 (21.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.2868s / 173705.3793 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0393
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1096
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 10661/50000 (21.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.7121s / 174038.0913 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0392
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1102
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 10681/50000 (21.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.1713s / 174370.2627 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0385
env0_second_0:                 episode reward: -0.3000,                 loss: 0.1063
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 10701/50000 (21.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 330.7860s / 174701.0487 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0394
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1051
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 10721/50000 (21.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 335.6119s / 175036.6606 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0405
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1060
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 10741/50000 (21.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.7533s / 175368.4139 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0383
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1078
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 10761/50000 (21.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.1457s / 175702.5596 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0376
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1115
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 10781/50000 (21.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 334.7562s / 176037.3157 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0381
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1068
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 10801/50000 (21.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.0648s / 176370.3805 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0388
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1062
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 10821/50000 (21.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2033s / 176703.5838 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0391
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1052
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 10841/50000 (21.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.0060s / 177035.5898 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0390
env0_second_0:                 episode reward: 0.8500,                 loss: 0.1076
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 10861/50000 (21.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.8498s / 177367.4396 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0384
env0_second_0:                 episode reward: 0.7500,                 loss: 0.1068
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 10881/50000 (21.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.7296s / 177699.1692 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0378
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1045
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 10901/50000 (21.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1367s / 178032.3059 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0373
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1053
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 10921/50000 (21.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 337.0213s / 178369.3273 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0382
env0_second_0:                 episode reward: -0.1500,                 loss: 0.1062
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 10941/50000 (21.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 335.0150s / 178704.3423 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0400
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1029
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 10961/50000 (21.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.5295s / 179038.8718 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.0384
env0_second_0:                 episode reward: -0.7500,                 loss: 0.1097
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 10981/50000 (21.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 330.6706s / 179369.5424 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0382
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1088
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 11001/50000 (22.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 336.2169s / 179705.7593 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0383
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1091
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 11021/50000 (22.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.4718s / 180039.2311 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0379
env0_second_0:                 episode reward: 0.7000,                 loss: 0.1097
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 11041/50000 (22.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.2676s / 180370.4986 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0377
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1065
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 11061/50000 (22.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.9704s / 180705.4690 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0376
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1078
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 11081/50000 (22.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.5656s / 181039.0347 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0366
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1092
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 11101/50000 (22.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.6025s / 181372.6372 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0362
env0_second_0:                 episode reward: -0.3000,                 loss: 0.1082
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 11121/50000 (22.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1547s / 181705.7919 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0374
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1035
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 11141/50000 (22.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.5018s / 182039.2936 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0370
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1067
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 11161/50000 (22.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.6401s / 182371.9338 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0377
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1047
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 11181/50000 (22.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.0996s / 182704.0334 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0371
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1016
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 11201/50000 (22.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.0884s / 183037.1218 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0364
env0_second_0:                 episode reward: 0.7000,                 loss: 0.1022
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 11221/50000 (22.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.5628s / 183369.6847 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0371
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1007
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 11241/50000 (22.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 330.7794s / 183700.4640 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0384
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1043
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 11261/50000 (22.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.4278s / 184031.8919 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0374
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1023
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 11281/50000 (22.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.4660s / 184364.3579 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0381
env0_second_0:                 episode reward: 1.0500,                 loss: 0.1041
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 11301/50000 (22.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 330.6267s / 184694.9846 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0377
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1012
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 11321/50000 (22.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.8899s / 185027.8745 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0377
env0_second_0:                 episode reward: 0.8000,                 loss: 0.1009
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 11341/50000 (22.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.1469s / 185360.0214 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0381
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1011
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 11361/50000 (22.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.9102s / 185692.9316 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0362
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1050
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 11381/50000 (22.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.6072s / 186024.5388 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0370
env0_second_0:                 episode reward: 1.0000,                 loss: 0.1056
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 11401/50000 (22.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.9251s / 186357.4639 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0378
env0_second_0:                 episode reward: 0.7000,                 loss: 0.1057
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 11421/50000 (22.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.4639s / 186689.9278 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0368
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1040
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 11441/50000 (22.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.4731s / 187021.4009 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0376
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1050
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 11461/50000 (22.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.8756s / 187354.2765 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0365
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1069
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 11481/50000 (22.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.4952s / 187687.7717 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0382
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1059
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 11501/50000 (23.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2247s / 188020.9965 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0377
env0_second_0:                 episode reward: -0.1000,                 loss: 0.1050
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 11521/50000 (23.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.4675s / 188354.4640 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0374
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1057
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 11541/50000 (23.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.7865s / 188686.2505 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0363
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1059
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 11561/50000 (23.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.4700s / 189017.7205 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0375
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1038
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 11581/50000 (23.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 334.0364s / 189351.7569 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0369
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1008
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 11601/50000 (23.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.4187s / 189683.1756 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0359
env0_second_0:                 episode reward: 1.2000,                 loss: 0.1081
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 11621/50000 (23.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.8158s / 190015.9914 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0351
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1072
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 11641/50000 (23.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.2832s / 190347.2747 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0363
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1068
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 11661/50000 (23.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.3049s / 190681.5796 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0363
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1065
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 11681/50000 (23.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.9628s / 191013.5424 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0353
env0_second_0:                 episode reward: 1.2000,                 loss: 0.1065
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 11701/50000 (23.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.9031s / 191346.4455 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0356
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1067
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 11721/50000 (23.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.9751s / 191677.4205 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0347
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1035
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 11741/50000 (23.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.5942s / 192010.0147 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0354
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1008
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 11761/50000 (23.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.6952s / 192341.7099 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0359
env0_second_0:                 episode reward: 0.7500,                 loss: 0.1008
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 11781/50000 (23.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 330.5146s / 192672.2245 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0361
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1003
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 11801/50000 (23.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.3555s / 193004.5800 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0361
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0994
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 11821/50000 (23.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.9843s / 193336.5643 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0354
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1011
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 11841/50000 (23.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 335.5670s / 193672.1313 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0353
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0998
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 11861/50000 (23.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 329.8189s / 194001.9502 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0350
env0_second_0:                 episode reward: 0.7500,                 loss: 0.1029
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 11881/50000 (23.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2967s / 194335.2469 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0349
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1006
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 11901/50000 (23.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.8042s / 194668.0511 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0348
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1028
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 11921/50000 (23.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 334.6393s / 195002.6904 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0355
env0_second_0:                 episode reward: 0.9000,                 loss: 0.1007
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 11941/50000 (23.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.7434s / 195334.4338 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0355
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0998
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 11961/50000 (23.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.1485s / 195665.5823 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0352
env0_second_0:                 episode reward: -0.1500,                 loss: 0.1022
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 11981/50000 (23.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.6645s / 195998.2468 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0341
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1027
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 12001/50000 (24.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.3511s / 196330.5979 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0341
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1006
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 12021/50000 (24.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.8147s / 196663.4125 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0360
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1011
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 12041/50000 (24.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 334.4658s / 196997.8783 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0353
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1024
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 12061/50000 (24.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.4711s / 197332.3494 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0350
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1035
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 12081/50000 (24.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.3763s / 197665.7257 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0346
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1038
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 12101/50000 (24.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.6271s / 197999.3529 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0350
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1051
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 12121/50000 (24.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.9906s / 198332.3434 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0350
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1017
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 12141/50000 (24.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 334.3590s / 198666.7024 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0337
env0_second_0:                 episode reward: 0.8000,                 loss: 0.1010
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 12161/50000 (24.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.5382s / 198999.2406 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0345
env0_second_0:                 episode reward: 0.8000,                 loss: 0.1041
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 12181/50000 (24.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.5532s / 199330.7938 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0354
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1042
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 12201/50000 (24.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.1358s / 199662.9296 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0350
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1019
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 12221/50000 (24.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.1585s / 199995.0881 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0354
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0991
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 12241/50000 (24.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 336.8126s / 200331.9007 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0356
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0959
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 12261/50000 (24.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.8390s / 200663.7396 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0339
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0955
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 12281/50000 (24.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.7177s / 200996.4574 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0342
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0986
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 12301/50000 (24.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.9479s / 201329.4053 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0326
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0996
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 12321/50000 (24.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.8129s / 201660.2182 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0330
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0960
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 12341/50000 (24.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.8144s / 201993.0327 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0343
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0958
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 12361/50000 (24.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.6898s / 202324.7224 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0334
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0959
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 12381/50000 (24.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1022s / 202657.8246 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0343
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0993
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 12401/50000 (24.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.5726s / 202990.3973 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0344
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1016
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 12421/50000 (24.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1529s / 203323.5501 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0325
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1011
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 12441/50000 (24.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.8798s / 203655.4299 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0338
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1002
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 12461/50000 (24.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 330.4562s / 203985.8861 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0338
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1003
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 12481/50000 (24.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2273s / 204319.1134 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0336
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0991
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 12501/50000 (25.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.5726s / 204652.6860 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0347
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0964
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 12521/50000 (25.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 330.9771s / 204983.6631 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0353
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0993
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 12541/50000 (25.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2240s / 205316.8871 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0332
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1001
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 12561/50000 (25.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.0963s / 205650.9834 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0354
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1003
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 12581/50000 (25.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.3000s / 205983.2834 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0367
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0988
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 12601/50000 (25.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.0502s / 206314.3336 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0373
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1002
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 12621/50000 (25.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.1613s / 206645.4949 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0355
env0_second_0:                 episode reward: 0.9500,                 loss: 0.1029
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 12641/50000 (25.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 330.9832s / 206976.4780 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0364
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1006
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 12661/50000 (25.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 329.5008s / 207305.9789 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0352
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1047
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 12681/50000 (25.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.7480s / 207638.7268 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0358
env0_second_0:                 episode reward: -0.3000,                 loss: 0.1026
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 12701/50000 (25.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.4977s / 207971.2245 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0355
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1051
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 12721/50000 (25.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1190s / 208304.3436 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0353
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1045
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 12741/50000 (25.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.0541s / 208636.3977 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0344
env0_second_0:                 episode reward: 0.8000,                 loss: 0.1033
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 12761/50000 (25.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.6777s / 208969.0754 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0343
env0_second_0:                 episode reward: 0.8500,                 loss: 0.1033
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 12781/50000 (25.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 330.8096s / 209299.8850 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0336
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0990
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 12801/50000 (25.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.0419s / 209631.9268 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0338
env0_second_0:                 episode reward: -0.3000,                 loss: 0.1026
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 12821/50000 (25.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.3652s / 209965.2920 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0350
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0988
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 12841/50000 (25.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.5811s / 210298.8731 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0345
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1019
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 12861/50000 (25.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.3132s / 210633.1863 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0333
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0999
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 12881/50000 (25.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.7982s / 210965.9845 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0338
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0998
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 12901/50000 (25.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.5008s / 211299.4853 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0340
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1003
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 12921/50000 (25.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.3306s / 211630.8159 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0333
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1002
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 12941/50000 (25.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.5773s / 211963.3932 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0345
env0_second_0:                 episode reward: 0.7500,                 loss: 0.1035
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 12961/50000 (25.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 333.6893s / 212297.0825 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0337
env0_second_0:                 episode reward: 0.7500,                 loss: 0.1004
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 12981/50000 (25.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 334.7428s / 212631.8253 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0333
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1024
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 13001/50000 (26.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.3900s / 212963.2153 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0337
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1045
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 13021/50000 (26.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.4157s / 213295.6309 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0344
env0_second_0:                 episode reward: 0.8500,                 loss: 0.1051
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 13041/50000 (26.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2447s / 213628.8756 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0353
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1030
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 13061/50000 (26.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2752s / 213962.1508 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0352
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1008
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 13081/50000 (26.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.9394s / 214295.0903 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0346
env0_second_0:                 episode reward: 0.7500,                 loss: 0.1020
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 13101/50000 (26.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.8840s / 214627.9742 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0349
env0_second_0:                 episode reward: 0.8000,                 loss: 0.1060
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 13121/50000 (26.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 348.3195s / 214976.2937 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0353
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1067
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13141/50000 (26.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 335.0404s / 215311.3342 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0343
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1095
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 13161/50000 (26.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.8655s / 215646.1996 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0345
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1090
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 13181/50000 (26.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.3967s / 215979.5963 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0331
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1089
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 13201/50000 (26.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 341.6479s / 216321.2442 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0350
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1078
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 13221/50000 (26.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 350.6019s / 216671.8460 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0336
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1078
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 13241/50000 (26.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.6351s / 217003.4811 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0342
env0_second_0:                 episode reward: 0.8500,                 loss: 0.1083
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 13261/50000 (26.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.8764s / 217336.3575 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0367
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1031
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 13281/50000 (26.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.0019s / 217668.3594 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0376
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1054
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 13301/50000 (26.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 330.8549s / 217999.2143 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0387
env0_second_0:                 episode reward: 0.7000,                 loss: 0.1058
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 13321/50000 (26.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 335.1073s / 218334.3216 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0364
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1035
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 13341/50000 (26.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.2406s / 218666.5622 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0355
env0_second_0:                 episode reward: 1.4000,                 loss: 0.1035
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 13361/50000 (26.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.8335s / 218998.3957 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0355
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0995
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 13381/50000 (26.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.6419s / 219331.0376 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0351
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0987
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 13401/50000 (26.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.7174s / 219663.7550 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0364
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0963
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 13421/50000 (26.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.4250s / 219996.1800 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0364
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0950
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 13441/50000 (26.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.5600s / 220328.7400 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0352
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0992
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 13461/50000 (26.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 329.1593s / 220657.8993 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0356
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0977
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 13481/50000 (26.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 329.5529s / 220987.4523 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0355
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0989
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 13501/50000 (27.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 335.7203s / 221323.1726 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0356
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1032
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 13521/50000 (27.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 334.8899s / 221658.0625 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0344
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0999
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 13541/50000 (27.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.4470s / 221991.5095 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0358
env0_second_0:                 episode reward: 0.8000,                 loss: 0.1010
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 13561/50000 (27.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.7890s / 222324.2985 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0346
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1011
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 13581/50000 (27.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.5371s / 222655.8356 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0340
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1027
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 13601/50000 (27.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 330.9809s / 222986.8165 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0343
env0_second_0:                 episode reward: 0.8500,                 loss: 0.1037
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 13621/50000 (27.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.4427s / 223320.2592 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0340
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1026
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 13641/50000 (27.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2308s / 223653.4901 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0332
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1014
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 13661/50000 (27.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 333.7472s / 223987.2373 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0337
env0_second_0:                 episode reward: 0.9000,                 loss: 0.1035
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 13681/50000 (27.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.6604s / 224318.8977 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0347
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1063
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 13701/50000 (27.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.3887s / 224651.2864 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0345
env0_second_0:                 episode reward: 0.7500,                 loss: 0.1086
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 13721/50000 (27.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1997s / 224984.4861 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0333
env0_second_0:                 episode reward: 0.9500,                 loss: 0.1089
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 13741/50000 (27.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.7937s / 225317.2798 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0330
env0_second_0:                 episode reward: 1.0000,                 loss: 0.1072
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 13761/50000 (27.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 330.3965s / 225647.6763 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0338
env0_second_0:                 episode reward: 1.0000,                 loss: 0.1050
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 13781/50000 (27.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1367s / 225980.8129 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0338
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1056
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 13801/50000 (27.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 334.1486s / 226314.9615 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0333
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1020
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 13821/50000 (27.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.7679s / 226647.7295 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0332
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1046
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 13841/50000 (27.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 336.2398s / 226983.9693 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0329
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1033
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 13861/50000 (27.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.2311s / 227315.2004 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0336
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1046
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 13881/50000 (27.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.4935s / 227647.6939 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0323
env0_second_0:                 episode reward: 0.7000,                 loss: 0.1039
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 13901/50000 (27.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.7361s / 227980.4300 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0328
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1028
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 13921/50000 (27.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.8181s / 228314.2481 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0326
env0_second_0:                 episode reward: 0.8500,                 loss: 0.1005
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 13941/50000 (27.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.0608s / 228647.3089 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0327
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0969
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 13961/50000 (27.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 333.8157s / 228981.1245 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0325
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0988
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 13981/50000 (27.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.9936s / 229315.1182 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0334
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1003
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 14001/50000 (28.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 330.4890s / 229645.6072 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0331
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0974
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 14021/50000 (28.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.7077s / 229979.3149 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0329
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1018
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 14041/50000 (28.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 335.8790s / 230315.1939 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0335
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1044
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 14061/50000 (28.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 333.6454s / 230648.8393 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0337
env0_second_0:                 episode reward: 0.9000,                 loss: 0.1059
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 14081/50000 (28.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 334.8963s / 230983.7355 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0334
env0_second_0:                 episode reward: 1.4000,                 loss: 0.1003
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 14101/50000 (28.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.6077s / 231317.3432 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0332
env0_second_0:                 episode reward: 0.6500,                 loss: 0.1010
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 14121/50000 (28.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.9990s / 231650.3422 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0337
env0_second_0:                 episode reward: 0.8500,                 loss: 0.1034
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 14141/50000 (28.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 335.3163s / 231985.6585 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0335
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1035
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 14161/50000 (28.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.1705s / 232317.8290 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0341
env0_second_0:                 episode reward: 1.5500,                 loss: 0.1049
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 14181/50000 (28.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 330.6878s / 232648.5168 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0344
env0_second_0:                 episode reward: 0.9000,                 loss: 0.1046
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 14201/50000 (28.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1310s / 232981.6478 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0333
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1029
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 14221/50000 (28.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2671s / 233314.9149 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0336
env0_second_0:                 episode reward: 1.1000,                 loss: 0.1015
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 14241/50000 (28.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.3476s / 233647.2625 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0337
env0_second_0:                 episode reward: 0.7500,                 loss: 0.1019
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 14261/50000 (28.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.9128s / 233980.1752 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0332
env0_second_0:                 episode reward: 1.1000,                 loss: 0.1026
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 14281/50000 (28.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 334.0086s / 234314.1838 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0344
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1049
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 14301/50000 (28.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.5650s / 234647.7488 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0341
env0_second_0:                 episode reward: 0.8500,                 loss: 0.1038
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 14321/50000 (28.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 334.6875s / 234982.4363 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0344
env0_second_0:                 episode reward: 0.7000,                 loss: 0.1081
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 14341/50000 (28.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.9972s / 235316.4335 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0337
env0_second_0:                 episode reward: 0.7500,                 loss: 0.1077
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 14361/50000 (28.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.6191s / 235649.0526 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0331
env0_second_0:                 episode reward: 0.9500,                 loss: 0.1087
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 14381/50000 (28.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 334.4050s / 235983.4576 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0348
env0_second_0:                 episode reward: 1.0000,                 loss: 0.1051
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 14401/50000 (28.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.8210s / 236317.2786 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0338
env0_second_0:                 episode reward: 0.9500,                 loss: 0.1048
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 14421/50000 (28.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.6875s / 236650.9661 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0343
env0_second_0:                 episode reward: 0.7500,                 loss: 0.1046
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 14441/50000 (28.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.0816s / 236983.0477 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0335
env0_second_0:                 episode reward: 0.6500,                 loss: 0.1028
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 14461/50000 (28.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.6349s / 237315.6825 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0328
env0_second_0:                 episode reward: 0.9000,                 loss: 0.1042
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 14481/50000 (28.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.3261s / 237648.0086 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0342
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1001
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 14501/50000 (29.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.4446s / 237980.4532 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0337
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0961
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 14521/50000 (29.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.7163s / 238312.1695 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0341
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0924
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 14541/50000 (29.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.7708s / 238645.9403 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0337
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0970
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 14561/50000 (29.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.2946s / 238980.2349 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0344
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0996
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 14581/50000 (29.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 334.7257s / 239314.9606 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0347
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1012
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 14601/50000 (29.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.5679s / 239647.5285 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0341
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0988
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 14621/50000 (29.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 334.3025s / 239981.8311 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0335
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0965
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 14641/50000 (29.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.5392s / 240315.3703 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0339
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0979
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 14661/50000 (29.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.2299s / 240649.6002 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0341
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0983
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 14681/50000 (29.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.6411s / 240982.2413 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0329
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0976
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 14701/50000 (29.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.5400s / 241314.7813 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0331
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0973
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 14721/50000 (29.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.5078s / 241647.2891 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0333
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0964
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 14741/50000 (29.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.8623s / 241981.1513 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0331
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0993
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 14761/50000 (29.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.1145s / 242315.2658 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0334
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0969
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 14781/50000 (29.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 334.7549s / 242650.0207 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0332
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0943
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 14801/50000 (29.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.8256s / 242982.8463 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0331
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0937
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 14821/50000 (29.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.2670s / 243315.1134 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0332
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0973
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 14841/50000 (29.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 334.3603s / 243649.4736 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0335
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0942
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 14861/50000 (29.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.0068s / 243981.4805 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0331
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0928
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 14881/50000 (29.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 334.1154s / 244315.5959 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0326
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0919
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 14901/50000 (29.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.6005s / 244648.1963 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0331
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0908
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 14921/50000 (29.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 334.0242s / 244982.2206 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0336
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0928
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 14941/50000 (29.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.8465s / 245315.0670 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0333
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0985
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 14961/50000 (29.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 333.9943s / 245649.0613 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0332
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0969
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 14981/50000 (29.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.8560s / 245982.9173 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0339
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0949
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 15001/50000 (30.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.0625s / 246314.9798 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0341
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0926
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 15021/50000 (30.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 329.8989s / 246644.8787 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0342
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0933
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 15041/50000 (30.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2870s / 246978.1656 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0348
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1005
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 15061/50000 (30.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 337.1679s / 247315.3336 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0366
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0984
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 15081/50000 (30.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.5360s / 247646.8696 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0354
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0926
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 15101/50000 (30.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.4218s / 247980.2913 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0350
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0918
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 15121/50000 (30.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.4425s / 248313.7338 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0348
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0923
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 15141/50000 (30.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.3377s / 248646.0715 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0342
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0931
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 15161/50000 (30.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.7274s / 248978.7989 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0353
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0938
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 15181/50000 (30.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.0317s / 249311.8306 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0351
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0973
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 15201/50000 (30.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.5409s / 249645.3715 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0334
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0960
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 15221/50000 (30.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.1723s / 249976.5438 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0337
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0988
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 15241/50000 (30.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.5842s / 250309.1281 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0324
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0986
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 15261/50000 (30.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 333.9405s / 250643.0686 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0318
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0984
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 15281/50000 (30.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 336.3050s / 250979.3736 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0331
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0958
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 15301/50000 (30.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.2342s / 251311.6078 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0338
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0953
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 15321/50000 (30.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.0364s / 251644.6443 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0330
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0977
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 15341/50000 (30.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.7145s / 251977.3588 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0332
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0994
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 15361/50000 (30.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.9782s / 252310.3369 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0317
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0957
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 15381/50000 (30.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.3084s / 252642.6453 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0334
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0989
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 15401/50000 (30.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2607s / 252975.9059 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0338
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0985
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 15421/50000 (30.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 334.5698s / 253310.4757 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0337
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0987
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 15441/50000 (30.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 334.3059s / 253644.7816 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0342
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1003
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 15461/50000 (30.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 342.6190s / 253987.4006 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0338
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1026
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 15481/50000 (30.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 335.9401s / 254323.3407 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0341
env0_second_0:                 episode reward: 0.9500,                 loss: 0.1019
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 15501/50000 (31.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 334.6185s / 254657.9592 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0342
env0_second_0:                 episode reward: 1.3500,                 loss: 0.1047
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 15521/50000 (31.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.3068s / 254989.2660 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0332
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1052
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 15541/50000 (31.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.6130s / 255321.8789 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0331
env0_second_0:                 episode reward: 0.6500,                 loss: 0.1073
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 15561/50000 (31.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.9162s / 255654.7951 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0330
env0_second_0:                 episode reward: 0.7500,                 loss: 0.1073
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 15581/50000 (31.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.3521s / 255988.1472 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0326
env0_second_0:                 episode reward: 0.8500,                 loss: 0.1059
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 15601/50000 (31.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.2531s / 256320.4003 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0324
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1080
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 15621/50000 (31.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.1218s / 256652.5221 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0329
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1054
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 15641/50000 (31.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.6248s / 256986.1469 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0329
env0_second_0:                 episode reward: 0.6500,                 loss: 0.1081
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 15661/50000 (31.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 333.4105s / 257319.5574 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0332
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1105
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 15681/50000 (31.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.4370s / 257651.9944 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0331
env0_second_0:                 episode reward: 1.4000,                 loss: 0.1101
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 15701/50000 (31.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.7572s / 257983.7516 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0319
env0_second_0:                 episode reward: 0.6000,                 loss: 0.1089
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 15721/50000 (31.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.0935s / 258316.8451 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0326
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1094
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 15741/50000 (31.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.3191s / 258650.1642 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0327
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1161
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 15761/50000 (31.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.6336s / 258984.7978 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0330
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1187
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 15781/50000 (31.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.0749s / 259316.8726 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0328
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1194
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 15801/50000 (31.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 330.8228s / 259647.6954 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0322
env0_second_0:                 episode reward: 0.7500,                 loss: 0.1227
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 15821/50000 (31.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.1196s / 259978.8150 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0328
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1207
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 15841/50000 (31.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.0923s / 260310.9074 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0331
env0_second_0:                 episode reward: 0.7000,                 loss: 0.1297
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 15861/50000 (31.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.1611s / 260643.0685 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0325
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1318
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 15881/50000 (31.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2576s / 260976.3261 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0319
env0_second_0:                 episode reward: 0.8500,                 loss: 0.1385
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 15901/50000 (31.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.0712s / 261307.3972 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0322
env0_second_0:                 episode reward: 0.4500,                 loss: 0.1381
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 15921/50000 (31.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.9634s / 261639.3606 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0338
env0_second_0:                 episode reward: 0.7500,                 loss: 0.1352
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 15941/50000 (31.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 334.5218s / 261973.8824 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0328
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1391
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 15961/50000 (31.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.6617s / 262306.5441 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0332
env0_second_0:                 episode reward: 1.3000,                 loss: 0.1395
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 15981/50000 (31.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.0879s / 262637.6320 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0327
env0_second_0:                 episode reward: 1.0500,                 loss: 0.1348
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 16001/50000 (32.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 330.1546s / 262967.7866 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0322
env0_second_0:                 episode reward: 0.3500,                 loss: 0.1363
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 16021/50000 (32.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.7781s / 263299.5647 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0332
env0_second_0:                 episode reward: 1.3000,                 loss: 0.1275
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 16041/50000 (32.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 334.9413s / 263634.5061 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0335
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1239
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 16061/50000 (32.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 335.7057s / 263970.2118 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0335
env0_second_0:                 episode reward: 1.1500,                 loss: 0.1206
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 16081/50000 (32.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 334.0397s / 264304.2515 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0344
env0_second_0:                 episode reward: 0.8500,                 loss: 0.1177
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 16101/50000 (32.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1023s / 264637.3538 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0336
env0_second_0:                 episode reward: 0.2000,                 loss: 0.1141
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 16121/50000 (32.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.1980s / 264968.5518 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0330
env0_second_0:                 episode reward: 0.9000,                 loss: 0.1155
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 16141/50000 (32.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.6971s / 265301.2489 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0334
env0_second_0:                 episode reward: 1.2500,                 loss: 0.1151
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 16161/50000 (32.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 333.6106s / 265634.8595 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0333
env0_second_0:                 episode reward: 1.4000,                 loss: 0.1143
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 16181/50000 (32.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1167s / 265967.9762 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0316
env0_second_0:                 episode reward: -0.1500,                 loss: 0.1109
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 16201/50000 (32.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2421s / 266301.2183 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0320
env0_second_0:                 episode reward: 0.8500,                 loss: 0.1102
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 16221/50000 (32.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 334.8680s / 266636.0863 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0325
env0_second_0:                 episode reward: 0.9000,                 loss: 0.1086
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 16241/50000 (32.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2550s / 266969.3413 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0324
env0_second_0:                 episode reward: 0.1000,                 loss: 0.1114
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 16261/50000 (32.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 333.4936s / 267302.8349 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0338
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1115
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 16281/50000 (32.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 334.2735s / 267637.1085 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0331
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1116
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 16301/50000 (32.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.9503s / 267969.0588 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0329
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1088
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 16321/50000 (32.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.1678s / 268301.2266 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0326
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1120
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 16341/50000 (32.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.7753s / 268635.0019 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0329
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1136
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 16361/50000 (32.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.7616s / 268967.7635 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0331
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1148
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 16381/50000 (32.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.0385s / 269298.8020 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0335
env0_second_0:                 episode reward: 1.3000,                 loss: 0.1091
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 16401/50000 (32.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 335.0819s / 269633.8840 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0327
env0_second_0:                 episode reward: 0.8000,                 loss: 0.1120
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 16421/50000 (32.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.7043s / 269966.5883 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0330
env0_second_0:                 episode reward: 1.1500,                 loss: 0.1101
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 16441/50000 (32.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 334.0414s / 270300.6297 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0328
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1089
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 16461/50000 (32.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.9659s / 270632.5956 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0321
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1066
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 16481/50000 (32.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.5563s / 270964.1520 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0325
env0_second_0:                 episode reward: 0.5500,                 loss: 0.1112
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 16501/50000 (33.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.2117s / 271295.3636 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0319
env0_second_0:                 episode reward: 1.3500,                 loss: 0.1058
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 16521/50000 (33.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 334.1792s / 271629.5428 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0313
env0_second_0:                 episode reward: 0.3000,                 loss: 0.1071
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 16541/50000 (33.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 334.5655s / 271964.1083 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0319
env0_second_0:                 episode reward: 0.7500,                 loss: 0.1059
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 16561/50000 (33.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.4874s / 272296.5957 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0316
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1049
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 16581/50000 (33.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.0724s / 272628.6680 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0314
env0_second_0:                 episode reward: 0.0500,                 loss: 0.1031
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 16601/50000 (33.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 334.3096s / 272962.9776 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0322
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1028
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 16621/50000 (33.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 336.3532s / 273299.3308 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0324
env0_second_0:                 episode reward: 1.4000,                 loss: 0.1030
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 16641/50000 (33.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 359.0438s / 273658.3746 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0310
env0_second_0:                 episode reward: 1.2500,                 loss: 0.1034
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 16661/50000 (33.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.0131s / 273992.3877 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0316
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1075
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 16681/50000 (33.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.7505s / 274326.1382 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0326
env0_second_0:                 episode reward: 0.7500,                 loss: 0.1057
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 16701/50000 (33.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.5134s / 274657.6516 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0316
env0_second_0:                 episode reward: 1.0500,                 loss: 0.1031
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 16721/50000 (33.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.4438s / 274991.0954 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0314
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1049
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 16741/50000 (33.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.8119s / 275324.9074 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0321
env0_second_0:                 episode reward: 0.6500,                 loss: 0.1061
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 16761/50000 (33.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.9933s / 275659.9007 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0322
env0_second_0:                 episode reward: 0.8000,                 loss: 0.1080
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 16781/50000 (33.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.3445s / 275992.2451 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0325
env0_second_0:                 episode reward: 0.8500,                 loss: 0.1054
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 16801/50000 (33.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2691s / 276325.5142 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0317
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1018
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 16821/50000 (33.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 334.6585s / 276660.1727 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0317
env0_second_0:                 episode reward: 0.9500,                 loss: 0.1028
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 16841/50000 (33.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 334.7515s / 276994.9243 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0323
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1047
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 16861/50000 (33.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.0348s / 277325.9591 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0311
env0_second_0:                 episode reward: 1.2500,                 loss: 0.1014
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 16881/50000 (33.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 335.5782s / 277661.5373 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0322
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1010
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 16901/50000 (33.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.5077s / 277995.0450 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0320
env0_second_0:                 episode reward: 1.6000,                 loss: 0.1017
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 16921/50000 (33.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 336.0335s / 278331.0785 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0318
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1018
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 16941/50000 (33.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.8775s / 278664.9559 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0316
env0_second_0:                 episode reward: 1.2500,                 loss: 0.1009
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 16961/50000 (33.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 336.9537s / 279001.9096 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0311
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0950
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 16981/50000 (33.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 335.1914s / 279337.1010 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0310
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0932
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 17001/50000 (34.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 334.3607s / 279671.4617 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0320
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0939
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 17021/50000 (34.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 335.0124s / 280006.4740 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0307
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0943
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 17041/50000 (34.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.5199s / 280339.9939 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0313
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0921
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 17061/50000 (34.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 336.7993s / 280676.7932 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0311
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0908
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 17081/50000 (34.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1426s / 281009.9358 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0309
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0909
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 17101/50000 (34.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1292s / 281343.0650 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0308
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0905
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 17121/50000 (34.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 334.4613s / 281677.5262 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0301
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0908
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 17141/50000 (34.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 334.5959s / 282012.1221 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0312
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0895
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 17161/50000 (34.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 337.0565s / 282349.1786 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0307
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0895
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 17181/50000 (34.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 337.8207s / 282686.9992 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0310
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0917
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 17201/50000 (34.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 334.5400s / 283021.5393 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0309
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0935
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 17221/50000 (34.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.1095s / 283353.6487 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0306
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0945
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 17241/50000 (34.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 336.0097s / 283689.6584 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0292
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0956
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 17261/50000 (34.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.3827s / 284024.0411 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0304
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0942
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 17281/50000 (34.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.8971s / 284356.9381 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0308
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0931
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 17301/50000 (34.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 336.5357s / 284693.4738 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0306
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0938
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 17321/50000 (34.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 335.1890s / 285028.6629 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0305
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0933
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 17341/50000 (34.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 334.3348s / 285362.9977 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0302
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0915
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 17361/50000 (34.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.2460s / 285695.2436 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0308
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0932
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 17381/50000 (34.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2288s / 286028.4724 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0304
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0915
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 17401/50000 (34.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.4116s / 286361.8841 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0297
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0920
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 17421/50000 (34.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 338.1864s / 286700.0705 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0299
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0910
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 17441/50000 (34.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 334.9503s / 287035.0208 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0302
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0934
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 17461/50000 (34.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.0444s / 287369.0652 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0297
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0924
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 17481/50000 (34.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 335.1355s / 287704.2007 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0297
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0900
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 17501/50000 (35.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.5244s / 288036.7250 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0297
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0935
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 17521/50000 (35.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.7589s / 288370.4839 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0299
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0929
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 17541/50000 (35.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2255s / 288703.7094 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0298
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0913
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 17561/50000 (35.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 333.7419s / 289037.4513 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0301
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0917
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 17581/50000 (35.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.8682s / 289371.3195 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0293
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0911
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 17601/50000 (35.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 330.8352s / 289702.1547 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0294
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0911
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 17621/50000 (35.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.9877s / 290034.1423 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0301
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0938
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 17641/50000 (35.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1330s / 290367.2754 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0310
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0925
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 17661/50000 (35.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.0092s / 290701.2846 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0316
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0914
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 17681/50000 (35.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.9101s / 291035.1946 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0323
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0901
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 17701/50000 (35.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 330.8512s / 291366.0458 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0315
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0921
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 17721/50000 (35.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.7540s / 291699.7998 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0311
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0946
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 17741/50000 (35.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 334.6444s / 292034.4442 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0309
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0915
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 17761/50000 (35.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 335.1349s / 292369.5792 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0310
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0936
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 17781/50000 (35.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 334.0909s / 292703.6700 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0326
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0949
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 17801/50000 (35.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 334.6873s / 293038.3573 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0318
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0919
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 17821/50000 (35.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 346.1882s / 293384.5455 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0324
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0896
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 17841/50000 (35.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.7121s / 293716.2576 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0316
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0896
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 17861/50000 (35.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 331.6778s / 294047.9354 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0314
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0896
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 17881/50000 (35.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.4301s / 294379.3655 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0304
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0861
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 17901/50000 (35.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.5291s / 294711.8946 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0307
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0880
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 17921/50000 (35.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 335.6187s / 295047.5133 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0297
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0848
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 17941/50000 (35.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.0297s / 295379.5430 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0311
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0860
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 17961/50000 (35.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2959s / 295712.8390 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0312
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0881
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 17981/50000 (35.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1666s / 296046.0056 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0309
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0872
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 18001/50000 (36.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.9661s / 296379.9717 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0300
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0887
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 18021/50000 (36.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.4461s / 296713.4178 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0303
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0863
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 18041/50000 (36.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 335.6822s / 297049.1000 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0298
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0889
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 18061/50000 (36.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1216s / 297382.2216 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0307
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0909
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 18081/50000 (36.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 330.9218s / 297713.1434 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0309
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0905
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 18101/50000 (36.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.0347s / 298044.1782 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0310
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0875
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 18121/50000 (36.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.6510s / 298375.8292 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0311
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0844
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 18141/50000 (36.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 334.2138s / 298710.0430 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0315
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0882
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 18161/50000 (36.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 334.0249s / 299044.0679 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0305
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0873
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 18181/50000 (36.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.9830s / 299377.0509 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0298
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0879
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 18201/50000 (36.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 334.1825s / 299711.2335 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0302
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0872
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 18221/50000 (36.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.7529s / 300044.9864 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0296
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0877
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 18241/50000 (36.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 334.1043s / 300379.0907 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0308
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0850
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 18261/50000 (36.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 333.6585s / 300712.7491 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0299
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0864
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 18281/50000 (36.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 334.5895s / 301047.3387 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0308
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0878
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 18301/50000 (36.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.7176s / 301381.0563 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0307
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0892
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 18321/50000 (36.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.7029s / 301712.7592 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0294
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0907
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 18341/50000 (36.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 332.5392s / 302045.2984 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0300
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0936
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 18361/50000 (36.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.4996s / 302377.7980 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0295
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0914
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 18381/50000 (36.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.0122s / 302709.8101 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0309
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0958
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 18401/50000 (36.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 334.3416s / 303044.1517 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0305
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0922
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 18421/50000 (36.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 334.9093s / 303379.0610 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0313
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0922
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 18441/50000 (36.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.4759s / 303712.5369 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0318
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0933
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 18461/50000 (36.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.9612s / 304045.4981 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0312
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0915
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 18481/50000 (36.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.7148s / 304378.2129 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0318
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0912
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 18501/50000 (37.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.0588s / 304711.2717 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0301
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0929
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 18521/50000 (37.0420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.2872s / 305044.5588 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0290
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0913
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 18541/50000 (37.0820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.5605s / 305378.1194 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0299
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0914
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 18561/50000 (37.1220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.0390s / 305710.1584 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0305
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0898
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 18581/50000 (37.1620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.8738s / 306043.0321 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0315
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0895
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 18601/50000 (37.2020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.8540s / 306375.8861 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0326
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0892
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 18621/50000 (37.2420%),                 avg. length: 299.0,                last time consumption/overall running time: 331.8926s / 306707.7787 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0308
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0884
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 18641/50000 (37.2820%),                 avg. length: 299.0,                last time consumption/overall running time: 333.8796s / 307041.6583 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0307
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0832
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 18661/50000 (37.3220%),                 avg. length: 299.0,                last time consumption/overall running time: 335.3038s / 307376.9621 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0314
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0859
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 18681/50000 (37.3620%),                 avg. length: 299.0,                last time consumption/overall running time: 334.9047s / 307711.8668 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0319
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0892
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 18701/50000 (37.4020%),                 avg. length: 299.0,                last time consumption/overall running time: 332.3695s / 308044.2363 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0304
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0874
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 18721/50000 (37.4420%),                 avg. length: 299.0,                last time consumption/overall running time: 332.5072s / 308376.7434 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0304
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0858
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 18741/50000 (37.4820%),                 avg. length: 299.0,                last time consumption/overall running time: 331.9555s / 308708.6989 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0301
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0842
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 18761/50000 (37.5220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.6361s / 309041.3350 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0311
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0848
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 18781/50000 (37.5620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.3218s / 309373.6568 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0314
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0852
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 18801/50000 (37.6020%),                 avg. length: 299.0,                last time consumption/overall running time: 333.1421s / 309706.7989 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0312
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0876
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 18821/50000 (37.6420%),                 avg. length: 299.0,                last time consumption/overall running time: 334.4601s / 310041.2589 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0309
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0884
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 18841/50000 (37.6820%),                 avg. length: 299.0,                last time consumption/overall running time: 335.5916s / 310376.8505 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0308
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0842
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 18861/50000 (37.7220%),                 avg. length: 299.0,                last time consumption/overall running time: 332.8781s / 310709.7286 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0312
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0862
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 18881/50000 (37.7620%),                 avg. length: 299.0,                last time consumption/overall running time: 332.9000s / 311042.6286 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0323
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0870
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 18901/50000 (37.8020%),                 avg. length: 299.0,                last time consumption/overall running time: 334.6544s / 311377.2831 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0315
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0874
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 18921/50000 (37.8420%),                 avg. length: 299.0,                last time consumption/overall running time: 333.4572s / 311710.7403 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0302
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0872
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 18941/50000 (37.8820%),                 avg. length: 299.0,                last time consumption/overall running time: 334.5343s / 312045.2746 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0296
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0866
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 18961/50000 (37.9220%),                 avg. length: 299.0,                last time consumption/overall running time: 343.2098s / 312388.4845 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0312
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0877
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 18981/50000 (37.9620%),                 avg. length: 299.0,                last time consumption/overall running time: 331.3629s / 312719.8473 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0317
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0915
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 19001/50000 (38.0020%),                 avg. length: 299.0,                last time consumption/overall running time: 331.0128s / 313050.8601 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0319
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0920
env1_first_0:                 episode reward: -0.2500,                 loss: nan