pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
SlimeVolley-v0 slimevolley
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'SlimeVolley-v0', 'env_type': 'slimevolley', 'num_envs': 2, 'ram': True, 'seed': 'random', 'against_baseline': False, 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'batch_size': 32, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220119_0524/slimevolley_SlimeVolley-v0_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220119_0524/slimevolley_SlimeVolley-v0_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 753.0,                last time consumption/overall running time: 8.1355s / 8.1355 s
env0_first_0:                 episode reward: 1.0000,                 loss: -0.0181
env0_second_0:                 episode reward: -1.0000,                 loss: -0.0333
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 575.05,                last time consumption/overall running time: 111.2156s / 119.3511 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0180
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0280
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 614.25,                last time consumption/overall running time: 167.4682s / 286.8193 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.1521
env0_second_0:                 episode reward: 0.2500,                 loss: 0.1568
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 560.45,                last time consumption/overall running time: 169.4041s / 456.2235 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.1944
env0_second_0:                 episode reward: -0.9500,                 loss: 0.1830
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 594.55,                last time consumption/overall running time: 178.4442s / 634.6677 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2200
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2038
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 598.85,                last time consumption/overall running time: 177.4753s / 812.1430 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.2054
env0_second_0:                 episode reward: -1.2000,                 loss: 0.1800
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 586.05,                last time consumption/overall running time: 174.1263s / 986.2693 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.1807
env0_second_0:                 episode reward: -1.4000,                 loss: 0.1694
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 523.4,                last time consumption/overall running time: 159.6470s / 1145.9163 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.1826
env0_second_0:                 episode reward: -1.0500,                 loss: 0.1779
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 571.15,                last time consumption/overall running time: 171.3120s / 1317.2283 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.1958
env0_second_0:                 episode reward: 0.1500,                 loss: 0.1748
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 588.9,                last time consumption/overall running time: 175.4560s / 1492.6843 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.1994
env0_second_0:                 episode reward: 0.5000,                 loss: 0.1883
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 602.55,                last time consumption/overall running time: 179.1984s / 1671.8827 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.1927
env0_second_0:                 episode reward: 0.4000,                 loss: 0.1790
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 575.05,                last time consumption/overall running time: 172.7775s / 1844.6602 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.2081
env0_second_0:                 episode reward: -1.3000,                 loss: 0.2072
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 582.7,                last time consumption/overall running time: 173.3478s / 2018.0079 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2378
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2324
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 571.5,                last time consumption/overall running time: 171.6531s / 2189.6611 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2141
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2076
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 591.4,                last time consumption/overall running time: 176.5968s / 2366.2578 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2166
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2060
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 571.05,                last time consumption/overall running time: 171.2681s / 2537.5260 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2359
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2377
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 583.25,                last time consumption/overall running time: 174.9912s / 2712.5171 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2609
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2469
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 597.35,                last time consumption/overall running time: 176.6241s / 2889.1413 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2490
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2487
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 523.55,                last time consumption/overall running time: 159.1624s / 3048.3036 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2508
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2479
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 603.0,                last time consumption/overall running time: 180.3535s / 3228.6572 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2589
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2471
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 572.3,                last time consumption/overall running time: 171.3302s / 3399.9874 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2504
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2525
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 581.2,                last time consumption/overall running time: 175.0345s / 3575.0219 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.2553
env0_second_0:                 episode reward: -0.8000,                 loss: 0.2419
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 584.05,                last time consumption/overall running time: 174.9144s / 3749.9363 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2762
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2825
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 578.3,                last time consumption/overall running time: 172.8563s / 3922.7926 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2697
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2690
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 529.55,                last time consumption/overall running time: 159.2061s / 4081.9986 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2651
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2644
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 538.05,                last time consumption/overall running time: 163.5067s / 4245.5053 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2811
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2725
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 584.3,                last time consumption/overall running time: 177.2393s / 4422.7446 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2691
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2690
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 563.1,                last time consumption/overall running time: 168.5576s / 4591.3022 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2463
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2401
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 577.35,                last time consumption/overall running time: 173.1478s / 4764.4501 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2562
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2524
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 558.85,                last time consumption/overall running time: 169.1349s / 4933.5850 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2395
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2375
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 499.3,                last time consumption/overall running time: 151.5658s / 5085.1508 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2297
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2322
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 587.7,                last time consumption/overall running time: 175.1702s / 5260.3210 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.2817
env0_second_0:                 episode reward: -1.2000,                 loss: 0.2716
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 553.9,                last time consumption/overall running time: 166.6572s / 5426.9782 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2467
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2302
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 583.25,                last time consumption/overall running time: 174.3990s / 5601.3772 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2392
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2316
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 540.95,                last time consumption/overall running time: 163.4883s / 5764.8655 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2187
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2193
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 545.75,                last time consumption/overall running time: 164.5114s / 5929.3769 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2615
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2513
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 559.9,                last time consumption/overall running time: 169.4278s / 6098.8047 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2537
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2397
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 525.25,                last time consumption/overall running time: 157.4238s / 6256.2285 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2352
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2268
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 548.3,                last time consumption/overall running time: 165.5210s / 6421.7495 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2477
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2371
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 550.55,                last time consumption/overall running time: 164.9429s / 6586.6925 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2571
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2518
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 580.5,                last time consumption/overall running time: 174.0580s / 6760.7505 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2690
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2582
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 548.35,                last time consumption/overall running time: 164.7623s / 6925.5127 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2613
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2509
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 570.95,                last time consumption/overall running time: 172.6469s / 7098.1596 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2620
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2561
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 561.8,                last time consumption/overall running time: 168.1556s / 7266.3152 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2521
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2498
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 600.1,                last time consumption/overall running time: 176.9019s / 7443.2171 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2643
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2653
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 573.1,                last time consumption/overall running time: 173.4783s / 7616.6954 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2558
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2461
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 575.8,                last time consumption/overall running time: 172.8088s / 7789.5042 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2719
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2746
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 554.95,                last time consumption/overall running time: 167.0212s / 7956.5254 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2570
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2578
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 579.3,                last time consumption/overall running time: 175.3919s / 8131.9173 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2388
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2368
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 577.95,                last time consumption/overall running time: 173.5829s / 8305.5002 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2432
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2485
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 552.55,                last time consumption/overall running time: 165.4699s / 8470.9701 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2714
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2609
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 536.25,                last time consumption/overall running time: 161.5234s / 8632.4935 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2520
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2605
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 587.95,                last time consumption/overall running time: 176.8977s / 8809.3913 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2357
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2386
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 564.4,                last time consumption/overall running time: 168.8751s / 8978.2663 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2464
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2494
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 554.1,                last time consumption/overall running time: 165.6985s / 9143.9648 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2425
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2461
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 600.5,                last time consumption/overall running time: 180.1113s / 9324.0761 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2492
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2548
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 574.15,                last time consumption/overall running time: 173.2088s / 9497.2849 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2505
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2458
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 549.1,                last time consumption/overall running time: 165.7686s / 9663.0535 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2656
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2553
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 608.2,                last time consumption/overall running time: 179.7749s / 9842.8284 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2579
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2505
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 603.2,                last time consumption/overall running time: 178.7693s / 10021.5977 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2644
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2723
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 574.8,                last time consumption/overall running time: 172.7473s / 10194.3449 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2905
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2912
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 574.05,                last time consumption/overall running time: 171.0126s / 10365.3575 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2906
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2857
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 555.65,                last time consumption/overall running time: 167.4191s / 10532.7766 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2627
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2592
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 532.9,                last time consumption/overall running time: 159.9017s / 10692.6783 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2750
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2791
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 572.2,                last time consumption/overall running time: 171.0552s / 10863.7334 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2558
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2482
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 567.45,                last time consumption/overall running time: 169.9692s / 11033.7026 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2677
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2612
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 589.4,                last time consumption/overall running time: 176.3746s / 11210.0773 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2640
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2638
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 590.9,                last time consumption/overall running time: 176.0832s / 11386.1605 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.2575
env0_second_0:                 episode reward: 1.0000,                 loss: 0.2654
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 603.05,                last time consumption/overall running time: 180.3911s / 11566.5516 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2686
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2624
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 550.95,                last time consumption/overall running time: 164.9119s / 11731.4635 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2743
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2695
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 584.25,                last time consumption/overall running time: 175.0490s / 11906.5125 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.2775
env0_second_0:                 episode reward: 1.6000,                 loss: 0.2771
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 577.55,                last time consumption/overall running time: 171.1202s / 12077.6327 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2630
env0_second_0:                 episode reward: 0.1000,                 loss: 0.2703
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 584.5,                last time consumption/overall running time: 175.1222s / 12252.7549 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2685
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2637
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 566.5,                last time consumption/overall running time: 169.2870s / 12422.0419 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.2862
env0_second_0:                 episode reward: 0.7500,                 loss: 0.2815
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 580.5,                last time consumption/overall running time: 171.7336s / 12593.7755 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2841
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3008
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 567.6,                last time consumption/overall running time: 169.4319s / 12763.2074 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2824
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2774
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 563.0,                last time consumption/overall running time: 168.6412s / 12931.8486 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2808
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2818
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 584.25,                last time consumption/overall running time: 174.3577s / 13106.2063 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2572
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2573
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 580.65,                last time consumption/overall running time: 172.7619s / 13278.9682 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2662
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2651
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 556.65,                last time consumption/overall running time: 166.4233s / 13445.3915 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2414
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2506
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 589.3,                last time consumption/overall running time: 175.3381s / 13620.7296 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2674
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2644
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 552.3,                last time consumption/overall running time: 167.6631s / 13788.3927 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2637
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2628
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 534.45,                last time consumption/overall running time: 158.7916s / 13947.1843 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2656
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2706
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 606.7,                last time consumption/overall running time: 180.1444s / 14127.3287 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2785
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2829
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 570.5,                last time consumption/overall running time: 169.9521s / 14297.2808 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2756
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2751
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 551.9,                last time consumption/overall running time: 165.9969s / 14463.2778 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2905
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2896
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 639.75,                last time consumption/overall running time: 189.1752s / 14652.4530 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2554
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2558
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 546.6,                last time consumption/overall running time: 163.8592s / 14816.3122 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2609
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2603
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 602.8,                last time consumption/overall running time: 178.2239s / 14994.5361 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2864
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2894
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 574.2,                last time consumption/overall running time: 172.0500s / 15166.5861 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2748
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2718
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 574.4,                last time consumption/overall running time: 170.5097s / 15337.0959 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.2662
env0_second_0:                 episode reward: -1.2500,                 loss: 0.2591
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 563.25,                last time consumption/overall running time: 167.4858s / 15504.5817 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2777
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2751
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 553.35,                last time consumption/overall running time: 165.0937s / 15669.6754 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2653
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2601
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 533.65,                last time consumption/overall running time: 159.8916s / 15829.5671 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2704
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2718
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 564.6,                last time consumption/overall running time: 168.1516s / 15997.7186 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2734
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2723
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 576.9,                last time consumption/overall running time: 172.4745s / 16170.1932 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2662
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2613
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 594.4,                last time consumption/overall running time: 177.4938s / 16347.6870 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2796
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2789
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 545.9,                last time consumption/overall running time: 163.0425s / 16510.7295 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2688
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2616
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 561.15,                last time consumption/overall running time: 169.4468s / 16680.1763 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2666
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2609
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 586.0,                last time consumption/overall running time: 174.6282s / 16854.8045 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2506
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2525
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 592.85,                last time consumption/overall running time: 175.1643s / 17029.9688 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2804
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2798
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 590.9,                last time consumption/overall running time: 175.4359s / 17205.4047 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2780
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2785
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 563.5,                last time consumption/overall running time: 167.7211s / 17373.1258 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2786
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2815
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 587.15,                last time consumption/overall running time: 175.9978s / 17549.1236 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2600
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2637
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 596.35,                last time consumption/overall running time: 175.4218s / 17724.5454 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2852
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2838
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 573.3,                last time consumption/overall running time: 169.7728s / 17894.3182 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.2586
env0_second_0:                 episode reward: -0.9000,                 loss: 0.2619
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 526.05,                last time consumption/overall running time: 158.0166s / 18052.3349 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2837
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2792
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 556.45,                last time consumption/overall running time: 167.6867s / 18220.0216 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2661
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2713
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 576.5,                last time consumption/overall running time: 171.9019s / 18391.9235 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2836
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2817
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 559.7,                last time consumption/overall running time: 167.4036s / 18559.3271 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2817
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2756
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 562.45,                last time consumption/overall running time: 168.4441s / 18727.7712 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2818
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2759
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 566.35,                last time consumption/overall running time: 168.7597s / 18896.5309 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.2760
env0_second_0:                 episode reward: 0.6000,                 loss: 0.2811
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 558.85,                last time consumption/overall running time: 165.5273s / 19062.0582 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2667
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2711
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 556.6,                last time consumption/overall running time: 166.5798s / 19228.6380 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2520
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2464
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 570.85,                last time consumption/overall running time: 170.0224s / 19398.6604 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2477
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2534
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 599.8,                last time consumption/overall running time: 178.7218s / 19577.3822 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2642
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2544
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 517.15,                last time consumption/overall running time: 156.8985s / 19734.2807 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2676
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2668
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 568.5,                last time consumption/overall running time: 170.2469s / 19904.5276 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2752
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2758
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 563.1,                last time consumption/overall running time: 166.9568s / 20071.4844 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2676
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2689
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 576.3,                last time consumption/overall running time: 170.9881s / 20242.4725 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2646
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2560
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 571.05,                last time consumption/overall running time: 170.7119s / 20413.1844 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2568
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2490
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 582.3,                last time consumption/overall running time: 173.0358s / 20586.2201 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2859
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2772
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 567.0,                last time consumption/overall running time: 169.9096s / 20756.1297 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2530
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2528
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 551.05,                last time consumption/overall running time: 165.2475s / 20921.3772 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2841
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2907
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 563.0,                last time consumption/overall running time: 168.2617s / 21089.6389 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2643
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2699
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 573.5,                last time consumption/overall running time: 169.9264s / 21259.5653 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.2818
env0_second_0:                 episode reward: 1.1000,                 loss: 0.2876
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 576.35,                last time consumption/overall running time: 171.9037s / 21431.4691 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2843
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2835
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 551.85,                last time consumption/overall running time: 164.1774s / 21595.6464 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2852
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2869
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 596.05,                last time consumption/overall running time: 177.2069s / 21772.8533 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2730
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2765
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 543.6,                last time consumption/overall running time: 163.2425s / 21936.0958 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2788
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2846
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 549.1,                last time consumption/overall running time: 165.2506s / 22101.3464 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2887
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2879
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 567.2,                last time consumption/overall running time: 168.4916s / 22269.8380 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2732
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2586
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 587.7,                last time consumption/overall running time: 174.6378s / 22444.4757 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2764
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2789
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 542.35,                last time consumption/overall running time: 162.1593s / 22606.6350 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.2690
env0_second_0:                 episode reward: -0.3500,                 loss: 0.2655
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 588.85,                last time consumption/overall running time: 175.0739s / 22781.7089 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.2816
env0_second_0:                 episode reward: -0.9500,                 loss: 0.2797
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 550.35,                last time consumption/overall running time: 163.6596s / 22945.3685 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2793
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2803
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 577.35,                last time consumption/overall running time: 172.2250s / 23117.5935 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2532
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2596
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 546.6,                last time consumption/overall running time: 162.8707s / 23280.4643 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2754
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2716
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 554.5,                last time consumption/overall running time: 167.5924s / 23448.0566 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2917
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2807
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 580.5,                last time consumption/overall running time: 173.8938s / 23621.9504 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2791
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2780
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 545.85,                last time consumption/overall running time: 164.1202s / 23786.0706 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2758
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2899
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 526.75,                last time consumption/overall running time: 158.4705s / 23944.5411 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2966
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2971
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 570.3,                last time consumption/overall running time: 168.1478s / 24112.6889 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2969
env0_second_0:                 episode reward: 0.8000,                 loss: 0.3024
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 535.45,                last time consumption/overall running time: 161.7201s / 24274.4090 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2623
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2610
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 554.9,                last time consumption/overall running time: 164.9405s / 24439.3496 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.2852
env0_second_0:                 episode reward: -1.1500,                 loss: 0.2847
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 588.45,                last time consumption/overall running time: 174.6142s / 24613.9638 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2858
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2928
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 568.8,                last time consumption/overall running time: 169.9398s / 24783.9036 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2785
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2889
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 558.3,                last time consumption/overall running time: 164.2427s / 24948.1463 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2768
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2666
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 572.85,                last time consumption/overall running time: 170.3389s / 25118.4852 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2855
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2888
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 573.8,                last time consumption/overall running time: 173.2843s / 25291.7695 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2840
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2795
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 527.75,                last time consumption/overall running time: 156.7100s / 25448.4794 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.2827
env0_second_0:                 episode reward: 0.9000,                 loss: 0.2851
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 555.4,                last time consumption/overall running time: 165.4801s / 25613.9595 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2925
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3034
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 555.6,                last time consumption/overall running time: 166.0305s / 25779.9900 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2890
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2873
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 572.7,                last time consumption/overall running time: 169.9087s / 25949.8987 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2801
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2774
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 545.15,                last time consumption/overall running time: 162.9679s / 26112.8666 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2829
env0_second_0:                 episode reward: 0.5000,                 loss: 0.2950
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 574.0,                last time consumption/overall running time: 170.4775s / 26283.3441 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2848
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2933
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 528.15,                last time consumption/overall running time: 159.4203s / 26442.7644 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.2756
env0_second_0:                 episode reward: -1.1000,                 loss: 0.2791
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 533.25,                last time consumption/overall running time: 160.3105s / 26603.0749 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.2779
env0_second_0:                 episode reward: 0.7000,                 loss: 0.2795
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 532.55,                last time consumption/overall running time: 159.0479s / 26762.1227 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2711
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2625
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 584.65,                last time consumption/overall running time: 172.6068s / 26934.7295 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2836
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2877
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 575.75,                last time consumption/overall running time: 171.3520s / 27106.0816 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2848
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2800
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 567.2,                last time consumption/overall running time: 168.5622s / 27274.6438 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2856
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2980
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 570.45,                last time consumption/overall running time: 168.6504s / 27443.2942 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2656
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2806
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 553.2,                last time consumption/overall running time: 164.3864s / 27607.6806 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2605
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2548
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 568.4,                last time consumption/overall running time: 170.3595s / 27778.0401 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.2628
env0_second_0:                 episode reward: 0.6500,                 loss: 0.2831
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 583.15,                last time consumption/overall running time: 172.2154s / 27950.2555 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2623
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2596
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 573.3,                last time consumption/overall running time: 170.9850s / 28121.2405 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2666
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2784
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 567.4,                last time consumption/overall running time: 169.5659s / 28290.8065 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2651
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2770
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 564.8,                last time consumption/overall running time: 168.4195s / 28459.2259 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.3165
env0_second_0:                 episode reward: -0.2500,                 loss: 0.3220
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 582.05,                last time consumption/overall running time: 173.3195s / 28632.5454 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.3029
env0_second_0:                 episode reward: -0.6500,                 loss: 0.3034
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 599.3,                last time consumption/overall running time: 179.2011s / 28811.7465 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.2799
env0_second_0:                 episode reward: -1.0000,                 loss: 0.2912
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 553.2,                last time consumption/overall running time: 164.8512s / 28976.5977 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2677
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2678
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 587.4,                last time consumption/overall running time: 173.6332s / 29150.2309 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.2816
env0_second_0:                 episode reward: -0.6000,                 loss: 0.2875
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 581.15,                last time consumption/overall running time: 172.8174s / 29323.0483 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.2837
env0_second_0:                 episode reward: -0.8500,                 loss: 0.2916
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 560.7,                last time consumption/overall running time: 166.5376s / 29489.5859 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.2753
env0_second_0:                 episode reward: -0.5500,                 loss: 0.2857
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 553.6,                last time consumption/overall running time: 165.7883s / 29655.3743 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2819
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2856
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 581.5,                last time consumption/overall running time: 171.7066s / 29827.0809 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.2796
env0_second_0:                 episode reward: -0.1500,                 loss: 0.2838
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 548.3,                last time consumption/overall running time: 163.5156s / 29990.5964 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2585
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2614
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 549.4,                last time consumption/overall running time: 165.4045s / 30156.0009 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2735
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2732
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 628.75,                last time consumption/overall running time: 185.5851s / 30341.5860 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2854
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2935
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 569.85,                last time consumption/overall running time: 169.3657s / 30510.9517 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2694
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2741
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 550.45,                last time consumption/overall running time: 163.9307s / 30674.8824 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.3011
env0_second_0:                 episode reward: -0.0500,                 loss: 0.3051
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 584.4,                last time consumption/overall running time: 172.7621s / 30847.6444 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2950
env0_second_0:                 episode reward: -0.1000,                 loss: 0.3041
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 558.4,                last time consumption/overall running time: 166.3028s / 31013.9472 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.2904
env0_second_0:                 episode reward: -0.4500,                 loss: 0.2934
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 541.25,                last time consumption/overall running time: 162.3658s / 31176.3130 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.3025
env0_second_0:                 episode reward: -0.5000,                 loss: 0.3139
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 574.6,                last time consumption/overall running time: 169.8033s / 31346.1163 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2815
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2902
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 584.4,                last time consumption/overall running time: 175.2569s / 31521.3733 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.2784
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2900
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 583.0,                last time consumption/overall running time: 173.6237s / 31694.9969 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2708
env0_second_0:                 episode reward: -1.0500,                 loss: 0.2589
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 558.0,                last time consumption/overall running time: 165.8960s / 31860.8930 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.2713
env0_second_0:                 episode reward: -1.1500,                 loss: 0.2723
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 548.55,                last time consumption/overall running time: 164.8046s / 32025.6976 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.2668
env0_second_0:                 episode reward: -0.2500,                 loss: 0.2675
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 566.05,                last time consumption/overall running time: 168.8034s / 32194.5011 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.2549
env0_second_0:                 episode reward: -0.1000,                 loss: 0.2565
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 586.2,                last time consumption/overall running time: 173.3640s / 32367.8651 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.2643
env0_second_0:                 episode reward: 0.0500,                 loss: 0.2691
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 559.75,                last time consumption/overall running time: 167.1795s / 32535.0446 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2821
env0_second_0:                 episode reward: -0.3000,                 loss: 0.2892
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 562.2,                last time consumption/overall running time: 167.3486s / 32702.3932 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2703
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2903
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 549.75,                last time consumption/overall running time: 163.3159s / 32865.7090 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2944
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2952
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 580.35,                last time consumption/overall running time: 172.6351s / 33038.3441 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2744
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2895
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 568.6,                last time consumption/overall running time: 170.9856s / 33209.3298 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.3024
env0_second_0:                 episode reward: 0.5500,                 loss: 0.3098
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 559.4,                last time consumption/overall running time: 167.1289s / 33376.4587 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2520
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2520
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 566.35,                last time consumption/overall running time: 166.7398s / 33543.1985 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2921
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2986
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 587.3,                last time consumption/overall running time: 175.1443s / 33718.3428 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.2827
env0_second_0:                 episode reward: 0.2500,                 loss: 0.2992
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 572.45,                last time consumption/overall running time: 171.1576s / 33889.5004 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2611
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2773
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 588.25,                last time consumption/overall running time: 173.3099s / 34062.8103 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2747
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2813
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 553.65,                last time consumption/overall running time: 164.9403s / 34227.7506 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2668
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2736
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 580.0,                last time consumption/overall running time: 172.8273s / 34400.5779 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2695
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2728
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 554.25,                last time consumption/overall running time: 164.9835s / 34565.5614 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.2681
env0_second_0:                 episode reward: 0.8000,                 loss: 0.2802
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 590.85,                last time consumption/overall running time: 174.5140s / 34740.0755 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.2617
env0_second_0:                 episode reward: 0.8500,                 loss: 0.2676
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 566.45,                last time consumption/overall running time: 168.1585s / 34908.2340 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2539
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2594
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 571.85,                last time consumption/overall running time: 170.8278s / 35079.0617 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2579
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2632
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 560.9,                last time consumption/overall running time: 167.3712s / 35246.4329 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.2746
env0_second_0:                 episode reward: -0.2000,                 loss: 0.2912
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 586.8,                last time consumption/overall running time: 174.6482s / 35421.0811 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2776
env0_second_0:                 episode reward: 0.1500,                 loss: 0.2804
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 538.9,                last time consumption/overall running time: 161.3860s / 35582.4671 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2659
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2724
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 588.25,                last time consumption/overall running time: 173.8599s / 35756.3270 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.2911
env0_second_0:                 episode reward: -0.0500,                 loss: 0.2976
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 553.1,                last time consumption/overall running time: 164.8061s / 35921.1331 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2645
env0_second_0:                 episode reward: 0.4000,                 loss: 0.2627
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 583.0,                last time consumption/overall running time: 174.3929s / 36095.5260 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2771
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2815
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 577.5,                last time consumption/overall running time: 169.1546s / 36264.6806 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.2537
env0_second_0:                 episode reward: 0.2000,                 loss: 0.2548
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 592.0,                last time consumption/overall running time: 175.3644s / 36440.0450 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.2704
env0_second_0:                 episode reward: 1.3500,                 loss: 0.2715
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 561.15,                last time consumption/overall running time: 169.6305s / 36609.6755 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.2863
env0_second_0:                 episode reward: -0.6500,                 loss: 0.2961
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 563.8,                last time consumption/overall running time: 169.8431s / 36779.5186 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.2950
env0_second_0:                 episode reward: 0.3000,                 loss: 0.2989
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 561.6,                last time consumption/overall running time: 166.2763s / 36945.7950 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2769