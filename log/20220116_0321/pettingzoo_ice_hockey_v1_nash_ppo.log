pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
ice_hockey_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [70, 76]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'ice_hockey_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220116_0321/pettingzoo_ice_hockey_v1_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220116_0321/pettingzoo_ice_hockey_v1_nash_ppo.
Episode: 1/10000 (0.0100%),                 avg. length: 2825.0,                last time consumption/overall running time: 37.5627s / 37.5627 s
env0_first_0:                 episode reward: -3.0000,                 loss: -0.4341
env0_second_0:                 episode reward: 3.0000,                 loss: -0.4443
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 21/10000 (0.2100%),                 avg. length: 2843.25,                last time consumption/overall running time: 747.4307s / 784.9934 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4337
env0_second_0:                 episode reward: 0.1500,                 loss: -0.4320
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 41/10000 (0.4100%),                 avg. length: 2837.35,                last time consumption/overall running time: 744.3882s / 1529.3817 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4304
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4325
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 61/10000 (0.6100%),                 avg. length: 2856.85,                last time consumption/overall running time: 753.4040s / 2282.7857 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.4310
env0_second_0:                 episode reward: 0.6500,                 loss: -0.4299
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 81/10000 (0.8100%),                 avg. length: 2804.5,                last time consumption/overall running time: 737.1994s / 3019.9851 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4417
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4391
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 101/10000 (1.0100%),                 avg. length: 2840.0,                last time consumption/overall running time: 745.4244s / 3765.4095 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4311
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4316
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 121/10000 (1.2100%),                 avg. length: 2823.3,                last time consumption/overall running time: 745.2212s / 4510.6307 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.4284
env0_second_0:                 episode reward: 0.5500,                 loss: -0.4227
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 141/10000 (1.4100%),                 avg. length: 2830.7,                last time consumption/overall running time: 746.9011s / 5257.5318 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4292
env0_second_0:                 episode reward: 0.3500,                 loss: -0.4296
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 161/10000 (1.6100%),                 avg. length: 2823.5,                last time consumption/overall running time: 738.6359s / 5996.1678 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4356
env0_second_0:                 episode reward: 0.0500,                 loss: -0.4326
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 181/10000 (1.8100%),                 avg. length: 2850.45,                last time consumption/overall running time: 749.1009s / 6745.2686 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4347
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4295
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 201/10000 (2.0100%),                 avg. length: 2822.2,                last time consumption/overall running time: 741.1744s / 7486.4430 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.4345
env0_second_0:                 episode reward: 0.5000,                 loss: -0.4302
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 221/10000 (2.2100%),                 avg. length: 2825.95,                last time consumption/overall running time: 741.0234s / 8227.4663 s
env0_first_0:                 episode reward: -1.3000,                 loss: -0.4380
env0_second_0:                 episode reward: 1.3000,                 loss: -0.4384
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 241/10000 (2.4100%),                 avg. length: 2851.15,                last time consumption/overall running time: 749.2022s / 8976.6685 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.4347
env0_second_0:                 episode reward: 0.7000,                 loss: -0.4345
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 261/10000 (2.6100%),                 avg. length: 2848.75,                last time consumption/overall running time: 747.0411s / 9723.7097 s
env0_first_0:                 episode reward: -0.9500,                 loss: -0.4325
env0_second_0:                 episode reward: 0.9500,                 loss: -0.4306
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 281/10000 (2.8100%),                 avg. length: 2859.85,                last time consumption/overall running time: 746.8302s / 10470.5399 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4303
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4303
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 301/10000 (3.0100%),                 avg. length: 2843.5,                last time consumption/overall running time: 744.5922s / 11215.1321 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.4331
env0_second_0:                 episode reward: -0.1500,                 loss: -0.4336
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 321/10000 (3.2100%),                 avg. length: 2847.0,                last time consumption/overall running time: 747.8240s / 11962.9561 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4343
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4327
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 341/10000 (3.4100%),                 avg. length: 2857.0,                last time consumption/overall running time: 751.2536s / 12714.2098 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4344
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4359
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 361/10000 (3.6100%),                 avg. length: 2859.95,                last time consumption/overall running time: 749.1147s / 13463.3244 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.4360
env0_second_0:                 episode reward: 0.4000,                 loss: -0.4316
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 381/10000 (3.8100%),                 avg. length: 2847.55,                last time consumption/overall running time: 747.7998s / 14211.1242 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.4344
env0_second_0:                 episode reward: 0.7000,                 loss: -0.4361
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 401/10000 (4.0100%),                 avg. length: 2851.65,                last time consumption/overall running time: 747.0471s / 14958.1713 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.4381
env0_second_0:                 episode reward: 0.3000,                 loss: -0.4363
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 421/10000 (4.2100%),                 avg. length: 2835.45,                last time consumption/overall running time: 743.0053s / 15701.1766 s
env0_first_0:                 episode reward: -1.0500,                 loss: -0.4344
env0_second_0:                 episode reward: 1.0500,                 loss: -0.4338
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 441/10000 (4.4100%),                 avg. length: 2811.2,                last time consumption/overall running time: 734.9786s / 16436.1552 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4421
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4408
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 461/10000 (4.6100%),                 avg. length: 2838.4,                last time consumption/overall running time: 746.3171s / 17182.4723 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.4385
env0_second_0:                 episode reward: 0.5000,                 loss: -0.4398
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 481/10000 (4.8100%),                 avg. length: 2845.4,                last time consumption/overall running time: 747.9249s / 17930.3972 s
env0_first_0:                 episode reward: -0.9000,                 loss: -0.4344
env0_second_0:                 episode reward: 0.9000,                 loss: -0.4383
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 501/10000 (5.0100%),                 avg. length: 2825.9,                last time consumption/overall running time: 741.5667s / 18671.9640 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4440
env0_second_0:                 episode reward: 0.1500,                 loss: -0.4417
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 521/10000 (5.2100%),                 avg. length: 2831.95,                last time consumption/overall running time: 741.7546s / 19413.7186 s
env0_first_0:                 episode reward: -0.8000,                 loss: -0.4384
env0_second_0:                 episode reward: 0.8000,                 loss: -0.4443
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 541/10000 (5.4100%),                 avg. length: 2843.6,                last time consumption/overall running time: 742.8730s / 20156.5915 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4373
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4423
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 561/10000 (5.6100%),                 avg. length: 2842.65,                last time consumption/overall running time: 746.3425s / 20902.9340 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.4381
env0_second_0:                 episode reward: 0.2500,                 loss: -0.4353
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 581/10000 (5.8100%),                 avg. length: 2820.15,                last time consumption/overall running time: 741.5398s / 21644.4738 s
env0_first_0:                 episode reward: -1.4000,                 loss: -0.4431
env0_second_0:                 episode reward: 1.4000,                 loss: -0.4389
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 601/10000 (6.0100%),                 avg. length: 2811.75,                last time consumption/overall running time: 734.0907s / 22378.5645 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4437
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4432
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 621/10000 (6.2100%),                 avg. length: 2829.4,                last time consumption/overall running time: 739.8349s / 23118.3994 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4383
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4332
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 641/10000 (6.4100%),                 avg. length: 2855.0,                last time consumption/overall running time: 747.7374s / 23866.1368 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4348
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4313
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 661/10000 (6.6100%),                 avg. length: 2832.7,                last time consumption/overall running time: 742.9769s / 24609.1137 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4374
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4370
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 681/10000 (6.8100%),                 avg. length: 2873.05,                last time consumption/overall running time: 750.5915s / 25359.7052 s
env0_first_0:                 episode reward: -1.0000,                 loss: -0.4338
env0_second_0:                 episode reward: 1.0000,                 loss: -0.4342
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 701/10000 (7.0100%),                 avg. length: 2860.15,                last time consumption/overall running time: 750.2690s / 26109.9742 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.4371
env0_second_0:                 episode reward: 0.3000,                 loss: -0.4380
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 721/10000 (7.2100%),                 avg. length: 2860.5,                last time consumption/overall running time: 748.5549s / 26858.5292 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.4377
env0_second_0:                 episode reward: -0.4000,                 loss: -0.4367
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 741/10000 (7.4100%),                 avg. length: 2851.7,                last time consumption/overall running time: 747.9947s / 27606.5239 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4325
env0_second_0:                 episode reward: 0.2000,                 loss: -0.4373
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 761/10000 (7.6100%),                 avg. length: 2815.75,                last time consumption/overall running time: 739.8646s / 28346.3885 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4422
env0_second_0:                 episode reward: 0.3500,                 loss: -0.4414
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 781/10000 (7.8100%),                 avg. length: 2864.35,                last time consumption/overall running time: 752.3463s / 29098.7348 s
env0_first_0:                 episode reward: 0.8000,                 loss: -0.4376
env0_second_0:                 episode reward: -0.8000,                 loss: -0.4349
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 801/10000 (8.0100%),                 avg. length: 2842.95,                last time consumption/overall running time: 746.3420s / 29845.0768 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.4315
env0_second_0:                 episode reward: 0.7000,                 loss: -0.4297
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 821/10000 (8.2100%),                 avg. length: 2855.75,                last time consumption/overall running time: 747.5939s / 30592.6707 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4350
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4370
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 841/10000 (8.4100%),                 avg. length: 2849.1,                last time consumption/overall running time: 747.6067s / 31340.2774 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.4384
env0_second_0:                 episode reward: 0.7000,                 loss: -0.4378
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 861/10000 (8.6100%),                 avg. length: 2857.05,                last time consumption/overall running time: 748.0619s / 32088.3394 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4313
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4305
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 881/10000 (8.8100%),                 avg. length: 2856.9,                last time consumption/overall running time: 749.0172s / 32837.3566 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.4294
env0_second_0:                 episode reward: -0.5500,                 loss: -0.4259
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 901/10000 (9.0100%),                 avg. length: 2856.3,                last time consumption/overall running time: 749.7095s / 33587.0660 s
env0_first_0:                 episode reward: 1.8000,                 loss: -0.4303
env0_second_0:                 episode reward: -1.8000,                 loss: -0.4316
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 921/10000 (9.2100%),                 avg. length: 2854.25,                last time consumption/overall running time: 750.7495s / 34337.8155 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4358
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4371
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 941/10000 (9.4100%),                 avg. length: 2837.85,                last time consumption/overall running time: 745.2547s / 35083.0702 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.4380
env0_second_0:                 episode reward: -0.7500,                 loss: -0.4386
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 961/10000 (9.6100%),                 avg. length: 2867.85,                last time consumption/overall running time: 754.4073s / 35837.4775 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.4257
env0_second_0:                 episode reward: -0.6000,                 loss: -0.4230
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 981/10000 (9.8100%),                 avg. length: 2858.45,                last time consumption/overall running time: 749.7294s / 36587.2070 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.4378
env0_second_0:                 episode reward: 0.4500,                 loss: -0.4342
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1001/10000 (10.0100%),                 avg. length: 2837.9,                last time consumption/overall running time: 744.6600s / 37331.8670 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.4318
env0_second_0:                 episode reward: 0.4500,                 loss: -0.4312
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1021/10000 (10.2100%),                 avg. length: 2826.05,                last time consumption/overall running time: 739.5867s / 38071.4537 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4319
env0_second_0:                 episode reward: 0.2000,                 loss: -0.4342
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1041/10000 (10.4100%),                 avg. length: 2817.75,                last time consumption/overall running time: 734.4595s / 38805.9132 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.4361
env0_second_0:                 episode reward: 0.7500,                 loss: -0.4331
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1061/10000 (10.6100%),                 avg. length: 2856.15,                last time consumption/overall running time: 750.4680s / 39556.3812 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4331
env0_second_0:                 episode reward: 0.1500,                 loss: -0.4353
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1081/10000 (10.8100%),                 avg. length: 2859.35,                last time consumption/overall running time: 749.1941s / 40305.5753 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.4305
env0_second_0:                 episode reward: 0.7000,                 loss: -0.4296
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 1101/10000 (11.0100%),                 avg. length: 2827.8,                last time consumption/overall running time: 738.4441s / 41044.0194 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.4404
env0_second_0:                 episode reward: 0.4000,                 loss: -0.4407
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 1121/10000 (11.2100%),                 avg. length: 2806.05,                last time consumption/overall running time: 734.5805s / 41778.5999 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4452
env0_second_0:                 episode reward: 0.3500,                 loss: -0.4395
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1141/10000 (11.4100%),                 avg. length: 2796.7,                last time consumption/overall running time: 732.7801s / 42511.3800 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4413
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4411
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 1161/10000 (11.6100%),                 avg. length: 2838.45,                last time consumption/overall running time: 738.9777s / 43250.3576 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4284
env0_second_0:                 episode reward: 0.3500,                 loss: -0.4239
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1181/10000 (11.8100%),                 avg. length: 2859.65,                last time consumption/overall running time: 749.8285s / 44000.1862 s
env0_first_0:                 episode reward: -1.3500,                 loss: -0.4295
env0_second_0:                 episode reward: 1.3500,                 loss: -0.4247
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 1201/10000 (12.0100%),                 avg. length: 2852.35,                last time consumption/overall running time: 743.0590s / 44743.2452 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.4363
env0_second_0:                 episode reward: 0.5500,                 loss: -0.4379
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1221/10000 (12.2100%),                 avg. length: 2825.05,                last time consumption/overall running time: 738.2808s / 45481.5260 s
env0_first_0:                 episode reward: -1.0500,                 loss: -0.4401
env0_second_0:                 episode reward: 1.0500,                 loss: -0.4410
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1241/10000 (12.4100%),                 avg. length: 2796.9,                last time consumption/overall running time: 730.7843s / 46212.3103 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4427
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4426
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1261/10000 (12.6100%),                 avg. length: 2799.65,                last time consumption/overall running time: 726.6413s / 46938.9517 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4431
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4422
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1281/10000 (12.8100%),                 avg. length: 2852.0,                last time consumption/overall running time: 744.5984s / 47683.5501 s
env0_first_0:                 episode reward: 1.4500,                 loss: -0.4360
env0_second_0:                 episode reward: -1.4500,                 loss: -0.4325
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1301/10000 (13.0100%),                 avg. length: 2868.95,                last time consumption/overall running time: 751.0169s / 48434.5670 s
env0_first_0:                 episode reward: 1.0500,                 loss: -0.4304
env0_second_0:                 episode reward: -1.0500,                 loss: -0.4271
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 1321/10000 (13.2100%),                 avg. length: 2869.05,                last time consumption/overall running time: 747.6432s / 49182.2102 s
env0_first_0:                 episode reward: -1.0500,                 loss: -0.4253
env0_second_0:                 episode reward: 1.0500,                 loss: -0.4234
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1341/10000 (13.4100%),                 avg. length: 2850.8,                last time consumption/overall running time: 744.4082s / 49926.6184 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4314
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4260
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 1361/10000 (13.6100%),                 avg. length: 2849.5,                last time consumption/overall running time: 752.4987s / 50679.1171 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.4209
env0_second_0:                 episode reward: -0.6500,                 loss: -0.4151
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 1381/10000 (13.8100%),                 avg. length: 2852.75,                last time consumption/overall running time: 747.3799s / 51426.4970 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.4289
env0_second_0:                 episode reward: -0.7500,                 loss: -0.4269
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1401/10000 (14.0100%),                 avg. length: 2826.15,                last time consumption/overall running time: 735.3001s / 52161.7971 s
env0_first_0:                 episode reward: -0.8000,                 loss: -0.4327
env0_second_0:                 episode reward: 0.8000,                 loss: -0.4286
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1421/10000 (14.2100%),                 avg. length: 2816.1,                last time consumption/overall running time: 684.5132s / 52846.3103 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.4384
env0_second_0:                 episode reward: 0.6000,                 loss: -0.4399
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1441/10000 (14.4100%),                 avg. length: 2837.8,                last time consumption/overall running time: 693.1512s / 53539.4615 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.4353
env0_second_0:                 episode reward: -0.3000,                 loss: -0.4344
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1461/10000 (14.6100%),                 avg. length: 2878.9,                last time consumption/overall running time: 664.9436s / 54204.4051 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4293
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4286
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 1481/10000 (14.8100%),                 avg. length: 2901.9,                last time consumption/overall running time: 640.5663s / 54844.9714 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.4281
env0_second_0:                 episode reward: -0.6500,                 loss: -0.4261
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1501/10000 (15.0100%),                 avg. length: 2824.8,                last time consumption/overall running time: 620.3928s / 55465.3642 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4389
env0_second_0:                 episode reward: 0.3500,                 loss: -0.4376
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1521/10000 (15.2100%),                 avg. length: 2818.5,                last time consumption/overall running time: 594.8530s / 56060.2172 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4418
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4437
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1541/10000 (15.4100%),                 avg. length: 2834.65,                last time consumption/overall running time: 576.9048s / 56637.1220 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4368
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4363
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1561/10000 (15.6100%),                 avg. length: 2835.05,                last time consumption/overall running time: 574.5267s / 57211.6486 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.4370
env0_second_0:                 episode reward: -0.5500,                 loss: -0.4361
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1581/10000 (15.8100%),                 avg. length: 2839.9,                last time consumption/overall running time: 567.1153s / 57778.7639 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4396
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4407
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1601/10000 (16.0100%),                 avg. length: 2841.55,                last time consumption/overall running time: 573.8738s / 58352.6378 s
env0_first_0:                 episode reward: 0.9000,                 loss: -0.4436
env0_second_0:                 episode reward: -0.9000,                 loss: -0.4450
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1621/10000 (16.2100%),                 avg. length: 2845.4,                last time consumption/overall running time: 573.0693s / 58925.7070 s
env0_first_0:                 episode reward: 1.7000,                 loss: -0.4405
env0_second_0:                 episode reward: -1.7000,                 loss: -0.4431
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 1641/10000 (16.4100%),                 avg. length: 2803.5,                last time consumption/overall running time: 564.0588s / 59489.7658 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4468
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4484
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 1661/10000 (16.6100%),                 avg. length: 2808.9,                last time consumption/overall running time: 567.6979s / 60057.4637 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4422
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4413
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 1681/10000 (16.8100%),                 avg. length: 2850.6,                last time consumption/overall running time: 576.2708s / 60633.7345 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4343
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4368
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 1701/10000 (17.0100%),                 avg. length: 2816.75,                last time consumption/overall running time: 564.1173s / 61197.8518 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4421
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4410
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1721/10000 (17.2100%),                 avg. length: 2808.9,                last time consumption/overall running time: 564.1865s / 61762.0383 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4461
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4454
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 1741/10000 (17.4100%),                 avg. length: 2838.5,                last time consumption/overall running time: 573.4043s / 62335.4426 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.4419
env0_second_0:                 episode reward: -0.3000,                 loss: -0.4381
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 1761/10000 (17.6100%),                 avg. length: 2867.85,                last time consumption/overall running time: 579.1160s / 62914.5585 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.4316
env0_second_0:                 episode reward: 0.4000,                 loss: -0.4289
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 1781/10000 (17.8100%),                 avg. length: 2839.65,                last time consumption/overall running time: 574.9233s / 63489.4818 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4354
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4301
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 1801/10000 (18.0100%),                 avg. length: 2828.2,                last time consumption/overall running time: 573.4549s / 64062.9368 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.4375
env0_second_0:                 episode reward: -0.5500,                 loss: -0.4347
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 1821/10000 (18.2100%),                 avg. length: 2811.85,                last time consumption/overall running time: 563.8143s / 64626.7511 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.4414
env0_second_0:                 episode reward: -0.4000,                 loss: -0.4368
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 1841/10000 (18.4100%),                 avg. length: 2812.1,                last time consumption/overall running time: 564.8645s / 65191.6156 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4376
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4359
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1861/10000 (18.6100%),                 avg. length: 2838.15,                last time consumption/overall running time: 553.6471s / 65745.2627 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.4334
env0_second_0:                 episode reward: 0.3000,                 loss: -0.4349
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 1881/10000 (18.8100%),                 avg. length: 2839.0,                last time consumption/overall running time: 512.9340s / 66258.1967 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4339
env0_second_0:                 episode reward: 0.0500,                 loss: -0.4319
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1901/10000 (19.0100%),                 avg. length: 2842.4,                last time consumption/overall running time: 524.5283s / 66782.7250 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.4415
env0_second_0:                 episode reward: -0.6000,                 loss: -0.4398
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1921/10000 (19.2100%),                 avg. length: 2864.9,                last time consumption/overall running time: 526.4009s / 67309.1259 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4314
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4288
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1941/10000 (19.4100%),                 avg. length: 2870.35,                last time consumption/overall running time: 520.0920s / 67829.2179 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.4245
env0_second_0:                 episode reward: 0.4000,                 loss: -0.4226
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 1961/10000 (19.6100%),                 avg. length: 2842.45,                last time consumption/overall running time: 517.4784s / 68346.6962 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4375
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4354
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1981/10000 (19.8100%),                 avg. length: 2825.05,                last time consumption/overall running time: 516.4508s / 68863.1470 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4399
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4403
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2001/10000 (20.0100%),                 avg. length: 2846.2,                last time consumption/overall running time: 516.9046s / 69380.0516 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.4370
env0_second_0:                 episode reward: -0.9500,                 loss: -0.4391
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 2021/10000 (20.2100%),                 avg. length: 2849.4,                last time consumption/overall running time: 519.8425s / 69899.8941 s
env0_first_0:                 episode reward: -0.9000,                 loss: -0.4363
env0_second_0:                 episode reward: 0.9000,                 loss: -0.4340
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2041/10000 (20.4100%),                 avg. length: 2848.4,                last time consumption/overall running time: 515.8545s / 70415.7486 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4330
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4314
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2061/10000 (20.6100%),                 avg. length: 2832.95,                last time consumption/overall running time: 514.5948s / 70930.3434 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.4391
env0_second_0:                 episode reward: -0.6000,                 loss: -0.4408
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2081/10000 (20.8100%),                 avg. length: 2820.85,                last time consumption/overall running time: 514.5092s / 71444.8526 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4339
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4285
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2101/10000 (21.0100%),                 avg. length: 2831.35,                last time consumption/overall running time: 515.4266s / 71960.2792 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4268
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4187
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2121/10000 (21.2100%),                 avg. length: 2843.55,                last time consumption/overall running time: 513.7146s / 72473.9938 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.4177
env0_second_0:                 episode reward: -0.9500,                 loss: -0.4163
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2141/10000 (21.4100%),                 avg. length: 2822.3,                last time consumption/overall running time: 511.6274s / 72985.6212 s
env0_first_0:                 episode reward: 1.3000,                 loss: -0.4297
env0_second_0:                 episode reward: -1.3000,                 loss: -0.4317
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2161/10000 (21.6100%),                 avg. length: 2852.05,                last time consumption/overall running time: 517.1112s / 73502.7325 s
env0_first_0:                 episode reward: 1.0000,                 loss: -0.4376
env0_second_0:                 episode reward: -1.0000,                 loss: -0.4363
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2181/10000 (21.8100%),                 avg. length: 2809.4,                last time consumption/overall running time: 509.1206s / 74011.8531 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4432
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4403
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 2201/10000 (22.0100%),                 avg. length: 2861.3,                last time consumption/overall running time: 518.9026s / 74530.7557 s
env0_first_0:                 episode reward: 0.9000,                 loss: -0.4374
env0_second_0:                 episode reward: -0.9000,                 loss: -0.4361
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2221/10000 (22.2100%),                 avg. length: 2859.95,                last time consumption/overall running time: 519.2903s / 75050.0459 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4371
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4328
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2241/10000 (22.4100%),                 avg. length: 2841.1,                last time consumption/overall running time: 515.9439s / 75565.9898 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4425
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4455
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2261/10000 (22.6100%),                 avg. length: 2833.25,                last time consumption/overall running time: 511.8425s / 76077.8322 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.4449
env0_second_0:                 episode reward: 0.4500,                 loss: -0.4423
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 2281/10000 (22.8100%),                 avg. length: 2863.2,                last time consumption/overall running time: 518.5202s / 76596.3525 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4359
env0_second_0:                 episode reward: 0.0000,                 loss: -0.4355
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2301/10000 (23.0100%),                 avg. length: 2805.8,                last time consumption/overall running time: 508.6145s / 77104.9670 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4447
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4434
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 2321/10000 (23.2100%),                 avg. length: 2845.4,                last time consumption/overall running time: 519.2611s / 77624.2281 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4319
env0_second_0:                 episode reward: 0.0000,                 loss: -0.4279
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 2341/10000 (23.4100%),                 avg. length: 2830.45,                last time consumption/overall running time: 510.8095s / 78135.0376 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4364
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4308
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2361/10000 (23.6100%),                 avg. length: 2830.65,                last time consumption/overall running time: 510.4562s / 78645.4939 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4426
env0_second_0:                 episode reward: 0.0500,                 loss: -0.4398
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2381/10000 (23.8100%),                 avg. length: 2833.0,                last time consumption/overall running time: 512.8902s / 79158.3840 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.4376
env0_second_0:                 episode reward: -1.1500,                 loss: -0.4383
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2401/10000 (24.0100%),                 avg. length: 2827.0,                last time consumption/overall running time: 510.5711s / 79668.9551 s
env0_first_0:                 episode reward: 1.3500,                 loss: -0.4381
env0_second_0:                 episode reward: -1.3500,                 loss: -0.4361
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 2421/10000 (24.2100%),                 avg. length: 2844.45,                last time consumption/overall running time: 511.8223s / 80180.7775 s
env0_first_0:                 episode reward: 0.9000,                 loss: -0.4385
env0_second_0:                 episode reward: -0.9000,                 loss: -0.4372
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 2441/10000 (24.4100%),                 avg. length: 2835.6,                last time consumption/overall running time: 511.3374s / 80692.1148 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.4401
env0_second_0:                 episode reward: 0.3000,                 loss: -0.4413
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2461/10000 (24.6100%),                 avg. length: 2815.45,                last time consumption/overall running time: 510.2220s / 81202.3369 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4436
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4431
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2481/10000 (24.8100%),                 avg. length: 2839.0,                last time consumption/overall running time: 510.3848s / 81712.7217 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4374
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4359
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2501/10000 (25.0100%),                 avg. length: 2819.2,                last time consumption/overall running time: 508.9848s / 82221.7065 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.4447
env0_second_0:                 episode reward: 0.5000,                 loss: -0.4453
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2521/10000 (25.2100%),                 avg. length: 2837.05,                last time consumption/overall running time: 510.5250s / 82732.2315 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4434
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4443
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2541/10000 (25.4100%),                 avg. length: 2804.45,                last time consumption/overall running time: 510.0410s / 83242.2725 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4458
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4439
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2561/10000 (25.6100%),                 avg. length: 2804.6,                last time consumption/overall running time: 522.2452s / 83764.5177 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4494
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4442
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2581/10000 (25.8100%),                 avg. length: 2850.0,                last time consumption/overall running time: 521.1700s / 84285.6877 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.4437
env0_second_0:                 episode reward: -0.5500,                 loss: -0.4401
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 2601/10000 (26.0100%),                 avg. length: 2849.25,                last time consumption/overall running time: 515.2585s / 84800.9462 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4365
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4377
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2621/10000 (26.2100%),                 avg. length: 2841.55,                last time consumption/overall running time: 513.8369s / 85314.7830 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4404
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4367
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2641/10000 (26.4100%),                 avg. length: 2838.45,                last time consumption/overall running time: 514.5136s / 85829.2967 s
env0_first_0:                 episode reward: 0.8000,                 loss: -0.4368
env0_second_0:                 episode reward: -0.8000,                 loss: -0.4325
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2661/10000 (26.6100%),                 avg. length: 2826.8,                last time consumption/overall running time: 512.8421s / 86342.1388 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.4367
env0_second_0:                 episode reward: 0.7000,                 loss: -0.4311
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2681/10000 (26.8100%),                 avg. length: 2832.95,                last time consumption/overall running time: 509.2057s / 86851.3445 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4384
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4387
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 2701/10000 (27.0100%),                 avg. length: 2822.25,                last time consumption/overall running time: 504.8311s / 87356.1756 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.4402
env0_second_0:                 episode reward: -0.6500,                 loss: -0.4382
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 2721/10000 (27.2100%),                 avg. length: 2839.5,                last time consumption/overall running time: 509.0215s / 87865.1970 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.4376
env0_second_0:                 episode reward: -0.5500,                 loss: -0.4307
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 2741/10000 (27.4100%),                 avg. length: 2841.45,                last time consumption/overall running time: 512.9343s / 88378.1313 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.4329
env0_second_0:                 episode reward: -0.6500,                 loss: -0.4332
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 2761/10000 (27.6100%),                 avg. length: 2828.3,                last time consumption/overall running time: 507.7731s / 88885.9044 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.4382
env0_second_0:                 episode reward: -0.5500,                 loss: -0.4360
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 2781/10000 (27.8100%),                 avg. length: 2852.4,                last time consumption/overall running time: 515.1617s / 89401.0661 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.4349
env0_second_0:                 episode reward: -0.6500,                 loss: -0.4326
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 2801/10000 (28.0100%),                 avg. length: 2835.5,                last time consumption/overall running time: 510.4620s / 89911.5281 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4281
env0_second_0:                 episode reward: 0.1500,                 loss: -0.4269
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2821/10000 (28.2100%),                 avg. length: 2855.2,                last time consumption/overall running time: 513.1599s / 90424.6880 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.4288
env0_second_0:                 episode reward: 0.6000,                 loss: -0.4272
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 2841/10000 (28.4100%),                 avg. length: 2848.05,                last time consumption/overall running time: 512.8552s / 90937.5432 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.4324
env0_second_0:                 episode reward: -0.6500,                 loss: -0.4315
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 2861/10000 (28.6100%),                 avg. length: 2845.3,                last time consumption/overall running time: 512.4375s / 91449.9807 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4298
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4247
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 2881/10000 (28.8100%),                 avg. length: 2847.65,                last time consumption/overall running time: 508.0241s / 91958.0048 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4253
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4214
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2901/10000 (29.0100%),                 avg. length: 2839.65,                last time consumption/overall running time: 510.5972s / 92468.6020 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4284
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4280
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 2921/10000 (29.2100%),                 avg. length: 2849.35,                last time consumption/overall running time: 514.2770s / 92982.8790 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4361
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4317
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 2941/10000 (29.4100%),                 avg. length: 2822.35,                last time consumption/overall running time: 509.2133s / 93492.0923 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4388
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4376
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 2961/10000 (29.6100%),                 avg. length: 2809.85,                last time consumption/overall running time: 505.7366s / 93997.8289 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4405
env0_second_0:                 episode reward: 0.1500,                 loss: -0.4411
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 2981/10000 (29.8100%),                 avg. length: 2822.05,                last time consumption/overall running time: 507.0020s / 94504.8309 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4391
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4399
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3001/10000 (30.0100%),                 avg. length: 2799.1,                last time consumption/overall running time: 502.1857s / 95007.0166 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4420
env0_second_0:                 episode reward: 0.2000,                 loss: -0.4433
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3021/10000 (30.2100%),                 avg. length: 2830.5,                last time consumption/overall running time: 508.0158s / 95515.0324 s
env0_first_0:                 episode reward: 0.8500,                 loss: -0.4409
env0_second_0:                 episode reward: -0.8500,                 loss: -0.4363
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3041/10000 (30.4100%),                 avg. length: 2829.95,                last time consumption/overall running time: 508.9124s / 96023.9447 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4378
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4331
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3061/10000 (30.6100%),                 avg. length: 2818.95,                last time consumption/overall running time: 509.2356s / 96533.1804 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4381
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4347
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3081/10000 (30.8100%),                 avg. length: 2835.95,                last time consumption/overall running time: 512.3884s / 97045.5688 s
env0_first_0:                 episode reward: 1.0000,                 loss: -0.4376
env0_second_0:                 episode reward: -1.0000,                 loss: -0.4288
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 3101/10000 (31.0100%),                 avg. length: 2861.35,                last time consumption/overall running time: 518.0230s / 97563.5918 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4356
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4292
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 3121/10000 (31.2100%),                 avg. length: 2842.4,                last time consumption/overall running time: 510.5142s / 98074.1060 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.4371
env0_second_0:                 episode reward: -0.9500,                 loss: -0.4287
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3141/10000 (31.4100%),                 avg. length: 2836.15,                last time consumption/overall running time: 509.5503s / 98583.6563 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.4391
env0_second_0:                 episode reward: -0.5500,                 loss: -0.4352
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3161/10000 (31.6100%),                 avg. length: 2874.6,                last time consumption/overall running time: 517.7540s / 99101.4103 s
env0_first_0:                 episode reward: 1.0500,                 loss: -0.4349
env0_second_0:                 episode reward: -1.0500,                 loss: -0.4355
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 3181/10000 (31.8100%),                 avg. length: 2883.0,                last time consumption/overall running time: 520.8085s / 99622.2189 s
env0_first_0:                 episode reward: 1.1000,                 loss: -0.4262
env0_second_0:                 episode reward: -1.1000,                 loss: -0.4251
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 3201/10000 (32.0100%),                 avg. length: 2875.0,                last time consumption/overall running time: 520.3356s / 100142.5545 s
env0_first_0:                 episode reward: 1.3000,                 loss: -0.4272
env0_second_0:                 episode reward: -1.3000,                 loss: -0.4204
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 3221/10000 (32.2100%),                 avg. length: 2880.4,                last time consumption/overall running time: 520.5267s / 100663.0811 s
env0_first_0:                 episode reward: 1.1000,                 loss: -0.4240
env0_second_0:                 episode reward: -1.1000,                 loss: -0.4204
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 3241/10000 (32.4100%),                 avg. length: 2865.0,                last time consumption/overall running time: 518.9878s / 101182.0689 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.4201
env0_second_0:                 episode reward: -0.5000,                 loss: -0.4162
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 3261/10000 (32.6100%),                 avg. length: 2868.75,                last time consumption/overall running time: 520.8418s / 101702.9107 s
env0_first_0:                 episode reward: 1.3500,                 loss: -0.4257
env0_second_0:                 episode reward: -1.3500,                 loss: -0.4215
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3281/10000 (32.8100%),                 avg. length: 2830.45,                last time consumption/overall running time: 507.4650s / 102210.3757 s
env0_first_0:                 episode reward: -0.8000,                 loss: -0.4327
env0_second_0:                 episode reward: 0.8000,                 loss: -0.4295
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3301/10000 (33.0100%),                 avg. length: 2849.9,                last time consumption/overall running time: 516.5667s / 102726.9424 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.4335
env0_second_0:                 episode reward: -0.1500,                 loss: -0.4267
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3321/10000 (33.2100%),                 avg. length: 2844.45,                last time consumption/overall running time: 512.2671s / 103239.2095 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4375
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4285
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 3341/10000 (33.4100%),                 avg. length: 2820.15,                last time consumption/overall running time: 512.3088s / 103751.5183 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4325
env0_second_0:                 episode reward: 0.3500,                 loss: -0.4280
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 3361/10000 (33.6100%),                 avg. length: 2860.45,                last time consumption/overall running time: 514.3891s / 104265.9074 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4289
env0_second_0:                 episode reward: 0.0000,                 loss: -0.4254
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3381/10000 (33.8100%),                 avg. length: 2878.2,                last time consumption/overall running time: 520.2294s / 104786.1367 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.4272
env0_second_0:                 episode reward: -0.7500,                 loss: -0.4236
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 3401/10000 (34.0100%),                 avg. length: 2839.95,                last time consumption/overall running time: 513.4357s / 105299.5724 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.4292
env0_second_0:                 episode reward: -1.1500,                 loss: -0.4245
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 3421/10000 (34.2100%),                 avg. length: 2822.0,                last time consumption/overall running time: 510.4568s / 105810.0292 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4374
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4325
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 3441/10000 (34.4100%),                 avg. length: 2826.8,                last time consumption/overall running time: 508.0806s / 106318.1098 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.4396
env0_second_0:                 episode reward: -0.4000,                 loss: -0.4401
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3461/10000 (34.6100%),                 avg. length: 2819.1,                last time consumption/overall running time: 509.0459s / 106827.1557 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4368
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4402
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3481/10000 (34.8100%),                 avg. length: 2836.3,                last time consumption/overall running time: 512.8255s / 107339.9812 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.4357
env0_second_0:                 episode reward: -0.3000,                 loss: -0.4344
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 3501/10000 (35.0100%),                 avg. length: 2850.5,                last time consumption/overall running time: 513.3400s / 107853.3212 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4314
env0_second_0:                 episode reward: 0.0500,                 loss: -0.4310
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3521/10000 (35.2100%),                 avg. length: 2832.9,                last time consumption/overall running time: 509.2847s / 108362.6059 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.4420
env0_second_0:                 episode reward: 0.5000,                 loss: -0.4387
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 3541/10000 (35.4100%),                 avg. length: 2820.55,                last time consumption/overall running time: 510.3550s / 108872.9609 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4393
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4341
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3561/10000 (35.6100%),                 avg. length: 2839.05,                last time consumption/overall running time: 512.7399s / 109385.7008 s
env0_first_0:                 episode reward: 1.4500,                 loss: -0.4364
env0_second_0:                 episode reward: -1.4500,                 loss: -0.4348
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3581/10000 (35.8100%),                 avg. length: 2837.4,                last time consumption/overall running time: 513.4052s / 109899.1060 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4360
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4364
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3601/10000 (36.0100%),                 avg. length: 2863.75,                last time consumption/overall running time: 514.7063s / 110413.8123 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.4297
env0_second_0:                 episode reward: -0.9500,                 loss: -0.4231
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 3621/10000 (36.2100%),                 avg. length: 2840.55,                last time consumption/overall running time: 511.7434s / 110925.5557 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4302
env0_second_0:                 episode reward: 0.0000,                 loss: -0.4289
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3641/10000 (36.4100%),                 avg. length: 2837.9,                last time consumption/overall running time: 511.2012s / 111436.7569 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4371
env0_second_0:                 episode reward: 0.1500,                 loss: -0.4310
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 3661/10000 (36.6100%),                 avg. length: 2837.5,                last time consumption/overall running time: 511.3077s / 111948.0647 s
env0_first_0:                 episode reward: 0.8500,                 loss: -0.4350
env0_second_0:                 episode reward: -0.8500,                 loss: -0.4266
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 3681/10000 (36.8100%),                 avg. length: 2818.35,                last time consumption/overall running time: 508.4002s / 112456.4648 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4413
env0_second_0:                 episode reward: 0.0000,                 loss: -0.4411
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3701/10000 (37.0100%),                 avg. length: 2838.35,                last time consumption/overall running time: 510.3611s / 112966.8259 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.4381
env0_second_0:                 episode reward: -1.1500,                 loss: -0.4385
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3721/10000 (37.2100%),                 avg. length: 2847.9,                last time consumption/overall running time: 511.2313s / 113478.0573 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4344
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4303
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 3741/10000 (37.4100%),                 avg. length: 2841.2,                last time consumption/overall running time: 512.1699s / 113990.2272 s
env0_first_0:                 episode reward: 1.1000,                 loss: -0.4333
env0_second_0:                 episode reward: -1.1000,                 loss: -0.4297
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3761/10000 (37.6100%),                 avg. length: 2842.1,                last time consumption/overall running time: 514.2035s / 114504.4307 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.4397
env0_second_0:                 episode reward: -0.9500,                 loss: -0.4395
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3781/10000 (37.8100%),                 avg. length: 2850.6,                last time consumption/overall running time: 515.9188s / 115020.3496 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.4368
env0_second_0:                 episode reward: 0.5500,                 loss: -0.4317
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 3801/10000 (38.0100%),                 avg. length: 2841.0,                last time consumption/overall running time: 511.6412s / 115531.9908 s
env0_first_0:                 episode reward: -0.1000,                 loss: -0.4429
env0_second_0:                 episode reward: 0.1000,                 loss: -0.4442
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 3821/10000 (38.2100%),                 avg. length: 2840.05,                last time consumption/overall running time: 508.5829s / 116040.5736 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.4424
env0_second_0:                 episode reward: -0.3000,                 loss: -0.4383
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 3841/10000 (38.4100%),                 avg. length: 2822.85,                last time consumption/overall running time: 510.3714s / 116550.9451 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.4443
env0_second_0:                 episode reward: 0.2500,                 loss: -0.4374
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 3861/10000 (38.6100%),                 avg. length: 2857.85,                last time consumption/overall running time: 490.9006s / 117041.8456 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.4317
env0_second_0:                 episode reward: 0.5500,                 loss: -0.4295
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3881/10000 (38.8100%),                 avg. length: 2848.1,                last time consumption/overall running time: 483.3066s / 117525.1522 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4348
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4317
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3901/10000 (39.0100%),                 avg. length: 2845.05,                last time consumption/overall running time: 478.6573s / 118003.8095 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.4324
env0_second_0:                 episode reward: -0.3000,                 loss: -0.4291
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 3921/10000 (39.2100%),                 avg. length: 2856.15,                last time consumption/overall running time: 480.2742s / 118484.0837 s
env0_first_0:                 episode reward: 1.3000,                 loss: -0.4331
env0_second_0:                 episode reward: -1.3000,                 loss: -0.4265
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3941/10000 (39.4100%),                 avg. length: 2857.45,                last time consumption/overall running time: 483.8475s / 118967.9311 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4322
env0_second_0:                 episode reward: 0.2000,                 loss: -0.4282
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 3961/10000 (39.6100%),                 avg. length: 2846.3,                last time consumption/overall running time: 483.2161s / 119451.1473 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4317
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4228
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 3981/10000 (39.8100%),                 avg. length: 2853.15,                last time consumption/overall running time: 479.7375s / 119930.8848 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.4359
env0_second_0:                 episode reward: 0.5000,                 loss: -0.4320
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 4001/10000 (40.0100%),                 avg. length: 2866.25,                last time consumption/overall running time: 489.9620s / 120420.8468 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.4349
env0_second_0:                 episode reward: -0.4000,                 loss: -0.4284
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 4021/10000 (40.2100%),                 avg. length: 2834.7,                last time consumption/overall running time: 482.7796s / 120903.6264 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4318
env0_second_0:                 episode reward: 0.0000,                 loss: -0.4231
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 4041/10000 (40.4100%),                 avg. length: 2878.85,                last time consumption/overall running time: 484.8781s / 121388.5045 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4324
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4275
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 4061/10000 (40.6100%),                 avg. length: 2890.95,                last time consumption/overall running time: 484.8631s / 121873.3676 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4261
env0_second_0:                 episode reward: 0.3500,                 loss: -0.4190
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 4081/10000 (40.8100%),                 avg. length: 2888.15,                last time consumption/overall running time: 492.2253s / 122365.5929 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.4294
env0_second_0:                 episode reward: -0.1000,                 loss: -0.4232
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 4101/10000 (41.0100%),                 avg. length: 2889.45,                last time consumption/overall running time: 485.6601s / 122851.2530 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.4363
env0_second_0:                 episode reward: -0.7500,                 loss: -0.4399
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 4121/10000 (41.2100%),                 avg. length: 2873.5,                last time consumption/overall running time: 496.1876s / 123347.4406 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.4344
env0_second_0:                 episode reward: -0.1500,                 loss: -0.4328
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4141/10000 (41.4100%),                 avg. length: 2924.35,                last time consumption/overall running time: 497.3822s / 123844.8227 s
env0_first_0:                 episode reward: 1.1000,                 loss: -0.4302
env0_second_0:                 episode reward: -1.1000,                 loss: -0.4294
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 4161/10000 (41.6100%),                 avg. length: 2847.85,                last time consumption/overall running time: 485.2496s / 124330.0724 s
env0_first_0:                 episode reward: 1.2500,                 loss: -0.4322
env0_second_0:                 episode reward: -1.2500,                 loss: -0.4330
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 4181/10000 (41.8100%),                 avg. length: 2868.55,                last time consumption/overall running time: 489.1503s / 124819.2227 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4319
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4283
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4201/10000 (42.0100%),                 avg. length: 2869.95,                last time consumption/overall running time: 489.4645s / 125308.6871 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.4269
env0_second_0:                 episode reward: -0.4000,                 loss: -0.4225
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 4221/10000 (42.2100%),                 avg. length: 2868.8,                last time consumption/overall running time: 477.3796s / 125786.0667 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.4308
env0_second_0:                 episode reward: 0.5000,                 loss: -0.4244
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 4241/10000 (42.4100%),                 avg. length: 2846.7,                last time consumption/overall running time: 472.9966s / 126259.0633 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4329
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4284
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4261/10000 (42.6100%),                 avg. length: 2864.1,                last time consumption/overall running time: 480.8732s / 126739.9365 s
env0_first_0:                 episode reward: 1.0500,                 loss: -0.4326
env0_second_0:                 episode reward: -1.0500,                 loss: -0.4278
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 4281/10000 (42.8100%),                 avg. length: 2868.6,                last time consumption/overall running time: 480.4878s / 127220.4244 s
env0_first_0:                 episode reward: 0.6500,                 loss: -0.4335
env0_second_0:                 episode reward: -0.6500,                 loss: -0.4315
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4301/10000 (43.0100%),                 avg. length: 2830.8,                last time consumption/overall running time: 469.4486s / 127689.8730 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4380
env0_second_0:                 episode reward: 0.2000,                 loss: -0.4347
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 4321/10000 (43.2100%),                 avg. length: 2856.8,                last time consumption/overall running time: 473.6080s / 128163.4810 s
env0_first_0:                 episode reward: -1.0500,                 loss: -0.4380
env0_second_0:                 episode reward: 1.0500,                 loss: -0.4315
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 4341/10000 (43.4100%),                 avg. length: 2844.45,                last time consumption/overall running time: 475.8265s / 128639.3075 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4356
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4294
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 4361/10000 (43.6100%),                 avg. length: 2853.4,                last time consumption/overall running time: 485.4038s / 129124.7113 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.4357
env0_second_0:                 episode reward: 0.7500,                 loss: -0.4293
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 4381/10000 (43.8100%),                 avg. length: 2846.1,                last time consumption/overall running time: 483.8091s / 129608.5205 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.4323
env0_second_0:                 episode reward: 0.5500,                 loss: -0.4297
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 4401/10000 (44.0100%),                 avg. length: 2828.15,                last time consumption/overall running time: 478.1473s / 130086.6677 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4306
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4221
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4421/10000 (44.2100%),                 avg. length: 2893.85,                last time consumption/overall running time: 489.3355s / 130576.0032 s
env0_first_0:                 episode reward: 0.2500,                 loss: -0.4150
env0_second_0:                 episode reward: -0.2500,                 loss: -0.4123
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4441/10000 (44.4100%),                 avg. length: 2868.65,                last time consumption/overall running time: 488.7446s / 131064.7479 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.4122
env0_second_0:                 episode reward: -0.7500,                 loss: -0.4054
env1_first_0:                 episode reward: 1.2500,                 loss: nan
env1_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 4461/10000 (44.6100%),                 avg. length: 2872.75,                last time consumption/overall running time: 477.9618s / 131542.7097 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.4192
env0_second_0:                 episode reward: -0.0500,                 loss: -0.4062
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4481/10000 (44.8100%),                 avg. length: 2822.1,                last time consumption/overall running time: 467.2576s / 132009.9673 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4223
env0_second_0:                 episode reward: 0.0500,                 loss: -0.4168
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4501/10000 (45.0100%),                 avg. length: 2829.05,                last time consumption/overall running time: 442.3715s / 132452.3388 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4201
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4154
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4521/10000 (45.2100%),                 avg. length: 2851.05,                last time consumption/overall running time: 443.8554s / 132896.1942 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4198
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4121
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4541/10000 (45.4100%),                 avg. length: 2847.65,                last time consumption/overall running time: 443.5451s / 133339.7393 s
env0_first_0:                 episode reward: 0.9500,                 loss: -0.4234
env0_second_0:                 episode reward: -0.9500,                 loss: -0.4150
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4561/10000 (45.6100%),                 avg. length: 2872.05,                last time consumption/overall running time: 450.4552s / 133790.1946 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.4187
env0_second_0:                 episode reward: -0.3000,                 loss: -0.4137
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 4581/10000 (45.8100%),                 avg. length: 2866.65,                last time consumption/overall running time: 451.2102s / 134241.4048 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4135
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4070
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4601/10000 (46.0100%),                 avg. length: 2907.05,                last time consumption/overall running time: 462.4071s / 134703.8119 s
env0_first_0:                 episode reward: 1.0000,                 loss: -0.4020
env0_second_0:                 episode reward: -1.0000,                 loss: -0.3969
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 4621/10000 (46.2100%),                 avg. length: 2848.0,                last time consumption/overall running time: 447.2196s / 135151.0314 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4147
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4086
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4641/10000 (46.4100%),                 avg. length: 2866.4,                last time consumption/overall running time: 446.0761s / 135597.1075 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4265
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4218
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4661/10000 (46.6100%),                 avg. length: 2852.95,                last time consumption/overall running time: 452.6444s / 136049.7519 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.4309
env0_second_0:                 episode reward: 0.5000,                 loss: -0.4305
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 4681/10000 (46.8100%),                 avg. length: 2837.0,                last time consumption/overall running time: 452.6309s / 136502.3828 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4340
env0_second_0:                 episode reward: 0.2000,                 loss: -0.4270
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4701/10000 (47.0100%),                 avg. length: 2838.4,                last time consumption/overall running time: 446.9225s / 136949.3053 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.4327
env0_second_0:                 episode reward: -0.1500,                 loss: -0.4282
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4721/10000 (47.2100%),                 avg. length: 2858.4,                last time consumption/overall running time: 450.5854s / 137399.8907 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.4347
env0_second_0:                 episode reward: -0.4500,                 loss: -0.4306
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4741/10000 (47.4100%),                 avg. length: 2847.75,                last time consumption/overall running time: 445.4280s / 137845.3188 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.4369
env0_second_0:                 episode reward: 0.2500,                 loss: -0.4324
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4761/10000 (47.6100%),                 avg. length: 2899.55,                last time consumption/overall running time: 454.5905s / 138299.9093 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4277
env0_second_0:                 episode reward: 0.3500,                 loss: -0.4191
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4781/10000 (47.8100%),                 avg. length: 2885.2,                last time consumption/overall running time: 452.5799s / 138752.4892 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.4248
env0_second_0:                 episode reward: -0.1500,                 loss: -0.4171
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 4801/10000 (48.0100%),                 avg. length: 2882.25,                last time consumption/overall running time: 448.3236s / 139200.8128 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4237
env0_second_0:                 episode reward: 0.1500,                 loss: -0.4173
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4821/10000 (48.2100%),                 avg. length: 2851.15,                last time consumption/overall running time: 447.1136s / 139647.9264 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4300
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4233
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4841/10000 (48.4100%),                 avg. length: 2888.15,                last time consumption/overall running time: 449.0839s / 140097.0103 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.4215
env0_second_0:                 episode reward: 0.3000,                 loss: -0.4107
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 4861/10000 (48.6100%),                 avg. length: 2828.2,                last time consumption/overall running time: 441.1902s / 140538.2005 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.4287
env0_second_0:                 episode reward: -0.7500,                 loss: -0.4177
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 4881/10000 (48.8100%),                 avg. length: 2846.9,                last time consumption/overall running time: 437.0088s / 140975.2093 s
env0_first_0:                 episode reward: -0.9500,                 loss: -0.4120
env0_second_0:                 episode reward: 0.9500,                 loss: -0.4082
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 4901/10000 (49.0100%),                 avg. length: 2848.0,                last time consumption/overall running time: 417.6546s / 141392.8639 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.4193
env0_second_0:                 episode reward: -0.4000,                 loss: -0.4146
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 4921/10000 (49.2100%),                 avg. length: 2868.0,                last time consumption/overall running time: 422.5355s / 141815.3993 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4234
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4115
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 4941/10000 (49.4100%),                 avg. length: 2848.7,                last time consumption/overall running time: 424.4110s / 142239.8103 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.4203
env0_second_0:                 episode reward: 0.7000,                 loss: -0.4119
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4961/10000 (49.6100%),                 avg. length: 2837.0,                last time consumption/overall running time: 420.7429s / 142660.5533 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4190
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4095
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4981/10000 (49.8100%),                 avg. length: 2853.7,                last time consumption/overall running time: 415.9484s / 143076.5017 s
env0_first_0:                 episode reward: 1.0500,                 loss: -0.4310
env0_second_0:                 episode reward: -1.0500,                 loss: -0.4262
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5001/10000 (50.0100%),                 avg. length: 2892.5,                last time consumption/overall running time: 426.6951s / 143503.1968 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.4269
env0_second_0:                 episode reward: -0.7500,                 loss: -0.4198
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5021/10000 (50.2100%),                 avg. length: 2869.2,                last time consumption/overall running time: 420.3887s / 143923.5854 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4276
env0_second_0:                 episode reward: 0.0500,                 loss: -0.4153
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5041/10000 (50.4100%),                 avg. length: 2853.2,                last time consumption/overall running time: 426.3721s / 144349.9576 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4184
env0_second_0:                 episode reward: 0.0500,                 loss: -0.4108
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5061/10000 (50.6100%),                 avg. length: 2835.7,                last time consumption/overall running time: 424.1216s / 144774.0792 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.4264
env0_second_0:                 episode reward: -1.1500,                 loss: -0.4210
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5081/10000 (50.8100%),                 avg. length: 2850.4,                last time consumption/overall running time: 432.2998s / 145206.3790 s
env0_first_0:                 episode reward: -0.0500,                 loss: -0.4261
env0_second_0:                 episode reward: 0.0500,                 loss: -0.4233
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 5101/10000 (51.0100%),                 avg. length: 2847.6,                last time consumption/overall running time: 418.7213s / 145625.1003 s
env0_first_0:                 episode reward: 2.2000,                 loss: -0.4257
env0_second_0:                 episode reward: -2.2000,                 loss: -0.4200
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5121/10000 (51.2100%),                 avg. length: 2884.4,                last time consumption/overall running time: 434.3866s / 146059.4869 s
env0_first_0:                 episode reward: 1.4000,                 loss: -0.4282
env0_second_0:                 episode reward: -1.4000,                 loss: -0.4246
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 5141/10000 (51.4100%),                 avg. length: 2899.3,                last time consumption/overall running time: 441.0206s / 146500.5075 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.4115
env0_second_0:                 episode reward: -0.6000,                 loss: -0.4086
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 5161/10000 (51.6100%),                 avg. length: 2845.45,                last time consumption/overall running time: 414.6677s / 146915.1752 s
env0_first_0:                 episode reward: 1.5000,                 loss: -0.4225
env0_second_0:                 episode reward: -1.5000,                 loss: -0.4171
env1_first_0:                 episode reward: 1.6000,                 loss: nan
env1_second_0:                 episode reward: -1.6000,                 loss: nan
Episode: 5181/10000 (51.8100%),                 avg. length: 2863.7,                last time consumption/overall running time: 413.0807s / 147328.2558 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.4320
env0_second_0:                 episode reward: -0.5500,                 loss: -0.4264
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 5201/10000 (52.0100%),                 avg. length: 2864.8,                last time consumption/overall running time: 424.9995s / 147753.2553 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.4297
env0_second_0:                 episode reward: -0.2000,                 loss: -0.4194
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5221/10000 (52.2100%),                 avg. length: 2828.85,                last time consumption/overall running time: 423.9897s / 148177.2451 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4361
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4188
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 5241/10000 (52.4100%),                 avg. length: 2843.25,                last time consumption/overall running time: 409.1649s / 148586.4099 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4388
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4337
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 5261/10000 (52.6100%),                 avg. length: 2873.35,                last time consumption/overall running time: 418.8028s / 149005.2127 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.4266
env0_second_0:                 episode reward: -1.1500,                 loss: -0.4182
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 5281/10000 (52.8100%),                 avg. length: 2894.9,                last time consumption/overall running time: 417.3782s / 149422.5910 s
env0_first_0:                 episode reward: 1.2500,                 loss: -0.4264
env0_second_0:                 episode reward: -1.2500,                 loss: -0.4175
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 5301/10000 (53.0100%),                 avg. length: 2906.1,                last time consumption/overall running time: 427.0529s / 149849.6439 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.4169
env0_second_0:                 episode reward: -0.5000,                 loss: -0.4089
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 5321/10000 (53.2100%),                 avg. length: 2920.0,                last time consumption/overall running time: 426.9701s / 150276.6140 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.4127
env0_second_0:                 episode reward: -0.5000,                 loss: -0.4004
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5341/10000 (53.4100%),                 avg. length: 2879.15,                last time consumption/overall running time: 418.3413s / 150694.9553 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.4229
env0_second_0:                 episode reward: -0.3000,                 loss: -0.4130
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 5361/10000 (53.6100%),                 avg. length: 2874.5,                last time consumption/overall running time: 419.2059s / 151114.1612 s
env0_first_0:                 episode reward: 1.1500,                 loss: -0.4266
env0_second_0:                 episode reward: -1.1500,                 loss: -0.4194
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 5381/10000 (53.8100%),                 avg. length: 2871.15,                last time consumption/overall running time: 419.6710s / 151533.8322 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4250
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4191
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 5401/10000 (54.0100%),                 avg. length: 2835.55,                last time consumption/overall running time: 407.7197s / 151941.5519 s
env0_first_0:                 episode reward: 0.3500,                 loss: -0.4308
env0_second_0:                 episode reward: -0.3500,                 loss: -0.4227
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 5421/10000 (54.2100%),                 avg. length: 2845.35,                last time consumption/overall running time: 418.3634s / 152359.9153 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4346
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4242
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 5441/10000 (54.4100%),                 avg. length: 2862.2,                last time consumption/overall running time: 419.6565s / 152779.5718 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4285
env0_second_0:                 episode reward: 0.1500,                 loss: -0.4226
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 5461/10000 (54.6100%),                 avg. length: 2866.3,                last time consumption/overall running time: 422.9121s / 153202.4839 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.4250
env0_second_0:                 episode reward: 0.6000,                 loss: -0.4146
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5481/10000 (54.8100%),                 avg. length: 2882.4,                last time consumption/overall running time: 427.7665s / 153630.2504 s
env0_first_0:                 episode reward: 1.6000,                 loss: -0.4200
env0_second_0:                 episode reward: -1.6000,                 loss: -0.4099
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 5501/10000 (55.0100%),                 avg. length: 2871.85,                last time consumption/overall running time: 422.4184s / 154052.6688 s
env0_first_0:                 episode reward: 0.8500,                 loss: -0.4187
env0_second_0:                 episode reward: -0.8500,                 loss: -0.4131
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5521/10000 (55.2100%),                 avg. length: 2906.65,                last time consumption/overall running time: 427.7273s / 154480.3962 s
env0_first_0:                 episode reward: 1.5000,                 loss: -0.4128
env0_second_0:                 episode reward: -1.5000,                 loss: -0.4058
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 5541/10000 (55.4100%),                 avg. length: 2914.9,                last time consumption/overall running time: 428.3348s / 154908.7309 s
env0_first_0:                 episode reward: -0.3500,                 loss: -0.4076
env0_second_0:                 episode reward: 0.3500,                 loss: -0.3992
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 5561/10000 (55.6100%),                 avg. length: 2883.25,                last time consumption/overall running time: 426.0845s / 155334.8154 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.4175
env0_second_0:                 episode reward: -0.7000,                 loss: -0.4108
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5581/10000 (55.8100%),                 avg. length: 2927.25,                last time consumption/overall running time: 432.5462s / 155767.3617 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.4075
env0_second_0:                 episode reward: -0.4000,                 loss: -0.4023
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5601/10000 (56.0100%),                 avg. length: 2896.35,                last time consumption/overall running time: 429.5318s / 156196.8935 s
env0_first_0:                 episode reward: 2.0000,                 loss: -0.4122
env0_second_0:                 episode reward: -2.0000,                 loss: -0.4060
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 5621/10000 (56.2100%),                 avg. length: 2904.2,                last time consumption/overall running time: 425.6640s / 156622.5575 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.4158
env0_second_0:                 episode reward: -0.5000,                 loss: -0.4082
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5641/10000 (56.4100%),                 avg. length: 2862.1,                last time consumption/overall running time: 421.3338s / 157043.8913 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.4303
env0_second_0:                 episode reward: 0.2000,                 loss: -0.4167
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5661/10000 (56.6100%),                 avg. length: 2867.9,                last time consumption/overall running time: 422.7502s / 157466.6415 s
env0_first_0:                 episode reward: 0.9000,                 loss: -0.4245
env0_second_0:                 episode reward: -0.9000,                 loss: -0.4130
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 5681/10000 (56.8100%),                 avg. length: 2910.25,                last time consumption/overall running time: 425.3137s / 157891.9552 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.4178
env0_second_0:                 episode reward: 0.0000,                 loss: -0.4080
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 5701/10000 (57.0100%),                 avg. length: 2909.25,                last time consumption/overall running time: 425.1955s / 158317.1507 s
env0_first_0:                 episode reward: -0.7500,                 loss: -0.4177
env0_second_0:                 episode reward: 0.7500,                 loss: -0.4079