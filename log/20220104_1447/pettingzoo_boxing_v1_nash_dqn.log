pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 50
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f522c300e50>
No agent are not learnable.
{'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'multiprocess': True}
pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
<mars.rl.agents.multiagent.MultiAgent object at 0x7efc8a29d450>
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 94
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'multiprocess': True}
Save models to : /home/zihan/research/MARS/data/model/0/pettingzoo_boxing_v1_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/0/pettingzoo_boxing_v1_nash_dqn.
Process ID: 0, episode: 20/10000 (0.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 280.2891s / 280.2891 s
first_0:                     episode reward: -3.0500
second_0:                     episode reward: 3.0500
Process ID: 0, episode: 40/10000 (0.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 458.4896s / 738.7787 s
first_0:                     episode reward: -0.7500
second_0:                     episode reward: 0.7500
Process ID: 0, episode: 60/10000 (0.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 492.9519s / 1231.7306 s
first_0:                     episode reward: -3.5000
second_0:                     episode reward: 3.5000
Process ID: 0, episode: 80/10000 (0.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 501.3525s / 1733.0831 s
first_0:                     episode reward: -0.3000
second_0:                     episode reward: 0.3000
Process ID: 0, episode: 100/10000 (1.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 504.0115s / 2237.0946 s
first_0:                     episode reward: -1.4000
second_0:                     episode reward: 1.4000
Process ID: 0, episode: 120/10000 (1.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 508.3594s / 2745.4539 s
first_0:                     episode reward: -1.3000
second_0:                     episode reward: 1.3000
Process ID: 0, episode: 140/10000 (1.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 506.2930s / 3251.7470 s
first_0:                     episode reward: -0.7000
second_0:                     episode reward: 0.7000
Process ID: 0, episode: 160/10000 (1.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 510.4392s / 3762.1862 s
first_0:                     episode reward: 1.5000
second_0:                     episode reward: -1.5000
Process ID: 0, episode: 180/10000 (1.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.1035s / 4269.2897 s
first_0:                     episode reward: -2.2500
second_0:                     episode reward: 2.2500
Process ID: 0, episode: 200/10000 (2.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 502.8662s / 4772.1559 s
first_0:                     episode reward: -0.4500
second_0:                     episode reward: 0.4500
Process ID: 0, episode: 220/10000 (2.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 504.9248s / 5277.0807 s
first_0:                     episode reward: -3.6500
second_0:                     episode reward: 3.6500
Process ID: 0, episode: 240/10000 (2.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 506.7144s / 5783.7951 s
first_0:                     episode reward: -1.3000
second_0:                     episode reward: 1.3000
Process ID: 0, episode: 260/10000 (2.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 505.9867s / 6289.7819 s
first_0:                     episode reward: -1.3000
second_0:                     episode reward: 1.3000
Process ID: 0, episode: 280/10000 (2.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 512.1745s / 6801.9564 s
first_0:                     episode reward: 1.0500
second_0:                     episode reward: -1.0500
Process ID: 0, episode: 300/10000 (3.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 503.8533s / 7305.8097 s
first_0:                     episode reward: -0.7000
second_0:                     episode reward: 0.7000
Process ID: 0, episode: 320/10000 (3.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 506.7241s / 7812.5338 s
first_0:                     episode reward: 0.3000
second_0:                     episode reward: -0.3000
Process ID: 0, episode: 340/10000 (3.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 503.8773s / 8316.4111 s
first_0:                     episode reward: -1.8500
second_0:                     episode reward: 1.8500
Process ID: 0, episode: 360/10000 (3.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.4359s / 8825.8470 s
first_0:                     episode reward: -0.3000
second_0:                     episode reward: 0.3000
Process ID: 0, episode: 380/10000 (3.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 508.6142s / 9334.4612 s
first_0:                     episode reward: 0.3500
second_0:                     episode reward: -0.3500
Process ID: 0, episode: 400/10000 (4.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 503.8599s / 9838.3211 s
first_0:                     episode reward: -1.0000
second_0:                     episode reward: 1.0000
Process ID: 0, episode: 420/10000 (4.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 508.6015s / 10346.9225 s
first_0:                     episode reward: 1.4000
second_0:                     episode reward: -1.4000
Process ID: 0, episode: 440/10000 (4.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 510.5208s / 10857.4433 s
first_0:                     episode reward: -4.7500
second_0:                     episode reward: 4.7500
Process ID: 0, episode: 460/10000 (4.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 502.9080s / 11360.3513 s
first_0:                     episode reward: -1.7500
second_0:                     episode reward: 1.7500
Process ID: 0, episode: 480/10000 (4.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 508.1193s / 11868.4706 s
first_0:                     episode reward: -0.3000
second_0:                     episode reward: 0.3000
Process ID: 0, episode: 500/10000 (5.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 504.7562s / 12373.2268 spygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
<mars.rl.agents.multiagent.MultiAgent object at 0x7efc8a29d410>
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 33
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'multiprocess': True}
Save models to : /home/zihan/research/MARS/data/model/1/pettingzoo_boxing_v1_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/1/pettingzoo_boxing_v1_nash_dqn.
Process ID: 1, episode: 20/10000 (0.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 281.3984s / 281.3984 s
first_0:                     episode reward: -3.1000
second_0:                     episode reward: 3.1000
Process ID: 1, episode: 40/10000 (0.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 456.8093s / 738.2077 s
first_0:                     episode reward: 0.5500
second_0:                     episode reward: -0.5500
Process ID: 1, episode: 60/10000 (0.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 498.7205s / 1236.9282 s
first_0:                     episode reward: 1.0000
second_0:                     episode reward: -1.0000
Process ID: 1, episode: 80/10000 (0.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 498.4294s / 1735.3576 s
first_0:                     episode reward: -1.2000
second_0:                     episode reward: 1.2000
Process ID: 1, episode: 100/10000 (1.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 506.6214s / 2241.9789 s
first_0:                     episode reward: -2.8000
second_0:                     episode reward: 2.8000
Process ID: 1, episode: 120/10000 (1.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 508.1119s / 2750.0908 s
first_0:                     episode reward: -0.4500
second_0:                     episode reward: 0.4500
Process ID: 1, episode: 140/10000 (1.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.8557s / 3259.9465 s
first_0:                     episode reward: -0.1500
second_0:                     episode reward: 0.1500
Process ID: 1, episode: 160/10000 (1.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.4266s / 3769.3730 s
first_0:                     episode reward: -1.3500
second_0:                     episode reward: 1.3500
Process ID: 1, episode: 180/10000 (1.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 508.8864s / 4278.2594 s
first_0:                     episode reward: -2.3500
second_0:                     episode reward: 2.3500
Process ID: 1, episode: 200/10000 (2.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.6594s / 4787.9188 s
first_0:                     episode reward: -1.9000
second_0:                     episode reward: 1.9000
Process ID: 1, episode: 220/10000 (2.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 510.2369s / 5298.1558 s
first_0:                     episode reward: -3.3500
second_0:                     episode reward: 3.3500
Process ID: 1, episode: 240/10000 (2.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 508.5057s / 5806.6614 s
first_0:                     episode reward: -3.4500
second_0:                     episode reward: 3.4500
Process ID: 1, episode: 260/10000 (2.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.0922s / 6315.7536 s
first_0:                     episode reward: -0.4500
second_0:                     episode reward: 0.4500
Process ID: 1, episode: 280/10000 (2.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 506.7610s / 6822.5146 s
first_0:                     episode reward: -0.7500
second_0:                     episode reward: 0.7500
Process ID: 1, episode: 300/10000 (3.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.1062s / 7329.6208 s
first_0:                     episode reward: -1.7500
second_0:                     episode reward: 1.7500
Process ID: 1, episode: 320/10000 (3.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.3145s / 7836.9353 s
first_0:                     episode reward: -1.0500
second_0:                     episode reward: 1.0500
Process ID: 1, episode: 340/10000 (3.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.6604s / 8344.5958 s
first_0:                     episode reward: 0.2500
second_0:                     episode reward: -0.2500
Process ID: 1, episode: 360/10000 (3.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.0084s / 8851.6042 s
first_0:                     episode reward: 2.8000
second_0:                     episode reward: -2.8000
Process ID: 1, episode: 380/10000 (3.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 509.9543s / 9361.5584 s
first_0:                     episode reward: -1.5000
second_0:                     episode reward: 1.5000
Process ID: 1, episode: 400/10000 (4.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 506.4464s / 9868.0048 s
first_0:                     episode reward: -0.5000
second_0:                     episode reward: 0.5000
Process ID: 1, episode: 420/10000 (4.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.8468s / 10375.8516 s
first_0:                     episode reward: 0.4000
second_0:                     episode reward: -0.4000
Process ID: 1, episode: 440/10000 (4.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 506.4406s / 10882.2922 s
first_0:                     episode reward: -0.5000
second_0:                     episode reward: 0.5000
Process ID: 1, episode: 460/10000 (4.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 506.6635s / 11388.9557 s
first_0:                     episode reward: -1.6500
second_0:                     episode reward: 1.6500
Process ID: 1, episode: 480/10000 (4.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 508.3369s / 11897.2925 s
first_0:                     episode reward: -1.9500
second_0:                     episode reward: 1.9500
Process ID: 1, episode: 500/10000 (5.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 507.8654s / 12405.1580 s