pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
random seed: 30
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7fb0692ed9d0>
No agent are not learnable.
{'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'multiprocess': True}
pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
<mars.rl.agents.multiagent.MultiAgent object at 0x7f132b0a9190>
pong_v2 pettingzoo
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
random seed: 67
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'multiprocess': True}
Save models to : /home/zihan/research/MARS/data/model/1/pettingzoo_pong_v2_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/1/pettingzoo_pong_v2_nash_dqn.
Process ID: 1, episode: 20/10000 (0.2000%),                     avg. length: 1404.2,                    last time consumption/overall running time: 175.6603s / 175.6603 s
first_0:                     episode reward: 5.4000
second_0:                     episode reward: -5.4000
Process ID: 1, episode: 40/10000 (0.4000%),                     avg. length: 1349.65,                    last time consumption/overall running time: 277.8395s / 453.4998 s
first_0:                     episode reward: 4.1500
second_0:                     episode reward: -4.1500
Process ID: 1, episode: 60/10000 (0.6000%),                     avg. length: 1388.8,                    last time consumption/overall running time: 308.2481s / 761.7478 s
first_0:                     episode reward: 0.4500
second_0:                     episode reward: -0.4500
Process ID: 1, episode: 80/10000 (0.8000%),                     avg. length: 1373.25,                    last time consumption/overall running time: 314.6655s / 1076.4133 s
first_0:                     episode reward: 0.7000
second_0:                     episode reward: -0.7000
Process ID: 1, episode: 100/10000 (1.0000%),                     avg. length: 1390.8,                    last time consumption/overall running time: 341.5941s / 1418.0073 s
first_0:                     episode reward: 3.4500
second_0:                     episode reward: -3.4500
Process ID: 1, episode: 120/10000 (1.2000%),                     avg. length: 1393.75,                    last time consumption/overall running time: 343.7578s / 1761.7652 s
first_0:                     episode reward: 2.2000
second_0:                     episode reward: -2.2000
Process ID: 1, episode: 140/10000 (1.4000%),                     avg. length: 1238.2,                    last time consumption/overall running time: 309.8864s / 2071.6516 s
first_0:                     episode reward: -3.0500
second_0:                     episode reward: 3.0500
Process ID: 1, episode: 160/10000 (1.6000%),                     avg. length: 1366.0,                    last time consumption/overall running time: 342.6550s / 2414.3066 s
first_0:                     episode reward: 2.9500
second_0:                     episode reward: -2.9500
Process ID: 1, episode: 180/10000 (1.8000%),                     avg. length: 1272.15,                    last time consumption/overall running time: 313.2942s / 2727.6008 s
first_0:                     episode reward: 3.5500
second_0:                     episode reward: -3.5500
Process ID: 1, episode: 200/10000 (2.0000%),                     avg. length: 1296.4,                    last time consumption/overall running time: 326.5506s / 3054.1514 s
first_0:                     episode reward: 2.6000
second_0:                     episode reward: -2.6000
Process ID: 1, episode: 220/10000 (2.2000%),                     avg. length: 1353.75,                    last time consumption/overall running time: 337.0772s / 3391.2286 s
first_0:                     episode reward: 2.7000
second_0:                     episode reward: -2.7000
Process ID: 1, episode: 240/10000 (2.4000%),                     avg. length: 1256.35,                    last time consumption/overall running time: 314.2234s / 3705.4520 s
first_0:                     episode reward: 5.7500
second_0:                     episode reward: -5.7500
Process ID: 1, episode: 260/10000 (2.6000%),                     avg. length: 1321.25,                    last time consumption/overall running time: 326.6025s / 4032.0545 s
first_0:                     episode reward: 1.1500
second_0:                     episode reward: -1.1500
Process ID: 1, episode: 280/10000 (2.8000%),                     avg. length: 1361.7,                    last time consumption/overall running time: 337.6210s / 4369.6755 s
first_0:                     episode reward: -2.7000
second_0:                     episode reward: 2.7000
Process ID: 1, episode: 300/10000 (3.0000%),                     avg. length: 1356.0,                    last time consumption/overall running time: 339.5789s / 4709.2545 s
first_0:                     episode reward: 1.3000
second_0:                     episode reward: -1.3000
Process ID: 1, episode: 320/10000 (3.2000%),                     avg. length: 1221.8,                    last time consumption/overall running time: 303.9774s / 5013.2318 s
first_0:                     episode reward: -1.3000
second_0:                     episode reward: 1.3000
Process ID: 1, episode: 340/10000 (3.4000%),                     avg. length: 1312.95,                    last time consumption/overall running time: 325.0308s / 5338.2626 s
first_0:                     episode reward: 7.0000
second_0:                     episode reward: -7.0000
Process ID: 1, episode: 360/10000 (3.6000%),                     avg. length: 1330.25,                    last time consumption/overall running time: 333.0442s / 5671.3068 s
first_0:                     episode reward: 3.5500
second_0:                     episode reward: -3.5500
Process ID: 1, episode: 380/10000 (3.8000%),                     avg. length: 1390.4,                    last time consumption/overall running time: 352.0572s / 6023.3640 s
first_0:                     episode reward: -2.1000
second_0:                     episode reward: 2.1000
Process ID: 1, episode: 400/10000 (4.0000%),                     avg. length: 1294.55,                    last time consumption/overall running time: 328.8016s / 6352.1656 s
first_0:                     episode reward: 2.8000
second_0:                     episode reward: -2.8000
Process ID: 1, episode: 420/10000 (4.2000%),                     avg. length: 1306.7,                    last time consumption/overall running time: 322.1077s / 6674.2733 s
first_0:                     episode reward: 0.5500
second_0:                     episode reward: -0.5500
Process ID: 1, episode: 440/10000 (4.4000%),                     avg. length: 1269.3,                    last time consumption/overall running time: 310.7595s / 6985.0328 s
first_0:                     episode reward: 1.6500
second_0:                     episode reward: -1.6500
Process ID: 1, episode: 460/10000 (4.6000%),                     avg. length: 1323.15,                    last time consumption/overall running time: 329.6783s / 7314.7110 s
first_0:                     episode reward: 2.6000
second_0:                     episode reward: -2.6000
Process ID: 1, episode: 480/10000 (4.8000%),                     avg. length: 1412.1,                    last time consumption/overall running time: 349.9190s / 7664.6300 s
first_0:                     episode reward: 1.6000
second_0:                     episode reward: -1.6000
Process ID: 1, episode: 500/10000 (5.0000%),                     avg. length: 1311.7,                    last time consumption/overall running time: 323.5329s / 7988.1629 spygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
<mars.rl.agents.multiagent.MultiAgent object at 0x7f132b0a9190>
pong_v2 pettingzoo
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
random seed: 27
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'multiprocess': True}
Save models to : /home/zihan/research/MARS/data/model/0/pettingzoo_pong_v2_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/0/pettingzoo_pong_v2_nash_dqn.
Process ID: 0, episode: 20/10000 (0.2000%),                     avg. length: 1289.3,                    last time consumption/overall running time: 154.1770s / 154.1770 s
first_0:                     episode reward: -1.6500
second_0:                     episode reward: 1.6500
Process ID: 0, episode: 40/10000 (0.4000%),                     avg. length: 1379.65,                    last time consumption/overall running time: 282.2442s / 436.4212 s
first_0:                     episode reward: 0.1500
second_0:                     episode reward: -0.1500
Process ID: 0, episode: 60/10000 (0.6000%),                     avg. length: 1376.4,                    last time consumption/overall running time: 305.3644s / 741.7856 s
first_0:                     episode reward: 1.2000
second_0:                     episode reward: -1.2000
Process ID: 0, episode: 80/10000 (0.8000%),                     avg. length: 1449.1,                    last time consumption/overall running time: 334.9694s / 1076.7550 s
first_0:                     episode reward: -0.5000
second_0:                     episode reward: 0.5000
Process ID: 0, episode: 100/10000 (1.0000%),                     avg. length: 1346.65,                    last time consumption/overall running time: 332.7506s / 1409.5056 s
first_0:                     episode reward: 5.0000
second_0:                     episode reward: -5.0000
Process ID: 0, episode: 120/10000 (1.2000%),                     avg. length: 1431.25,                    last time consumption/overall running time: 357.5342s / 1767.0398 s
first_0:                     episode reward: 2.2000
second_0:                     episode reward: -2.2000
Process ID: 0, episode: 140/10000 (1.4000%),                     avg. length: 1279.4,                    last time consumption/overall running time: 321.4433s / 2088.4830 s
first_0:                     episode reward: 0.4500
second_0:                     episode reward: -0.4500
Process ID: 0, episode: 160/10000 (1.6000%),                     avg. length: 1285.95,                    last time consumption/overall running time: 323.2801s / 2411.7631 s
first_0:                     episode reward: -0.6500
second_0:                     episode reward: 0.6500
Process ID: 0, episode: 180/10000 (1.8000%),                     avg. length: 1380.2,                    last time consumption/overall running time: 343.2939s / 2755.0570 s
first_0:                     episode reward: 0.9000
second_0:                     episode reward: -0.9000
Process ID: 0, episode: 200/10000 (2.0000%),                     avg. length: 1291.85,                    last time consumption/overall running time: 317.5047s / 3072.5617 s
first_0:                     episode reward: 0.5500
second_0:                     episode reward: -0.5500
Process ID: 0, episode: 220/10000 (2.2000%),                     avg. length: 1367.9,                    last time consumption/overall running time: 340.4411s / 3413.0029 s
first_0:                     episode reward: -2.1000
second_0:                     episode reward: 2.1000
Process ID: 0, episode: 240/10000 (2.4000%),                     avg. length: 1323.85,                    last time consumption/overall running time: 330.9888s / 3743.9917 s
first_0:                     episode reward: 0.9000
second_0:                     episode reward: -0.9000
Process ID: 0, episode: 260/10000 (2.6000%),                     avg. length: 1365.55,                    last time consumption/overall running time: 338.1567s / 4082.1484 s
first_0:                     episode reward: -0.2000
second_0:                     episode reward: 0.2000
Process ID: 0, episode: 280/10000 (2.8000%),                     avg. length: 1367.95,                    last time consumption/overall running time: 335.5336s / 4417.6820 s
first_0:                     episode reward: 3.4500
second_0:                     episode reward: -3.4500
Process ID: 0, episode: 300/10000 (3.0000%),                     avg. length: 1465.6,                    last time consumption/overall running time: 365.0785s / 4782.7605 s
first_0:                     episode reward: 0.6500
second_0:                     episode reward: -0.6500
Process ID: 0, episode: 320/10000 (3.2000%),                     avg. length: 1401.6,                    last time consumption/overall running time: 349.9453s / 5132.7057 s
first_0:                     episode reward: 2.4500
second_0:                     episode reward: -2.4500
Process ID: 0, episode: 340/10000 (3.4000%),                     avg. length: 1265.45,                    last time consumption/overall running time: 317.9624s / 5450.6682 s
first_0:                     episode reward: -1.3500
second_0:                     episode reward: 1.3500
Process ID: 0, episode: 360/10000 (3.6000%),                     avg. length: 1345.55,                    last time consumption/overall running time: 330.8854s / 5781.5535 s
first_0:                     episode reward: 0.5500
second_0:                     episode reward: -0.5500
Process ID: 0, episode: 380/10000 (3.8000%),                     avg. length: 1481.4,                    last time consumption/overall running time: 365.7269s / 6147.2804 s
first_0:                     episode reward: -1.7500
second_0:                     episode reward: 1.7500
Process ID: 0, episode: 400/10000 (4.0000%),                     avg. length: 1441.85,                    last time consumption/overall running time: 362.5046s / 6509.7850 s
first_0:                     episode reward: 0.5000
second_0:                     episode reward: -0.5000
Process ID: 0, episode: 420/10000 (4.2000%),                     avg. length: 1368.95,                    last time consumption/overall running time: 341.3242s / 6851.1092 s
first_0:                     episode reward: 0.7000
second_0:                     episode reward: -0.7000
Process ID: 0, episode: 440/10000 (4.4000%),                     avg. length: 1368.45,                    last time consumption/overall running time: 344.7231s / 7195.8323 s
first_0:                     episode reward: 1.6000
second_0:                     episode reward: -1.6000
Process ID: 0, episode: 460/10000 (4.6000%),                     avg. length: 1221.1,                    last time consumption/overall running time: 304.5264s / 7500.3587 s
first_0:                     episode reward: 2.2500
second_0:                     episode reward: -2.2500
Process ID: 0, episode: 480/10000 (4.8000%),                     avg. length: 1294.55,                    last time consumption/overall running time: 321.2159s / 7821.5747 s
first_0:                     episode reward: 5.2500
second_0:                     episode reward: -5.2500
Process ID: 0, episode: 500/10000 (5.0000%),                     avg. length: 1352.1,                    last time consumption/overall running time: 339.6724s / 8161.2471 s
first_0:                     episode reward: -1.3500
second_0:                     episode reward: 1.3500
Process ID: 1, episode: 520/10000 (5.2000%),                     avg. length: 1406.6,                    last time consumption/overall running time: 348.8728s / 8337.0357 s
first_0:                     episode reward: -2.3500
second_0:                     episode reward: 2.3500
Process ID: 1, episode: 540/10000 (5.4000%),                     avg. length: 1282.0,                    last time consumption/overall running time: 321.0681s / 8658.1038 s
first_0:                     episode reward: 6.7000
second_0:                     episode reward: -6.7000
Process ID: 1, episode: 560/10000 (5.6000%),                     avg. length: 1338.35,                    last time consumption/overall running time: 338.5034s / 8996.6072 s
first_0:                     episode reward: -6.6500
second_0:                     episode reward: 6.6500
Process ID: 1, episode: 580/10000 (5.8000%),                     avg. length: 1225.2,                    last time consumption/overall running time: 304.7928s / 9301.4000 s
first_0:                     episode reward: 7.9500
second_0:                     episode reward: -7.9500
Process ID: 1, episode: 600/10000 (6.0000%),                     avg. length: 1259.0,                    last time consumption/overall running time: 308.6676s / 9610.0676 s
first_0:                     episode reward: 6.4000
second_0:                     episode reward: -6.4000
Process ID: 1, episode: 620/10000 (6.2000%),                     avg. length: 1353.95,                    last time consumption/overall running time: 335.2843s / 9945.3520 s
first_0:                     episode reward: 2.7500
second_0:                     episode reward: -2.7500
Process ID: 1, episode: 640/10000 (6.4000%),                     avg. length: 1339.95,                    last time consumption/overall running time: 330.3497s / 10275.7017 s
first_0:                     episode reward: 4.7500
second_0:                     episode reward: -4.7500
Process ID: 1, episode: 660/10000 (6.6000%),                     avg. length: 1362.55,                    last time consumption/overall running time: 340.0681s / 10615.7697 s
first_0:                     episode reward: 0.7500
second_0:                     episode reward: -0.7500
Process ID: 1, episode: 680/10000 (6.8000%),                     avg. length: 1341.6,                    last time consumption/overall running time: 332.3102s / 10948.0799 s
first_0:                     episode reward: 3.1500
second_0:                     episode reward: -3.1500
Process ID: 1, episode: 700/10000 (7.0000%),                     avg. length: 1280.8,                    last time consumption/overall running time: 323.3446s / 11271.4245 s
first_0:                     episode reward: 4.6000
second_0:                     episode reward: -4.6000
Process ID: 1, episode: 720/10000 (7.2000%),                     avg. length: 1288.0,                    last time consumption/overall running time: 320.4925s / 11591.9169 s
first_0:                     episode reward: 3.6000
second_0:                     episode reward: -3.6000
Process ID: 1, episode: 740/10000 (7.4000%),                     avg. length: 1354.1,                    last time consumption/overall running time: 338.6976s / 11930.6146 s
first_0:                     episode reward: 0.4000
second_0:                     episode reward: -0.4000
Process ID: 1, episode: 760/10000 (7.6000%),                     avg. length: 1306.8,                    last time consumption/overall running time: 329.7953s / 12260.4098 s
first_0:                     episode reward: -2.3000
second_0:                     episode reward: 2.3000
Process ID: 1, episode: 780/10000 (7.8000%),                     avg. length: 1298.0,                    last time consumption/overall running time: 325.4479s / 12585.8577 s
first_0:                     episode reward: 2.6500
second_0:                     episode reward: -2.6500
Process ID: 1, episode: 800/10000 (8.0000%),                     avg. length: 1307.7,                    last time consumption/overall running time: 325.1403s / 12910.9980 s
first_0:                     episode reward: 6.8500
second_0:                     episode reward: -6.8500
Process ID: 1, episode: 820/10000 (8.2000%),                     avg. length: 1490.5,                    last time consumption/overall running time: 366.8260s / 13277.8240 s
first_0:                     episode reward: -0.3000
second_0:                     episode reward: 0.3000
Process ID: 1, episode: 840/10000 (8.4000%),                     avg. length: 1318.75,                    last time consumption/overall running time: 328.7638s / 13606.5878 s
first_0:                     episode reward: 2.2000
second_0:                     episode reward: -2.2000
Process ID: 1, episode: 860/10000 (8.6000%),                     avg. length: 1315.15,                    last time consumption/overall running time: 324.8453s / 13931.4331 s
first_0:                     episode reward: -0.1500
second_0:                     episode reward: 0.1500
Process ID: 1, episode: 880/10000 (8.8000%),                     avg. length: 1431.45,                    last time consumption/overall running time: 363.5685s / 14295.0016 s
first_0:                     episode reward: 0.4500
second_0:                     episode reward: -0.4500
Process ID: 1, episode: 900/10000 (9.0000%),                     avg. length: 1385.1,                    last time consumption/overall running time: 345.7035s / 14640.7051 s
first_0:                     episode reward: 0.3500
second_0:                     episode reward: -0.3500
Process ID: 1, episode: 920/10000 (9.2000%),                     avg. length: 1260.4,                    last time consumption/overall running time: 314.8062s / 14955.5113 s
first_0:                     episode reward: 5.7000
second_0:                     episode reward: -5.7000
Process ID: 1, episode: 940/10000 (9.4000%),                     avg. length: 1262.55,                    last time consumption/overall running time: 313.2107s / 15268.7220 s
first_0:                     episode reward: 4.7500
second_0:                     episode reward: -4.7500
Process ID: 1, episode: 960/10000 (9.6000%),                     avg. length: 1339.55,                    last time consumption/overall running time: 334.4895s / 15603.2115 s
first_0:                     episode reward: 2.0500
second_0:                     episode reward: -2.0500
Process ID: 1, episode: 980/10000 (9.8000%),                     avg. length: 1374.65,                    last time consumption/overall running time: 340.7221s / 15943.9336 s
first_0:                     episode reward: 0.3500
second_0:                     episode reward: -0.3500
Process ID: 1, episode: 1000/10000 (10.0000%),                     avg. length: 1435.95,                    last time consumption/overall running time: 356.8359s / 16300.7694 s
first_0:                     episode reward: 1.7500
second_0:                     episode reward: -1.7500
Process ID: 1, episode: 1020/10000 (10.2000%),                     avg. length: 1312.65,                    last time consumption/overall running time: 330.7303s / 16631.4998 s
first_0:                     episode reward: 3.5500
second_0:                     episode reward: -3.5500
Process ID: 1, episode: 1040/10000 (10.4000%),                     avg. length: 1390.6,                    last time consumption/overall running time: 346.2290s / 16977.7288 s
first_0:                     episode reward: -5.0500
second_0:                     episode reward: 5.0500
Process ID: 1, episode: 1060/10000 (10.6000%),                     avg. length: 1365.85,                    last time consumption/overall running time: 344.9107s / 17322.6395 s
first_0:                     episode reward: -0.2000
second_0:                     episode reward: 0.2000
Process ID: 1, episode: 1080/10000 (10.8000%),                     avg. length: 1310.55,                    last time consumption/overall running time: 326.0599s / 17648.6994 s
first_0:                     episode reward: 6.7000
second_0:                     episode reward: -6.7000
first_0:                     episode reward: -3.5000
second_0:                     episode reward: 3.5000
Process ID: 0, episode: 520/10000 (5.2000%),                     avg. length: 1448.4,                    last time consumption/overall running time: 359.1985s / 8520.4456 s
first_0:                     episode reward: -2.3000
second_0:                     episode reward: 2.3000
Process ID: 0, episode: 540/10000 (5.4000%),                     avg. length: 1288.55,                    last time consumption/overall running time: 323.4407s / 8843.8863 s
first_0:                     episode reward: 1.4000
second_0:                     episode reward: -1.4000
Process ID: 0, episode: 560/10000 (5.6000%),                     avg. length: 1367.15,                    last time consumption/overall running time: 341.1300s / 9185.0163 s
first_0:                     episode reward: -2.4000
second_0:                     episode reward: 2.4000
Process ID: 0, episode: 580/10000 (5.8000%),                     avg. length: 1338.05,                    last time consumption/overall running time: 336.6575s / 9521.6738 s
first_0:                     episode reward: 1.2000
second_0:                     episode reward: -1.2000
Process ID: 0, episode: 600/10000 (6.0000%),                     avg. length: 1300.9,                    last time consumption/overall running time: 324.8418s / 9846.5156 s
first_0:                     episode reward: 4.4000
second_0:                     episode reward: -4.4000
Process ID: 0, episode: 620/10000 (6.2000%),                     avg. length: 1262.55,                    last time consumption/overall running time: 314.2528s / 10160.7684 s
first_0:                     episode reward: 3.3000
second_0:                     episode reward: -3.3000
Process ID: 0, episode: 640/10000 (6.4000%),                     avg. length: 1379.15,                    last time consumption/overall running time: 347.7798s / 10508.5482 s
first_0:                     episode reward: -2.3000
second_0:                     episode reward: 2.3000
Process ID: 0, episode: 660/10000 (6.6000%),                     avg. length: 1389.2,                    last time consumption/overall running time: 347.5988s / 10856.1470 s
first_0:                     episode reward: -1.8000
second_0:                     episode reward: 1.8000
Process ID: 0, episode: 680/10000 (6.8000%),                     avg. length: 1327.15,                    last time consumption/overall running time: 329.8339s / 11185.9810 s
first_0:                     episode reward: 4.5500
second_0:                     episode reward: -4.5500
Process ID: 0, episode: 700/10000 (7.0000%),                     avg. length: 1337.45,                    last time consumption/overall running time: 336.7515s / 11522.7325 s
first_0:                     episode reward: -0.1500
second_0:                     episode reward: 0.1500
Process ID: 0, episode: 720/10000 (7.2000%),                     avg. length: 1368.7,                    last time consumption/overall running time: 339.8325s / 11862.5650 s
first_0:                     episode reward: 1.6000
second_0:                     episode reward: -1.6000
Process ID: 0, episode: 740/10000 (7.4000%),                     avg. length: 1336.9,                    last time consumption/overall running time: 334.6042s / 12197.1691 s
first_0:                     episode reward: 0.5000
second_0:                     episode reward: -0.5000
Process ID: 0, episode: 760/10000 (7.6000%),                     avg. length: 1206.35,                    last time consumption/overall running time: 307.2149s / 12504.3840 s
first_0:                     episode reward: 3.8000
second_0:                     episode reward: -3.8000
Process ID: 0, episode: 780/10000 (7.8000%),                     avg. length: 1341.75,                    last time consumption/overall running time: 332.7816s / 12837.1656 s
first_0:                     episode reward: -0.7500
second_0:                     episode reward: 0.7500
Process ID: 0, episode: 800/10000 (8.0000%),                     avg. length: 1226.95,                    last time consumption/overall running time: 305.8921s / 13143.0577 s
first_0:                     episode reward: 3.0000
second_0:                     episode reward: -3.0000
Process ID: 0, episode: 820/10000 (8.2000%),                     avg. length: 1306.9,                    last time consumption/overall running time: 329.8087s / 13472.8664 s
first_0:                     episode reward: 6.9000
second_0:                     episode reward: -6.9000
Process ID: 0, episode: 840/10000 (8.4000%),                     avg. length: 1258.75,                    last time consumption/overall running time: 315.1607s / 13788.0271 s
first_0:                     episode reward: 0.3500
second_0:                     episode reward: -0.3500
Process ID: 0, episode: 860/10000 (8.6000%),                     avg. length: 1335.4,                    last time consumption/overall running time: 330.5807s / 14118.6079 s
first_0:                     episode reward: 5.2500
second_0:                     episode reward: -5.2500
Process ID: 0, episode: 880/10000 (8.8000%),                     avg. length: 1355.5,                    last time consumption/overall running time: 336.6669s / 14455.2748 s
first_0:                     episode reward: 0.6500
second_0:                     episode reward: -0.6500
Process ID: 0, episode: 900/10000 (9.0000%),                     avg. length: 1304.3,                    last time consumption/overall running time: 324.5174s / 14779.7922 s
first_0:                     episode reward: -0.1500
second_0:                     episode reward: 0.1500
Process ID: 0, episode: 920/10000 (9.2000%),                     avg. length: 1246.2,                    last time consumption/overall running time: 311.4254s / 15091.2175 s
first_0:                     episode reward: 4.2500
second_0:                     episode reward: -4.2500
Process ID: 0, episode: 940/10000 (9.4000%),                     avg. length: 1367.95,                    last time consumption/overall running time: 342.5278s / 15433.7453 s
first_0:                     episode reward: 2.1000
second_0:                     episode reward: -2.1000
Process ID: 0, episode: 960/10000 (9.6000%),                     avg. length: 1297.7,                    last time consumption/overall running time: 323.4938s / 15757.2391 s
first_0:                     episode reward: 2.3500
second_0:                     episode reward: -2.3500
Process ID: 0, episode: 980/10000 (9.8000%),                     avg. length: 1300.6,                    last time consumption/overall running time: 324.4288s / 16081.6679 s
first_0:                     episode reward: -0.4500
second_0:                     episode reward: 0.4500
Process ID: 0, episode: 1000/10000 (10.0000%),                     avg. length: 1373.4,                    last time consumption/overall running time: 345.3463s / 16427.0142 s
first_0:                     episode reward: 1.2500
second_0:                     episode reward: -1.2500
Process ID: 0, episode: 1020/10000 (10.2000%),                     avg. length: 1384.8,                    last time consumption/overall running time: 340.7651s / 16767.7792 s
first_0:                     episode reward: -0.4500
second_0:                     episode reward: 0.4500
Process ID: 0, episode: 1040/10000 (10.4000%),                     avg. length: 1461.1,                    last time consumption/overall running time: 369.7775s / 17137.5567 s
first_0:                     episode reward: 2.4500
second_0:                     episode reward: -2.4500
Process ID: 0, episode: 1060/10000 (10.6000%),                     avg. length: 1382.35,                    last time consumption/overall running time: 338.7653s / 17476.3220 s
first_0:                     episode reward: -3.9500
second_0:                     episode reward: 3.9500
Process ID: 0, episode: 1080/10000 (10.8000%),                     avg. length: 1300.4,                    last time consumption/overall running time: 327.5587s / 17803.8807 s
first_0:                     episode reward: -0.5500
second_0:                     episode reward: 0.5500pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
Load pong_v2 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(6)
random seed: 58
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'multiprocess': True}
Save models to : /home/zihan/research/MARS/data/model/20220104_1447/pettingzoo_pong_v2_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20220104_1447/pettingzoo_pong_v2_nash_dqn.
Update itr: 20000/10000000 (0.2000%),                     last time consumption/overall running time: 2559.3944s / 2559.3944 s
first_0: loss: 0.0054
second_0: loss: 0.0043
Update itr: 40000/10000000 (0.4000%),                     last time consumption/overall running time: 2611.2221s / 5170.6165 s
first_0: loss: 0.0066
second_0: loss: 0.0084
Update itr: 60000/10000000 (0.6000%),                     last time consumption/overall running time: 2612.7626s / 7783.3791 s
first_0: loss: 0.0206
second_0: loss: 0.0231
Update itr: 80000/10000000 (0.8000%),                     last time consumption/overall running time: 2612.3552s / 10395.7344 s
first_0: loss: 0.0176
second_0: loss: 0.0241
Update itr: 100000/10000000 (1.0000%),                     last time consumption/overall running time: 2613.3698s / 13009.1042 s
first_0: loss: 0.0181
second_0: loss: 0.0153
Update itr: 120000/10000000 (1.2000%),                     last time consumption/overall running time: 2613.7148s / 15622.8189 s
first_0: loss: 0.0196
second_0: loss: 0.0224
Update itr: 140000/10000000 (1.4000%),                     last time consumption/overall running time: 2610.5945s / 18233.4134 s
first_0: loss: 0.0190
second_0: loss: 0.0227
Update itr: 160000/10000000 (1.6000%),                     last time consumption/overall running time: 2611.1352s / 20844.5486 s
first_0: loss: 0.0197
second_0: loss: 0.0217
Update itr: 180000/10000000 (1.8000%),                     last time consumption/overall running time: 2603.9623s / 23448.5110 s
first_0: loss: 0.0193
second_0: loss: 0.0170
Update itr: 200000/10000000 (2.0000%),                     last time consumption/overall running time: 2611.0808s / 26059.5917 s
first_0: loss: 0.0164
second_0: loss: 0.0189
Process Process-4:
Traceback (most recent call last):
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zihan/research/MARS/updateModel.py", line 24, in updateModel
    update_normal(env, model, save_id, args)
  File "/home/zihan/research/MARS/updateModel.py", line 46, in update_normal
    loss = model.update()
  File "/home/zihan/research/MARS/mars/rl/agents/multiagent.py", line 244, in update
    loss = agent.update()
  File "/home/zihan/research/MARS/mars/rl/agents/nash_dqn.py", line 284, in update
    state, action, reward, next_state, done = self.buffer.sample(self.batch_size)
  File "<string>", line 2, in sample
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/managers.py", line 819, in _callmethod
    kind, result = conn.recv()
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
