pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220204_1545/pettingzoo_boxing_v1_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220204_1545/pettingzoo_boxing_v1_nash_ppo.
Episode: 1/30000 (0.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 16.2184s / 16.2184 s
env0_first_0:                 episode reward: 4.0000,                 loss: -0.1267
env0_second_0:                 episode reward: -4.0000,                 loss: -0.1173
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 287.8856s / 304.1041 s
env0_first_0:                 episode reward: -1.8000,                 loss: -0.0723
env0_second_0:                 episode reward: 1.8000,                 loss: -0.0631
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 283.6829s / 587.7870 s
env0_first_0:                 episode reward: -0.4500,                 loss: -0.1026
env0_second_0:                 episode reward: 0.4500,                 loss: -0.0948
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 303.8776s / 891.6646 s
env0_first_0:                 episode reward: -0.7000,                 loss: -0.0268
env0_second_0:                 episode reward: 0.7000,                 loss: -0.0243
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.2509s / 1193.9155 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0322
env0_second_0:                 episode reward: 1.7500,                 loss: 0.0312
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 292.0589s / 1485.9744 s
env0_first_0:                 episode reward: -1.2000,                 loss: -0.1751
env0_second_0:                 episode reward: 1.2000,                 loss: -0.1731
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 283.7656s / 1769.7400 s
env0_first_0:                 episode reward: -5.1000,                 loss: 0.3402
env0_second_0:                 episode reward: 5.1000,                 loss: 0.3358
env1_first_0:                 episode reward: -4.6500,                 loss: nan
env1_second_0:                 episode reward: 4.6500,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 293.7961s / 2063.5361 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.3632
env0_second_0:                 episode reward: 2.8000,                 loss: 0.3737
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 286.5049s / 2350.0410 s
env0_first_0:                 episode reward: -7.3000,                 loss: 0.4069
env0_second_0:                 episode reward: 7.3000,                 loss: 0.4095
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 293.4455s / 2643.4864 s
env0_first_0:                 episode reward: 0.3000,                 loss: -0.0358
env0_second_0:                 episode reward: -0.3000,                 loss: -0.0345
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 297.2463s / 2940.7327 s
env0_first_0:                 episode reward: 1.0000,                 loss: -0.0451
env0_second_0:                 episode reward: -1.0000,                 loss: -0.0467
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 294.5052s / 3235.2379 s
env0_first_0:                 episode reward: -4.1000,                 loss: -0.1249
env0_second_0:                 episode reward: 4.1000,                 loss: -0.1210
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.5671s / 3535.8051 s
env0_first_0:                 episode reward: -1.2000,                 loss: -0.2398
env0_second_0:                 episode reward: 1.2000,                 loss: -0.2407
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.9069s / 3834.7120 s
env0_first_0:                 episode reward: -2.0500,                 loss: -0.2038
env0_second_0:                 episode reward: 2.0500,                 loss: -0.2034
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.5136s / 4137.2256 s
env0_first_0:                 episode reward: -1.5500,                 loss: -0.1257
env0_second_0:                 episode reward: 1.5500,                 loss: -0.1268
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.0232s / 4437.2488 s
env0_first_0:                 episode reward: -1.0000,                 loss: -0.2313
env0_second_0:                 episode reward: 1.0000,                 loss: -0.2368
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 283.7413s / 4720.9901 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.2140
env0_second_0:                 episode reward: 0.2500,                 loss: -0.2193
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 296.4427s / 5017.4328 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.1559
env0_second_0:                 episode reward: 1.5500,                 loss: 0.1563
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 303.9954s / 5321.4282 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.2677
env0_second_0:                 episode reward: 7.0000,                 loss: 0.2753
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.3690s / 5619.7972 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.1245
env0_second_0:                 episode reward: 5.7500,                 loss: 0.1302
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 287.1791s / 5906.9762 s
env0_first_0:                 episode reward: -0.5000,                 loss: -0.0314
env0_second_0:                 episode reward: 0.5000,                 loss: -0.0254
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 296.3885s / 6203.3647 s
env0_first_0:                 episode reward: -1.1000,                 loss: -0.0457
env0_second_0:                 episode reward: 1.1000,                 loss: -0.0427
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 286.4696s / 6489.8344 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0506
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0597
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 278.2987s / 6768.1331 s
env0_first_0:                 episode reward: -2.0500,                 loss: -0.0433
env0_second_0:                 episode reward: 2.0500,                 loss: -0.0415
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 304.3894s / 7072.5224 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.1559
env0_second_0:                 episode reward: 1.7500,                 loss: 0.1655
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.3490s / 7374.8714 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.4162
env0_second_0:                 episode reward: 0.3000,                 loss: -0.4248
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 308.1527s / 7683.0242 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0545
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0651
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 307.5055s / 7990.5297 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.5735
env0_second_0:                 episode reward: 3.9500,                 loss: 0.5934
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 317.4573s / 8307.9869 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.1786
env0_second_0:                 episode reward: 1.9500,                 loss: 0.1895
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 311.5022s / 8619.4891 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.1814
env0_second_0:                 episode reward: 4.3500,                 loss: 0.1823
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 321.7253s / 8941.2144 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0487
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0528
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 316.8943s / 9258.1087 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3329
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3505
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 326.7043s / 9584.8130 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.2031
env0_second_0:                 episode reward: 1.8500,                 loss: 0.2150
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 315.0926s / 9899.9056 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0017
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0151
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 309.6636s / 10209.5692 s
env0_first_0:                 episode reward: -2.7000,                 loss: -0.1686
env0_second_0:                 episode reward: 2.7000,                 loss: -0.1658
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 325.9010s / 10535.4703 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0697
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0983
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 321.9221s / 10857.3924 s
env0_first_0:                 episode reward: -8.3500,                 loss: 1.0069
env0_second_0:                 episode reward: 8.3500,                 loss: 1.0545
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 1748.55,                last time consumption/overall running time: 305.6938s / 11163.0862 s
env0_first_0:                 episode reward: -12.7500,                 loss: 2.1841
env0_second_0:                 episode reward: 12.7500,                 loss: 2.2459
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 1534.55,                last time consumption/overall running time: 257.3603s / 11420.4465 s
env0_first_0:                 episode reward: -22.6500,                 loss: 3.4770
env0_second_0:                 episode reward: 22.6500,                 loss: 3.5425
env1_first_0:                 episode reward: -30.0000,                 loss: nan
env1_second_0:                 episode reward: 30.0000,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 1503.45,                last time consumption/overall running time: 246.2564s / 11666.7029 s
env0_first_0:                 episode reward: -37.0000,                 loss: 4.3000
env0_second_0:                 episode reward: 37.0000,                 loss: 4.2727
env1_first_0:                 episode reward: -27.6000,                 loss: nan
env1_second_0:                 episode reward: 27.6000,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 1554.4,                last time consumption/overall running time: 267.3810s / 11934.0838 s
env0_first_0:                 episode reward: -21.0500,                 loss: 3.2604
env0_second_0:                 episode reward: 21.0500,                 loss: 3.1725
env1_first_0:                 episode reward: -24.4500,                 loss: nan
env1_second_0:                 episode reward: 24.4500,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 1726.45,                last time consumption/overall running time: 295.5897s / 12229.6735 s
env0_first_0:                 episode reward: -14.1000,                 loss: 1.4330
env0_second_0:                 episode reward: 14.1000,                 loss: 1.4273
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 1705.45,                last time consumption/overall running time: 293.0379s / 12522.7114 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.9238
env0_second_0:                 episode reward: 13.9500,                 loss: 1.0103
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 1609.3,                last time consumption/overall running time: 284.8379s / 12807.5493 s
env0_first_0:                 episode reward: -17.4500,                 loss: 2.1791
env0_second_0:                 episode reward: 17.4500,                 loss: 2.2814
env1_first_0:                 episode reward: -18.7500,                 loss: nan
env1_second_0:                 episode reward: 18.7500,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 1506.0,                last time consumption/overall running time: 266.5609s / 13074.1102 s
env0_first_0:                 episode reward: -21.6500,                 loss: 3.3473
env0_second_0:                 episode reward: 21.6500,                 loss: 3.4054
env1_first_0:                 episode reward: -30.1000,                 loss: nan
env1_second_0:                 episode reward: 30.1000,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 1203.4,                last time consumption/overall running time: 206.8633s / 13280.9735 s
env0_first_0:                 episode reward: -39.1500,                 loss: 5.8841
env0_second_0:                 episode reward: 39.1500,                 loss: 5.9396
env1_first_0:                 episode reward: -39.5000,                 loss: nan
env1_second_0:                 episode reward: 39.5000,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 1404.15,                last time consumption/overall running time: 239.8516s / 13520.8251 s
env0_first_0:                 episode reward: -24.6000,                 loss: 4.5703
env0_second_0:                 episode reward: 24.6000,                 loss: 4.4794
env1_first_0:                 episode reward: -27.5000,                 loss: nan
env1_second_0:                 episode reward: 27.5000,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 1514.95,                last time consumption/overall running time: 249.6245s / 13770.4496 s
env0_first_0:                 episode reward: -28.9500,                 loss: 3.6565
env0_second_0:                 episode reward: 28.9500,                 loss: 3.6778
env1_first_0:                 episode reward: -26.2500,                 loss: nan
env1_second_0:                 episode reward: 26.2500,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 1411.7,                last time consumption/overall running time: 244.3044s / 14014.7540 s
env0_first_0:                 episode reward: -32.6000,                 loss: 4.5136
env0_second_0:                 episode reward: 32.6000,                 loss: 4.4770
env1_first_0:                 episode reward: -31.2000,                 loss: nan
env1_second_0:                 episode reward: 31.2000,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 1233.45,                last time consumption/overall running time: 207.4907s / 14222.2447 s
env0_first_0:                 episode reward: -32.6000,                 loss: 5.5064
env0_second_0:                 episode reward: 32.6000,                 loss: 5.5072
env1_first_0:                 episode reward: -33.4500,                 loss: nan
env1_second_0:                 episode reward: 33.4500,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 1369.75,                last time consumption/overall running time: 227.7055s / 14449.9502 s
env0_first_0:                 episode reward: -29.7500,                 loss: 4.1760
env0_second_0:                 episode reward: 29.7500,                 loss: 4.1354
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 1506.05,                last time consumption/overall running time: 247.1788s / 14697.1290 s
env0_first_0:                 episode reward: -28.3500,                 loss: 4.5022
env0_second_0:                 episode reward: 28.3500,                 loss: 4.4531
env1_first_0:                 episode reward: -27.0500,                 loss: nan
env1_second_0:                 episode reward: 27.0500,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 1183.65,                last time consumption/overall running time: 185.7200s / 14882.8490 s
env0_first_0:                 episode reward: -36.1500,                 loss: 6.1521
env0_second_0:                 episode reward: 36.1500,                 loss: 6.1491
env1_first_0:                 episode reward: -36.8500,                 loss: nan
env1_second_0:                 episode reward: 36.8500,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 1272.75,                last time consumption/overall running time: 219.3163s / 15102.1653 s
env0_first_0:                 episode reward: -31.7000,                 loss: 5.6634
env0_second_0:                 episode reward: 31.7000,                 loss: 5.6307
env1_first_0:                 episode reward: -37.2000,                 loss: nan
env1_second_0:                 episode reward: 37.2000,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 1303.75,                last time consumption/overall running time: 223.6067s / 15325.7720 s
env0_first_0:                 episode reward: -32.3000,                 loss: 5.4089
env0_second_0:                 episode reward: 32.3000,                 loss: 5.4864
env1_first_0:                 episode reward: -32.1500,                 loss: nan
env1_second_0:                 episode reward: 32.1500,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 1412.05,                last time consumption/overall running time: 235.0794s / 15560.8514 s
env0_first_0:                 episode reward: -22.2500,                 loss: 5.0739
env0_second_0:                 episode reward: 22.2500,                 loss: 4.9801
env1_first_0:                 episode reward: -35.9000,                 loss: nan
env1_second_0:                 episode reward: 35.9000,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 1588.25,                last time consumption/overall running time: 265.7545s / 15826.6059 s
env0_first_0:                 episode reward: -22.7000,                 loss: 4.5700
env0_second_0:                 episode reward: 22.7000,                 loss: 4.5172
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 1560.25,                last time consumption/overall running time: 269.3800s / 16095.9860 s
env0_first_0:                 episode reward: -17.2500,                 loss: 4.9995
env0_second_0:                 episode reward: 17.2500,                 loss: 4.9334
env1_first_0:                 episode reward: -29.6500,                 loss: nan
env1_second_0:                 episode reward: 29.6500,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 1710.35,                last time consumption/overall running time: 282.6836s / 16378.6696 s
env0_first_0:                 episode reward: -24.8000,                 loss: 4.2180
env0_second_0:                 episode reward: 24.8000,                 loss: 4.1222
env1_first_0:                 episode reward: -24.5000,                 loss: nan
env1_second_0:                 episode reward: 24.5000,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 1630.95,                last time consumption/overall running time: 257.1589s / 16635.8285 s
env0_first_0:                 episode reward: -25.2500,                 loss: 4.8780
env0_second_0:                 episode reward: 25.2500,                 loss: 4.8314
env1_first_0:                 episode reward: -27.3000,                 loss: nan
env1_second_0:                 episode reward: 27.3000,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 1451.15,                last time consumption/overall running time: 250.1869s / 16886.0154 s
env0_first_0:                 episode reward: -35.2000,                 loss: 5.8901
env0_second_0:                 episode reward: 35.2000,                 loss: 5.8507
env1_first_0:                 episode reward: -30.3000,                 loss: nan
env1_second_0:                 episode reward: 30.3000,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 1325.35,                last time consumption/overall running time: 217.3987s / 17103.4141 s
env0_first_0:                 episode reward: -35.8000,                 loss: 6.1019
env0_second_0:                 episode reward: 35.8000,                 loss: 6.1013
env1_first_0:                 episode reward: -27.5500,                 loss: nan
env1_second_0:                 episode reward: 27.5500,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 1346.1,                last time consumption/overall running time: 226.0154s / 17329.4295 s
env0_first_0:                 episode reward: -33.6500,                 loss: 6.1227
env0_second_0:                 episode reward: 33.6500,                 loss: 6.1802
env1_first_0:                 episode reward: -32.4000,                 loss: nan
env1_second_0:                 episode reward: 32.4000,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 1324.0,                last time consumption/overall running time: 224.9102s / 17554.3397 s
env0_first_0:                 episode reward: -35.8500,                 loss: 6.3780
env0_second_0:                 episode reward: 35.8500,                 loss: 6.3497
env1_first_0:                 episode reward: -34.0500,                 loss: nan
env1_second_0:                 episode reward: 34.0500,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 1439.55,                last time consumption/overall running time: 228.9556s / 17783.2952 s
env0_first_0:                 episode reward: -29.9500,                 loss: 5.8859
env0_second_0:                 episode reward: 29.9500,                 loss: 5.8390
env1_first_0:                 episode reward: -32.2500,                 loss: nan
env1_second_0:                 episode reward: 32.2500,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 1350.4,                last time consumption/overall running time: 230.5177s / 18013.8129 s
env0_first_0:                 episode reward: -37.4500,                 loss: 6.4198
env0_second_0:                 episode reward: 37.4500,                 loss: 6.3601
env1_first_0:                 episode reward: -30.0500,                 loss: nan
env1_second_0:                 episode reward: 30.0500,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 1395.65,                last time consumption/overall running time: 239.4455s / 18253.2584 s
env0_first_0:                 episode reward: -36.1500,                 loss: 6.9183
env0_second_0:                 episode reward: 36.1500,                 loss: 6.8458
env1_first_0:                 episode reward: -44.2500,                 loss: nan
env1_second_0:                 episode reward: 44.2500,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 1186.65,                last time consumption/overall running time: 212.4553s / 18465.7137 s
env0_first_0:                 episode reward: -45.5500,                 loss: 8.0041
env0_second_0:                 episode reward: 45.5500,                 loss: 8.1287
env1_first_0:                 episode reward: -41.8500,                 loss: nan
env1_second_0:                 episode reward: 41.8500,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 1177.05,                last time consumption/overall running time: 205.6071s / 18671.3208 s
env0_first_0:                 episode reward: -51.1500,                 loss: 9.1763
env0_second_0:                 episode reward: 51.1500,                 loss: 9.1172
env1_first_0:                 episode reward: -37.4500,                 loss: nan
env1_second_0:                 episode reward: 37.4500,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 1453.15,                last time consumption/overall running time: 255.6801s / 18927.0009 s
env0_first_0:                 episode reward: -33.4000,                 loss: 6.0243
env0_second_0:                 episode reward: 33.4000,                 loss: 6.1541
env1_first_0:                 episode reward: -32.1500,                 loss: nan
env1_second_0:                 episode reward: 32.1500,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 1385.25,                last time consumption/overall running time: 240.6621s / 19167.6629 s
env0_first_0:                 episode reward: -32.3000,                 loss: 6.0999
env0_second_0:                 episode reward: 32.3000,                 loss: 6.3602
env1_first_0:                 episode reward: -35.6000,                 loss: nan
env1_second_0:                 episode reward: 35.6000,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 904.5,                last time consumption/overall running time: 160.5292s / 19328.1921 s
env0_first_0:                 episode reward: -50.9500,                 loss: 11.1378
env0_second_0:                 episode reward: 50.9500,                 loss: 11.7418
env1_first_0:                 episode reward: -49.6500,                 loss: nan
env1_second_0:                 episode reward: 49.6500,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 859.8,                last time consumption/overall running time: 156.0032s / 19484.1953 s
env0_first_0:                 episode reward: -53.0500,                 loss: 14.8581
env0_second_0:                 episode reward: 53.0500,                 loss: 14.7217
env1_first_0:                 episode reward: -50.6500,                 loss: nan
env1_second_0:                 episode reward: 50.6500,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 877.4,                last time consumption/overall running time: 158.6138s / 19642.8091 s
env0_first_0:                 episode reward: -51.9500,                 loss: 12.4697
env0_second_0:                 episode reward: 51.9500,                 loss: 12.5420
env1_first_0:                 episode reward: -53.2000,                 loss: nan
env1_second_0:                 episode reward: 53.2000,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 1066.05,                last time consumption/overall running time: 186.3186s / 19829.1276 s
env0_first_0:                 episode reward: -58.4000,                 loss: 11.4966
env0_second_0:                 episode reward: 58.4000,                 loss: 11.4690
env1_first_0:                 episode reward: -53.0000,                 loss: nan
env1_second_0:                 episode reward: 53.0000,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 946.95,                last time consumption/overall running time: 161.0817s / 19990.2093 s
env0_first_0:                 episode reward: -47.9500,                 loss: 13.5445
env0_second_0:                 episode reward: 47.9500,                 loss: 13.4101
env1_first_0:                 episode reward: -55.8500,                 loss: nan
env1_second_0:                 episode reward: 55.8500,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 977.15,                last time consumption/overall running time: 163.9456s / 20154.1549 s
env0_first_0:                 episode reward: -52.8000,                 loss: 12.1145
env0_second_0:                 episode reward: 52.8000,                 loss: 12.1215
env1_first_0:                 episode reward: -41.0000,                 loss: nan
env1_second_0:                 episode reward: 41.0000,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 922.85,                last time consumption/overall running time: 169.1344s / 20323.2893 s
env0_first_0:                 episode reward: -49.4000,                 loss: 11.9766
env0_second_0:                 episode reward: 49.4000,                 loss: 12.0483
env1_first_0:                 episode reward: -55.9500,                 loss: nan
env1_second_0:                 episode reward: 55.9500,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 964.75,                last time consumption/overall running time: 172.7104s / 20495.9997 s
env0_first_0:                 episode reward: -46.2000,                 loss: 11.2381
env0_second_0:                 episode reward: 46.2000,                 loss: 10.9930
env1_first_0:                 episode reward: -37.6000,                 loss: nan
env1_second_0:                 episode reward: 37.6000,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 1210.25,                last time consumption/overall running time: 214.2722s / 20710.2719 s
env0_first_0:                 episode reward: -37.7500,                 loss: 7.6671
env0_second_0:                 episode reward: 37.7500,                 loss: 7.6184
env1_first_0:                 episode reward: -29.5500,                 loss: nan
env1_second_0:                 episode reward: 29.5500,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 833.2,                last time consumption/overall running time: 146.4856s / 20856.7575 s
env0_first_0:                 episode reward: -48.3500,                 loss: 14.7767
env0_second_0:                 episode reward: 48.3500,                 loss: 14.9323
env1_first_0:                 episode reward: -49.1000,                 loss: nan
env1_second_0:                 episode reward: 49.1000,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 772.4,                last time consumption/overall running time: 139.8912s / 20996.6487 s
env0_first_0:                 episode reward: -54.2000,                 loss: 14.8581
env0_second_0:                 episode reward: 54.2000,                 loss: 14.7914
env1_first_0:                 episode reward: -53.8000,                 loss: nan
env1_second_0:                 episode reward: 53.8000,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 673.8,                last time consumption/overall running time: 121.2126s / 21117.8613 s
env0_first_0:                 episode reward: -65.5500,                 loss: 19.3205
env0_second_0:                 episode reward: 65.5500,                 loss: 19.2174
env1_first_0:                 episode reward: -52.6000,                 loss: nan
env1_second_0:                 episode reward: 52.6000,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 710.35,                last time consumption/overall running time: 131.4452s / 21249.3065 s
env0_first_0:                 episode reward: -57.1000,                 loss: 17.2248
env0_second_0:                 episode reward: 57.1000,                 loss: 16.9276
env1_first_0:                 episode reward: -48.9000,                 loss: nan
env1_second_0:                 episode reward: 48.9000,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 715.35,                last time consumption/overall running time: 129.0421s / 21378.3486 s
env0_first_0:                 episode reward: -61.8500,                 loss: 16.8548
env0_second_0:                 episode reward: 61.8500,                 loss: 17.2093
env1_first_0:                 episode reward: -52.0000,                 loss: nan
env1_second_0:                 episode reward: 52.0000,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 648.35,                last time consumption/overall running time: 118.7807s / 21497.1293 s
env0_first_0:                 episode reward: -54.1000,                 loss: 21.0055
env0_second_0:                 episode reward: 54.1000,                 loss: 20.7666
env1_first_0:                 episode reward: -63.9000,                 loss: nan
env1_second_0:                 episode reward: 63.9000,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 771.2,                last time consumption/overall running time: 140.4746s / 21637.6039 s
env0_first_0:                 episode reward: -58.5500,                 loss: 18.0738
env0_second_0:                 episode reward: 58.5500,                 loss: 17.9769
env1_first_0:                 episode reward: -54.5500,                 loss: nan
env1_second_0:                 episode reward: 54.5500,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 672.55,                last time consumption/overall running time: 122.4297s / 21760.0336 s
env0_first_0:                 episode reward: -61.8000,                 loss: 19.1638
env0_second_0:                 episode reward: 61.8000,                 loss: 19.3783
env1_first_0:                 episode reward: -51.2000,                 loss: nan
env1_second_0:                 episode reward: 51.2000,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 606.0,                last time consumption/overall running time: 105.8720s / 21865.9056 s
env0_first_0:                 episode reward: -57.3500,                 loss: 22.9906
env0_second_0:                 episode reward: 57.3500,                 loss: 23.3753
env1_first_0:                 episode reward: -67.5000,                 loss: nan
env1_second_0:                 episode reward: 67.5000,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 579.3,                last time consumption/overall running time: 109.0853s / 21974.9908 s
env0_first_0:                 episode reward: -53.4000,                 loss: 25.6796
env0_second_0:                 episode reward: 53.4000,                 loss: 25.2358
env1_first_0:                 episode reward: -66.8000,                 loss: nan
env1_second_0:                 episode reward: 66.8000,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 641.2,                last time consumption/overall running time: 117.0851s / 22092.0759 s
env0_first_0:                 episode reward: -53.3000,                 loss: 19.7428
env0_second_0:                 episode reward: 53.3000,                 loss: 19.8099
env1_first_0:                 episode reward: -63.2000,                 loss: nan
env1_second_0:                 episode reward: 63.2000,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 536.35,                last time consumption/overall running time: 95.1357s / 22187.2116 s
env0_first_0:                 episode reward: -59.8000,                 loss: 24.1093
env0_second_0:                 episode reward: 59.8000,                 loss: 24.6661
env1_first_0:                 episode reward: -71.4500,                 loss: nan
env1_second_0:                 episode reward: 71.4500,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 437.4,                last time consumption/overall running time: 80.6113s / 22267.8229 s
env0_first_0:                 episode reward: -79.3000,                 loss: 32.7953
env0_second_0:                 episode reward: 79.3000,                 loss: 33.0875
env1_first_0:                 episode reward: -59.0500,                 loss: nan
env1_second_0:                 episode reward: 59.0500,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 557.55,                last time consumption/overall running time: 98.8812s / 22366.7042 s
env0_first_0:                 episode reward: -62.4000,                 loss: 31.3110
env0_second_0:                 episode reward: 62.4000,                 loss: 30.8531
env1_first_0:                 episode reward: -53.9500,                 loss: nan
env1_second_0:                 episode reward: 53.9500,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 453.45,                last time consumption/overall running time: 85.5621s / 22452.2662 s
env0_first_0:                 episode reward: -68.7500,                 loss: 31.2954
env0_second_0:                 episode reward: 68.7500,                 loss: 31.0789
env1_first_0:                 episode reward: -69.6000,                 loss: nan
env1_second_0:                 episode reward: 69.6000,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 469.95,                last time consumption/overall running time: 85.9823s / 22538.2486 s
env0_first_0:                 episode reward: -84.4000,                 loss: 33.4545
env0_second_0:                 episode reward: 84.4000,                 loss: 33.1119
env1_first_0:                 episode reward: -67.5000,                 loss: nan
env1_second_0:                 episode reward: 67.5000,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 594.9,                last time consumption/overall running time: 106.7493s / 22644.9979 s
env0_first_0:                 episode reward: -63.2500,                 loss: 25.1048
env0_second_0:                 episode reward: 63.2500,                 loss: 25.4533
env1_first_0:                 episode reward: -66.3000,                 loss: nan
env1_second_0:                 episode reward: 66.3000,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 536.5,                last time consumption/overall running time: 94.8779s / 22739.8758 s
env0_first_0:                 episode reward: -73.0500,                 loss: 26.9511
env0_second_0:                 episode reward: 73.0500,                 loss: 26.8081
env1_first_0:                 episode reward: -71.4000,                 loss: nan
env1_second_0:                 episode reward: 71.4000,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 607.3,                last time consumption/overall running time: 111.2226s / 22851.0984 s
env0_first_0:                 episode reward: -69.3000,                 loss: 22.6410
env0_second_0:                 episode reward: 69.3000,                 loss: 21.6249
env1_first_0:                 episode reward: -64.7000,                 loss: nan
env1_second_0:                 episode reward: 64.7000,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 447.5,                last time consumption/overall running time: 86.0892s / 22937.1876 s
env0_first_0:                 episode reward: -68.5000,                 loss: 32.7388
env0_second_0:                 episode reward: 68.5000,                 loss: 32.6640
env1_first_0:                 episode reward: -71.0000,                 loss: nan
env1_second_0:                 episode reward: 71.0000,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 542.6,                last time consumption/overall running time: 100.0631s / 23037.2507 s
env0_first_0:                 episode reward: -69.1500,                 loss: 26.3629
env0_second_0:                 episode reward: 69.1500,                 loss: 25.9430
env1_first_0:                 episode reward: -71.5500,                 loss: nan
env1_second_0:                 episode reward: 71.5500,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 504.55,                last time consumption/overall running time: 96.9035s / 23134.1542 s
env0_first_0:                 episode reward: -76.5500,                 loss: 28.7546
env0_second_0:                 episode reward: 76.5500,                 loss: 28.5275
env1_first_0:                 episode reward: -62.2500,                 loss: nan
env1_second_0:                 episode reward: 62.2500,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 415.3,                last time consumption/overall running time: 80.6998s / 23214.8541 s
env0_first_0:                 episode reward: -74.7000,                 loss: 36.0846
env0_second_0:                 episode reward: 74.7000,                 loss: 35.9255
env1_first_0:                 episode reward: -76.6500,                 loss: nan
env1_second_0:                 episode reward: 76.6500,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 913.3,                last time consumption/overall running time: 163.3229s / 23378.1769 s
env0_first_0:                 episode reward: -36.5500,                 loss: 21.2943
env0_second_0:                 episode reward: 36.5500,                 loss: 20.5513
env1_first_0:                 episode reward: -56.0500,                 loss: nan
env1_second_0:                 episode reward: 56.0500,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 688.15,                last time consumption/overall running time: 128.0136s / 23506.1906 s
env0_first_0:                 episode reward: -57.4500,                 loss: 20.8647
env0_second_0:                 episode reward: 57.4500,                 loss: 20.9636
env1_first_0:                 episode reward: -59.4500,                 loss: nan
env1_second_0:                 episode reward: 59.4500,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 528.1,                last time consumption/overall running time: 95.0924s / 23601.2830 s
env0_first_0:                 episode reward: -74.1000,                 loss: 29.7095
env0_second_0:                 episode reward: 74.1000,                 loss: 29.2819
env1_first_0:                 episode reward: -72.1000,                 loss: nan
env1_second_0:                 episode reward: 72.1000,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 450.45,                last time consumption/overall running time: 87.7953s / 23689.0783 s
env0_first_0:                 episode reward: -73.0000,                 loss: 36.1598
env0_second_0:                 episode reward: 73.0000,                 loss: 38.6751
env1_first_0:                 episode reward: -74.0000,                 loss: nan
env1_second_0:                 episode reward: 74.0000,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 488.1,                last time consumption/overall running time: 93.5693s / 23782.6476 s
env0_first_0:                 episode reward: -72.5000,                 loss: 32.2171
env0_second_0:                 episode reward: 72.5000,                 loss: 34.9907
env1_first_0:                 episode reward: -67.1500,                 loss: nan
env1_second_0:                 episode reward: 67.1500,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 1357.5,                last time consumption/overall running time: 224.4003s / 24007.0478 s
env0_first_0:                 episode reward: -23.7000,                 loss: 8.3458
env0_second_0:                 episode reward: 23.7000,                 loss: 10.3646
env1_first_0:                 episode reward: -24.3500,                 loss: nan
env1_second_0:                 episode reward: 24.3500,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 589.25,                last time consumption/overall running time: 99.7166s / 24106.7644 s
env0_first_0:                 episode reward: -54.8500,                 loss: 18.7794
env0_second_0:                 episode reward: 54.8500,                 loss: 21.3077
env1_first_0:                 episode reward: -70.4000,                 loss: nan
env1_second_0:                 episode reward: 70.4000,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 400.35,                last time consumption/overall running time: 79.3895s / 24186.1538 s
env0_first_0:                 episode reward: -75.0500,                 loss: 35.8723
env0_second_0:                 episode reward: 75.0500,                 loss: 38.4097
env1_first_0:                 episode reward: -76.0000,                 loss: nan
env1_second_0:                 episode reward: 76.0000,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 372.9,                last time consumption/overall running time: 75.9839s / 24262.1378 s
env0_first_0:                 episode reward: -81.6000,                 loss: 37.2627
env0_second_0:                 episode reward: 81.6000,                 loss: 38.9362
env1_first_0:                 episode reward: -74.1000,                 loss: nan
env1_second_0:                 episode reward: 74.1000,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 528.8,                last time consumption/overall running time: 99.8585s / 24361.9962 s
env0_first_0:                 episode reward: -72.7000,                 loss: 29.3174
env0_second_0:                 episode reward: 72.7000,                 loss: 29.6264
env1_first_0:                 episode reward: -74.3000,                 loss: nan
env1_second_0:                 episode reward: 74.3000,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 487.25,                last time consumption/overall running time: 91.8340s / 24453.8302 s
env0_first_0:                 episode reward: -73.0500,                 loss: 33.2278
env0_second_0:                 episode reward: 73.0500,                 loss: 34.2119
env1_first_0:                 episode reward: -65.0000,                 loss: nan
env1_second_0:                 episode reward: 65.0000,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 620.15,                last time consumption/overall running time: 115.6679s / 24569.4982 s
env0_first_0:                 episode reward: -54.3500,                 loss: 26.1388
env0_second_0:                 episode reward: 54.3500,                 loss: 26.2435
env1_first_0:                 episode reward: -66.8000,                 loss: nan
env1_second_0:                 episode reward: 66.8000,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 687.8,                last time consumption/overall running time: 119.0897s / 24688.5878 s
env0_first_0:                 episode reward: -60.7000,                 loss: 20.5032
env0_second_0:                 episode reward: 60.7000,                 loss: 20.9129
env1_first_0:                 episode reward: -34.5500,                 loss: nan
env1_second_0:                 episode reward: 34.5500,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 1133.65,                last time consumption/overall running time: 197.1501s / 24885.7380 s
env0_first_0:                 episode reward: -39.6500,                 loss: 17.8317
env0_second_0:                 episode reward: 39.6500,                 loss: 17.4071
env1_first_0:                 episode reward: -63.8500,                 loss: nan
env1_second_0:                 episode reward: 63.8500,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 1727.0,                last time consumption/overall running time: 279.0526s / 25164.7905 s
env0_first_0:                 episode reward: -20.3500,                 loss: 2.4925
env0_second_0:                 episode reward: 20.3500,                 loss: 2.5564
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 1711.05,                last time consumption/overall running time: 278.5589s / 25443.3495 s
env0_first_0:                 episode reward: -20.5000,                 loss: 7.3015
env0_second_0:                 episode reward: 20.5000,                 loss: 6.9023
env1_first_0:                 episode reward: -29.3000,                 loss: nan
env1_second_0:                 episode reward: 29.3000,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.3310s / 25744.6805 s
env0_first_0:                 episode reward: -21.8500,                 loss: 2.1049
env0_second_0:                 episode reward: 21.8500,                 loss: 2.5528
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 1628.5,                last time consumption/overall running time: 265.7961s / 26010.4765 s
env0_first_0:                 episode reward: -39.0000,                 loss: 11.3455
env0_second_0:                 episode reward: 39.0000,                 loss: 12.6557
env1_first_0:                 episode reward: -20.5000,                 loss: nan
env1_second_0:                 episode reward: 20.5000,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 1574.3,                last time consumption/overall running time: 266.7795s / 26277.2561 s
env0_first_0:                 episode reward: -20.7500,                 loss: 7.6375
env0_second_0:                 episode reward: 20.7500,                 loss: 8.6362
env1_first_0:                 episode reward: -34.1500,                 loss: nan
env1_second_0:                 episode reward: 34.1500,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 307.6032s / 26584.8592 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0157
env0_second_0:                 episode reward: 0.0000,                 loss: 0.8826
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 296.9451s / 26881.8044 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0701
env0_second_0:                 episode reward: 0.0000,                 loss: 0.9380
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 304.7684s / 27186.5728 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0662
env0_second_0:                 episode reward: 0.0000,                 loss: 2.4267
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 305.7443s / 27492.3170 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0218
env0_second_0:                 episode reward: -0.2000,                 loss: 2.9552
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 309.2644s / 27801.5814 s
env0_first_0:                 episode reward: 4.9500,                 loss: 1.5435
env0_second_0:                 episode reward: -4.9500,                 loss: 16.7721
env1_first_0:                 episode reward: 8.8500,                 loss: nan
env1_second_0:                 episode reward: -8.8500,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 308.7934s / 28110.3748 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.4753
env0_second_0:                 episode reward: 7.2500,                 loss: 5.4717
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 1336.6,                last time consumption/overall running time: 233.8988s / 28344.2735 s
env0_first_0:                 episode reward: -49.0500,                 loss: 3.3487
env0_second_0:                 episode reward: 49.0500,                 loss: 8.5225
env1_first_0:                 episode reward: -49.2500,                 loss: nan
env1_second_0:                 episode reward: 49.2500,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 924.85,                last time consumption/overall running time: 163.6704s / 28507.9439 s
env0_first_0:                 episode reward: -64.2500,                 loss: 5.3387
env0_second_0:                 episode reward: 64.2500,                 loss: 10.7303
env1_first_0:                 episode reward: -63.3500,                 loss: nan
env1_second_0:                 episode reward: 63.3500,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 823.75,                last time consumption/overall running time: 152.2293s / 28660.1732 s
env0_first_0:                 episode reward: -54.6000,                 loss: 6.5202
env0_second_0:                 episode reward: 54.6000,                 loss: 12.3895
env1_first_0:                 episode reward: -62.6500,                 loss: nan
env1_second_0:                 episode reward: 62.6500,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 622.8,                last time consumption/overall running time: 119.5988s / 28779.7720 s
env0_first_0:                 episode reward: -75.6000,                 loss: 12.5848
env0_second_0:                 episode reward: 75.6000,                 loss: 17.8414
env1_first_0:                 episode reward: -63.0000,                 loss: nan
env1_second_0:                 episode reward: 63.0000,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 510.1,                last time consumption/overall running time: 90.3975s / 28870.1694 s
env0_first_0:                 episode reward: -72.7500,                 loss: 21.9815
env0_second_0:                 episode reward: 72.7500,                 loss: 25.2085
env1_first_0:                 episode reward: -75.9500,                 loss: nan
env1_second_0:                 episode reward: 75.9500,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 599.15,                last time consumption/overall running time: 111.8798s / 28982.0492 s
env0_first_0:                 episode reward: -70.2000,                 loss: 21.0554
env0_second_0:                 episode reward: 70.2000,                 loss: 25.0628
env1_first_0:                 episode reward: -71.1500,                 loss: nan
env1_second_0:                 episode reward: 71.1500,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 483.05,                last time consumption/overall running time: 93.5796s / 29075.6288 s
env0_first_0:                 episode reward: -71.8000,                 loss: 26.3799
env0_second_0:                 episode reward: 71.8000,                 loss: 30.5546
env1_first_0:                 episode reward: -72.9000,                 loss: nan
env1_second_0:                 episode reward: 72.9000,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 626.4,                last time consumption/overall running time: 112.6400s / 29188.2688 s
env0_first_0:                 episode reward: -62.7500,                 loss: 24.5494
env0_second_0:                 episode reward: 62.7500,                 loss: 28.0103
env1_first_0:                 episode reward: -74.6000,                 loss: nan
env1_second_0:                 episode reward: 74.6000,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 860.6,                last time consumption/overall running time: 153.9784s / 29342.2472 s
env0_first_0:                 episode reward: -66.7500,                 loss: 15.2514
env0_second_0:                 episode reward: 66.7500,                 loss: 19.3639
env1_first_0:                 episode reward: -52.9000,                 loss: nan
env1_second_0:                 episode reward: 52.9000,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 497.2,                last time consumption/overall running time: 92.4248s / 29434.6720 s
env0_first_0:                 episode reward: -58.5500,                 loss: 30.9382
env0_second_0:                 episode reward: 58.5500,                 loss: 33.2524
env1_first_0:                 episode reward: -77.5000,                 loss: nan
env1_second_0:                 episode reward: 77.5000,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 494.6,                last time consumption/overall running time: 92.9362s / 29527.6082 s
env0_first_0:                 episode reward: -63.9500,                 loss: 29.1419
env0_second_0:                 episode reward: 63.9500,                 loss: 33.3081
env1_first_0:                 episode reward: -71.4000,                 loss: nan
env1_second_0:                 episode reward: 71.4000,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 500.75,                last time consumption/overall running time: 90.2544s / 29617.8626 s
env0_first_0:                 episode reward: -73.7000,                 loss: 31.2796
env0_second_0:                 episode reward: 73.7000,                 loss: 36.4768
env1_first_0:                 episode reward: -63.7000,                 loss: nan
env1_second_0:                 episode reward: 63.7000,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 459.0,                last time consumption/overall running time: 86.1666s / 29704.0292 s
env0_first_0:                 episode reward: -71.0500,                 loss: 36.0518
env0_second_0:                 episode reward: 71.0500,                 loss: 39.2979
env1_first_0:                 episode reward: -67.9000,                 loss: nan
env1_second_0:                 episode reward: 67.9000,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 523.5,                last time consumption/overall running time: 98.3117s / 29802.3409 s
env0_first_0:                 episode reward: -69.3500,                 loss: 31.4369
env0_second_0:                 episode reward: 69.3500,                 loss: 35.2583
env1_first_0:                 episode reward: -59.9000,                 loss: nan
env1_second_0:                 episode reward: 59.9000,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 454.85,                last time consumption/overall running time: 86.8631s / 29889.2040 s
env0_first_0:                 episode reward: -73.7000,                 loss: 33.5943
env0_second_0:                 episode reward: 73.7000,                 loss: 37.4438
env1_first_0:                 episode reward: -77.8000,                 loss: nan
env1_second_0:                 episode reward: 77.8000,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 445.7,                last time consumption/overall running time: 87.1503s / 29976.3543 s
env0_first_0:                 episode reward: -72.8000,                 loss: 33.4032
env0_second_0:                 episode reward: 72.8000,                 loss: 36.3647
env1_first_0:                 episode reward: -75.6000,                 loss: nan
env1_second_0:                 episode reward: 75.6000,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 342.9,                last time consumption/overall running time: 65.6597s / 30042.0140 s
env0_first_0:                 episode reward: -73.8500,                 loss: 42.5684
env0_second_0:                 episode reward: 73.8500,                 loss: 46.7772
env1_first_0:                 episode reward: -71.3000,                 loss: nan
env1_second_0:                 episode reward: 71.3000,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 417.1,                last time consumption/overall running time: 73.9795s / 30115.9935 s
env0_first_0:                 episode reward: -60.1000,                 loss: 37.0321
env0_second_0:                 episode reward: 60.1000,                 loss: 40.4809
env1_first_0:                 episode reward: -77.6000,                 loss: nan
env1_second_0:                 episode reward: 77.6000,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 777.6,                last time consumption/overall running time: 132.9571s / 30248.9506 s
env0_first_0:                 episode reward: -54.5000,                 loss: 28.9633
env0_second_0:                 episode reward: 54.5000,                 loss: 33.2792
env1_first_0:                 episode reward: -51.3500,                 loss: nan
env1_second_0:                 episode reward: 51.3500,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 1531.25,                last time consumption/overall running time: 263.3901s / 30512.3407 s
env0_first_0:                 episode reward: -15.7500,                 loss: 5.9527
env0_second_0:                 episode reward: 15.7500,                 loss: 10.5366
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 464.85,                last time consumption/overall running time: 80.1327s / 30592.4734 s
env0_first_0:                 episode reward: -72.1000,                 loss: 24.7952
env0_second_0:                 episode reward: 72.1000,                 loss: 28.6859
env1_first_0:                 episode reward: -67.1000,                 loss: nan
env1_second_0:                 episode reward: 67.1000,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 485.9,                last time consumption/overall running time: 84.9510s / 30677.4244 s
env0_first_0:                 episode reward: -71.1500,                 loss: 47.6250
env0_second_0:                 episode reward: 71.1500,                 loss: 50.8731
env1_first_0:                 episode reward: -59.5000,                 loss: nan
env1_second_0:                 episode reward: 59.5000,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 1541.1,                last time consumption/overall running time: 253.8893s / 30931.3137 s
env0_first_0:                 episode reward: -10.7500,                 loss: 4.8962
env0_second_0:                 episode reward: 10.7500,                 loss: 10.1228
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 1320.25,                last time consumption/overall running time: 218.1599s / 31149.4736 s
env0_first_0:                 episode reward: -48.0000,                 loss: 5.5579
env0_second_0:                 episode reward: 48.0000,                 loss: 8.2155
env1_first_0:                 episode reward: -34.8000,                 loss: nan
env1_second_0:                 episode reward: 34.8000,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 1041.55,                last time consumption/overall running time: 180.2056s / 31329.6793 s
env0_first_0:                 episode reward: -50.6500,                 loss: 9.1273
env0_second_0:                 episode reward: 50.6500,                 loss: 16.7831
env1_first_0:                 episode reward: -45.9500,                 loss: nan
env1_second_0:                 episode reward: 45.9500,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 489.05,                last time consumption/overall running time: 92.8002s / 31422.4794 s
env0_first_0:                 episode reward: -70.1000,                 loss: 32.0130
env0_second_0:                 episode reward: 70.1000,                 loss: 34.7638
env1_first_0:                 episode reward: -79.2500,                 loss: nan
env1_second_0:                 episode reward: 79.2500,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 392.95,                last time consumption/overall running time: 71.6480s / 31494.1274 s
env0_first_0:                 episode reward: -68.6000,                 loss: 38.3205
env0_second_0:                 episode reward: 68.6000,                 loss: 42.7553
env1_first_0:                 episode reward: -71.7000,                 loss: nan
env1_second_0:                 episode reward: 71.7000,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 636.25,                last time consumption/overall running time: 111.1227s / 31605.2501 s
env0_first_0:                 episode reward: -62.8000,                 loss: 24.6898
env0_second_0:                 episode reward: 62.8000,                 loss: 27.9024
env1_first_0:                 episode reward: -61.2000,                 loss: nan
env1_second_0:                 episode reward: 61.2000,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 356.65,                last time consumption/overall running time: 67.6428s / 31672.8929 s
env0_first_0:                 episode reward: -77.6000,                 loss: 42.0429
env0_second_0:                 episode reward: 77.6000,                 loss: 51.1178
env1_first_0:                 episode reward: -67.7500,                 loss: nan
env1_second_0:                 episode reward: 67.7500,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 406.1,                last time consumption/overall running time: 78.7902s / 31751.6830 s
env0_first_0:                 episode reward: -68.7000,                 loss: 30.8563
env0_second_0:                 episode reward: 68.7000,                 loss: 35.0147
env1_first_0:                 episode reward: -77.5500,                 loss: nan
env1_second_0:                 episode reward: 77.5500,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 355.5,                last time consumption/overall running time: 67.3256s / 31819.0086 s
env0_first_0:                 episode reward: -73.3000,                 loss: 34.7383
env0_second_0:                 episode reward: 73.3000,                 loss: 39.4317
env1_first_0:                 episode reward: -72.3500,                 loss: nan
env1_second_0:                 episode reward: 72.3500,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 323.95,                last time consumption/overall running time: 60.6202s / 31879.6287 s
env0_first_0:                 episode reward: -90.3000,                 loss: 40.2300
env0_second_0:                 episode reward: 90.3000,                 loss: 43.8160
env1_first_0:                 episode reward: -71.6000,                 loss: nan
env1_second_0:                 episode reward: 71.6000,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 992.2,                last time consumption/overall running time: 167.3543s / 32046.9831 s
env0_first_0:                 episode reward: -59.8500,                 loss: 21.3068
env0_second_0:                 episode reward: 59.8500,                 loss: 24.9367
env1_first_0:                 episode reward: -48.1500,                 loss: nan
env1_second_0:                 episode reward: 48.1500,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 1396.15,                last time consumption/overall running time: 222.2022s / 32269.1853 s
env0_first_0:                 episode reward: -50.9000,                 loss: 7.4867
env0_second_0:                 episode reward: 50.9000,                 loss: 10.8452
env1_first_0:                 episode reward: -54.8000,                 loss: nan
env1_second_0:                 episode reward: 54.8000,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 315.1,                last time consumption/overall running time: 58.7125s / 32327.8978 s
env0_first_0:                 episode reward: -66.7000,                 loss: 47.7212
env0_second_0:                 episode reward: 66.7000,                 loss: 48.3534
env1_first_0:                 episode reward: -76.0000,                 loss: nan
env1_second_0:                 episode reward: 76.0000,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 348.8,                last time consumption/overall running time: 68.0118s / 32395.9097 s
env0_first_0:                 episode reward: -61.8500,                 loss: 36.5348
env0_second_0:                 episode reward: 61.8500,                 loss: 42.1171
env1_first_0:                 episode reward: -70.3000,                 loss: nan
env1_second_0:                 episode reward: 70.3000,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 304.5,                last time consumption/overall running time: 61.1669s / 32457.0765 s
env0_first_0:                 episode reward: -66.8500,                 loss: 43.2096
env0_second_0:                 episode reward: 66.8500,                 loss: 45.0835
env1_first_0:                 episode reward: -84.2000,                 loss: nan
env1_second_0:                 episode reward: 84.2000,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 342.8,                last time consumption/overall running time: 69.4277s / 32526.5042 s
env0_first_0:                 episode reward: -79.1500,                 loss: 41.7796
env0_second_0:                 episode reward: 79.1500,                 loss: 44.8479
env1_first_0:                 episode reward: -78.4000,                 loss: nan
env1_second_0:                 episode reward: 78.4000,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 1482.55,                last time consumption/overall running time: 258.5380s / 32785.0422 s
env0_first_0:                 episode reward: -12.4000,                 loss: 7.7835
env0_second_0:                 episode reward: 12.4000,                 loss: 12.9855
env1_first_0:                 episode reward: -15.7000,                 loss: nan
env1_second_0:                 episode reward: 15.7000,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 518.75,                last time consumption/overall running time: 98.3841s / 32883.4263 s
env0_first_0:                 episode reward: -71.4500,                 loss: 23.6915
env0_second_0:                 episode reward: 71.4500,                 loss: 26.6363
env1_first_0:                 episode reward: -61.6500,                 loss: nan
env1_second_0:                 episode reward: 61.6500,                 loss: nan
Episode: 3361/30000 (11.2033%),                 avg. length: 292.15,                last time consumption/overall running time: 54.5450s / 32937.9713 s
env0_first_0:                 episode reward: -93.4000,                 loss: 36.7976
env0_second_0:                 episode reward: 93.4000,                 loss: 43.0246
env1_first_0:                 episode reward: -59.9000,                 loss: nan
env1_second_0:                 episode reward: 59.9000,                 loss: nan
Episode: 3381/30000 (11.2700%),                 avg. length: 366.1,                last time consumption/overall running time: 72.1531s / 33010.1243 s
env0_first_0:                 episode reward: -77.2000,                 loss: 34.8122
env0_second_0:                 episode reward: 77.2000,                 loss: 37.6069
env1_first_0:                 episode reward: -73.2500,                 loss: nan
env1_second_0:                 episode reward: 73.2500,                 loss: nan
Episode: 3401/30000 (11.3367%),                 avg. length: 491.45,                last time consumption/overall running time: 90.1309s / 33100.2552 s
env0_first_0:                 episode reward: -58.5000,                 loss: 34.7527
env0_second_0:                 episode reward: 58.5000,                 loss: 37.6852
env1_first_0:                 episode reward: -68.1000,                 loss: nan
env1_second_0:                 episode reward: 68.1000,                 loss: nan
Episode: 3421/30000 (11.4033%),                 avg. length: 793.2,                last time consumption/overall running time: 134.5666s / 33234.8218 s
env0_first_0:                 episode reward: -47.5000,                 loss: 19.9936
env0_second_0:                 episode reward: 47.5000,                 loss: 23.3512
env1_first_0:                 episode reward: -50.8000,                 loss: nan
env1_second_0:                 episode reward: 50.8000,                 loss: nan
Episode: 3441/30000 (11.4700%),                 avg. length: 318.3,                last time consumption/overall running time: 65.6554s / 33300.4772 s
env0_first_0:                 episode reward: -74.6500,                 loss: 41.7903
env0_second_0:                 episode reward: 74.6500,                 loss: 135.8975
env1_first_0:                 episode reward: -74.8000,                 loss: nan
env1_second_0:                 episode reward: 74.8000,                 loss: nan
Episode: 3461/30000 (11.5367%),                 avg. length: 351.85,                last time consumption/overall running time: 70.4557s / 33370.9329 s
env0_first_0:                 episode reward: -64.0000,                 loss: 39.6315
env0_second_0:                 episode reward: 64.0000,                 loss: 44.9697
env1_first_0:                 episode reward: -79.4000,                 loss: nan
env1_second_0:                 episode reward: 79.4000,                 loss: nan
Episode: 3481/30000 (11.6033%),                 avg. length: 341.5,                last time consumption/overall running time: 62.3487s / 33433.2816 s
env0_first_0:                 episode reward: -72.0500,                 loss: 42.3573
env0_second_0:                 episode reward: 72.0500,                 loss: 45.6516
env1_first_0:                 episode reward: -71.2500,                 loss: nan
env1_second_0:                 episode reward: 71.2500,                 loss: nan
Episode: 3501/30000 (11.6700%),                 avg. length: 1570.5,                last time consumption/overall running time: 275.4963s / 33708.7779 s
env0_first_0:                 episode reward: -7.0500,                 loss: 7.8309
env0_second_0:                 episode reward: 7.0500,                 loss: 10.3950
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 3521/30000 (11.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 309.4528s / 34018.2307 s
env0_first_0:                 episode reward: -0.2000,                 loss: 1.3706
env0_second_0:                 episode reward: 0.2000,                 loss: 3.7710
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 3541/30000 (11.8033%),                 avg. length: 612.75,                last time consumption/overall running time: 109.9493s / 34128.1800 s
env0_first_0:                 episode reward: -65.3000,                 loss: 28.2141
env0_second_0:                 episode reward: 65.3000,                 loss: 34.0427
env1_first_0:                 episode reward: -46.3000,                 loss: nan
env1_second_0:                 episode reward: 46.3000,                 loss: nan
Episode: 3561/30000 (11.8700%),                 avg. length: 633.75,                last time consumption/overall running time: 113.9403s / 34242.1204 s
env0_first_0:                 episode reward: -57.6500,                 loss: 27.7062
env0_second_0:                 episode reward: 57.6500,                 loss: 31.4224
env1_first_0:                 episode reward: -66.6500,                 loss: nan
env1_second_0:                 episode reward: 66.6500,                 loss: nan
Episode: 3581/30000 (11.9367%),                 avg. length: 1145.5,                last time consumption/overall running time: 201.7134s / 34443.8337 s
env0_first_0:                 episode reward: -35.1500,                 loss: 9.1474
env0_second_0:                 episode reward: 35.1500,                 loss: 14.1978
env1_first_0:                 episode reward: -40.6000,                 loss: nan
env1_second_0:                 episode reward: 40.6000,                 loss: nan
Episode: 3601/30000 (12.0033%),                 avg. length: 669.85,                last time consumption/overall running time: 118.3474s / 34562.1811 s
env0_first_0:                 episode reward: -52.7500,                 loss: 23.4521
env0_second_0:                 episode reward: 52.7500,                 loss: 28.0411
env1_first_0:                 episode reward: -53.7000,                 loss: nan
env1_second_0:                 episode reward: 53.7000,                 loss: nan
Episode: 3621/30000 (12.0700%),                 avg. length: 453.1,                last time consumption/overall running time: 81.7920s / 34643.9731 s
env0_first_0:                 episode reward: -65.0500,                 loss: 35.7189
env0_second_0:                 episode reward: 65.0500,                 loss: 41.2725
env1_first_0:                 episode reward: -64.4500,                 loss: nan
env1_second_0:                 episode reward: 64.4500,                 loss: nan
Episode: 3641/30000 (12.1367%),                 avg. length: 567.2,                last time consumption/overall running time: 100.3417s / 34744.3148 s
env0_first_0:                 episode reward: -60.7000,                 loss: 38.2676
env0_second_0:                 episode reward: 60.7000,                 loss: 44.1962
env1_first_0:                 episode reward: -56.6500,                 loss: nan
env1_second_0:                 episode reward: 56.6500,                 loss: nan
Episode: 3661/30000 (12.2033%),                 avg. length: 451.45,                last time consumption/overall running time: 84.9845s / 34829.2993 s
env0_first_0:                 episode reward: -71.8500,                 loss: 35.8169
env0_second_0:                 episode reward: 71.8500,                 loss: 44.1896
env1_first_0:                 episode reward: -64.9500,                 loss: nan
env1_second_0:                 episode reward: 64.9500,                 loss: nan
Episode: 3681/30000 (12.2700%),                 avg. length: 378.75,                last time consumption/overall running time: 75.6389s / 34904.9382 s
env0_first_0:                 episode reward: -64.2500,                 loss: 45.8367
env0_second_0:                 episode reward: 64.2500,                 loss: 50.4534
env1_first_0:                 episode reward: -75.4000,                 loss: nan
env1_second_0:                 episode reward: 75.4000,                 loss: nan
Episode: 3701/30000 (12.3367%),                 avg. length: 412.7,                last time consumption/overall running time: 80.8290s / 34985.7672 s
env0_first_0:                 episode reward: -59.8000,                 loss: 37.0311
env0_second_0:                 episode reward: 59.8000,                 loss: 41.4172
env1_first_0:                 episode reward: -71.0000,                 loss: nan
env1_second_0:                 episode reward: 71.0000,                 loss: nan
Episode: 3721/30000 (12.4033%),                 avg. length: 421.7,                last time consumption/overall running time: 79.7808s / 35065.5480 s
env0_first_0:                 episode reward: -57.8000,                 loss: 34.9851
env0_second_0:                 episode reward: 57.8000,                 loss: 40.8881
env1_first_0:                 episode reward: -71.0500,                 loss: nan
env1_second_0:                 episode reward: 71.0500,                 loss: nan
Episode: 3741/30000 (12.4700%),                 avg. length: 374.25,                last time consumption/overall running time: 69.2943s / 35134.8423 s
env0_first_0:                 episode reward: -63.0000,                 loss: 40.6375
env0_second_0:                 episode reward: 63.0000,                 loss: 46.1216
env1_first_0:                 episode reward: -72.7500,                 loss: nan
env1_second_0:                 episode reward: 72.7500,                 loss: nan
Episode: 3761/30000 (12.5367%),                 avg. length: 458.8,                last time consumption/overall running time: 82.9682s / 35217.8105 s
env0_first_0:                 episode reward: -73.3500,                 loss: 34.6123
env0_second_0:                 episode reward: 73.3500,                 loss: 38.2896
env1_first_0:                 episode reward: -66.8000,                 loss: nan
env1_second_0:                 episode reward: 66.8000,                 loss: nan
Episode: 3781/30000 (12.6033%),                 avg. length: 429.9,                last time consumption/overall running time: 79.9692s / 35297.7797 s
env0_first_0:                 episode reward: -59.5000,                 loss: 37.9178
env0_second_0:                 episode reward: 59.5000,                 loss: 42.0629
env1_first_0:                 episode reward: -63.4000,                 loss: nan
env1_second_0:                 episode reward: 63.4000,                 loss: nan
Episode: 3801/30000 (12.6700%),                 avg. length: 806.0,                last time consumption/overall running time: 144.9142s / 35442.6939 s
env0_first_0:                 episode reward: -52.1000,                 loss: 29.3953
env0_second_0:                 episode reward: 52.1000,                 loss: 32.2902
env1_first_0:                 episode reward: -51.0000,                 loss: nan
env1_second_0:                 episode reward: 51.0000,                 loss: nan
Episode: 3821/30000 (12.7367%),                 avg. length: 350.1,                last time consumption/overall running time: 68.8775s / 35511.5714 s
env0_first_0:                 episode reward: -71.7000,                 loss: 43.8909
env0_second_0:                 episode reward: 71.7000,                 loss: 46.2968
env1_first_0:                 episode reward: -72.5500,                 loss: nan
env1_second_0:                 episode reward: 72.5500,                 loss: nan
Episode: 3841/30000 (12.8033%),                 avg. length: 1072.2,                last time consumption/overall running time: 184.3727s / 35695.9441 s
env0_first_0:                 episode reward: -43.0000,                 loss: 22.8083
env0_second_0:                 episode reward: 43.0000,                 loss: 26.3590
env1_first_0:                 episode reward: -48.5500,                 loss: nan
env1_second_0:                 episode reward: 48.5500,                 loss: nan
Episode: 3861/30000 (12.8700%),                 avg. length: 1211.75,                last time consumption/overall running time: 199.8367s / 35895.7808 s
env0_first_0:                 episode reward: -7.6000,                 loss: 9.5681
env0_second_0:                 episode reward: 7.6000,                 loss: 13.6527
env1_first_0:                 episode reward: -17.1500,                 loss: nan
env1_second_0:                 episode reward: 17.1500,                 loss: nan
Episode: 3881/30000 (12.9367%),                 avg. length: 942.0,                last time consumption/overall running time: 162.4801s / 36058.2610 s
env0_first_0:                 episode reward: -27.2000,                 loss: 15.0904
env0_second_0:                 episode reward: 27.2000,                 loss: 18.0052
env1_first_0:                 episode reward: -21.6000,                 loss: nan
env1_second_0:                 episode reward: 21.6000,                 loss: nan
Episode: 3901/30000 (13.0033%),                 avg. length: 576.6,                last time consumption/overall running time: 97.4555s / 36155.7164 s
env0_first_0:                 episode reward: -41.0000,                 loss: 24.2099
env0_second_0:                 episode reward: 41.0000,                 loss: 24.2289
env1_first_0:                 episode reward: -70.9000,                 loss: nan
env1_second_0:                 episode reward: 70.9000,                 loss: nan
Episode: 3921/30000 (13.0700%),                 avg. length: 795.55,                last time consumption/overall running time: 136.6462s / 36292.3626 s
env0_first_0:                 episode reward: -38.5500,                 loss: 25.7538
env0_second_0:                 episode reward: 38.5500,                 loss: 25.9435
env1_first_0:                 episode reward: -44.0000,                 loss: nan
env1_second_0:                 episode reward: 44.0000,                 loss: nan
Episode: 3941/30000 (13.1367%),                 avg. length: 565.75,                last time consumption/overall running time: 97.5815s / 36389.9441 s
env0_first_0:                 episode reward: -66.4500,                 loss: 29.3060
env0_second_0:                 episode reward: 66.4500,                 loss: 28.7804
env1_first_0:                 episode reward: -53.8000,                 loss: nan
env1_second_0:                 episode reward: 53.8000,                 loss: nan
Episode: 3961/30000 (13.2033%),                 avg. length: 580.65,                last time consumption/overall running time: 102.7259s / 36492.6700 s
env0_first_0:                 episode reward: -67.2500,                 loss: 27.0782
env0_second_0:                 episode reward: 67.2500,                 loss: 25.9702
env1_first_0:                 episode reward: -71.6500,                 loss: nan
env1_second_0:                 episode reward: 71.6500,                 loss: nan
Episode: 3981/30000 (13.2700%),                 avg. length: 890.4,                last time consumption/overall running time: 150.0195s / 36642.6895 s
env0_first_0:                 episode reward: -48.9500,                 loss: 17.3539
env0_second_0:                 episode reward: 48.9500,                 loss: 18.6505
env1_first_0:                 episode reward: -55.4000,                 loss: nan
env1_second_0:                 episode reward: 55.4000,                 loss: nan
Episode: 4001/30000 (13.3367%),                 avg. length: 1468.75,                last time consumption/overall running time: 249.2979s / 36891.9874 s
env0_first_0:                 episode reward: -19.3500,                 loss: 8.8796
env0_second_0:                 episode reward: 19.3500,                 loss: 11.3620
env1_first_0:                 episode reward: -29.1500,                 loss: nan
env1_second_0:                 episode reward: 29.1500,                 loss: nan
Episode: 4021/30000 (13.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.5885s / 37193.5759 s
env0_first_0:                 episode reward: -5.6000,                 loss: 1.7117
env0_second_0:                 episode reward: 5.6000,                 loss: 12.6161
env1_first_0:                 episode reward: -5.1000,                 loss: nan
env1_second_0:                 episode reward: 5.1000,                 loss: nan
Episode: 4041/30000 (13.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.5858s / 37492.1617 s
env0_first_0:                 episode reward: -12.0000,                 loss: 1.6422
env0_second_0:                 episode reward: 12.0000,                 loss: 5.2006
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 4061/30000 (13.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.1395s / 37790.3012 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.2071
env0_second_0:                 episode reward: 2.0500,                 loss: 3.3315
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 4081/30000 (13.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 291.4506s / 38081.7517 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0295
env0_second_0:                 episode reward: 0.0000,                 loss: 2.8419
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 4101/30000 (13.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.6486s / 38377.4003 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.0403
env0_second_0:                 episode reward: 0.3000,                 loss: 44.9574
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4121/30000 (13.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 293.2953s / 38670.6956 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0792
env0_second_0:                 episode reward: 0.0000,                 loss: 2.6004
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4141/30000 (13.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 281.9440s / 38952.6396 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1005
env0_second_0:                 episode reward: 0.0000,                 loss: 2.0551
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 4161/30000 (13.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 276.8543s / 39229.4939 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0805
env0_second_0:                 episode reward: 0.2000,                 loss: 1.4960
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 4181/30000 (13.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 284.4302s / 39513.9241 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.0657
env0_second_0:                 episode reward: 0.4000,                 loss: 0.9692
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 4201/30000 (14.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 291.3520s / 39805.2761 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0739
env0_second_0:                 episode reward: 0.0000,                 loss: 1.3128
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4221/30000 (14.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.7707s / 40101.0468 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0673
env0_second_0:                 episode reward: 0.0000,                 loss: 4.9072
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4241/30000 (14.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 294.5932s / 40395.6400 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0573
env0_second_0:                 episode reward: 0.0000,                 loss: 3.2357
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4261/30000 (14.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 286.2450s / 40681.8850 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0654
env0_second_0:                 episode reward: 0.0000,                 loss: 2.1567
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4281/30000 (14.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.5663s / 40981.4513 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0738
env0_second_0:                 episode reward: 0.0000,                 loss: 1.7368
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4301/30000 (14.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.2175s / 41280.6688 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0529
env0_second_0:                 episode reward: 0.0000,                 loss: 1.3488
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4321/30000 (14.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.3237s / 41580.9926 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0326
env0_second_0:                 episode reward: 0.0000,                 loss: 0.8984
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4341/30000 (14.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 296.4810s / 41877.4736 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0156
env0_second_0:                 episode reward: 0.0000,                 loss: 1.1218
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4361/30000 (14.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.0825s / 42177.5561 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0497
env0_second_0:                 episode reward: -0.2000,                 loss: 0.6173
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4381/30000 (14.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.9254s / 42476.4815 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0388
env0_second_0:                 episode reward: -0.1000,                 loss: 0.9490
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4401/30000 (14.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 297.0813s / 42773.5628 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0606
env0_second_0:                 episode reward: 0.0000,                 loss: 0.8686
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4421/30000 (14.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.0352s / 43072.5980 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0579
env0_second_0:                 episode reward: 0.0000,                 loss: 2.5458
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4441/30000 (14.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.2616s / 43371.8596 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0272
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3112
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4461/30000 (14.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 297.0677s / 43668.9274 s
env0_first_0:                 episode reward: 0.0500,                 loss: -0.0326
env0_second_0:                 episode reward: -0.0500,                 loss: 0.1153
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 4481/30000 (14.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.0300s / 43967.9574 s
env0_first_0:                 episode reward: 0.2000,                 loss: -0.0195
env0_second_0:                 episode reward: -0.2000,                 loss: 0.1777
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4501/30000 (15.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 296.7248s / 44264.6822 s
env0_first_0:                 episode reward: 1.1000,                 loss: -0.0399
env0_second_0:                 episode reward: -1.1000,                 loss: 0.4663
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 4521/30000 (15.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.4079s / 44565.0901 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0655
env0_second_0:                 episode reward: 0.9500,                 loss: 0.3841
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 4541/30000 (15.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.1849s / 44865.2750 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0593
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1668
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4561/30000 (15.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.8455s / 45165.1205 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0586
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0355
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4581/30000 (15.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 296.6911s / 45461.8117 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0552
env0_second_0:                 episode reward: -0.1000,                 loss: -0.0134
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4601/30000 (15.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.9243s / 45760.7360 s
env0_first_0:                 episode reward: -1.2500,                 loss: -0.0094
env0_second_0:                 episode reward: 1.2500,                 loss: 0.2764
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 4621/30000 (15.4033%),                 avg. length: 940.85,                last time consumption/overall running time: 164.5650s / 45925.3010 s
env0_first_0:                 episode reward: -54.0000,                 loss: 9.9083
env0_second_0:                 episode reward: 54.0000,                 loss: 10.4617
env1_first_0:                 episode reward: -51.1000,                 loss: nan
env1_second_0:                 episode reward: 51.1000,                 loss: nan
Episode: 4641/30000 (15.4700%),                 avg. length: 940.4,                last time consumption/overall running time: 164.7863s / 46090.0873 s
env0_first_0:                 episode reward: -46.8500,                 loss: 20.9634
env0_second_0:                 episode reward: 46.8500,                 loss: 23.8697
env1_first_0:                 episode reward: -55.8000,                 loss: nan
env1_second_0:                 episode reward: 55.8000,                 loss: nan
Episode: 4661/30000 (15.5367%),                 avg. length: 378.15,                last time consumption/overall running time: 72.8744s / 46162.9617 s
env0_first_0:                 episode reward: -68.6500,                 loss: 38.6999
env0_second_0:                 episode reward: 68.6500,                 loss: 48.0440
env1_first_0:                 episode reward: -72.8000,                 loss: nan
env1_second_0:                 episode reward: 72.8000,                 loss: nan
Episode: 4681/30000 (15.6033%),                 avg. length: 555.25,                last time consumption/overall running time: 104.6124s / 46267.5740 s
env0_first_0:                 episode reward: -65.9500,                 loss: 38.2055
env0_second_0:                 episode reward: 65.9500,                 loss: 42.3704
env1_first_0:                 episode reward: -62.9500,                 loss: nan
env1_second_0:                 episode reward: 62.9500,                 loss: nan
Episode: 4701/30000 (15.6700%),                 avg. length: 360.25,                last time consumption/overall running time: 71.7488s / 46339.3228 s
env0_first_0:                 episode reward: -79.9500,                 loss: 41.8293
env0_second_0:                 episode reward: 79.9500,                 loss: 48.0887
env1_first_0:                 episode reward: -61.5000,                 loss: nan
env1_second_0:                 episode reward: 61.5000,                 loss: nan
Episode: 4721/30000 (15.7367%),                 avg. length: 301.95,                last time consumption/overall running time: 62.5036s / 46401.8265 s
env0_first_0:                 episode reward: -84.7500,                 loss: 44.9820
env0_second_0:                 episode reward: 84.7500,                 loss: 48.3250
env1_first_0:                 episode reward: -63.0500,                 loss: nan
env1_second_0:                 episode reward: 63.0500,                 loss: nan
Episode: 4741/30000 (15.8033%),                 avg. length: 268.8,                last time consumption/overall running time: 57.6409s / 46459.4674 s
env0_first_0:                 episode reward: -80.0000,                 loss: 52.3549
env0_second_0:                 episode reward: 80.0000,                 loss: 54.6238
env1_first_0:                 episode reward: -75.7500,                 loss: nan
env1_second_0:                 episode reward: 75.7500,                 loss: nan
Episode: 4761/30000 (15.8700%),                 avg. length: 305.0,                last time consumption/overall running time: 63.2857s / 46522.7531 s
env0_first_0:                 episode reward: -78.1000,                 loss: 51.6033
env0_second_0:                 episode reward: 78.1000,                 loss: 51.7594
env1_first_0:                 episode reward: -85.9000,                 loss: nan
env1_second_0:                 episode reward: 85.9000,                 loss: nan
Episode: 4781/30000 (15.9367%),                 avg. length: 336.6,                last time consumption/overall running time: 68.0873s / 46590.8404 s
env0_first_0:                 episode reward: -90.9500,                 loss: 42.1896
env0_second_0:                 episode reward: 90.9500,                 loss: 45.8975
env1_first_0:                 episode reward: -81.0000,                 loss: nan
env1_second_0:                 episode reward: 81.0000,                 loss: nan
Episode: 4801/30000 (16.0033%),                 avg. length: 462.65,                last time consumption/overall running time: 88.0018s / 46678.8423 s
env0_first_0:                 episode reward: -68.7000,                 loss: 32.6114
env0_second_0:                 episode reward: 68.7000,                 loss: 37.5639
env1_first_0:                 episode reward: -77.9000,                 loss: nan
env1_second_0:                 episode reward: 77.9000,                 loss: nan
Episode: 4821/30000 (16.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 310.4724s / 46989.3146 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.4661
env0_second_0:                 episode reward: -0.1000,                 loss: 3.6288
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4841/30000 (16.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.0884s / 47284.4030 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0250
env0_second_0:                 episode reward: 0.0000,                 loss: 2.2635
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4861/30000 (16.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.2284s / 47579.6314 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0056
env0_second_0:                 episode reward: 0.0000,                 loss: 1.9378
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4881/30000 (16.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.6023s / 47881.2337 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0371
env0_second_0:                 episode reward: -0.1000,                 loss: 1.9143
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 4901/30000 (16.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 303.6895s / 48184.9233 s
env0_first_0:                 episode reward: 0.4500,                 loss: -0.0711
env0_second_0:                 episode reward: -0.4500,                 loss: 2.0193
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 4921/30000 (16.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 290.1283s / 48475.0515 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0555
env0_second_0:                 episode reward: -0.1000,                 loss: 8.3052
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 4941/30000 (16.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.1497s / 48774.2012 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.0468
env0_second_0:                 episode reward: -0.4000,                 loss: 3.0834
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4961/30000 (16.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 304.3411s / 49078.5424 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0335
env0_second_0:                 episode reward: 0.0000,                 loss: 1.7105
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 4981/30000 (16.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.0381s / 49379.5805 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0460
env0_second_0:                 episode reward: 0.0000,                 loss: 2.9370
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5001/30000 (16.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.9654s / 49681.5459 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0477
env0_second_0:                 episode reward: 0.0000,                 loss: 2.4979
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5021/30000 (16.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.6683s / 49983.2142 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0740
env0_second_0:                 episode reward: -0.1000,                 loss: 4.1713
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5041/30000 (16.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 289.4355s / 50272.6497 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0438
env0_second_0:                 episode reward: 0.0000,                 loss: 1.5245
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5061/30000 (16.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 292.4586s / 50565.1083 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0305
env0_second_0:                 episode reward: 0.0000,                 loss: 1.1810
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5081/30000 (16.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 291.4872s / 50856.5955 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0250
env0_second_0:                 episode reward: 0.2000,                 loss: 0.7511
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5101/30000 (17.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 286.5259s / 51143.1214 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0644
env0_second_0:                 episode reward: 0.0000,                 loss: 1.1494
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5121/30000 (17.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 289.4691s / 51432.5905 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1234
env0_second_0:                 episode reward: 0.0000,                 loss: 1.2704
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5141/30000 (17.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 293.2240s / 51725.8146 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1263
env0_second_0:                 episode reward: 0.0000,                 loss: 1.2659
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5161/30000 (17.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 291.7911s / 52017.6057 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1320
env0_second_0:                 episode reward: 0.0000,                 loss: 1.2595
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5181/30000 (17.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.1020s / 52315.7077 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1227
env0_second_0:                 episode reward: 0.0000,                 loss: 1.0989
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5201/30000 (17.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 290.8028s / 52606.5105 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1151
env0_second_0:                 episode reward: 0.0000,                 loss: 0.8296
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5221/30000 (17.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.0837s / 52906.5942 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1083
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2750
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5241/30000 (17.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.7804s / 53205.3746 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0712
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2261
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5261/30000 (17.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.0257s / 53504.4002 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0702
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2463
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5281/30000 (17.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.9586s / 53800.3588 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.0674
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4700
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5301/30000 (17.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 297.0930s / 54097.4518 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1061
env0_second_0:                 episode reward: 0.0000,                 loss: 0.6980
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5321/30000 (17.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 305.5021s / 54402.9539 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.2783
env0_second_0:                 episode reward: 6.0000,                 loss: 1.5680
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 5341/30000 (17.8033%),                 avg. length: 1315.35,                last time consumption/overall running time: 231.4835s / 54634.4374 s
env0_first_0:                 episode reward: -29.5000,                 loss: 9.6962
env0_second_0:                 episode reward: 29.5000,                 loss: 12.1668
env1_first_0:                 episode reward: -34.6500,                 loss: nan
env1_second_0:                 episode reward: 34.6500,                 loss: nan
Episode: 5361/30000 (17.8700%),                 avg. length: 376.0,                last time consumption/overall running time: 71.1696s / 54705.6070 s
env0_first_0:                 episode reward: -69.9000,                 loss: 32.2650
env0_second_0:                 episode reward: 69.9000,                 loss: 36.5415
env1_first_0:                 episode reward: -79.6500,                 loss: nan
env1_second_0:                 episode reward: 79.6500,                 loss: nan
Episode: 5381/30000 (17.9367%),                 avg. length: 877.25,                last time consumption/overall running time: 151.5177s / 54857.1247 s
env0_first_0:                 episode reward: -61.0500,                 loss: 29.8980
env0_second_0:                 episode reward: 61.0500,                 loss: 33.7803
env1_first_0:                 episode reward: -61.1000,                 loss: nan
env1_second_0:                 episode reward: 61.1000,                 loss: nan
Episode: 5401/30000 (18.0033%),                 avg. length: 542.45,                last time consumption/overall running time: 102.1192s / 54959.2439 s
env0_first_0:                 episode reward: -68.1000,                 loss: 40.1198
env0_second_0:                 episode reward: 68.1000,                 loss: 43.5100
env1_first_0:                 episode reward: -64.2000,                 loss: nan
env1_second_0:                 episode reward: 64.2000,                 loss: nan
Episode: 5421/30000 (18.0700%),                 avg. length: 349.7,                last time consumption/overall running time: 68.5322s / 55027.7761 s
env0_first_0:                 episode reward: -79.8000,                 loss: 44.4771
env0_second_0:                 episode reward: 79.8000,                 loss: 51.1843
env1_first_0:                 episode reward: -71.6000,                 loss: nan
env1_second_0:                 episode reward: 71.6000,                 loss: nan
Episode: 5441/30000 (18.1367%),                 avg. length: 865.7,                last time consumption/overall running time: 149.4122s / 55177.1883 s
env0_first_0:                 episode reward: -55.1500,                 loss: 23.3343
env0_second_0:                 episode reward: 55.1500,                 loss: 25.9555
env1_first_0:                 episode reward: -60.3500,                 loss: nan
env1_second_0:                 episode reward: 60.3500,                 loss: nan
Episode: 5461/30000 (18.2033%),                 avg. length: 711.2,                last time consumption/overall running time: 131.0909s / 55308.2792 s
env0_first_0:                 episode reward: -72.6500,                 loss: 31.5533
env0_second_0:                 episode reward: 72.6500,                 loss: 35.0579
env1_first_0:                 episode reward: -70.8500,                 loss: nan
env1_second_0:                 episode reward: 70.8500,                 loss: nan
Episode: 5481/30000 (18.2700%),                 avg. length: 376.95,                last time consumption/overall running time: 71.6824s / 55379.9617 s
env0_first_0:                 episode reward: -88.3000,                 loss: 31.3435
env0_second_0:                 episode reward: 88.3000,                 loss: 33.7130
env1_first_0:                 episode reward: -83.6500,                 loss: nan
env1_second_0:                 episode reward: 83.6500,                 loss: nan
Episode: 5501/30000 (18.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 306.6046s / 55686.5663 s
env0_first_0:                 episode reward: -0.8000,                 loss: 1.0729
env0_second_0:                 episode reward: 0.8000,                 loss: 12.1913
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 5521/30000 (18.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 310.7457s / 55997.3120 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0681
env0_second_0:                 episode reward: 0.3500,                 loss: 2.8910
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 5541/30000 (18.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.1819s / 56298.4939 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0649
env0_second_0:                 episode reward: 0.6000,                 loss: 1.9852
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 5561/30000 (18.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 304.0027s / 56602.4967 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0303
env0_second_0:                 episode reward: 0.4000,                 loss: 2.0280
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 5581/30000 (18.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.4938s / 56904.9904 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0225
env0_second_0:                 episode reward: 0.9000,                 loss: 1.8691
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5601/30000 (18.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 297.0165s / 57202.0069 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.0129
env0_second_0:                 episode reward: 0.4000,                 loss: 3.6145
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 5621/30000 (18.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.6041s / 57500.6110 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0526
env0_second_0:                 episode reward: 0.0000,                 loss: 4.0707
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5641/30000 (18.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.9932s / 57802.6042 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0573
env0_second_0:                 episode reward: 0.0000,                 loss: 2.2559
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5661/30000 (18.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 291.8481s / 58094.4523 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0476
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2831
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5681/30000 (18.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 289.8092s / 58384.2616 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0608
env0_second_0:                 episode reward: 0.0000,                 loss: 0.8390
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5701/30000 (19.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 286.1490s / 58670.4106 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0791
env0_second_0:                 episode reward: 0.0000,                 loss: 0.7702
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5721/30000 (19.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.8301s / 58971.2407 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0985
env0_second_0:                 episode reward: 0.0000,                 loss: 0.8823
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5741/30000 (19.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.1219s / 59271.3626 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1547
env0_second_0:                 episode reward: 0.0000,                 loss: 0.4234
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5761/30000 (19.2033%),                 avg. length: 1490.2,                last time consumption/overall running time: 254.3696s / 59525.7322 s
env0_first_0:                 episode reward: -38.5500,                 loss: 2.1713
env0_second_0:                 episode reward: 38.5500,                 loss: 4.2105
env1_first_0:                 episode reward: -40.1500,                 loss: nan
env1_second_0:                 episode reward: 40.1500,                 loss: nan
Episode: 5781/30000 (19.2700%),                 avg. length: 1408.05,                last time consumption/overall running time: 246.5786s / 59772.3109 s
env0_first_0:                 episode reward: -63.4000,                 loss: 2.8339
env0_second_0:                 episode reward: 63.4000,                 loss: 5.9467
env1_first_0:                 episode reward: -67.2000,                 loss: nan
env1_second_0:                 episode reward: 67.2000,                 loss: nan
Episode: 5801/30000 (19.3367%),                 avg. length: 1769.6,                last time consumption/overall running time: 307.8461s / 60080.1569 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.2493
env0_second_0:                 episode reward: 9.7500,                 loss: 2.0175
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 5821/30000 (19.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.9968s / 60383.1537 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2132
env0_second_0:                 episode reward: 0.0000,                 loss: 0.5190
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5841/30000 (19.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.8565s / 60686.0102 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2243
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2418
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5861/30000 (19.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 312.7177s / 60998.7280 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.2206
env0_second_0:                 episode reward: 0.0000,                 loss: 0.1725
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5881/30000 (19.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 296.2238s / 61294.9518 s
env0_first_0:                 episode reward: -0.2500,                 loss: -0.1922
env0_second_0:                 episode reward: 0.2500,                 loss: 0.3216
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5901/30000 (19.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.9359s / 61593.8876 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.1718
env0_second_0:                 episode reward: 0.1500,                 loss: 0.6762
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 5921/30000 (19.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 310.9836s / 61904.8712 s
env0_first_0:                 episode reward: -0.3000,                 loss: -0.1535
env0_second_0:                 episode reward: 0.3000,                 loss: 1.2759
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 5941/30000 (19.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.6146s / 62203.4858 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1990
env0_second_0:                 episode reward: 0.0000,                 loss: 1.0317
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 5961/30000 (19.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.0206s / 62501.5064 s
env0_first_0:                 episode reward: -0.2000,                 loss: -0.2442
env0_second_0:                 episode reward: 0.2000,                 loss: 0.4453
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 5981/30000 (19.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.2835s / 62803.7898 s
env0_first_0:                 episode reward: -1.2500,                 loss: -0.2578
env0_second_0:                 episode reward: 1.2500,                 loss: 1.2731
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 6001/30000 (20.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.4267s / 63105.2165 s
env0_first_0:                 episode reward: -2.8000,                 loss: -0.1523
env0_second_0:                 episode reward: 2.8000,                 loss: 0.9329
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 6021/30000 (20.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 309.7259s / 63414.9424 s
env0_first_0:                 episode reward: -2.0000,                 loss: -0.2295
env0_second_0:                 episode reward: 2.0000,                 loss: 1.0622
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 6041/30000 (20.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 303.7155s / 63718.6580 s
env0_first_0:                 episode reward: -1.0000,                 loss: -0.3584
env0_second_0:                 episode reward: 1.0000,                 loss: 1.4562
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 6061/30000 (20.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 312.0891s / 64030.7471 s
env0_first_0:                 episode reward: 0.5000,                 loss: -0.3676
env0_second_0:                 episode reward: -0.5000,                 loss: 0.8635
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 6081/30000 (20.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 308.0766s / 64338.8237 s
env0_first_0:                 episode reward: -0.6000,                 loss: -0.3587
env0_second_0:                 episode reward: 0.6000,                 loss: 1.0247
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6101/30000 (20.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.0266s / 64640.8504 s
env0_first_0:                 episode reward: -0.1500,                 loss: -0.4037
env0_second_0:                 episode reward: 0.1500,                 loss: 1.1663
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6121/30000 (20.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.9567s / 64940.8070 s
env0_first_0:                 episode reward: -0.4000,                 loss: -0.3825
env0_second_0:                 episode reward: 0.4000,                 loss: 0.5101
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 6141/30000 (20.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.5089s / 65242.3159 s
env0_first_0:                 episode reward: -0.5500,                 loss: -0.3423
env0_second_0:                 episode reward: 0.5500,                 loss: 0.2016
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 6161/30000 (20.5367%),                 avg. length: 1378.15,                last time consumption/overall running time: 235.9725s / 65478.2884 s
env0_first_0:                 episode reward: -28.0000,                 loss: 3.2645
env0_second_0:                 episode reward: 28.0000,                 loss: 4.0707
env1_first_0:                 episode reward: -34.7500,                 loss: nan
env1_second_0:                 episode reward: 34.7500,                 loss: nan
Episode: 6181/30000 (20.6033%),                 avg. length: 459.4,                last time consumption/overall running time: 88.3723s / 65566.6608 s
env0_first_0:                 episode reward: -68.5500,                 loss: 18.8846
env0_second_0:                 episode reward: 68.5500,                 loss: 19.1500
env1_first_0:                 episode reward: -77.7500,                 loss: nan
env1_second_0:                 episode reward: 77.7500,                 loss: nan
Episode: 6201/30000 (20.6700%),                 avg. length: 395.85,                last time consumption/overall running time: 76.7174s / 65643.3782 s
env0_first_0:                 episode reward: -67.3500,                 loss: 31.5977
env0_second_0:                 episode reward: 67.3500,                 loss: 31.8602
env1_first_0:                 episode reward: -78.2500,                 loss: nan
env1_second_0:                 episode reward: 78.2500,                 loss: nan
Episode: 6221/30000 (20.7367%),                 avg. length: 317.4,                last time consumption/overall running time: 58.1175s / 65701.4957 s
env0_first_0:                 episode reward: -81.4500,                 loss: 34.9087
env0_second_0:                 episode reward: 81.4500,                 loss: 36.7973
env1_first_0:                 episode reward: -76.4000,                 loss: nan
env1_second_0:                 episode reward: 76.4000,                 loss: nan
Episode: 6241/30000 (20.8033%),                 avg. length: 314.2,                last time consumption/overall running time: 58.7253s / 65760.2210 s
env0_first_0:                 episode reward: -70.1000,                 loss: 33.4817
env0_second_0:                 episode reward: 70.1000,                 loss: 34.7701
env1_first_0:                 episode reward: -84.2000,                 loss: nan
env1_second_0:                 episode reward: 84.2000,                 loss: nan
Episode: 6261/30000 (20.8700%),                 avg. length: 827.85,                last time consumption/overall running time: 142.9332s / 65903.1543 s
env0_first_0:                 episode reward: -43.7000,                 loss: 23.7002
env0_second_0:                 episode reward: 43.7000,                 loss: 25.7501
env1_first_0:                 episode reward: -52.8000,                 loss: nan
env1_second_0:                 episode reward: 52.8000,                 loss: nan
Episode: 6281/30000 (20.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 306.7755s / 66209.9297 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0624
env0_second_0:                 episode reward: 0.0000,                 loss: 0.7771
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6301/30000 (21.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 308.9473s / 66518.8770 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0729
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0455
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6321/30000 (21.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 307.9874s / 66826.8644 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.1361
env0_second_0:                 episode reward: 0.0000,                 loss: -0.0937
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 6341/30000 (21.1367%),                 avg. length: 1743.15,                last time consumption/overall running time: 305.0402s / 67131.9046 s
env0_first_0:                 episode reward: -4.8000,                 loss: 1.1058
env0_second_0:                 episode reward: 4.8000,                 loss: 1.3172
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 6361/30000 (21.2033%),                 avg. length: 1012.6,                last time consumption/overall running time: 179.0897s / 67310.9943 s
env0_first_0:                 episode reward: -35.6000,                 loss: 8.4560
env0_second_0:                 episode reward: 35.6000,                 loss: 9.9702
env1_first_0:                 episode reward: -45.5500,                 loss: nan
env1_second_0:                 episode reward: 45.5500,                 loss: nan
Episode: 6381/30000 (21.2700%),                 avg. length: 459.4,                last time consumption/overall running time: 80.4711s / 67391.4654 s
env0_first_0:                 episode reward: -51.5500,                 loss: 21.8340
env0_second_0:                 episode reward: 51.5500,                 loss: 24.1327
env1_first_0:                 episode reward: -86.6000,                 loss: nan
env1_second_0:                 episode reward: 86.6000,                 loss: nan
Episode: 6401/30000 (21.3367%),                 avg. length: 483.8,                last time consumption/overall running time: 93.5593s / 67485.0247 s
env0_first_0:                 episode reward: -64.2000,                 loss: 36.3913
env0_second_0:                 episode reward: 64.2000,                 loss: 38.7229
env1_first_0:                 episode reward: -59.5500,                 loss: nan
env1_second_0:                 episode reward: 59.5500,                 loss: nan
Episode: 6421/30000 (21.4033%),                 avg. length: 270.2,                last time consumption/overall running time: 51.4166s / 67536.4413 s
env0_first_0:                 episode reward: -79.6500,                 loss: 44.5528
env0_second_0:                 episode reward: 79.6500,                 loss: 45.9782
env1_first_0:                 episode reward: -83.7000,                 loss: nan
env1_second_0:                 episode reward: 83.7000,                 loss: nan
Episode: 6441/30000 (21.4700%),                 avg. length: 407.35,                last time consumption/overall running time: 77.2247s / 67613.6660 s
env0_first_0:                 episode reward: -78.1500,                 loss: 35.1038
env0_second_0:                 episode reward: 78.1500,                 loss: 35.8763
env1_first_0:                 episode reward: -77.2500,                 loss: nan
env1_second_0:                 episode reward: 77.2500,                 loss: nan
Episode: 6461/30000 (21.5367%),                 avg. length: 372.5,                last time consumption/overall running time: 70.9061s / 67684.5721 s
env0_first_0:                 episode reward: -89.0500,                 loss: 36.9265
env0_second_0:                 episode reward: 89.0500,                 loss: 42.6041
env1_first_0:                 episode reward: -70.2000,                 loss: nan
env1_second_0:                 episode reward: 70.2000,                 loss: nan
Episode: 6481/30000 (21.6033%),                 avg. length: 395.95,                last time consumption/overall running time: 74.4676s / 67759.0397 s
env0_first_0:                 episode reward: -75.8500,                 loss: 37.4536
env0_second_0:                 episode reward: 75.8500,                 loss: 41.7767
env1_first_0:                 episode reward: -75.0500,                 loss: nan
env1_second_0:                 episode reward: 75.0500,                 loss: nan
Episode: 6501/30000 (21.6700%),                 avg. length: 424.0,                last time consumption/overall running time: 74.7124s / 67833.7521 s
env0_first_0:                 episode reward: -68.5000,                 loss: 31.7521
env0_second_0:                 episode reward: 68.5000,                 loss: 35.0103
env1_first_0:                 episode reward: -74.1500,                 loss: nan
env1_second_0:                 episode reward: 74.1500,                 loss: nan
Episode: 6521/30000 (21.7367%),                 avg. length: 486.2,                last time consumption/overall running time: 84.1139s / 67917.8661 s
env0_first_0:                 episode reward: -77.9000,                 loss: 20.3137
env0_second_0:                 episode reward: 77.9000,                 loss: 24.2598
env1_first_0:                 episode reward: -71.7500,                 loss: nan
env1_second_0:                 episode reward: 71.7500,                 loss: nan
Episode: 6541/30000 (21.8033%),                 avg. length: 529.4,                last time consumption/overall running time: 89.1036s / 68006.9697 s
env0_first_0:                 episode reward: -73.2500,                 loss: 21.8618
env0_second_0:                 episode reward: 73.2500,                 loss: 23.4038
env1_first_0:                 episode reward: -74.3000,                 loss: nan
env1_second_0:                 episode reward: 74.3000,                 loss: nan
Episode: 6561/30000 (21.8700%),                 avg. length: 832.7,                last time consumption/overall running time: 141.1350s / 68148.1047 s
env0_first_0:                 episode reward: -59.3500,                 loss: 18.2521
env0_second_0:                 episode reward: 59.3500,                 loss: 18.6113
env1_first_0:                 episode reward: -60.6500,                 loss: nan
env1_second_0:                 episode reward: 60.6500,                 loss: nan
Episode: 6581/30000 (21.9367%),                 avg. length: 466.35,                last time consumption/overall running time: 86.3356s / 68234.4403 s
env0_first_0:                 episode reward: -70.8500,                 loss: 25.7167
env0_second_0:                 episode reward: 70.8500,                 loss: 25.5719
env1_first_0:                 episode reward: -75.0500,                 loss: nan
env1_second_0:                 episode reward: 75.0500,                 loss: nan
Episode: 6601/30000 (22.0033%),                 avg. length: 327.5,                last time consumption/overall running time: 63.8251s / 68298.2654 s
env0_first_0:                 episode reward: -82.8000,                 loss: 38.0770
env0_second_0:                 episode reward: 82.8000,                 loss: 39.2701
env1_first_0:                 episode reward: -84.0000,                 loss: nan
env1_second_0:                 episode reward: 84.0000,                 loss: nan
Episode: 6621/30000 (22.0700%),                 avg. length: 457.55,                last time consumption/overall running time: 79.3220s / 68377.5874 s
env0_first_0:                 episode reward: -69.2500,                 loss: 28.9140
env0_second_0:                 episode reward: 69.2500,                 loss: 29.5910
env1_first_0:                 episode reward: -73.1000,                 loss: nan
env1_second_0:                 episode reward: 73.1000,                 loss: nan
Episode: 6641/30000 (22.1367%),                 avg. length: 658.15,                last time consumption/overall running time: 113.8314s / 68491.4188 s
env0_first_0:                 episode reward: -43.9500,                 loss: 17.0333
env0_second_0:                 episode reward: 43.9500,                 loss: 15.5733
env1_first_0:                 episode reward: -44.6000,                 loss: nan
env1_second_0:                 episode reward: 44.6000,                 loss: nan
Episode: 6661/30000 (22.2033%),                 avg. length: 275.3,                last time consumption/overall running time: 56.7316s / 68548.1504 s
env0_first_0:                 episode reward: -93.7000,                 loss: 37.2271
env0_second_0:                 episode reward: 93.7000,                 loss: 38.2528
env1_first_0:                 episode reward: -80.2000,                 loss: nan
env1_second_0:                 episode reward: 80.2000,                 loss: nan
Episode: 6681/30000 (22.2700%),                 avg. length: 281.3,                last time consumption/overall running time: 54.8187s / 68602.9691 s
env0_first_0:                 episode reward: -83.7500,                 loss: 35.0521
env0_second_0:                 episode reward: 83.7500,                 loss: 36.9599
env1_first_0:                 episode reward: -82.5500,                 loss: nan
env1_second_0:                 episode reward: 82.5500,                 loss: nan
Episode: 6701/30000 (22.3367%),                 avg. length: 365.55,                last time consumption/overall running time: 67.8875s / 68670.8566 s
env0_first_0:                 episode reward: -82.0000,                 loss: 34.4324
env0_second_0:                 episode reward: 82.0000,                 loss: 34.8221
env1_first_0:                 episode reward: -75.1500,                 loss: nan
env1_second_0:                 episode reward: 75.1500,                 loss: nan
Episode: 6721/30000 (22.4033%),                 avg. length: 321.95,                last time consumption/overall running time: 61.5902s / 68732.4468 s
env0_first_0:                 episode reward: -84.0500,                 loss: 30.5682
env0_second_0:                 episode reward: 84.0500,                 loss: 29.6322
env1_first_0:                 episode reward: -76.6500,                 loss: nan
env1_second_0:                 episode reward: 76.6500,                 loss: nan
Episode: 6741/30000 (22.4700%),                 avg. length: 342.3,                last time consumption/overall running time: 61.9870s / 68794.4339 s
env0_first_0:                 episode reward: -71.3500,                 loss: 35.3957
env0_second_0:                 episode reward: 71.3500,                 loss: 34.9897
env1_first_0:                 episode reward: -79.2500,                 loss: nan
env1_second_0:                 episode reward: 79.2500,                 loss: nan
Episode: 6761/30000 (22.5367%),                 avg. length: 586.1,                last time consumption/overall running time: 106.4797s / 68900.9136 s
env0_first_0:                 episode reward: -70.5000,                 loss: 23.5055
env0_second_0:                 episode reward: 70.5000,                 loss: 25.2706
env1_first_0:                 episode reward: -59.8000,                 loss: nan
env1_second_0:                 episode reward: 59.8000,                 loss: nan
Episode: 6781/30000 (22.6033%),                 avg. length: 407.95,                last time consumption/overall running time: 78.4594s / 68979.3729 s
env0_first_0:                 episode reward: -73.9000,                 loss: 28.4483
env0_second_0:                 episode reward: 73.9000,                 loss: 28.6892
env1_first_0:                 episode reward: -81.5000,                 loss: nan
env1_second_0:                 episode reward: 81.5000,                 loss: nan
Episode: 6801/30000 (22.6700%),                 avg. length: 435.05,                last time consumption/overall running time: 82.5610s / 69061.9339 s
env0_first_0:                 episode reward: -71.3500,                 loss: 24.4461
env0_second_0:                 episode reward: 71.3500,                 loss: 27.5682
env1_first_0:                 episode reward: -84.4000,                 loss: nan
env1_second_0:                 episode reward: 84.4000,                 loss: nan
Episode: 6821/30000 (22.7367%),                 avg. length: 436.95,                last time consumption/overall running time: 82.5127s / 69144.4466 s
env0_first_0:                 episode reward: -78.4000,                 loss: 30.2253
env0_second_0:                 episode reward: 78.4000,                 loss: 53.0166
env1_first_0:                 episode reward: -75.5500,                 loss: nan
env1_second_0:                 episode reward: 75.5500,                 loss: nan
Episode: 6841/30000 (22.8033%),                 avg. length: 408.75,                last time consumption/overall running time: 76.5470s / 69220.9937 s
env0_first_0:                 episode reward: -71.7000,                 loss: 33.1837
env0_second_0:                 episode reward: 71.7000,                 loss: 35.5121
env1_first_0:                 episode reward: -69.2500,                 loss: nan
env1_second_0:                 episode reward: 69.2500,                 loss: nan
Episode: 6861/30000 (22.8700%),                 avg. length: 477.25,                last time consumption/overall running time: 90.4358s / 69311.4294 s
env0_first_0:                 episode reward: -67.7000,                 loss: 28.3569
env0_second_0:                 episode reward: 67.7000,                 loss: 28.5432
env1_first_0:                 episode reward: -73.6000,                 loss: nan
env1_second_0:                 episode reward: 73.6000,                 loss: nan
Episode: 6881/30000 (22.9367%),                 avg. length: 564.55,                last time consumption/overall running time: 102.6462s / 69414.0757 s
env0_first_0:                 episode reward: -63.8000,                 loss: 25.5216
env0_second_0:                 episode reward: 63.8000,                 loss: 26.0413
env1_first_0:                 episode reward: -63.3500,                 loss: nan
env1_second_0:                 episode reward: 63.3500,                 loss: nan
Episode: 6901/30000 (23.0033%),                 avg. length: 511.7,                last time consumption/overall running time: 94.3171s / 69508.3928 s
env0_first_0:                 episode reward: -74.7500,                 loss: 27.4155
env0_second_0:                 episode reward: 74.7500,                 loss: 27.4047
env1_first_0:                 episode reward: -74.4500,                 loss: nan
env1_second_0:                 episode reward: 74.4500,                 loss: nan
Episode: 6921/30000 (23.0700%),                 avg. length: 444.55,                last time consumption/overall running time: 82.4086s / 69590.8014 s
env0_first_0:                 episode reward: -70.7500,                 loss: 26.9331
env0_second_0:                 episode reward: 70.7500,                 loss: 27.2106
env1_first_0:                 episode reward: -72.7000,                 loss: nan
env1_second_0:                 episode reward: 72.7000,                 loss: nan
Episode: 6941/30000 (23.1367%),                 avg. length: 685.9,                last time consumption/overall running time: 122.6609s / 69713.4623 s
env0_first_0:                 episode reward: -68.6000,                 loss: 21.3110
env0_second_0:                 episode reward: 68.6000,                 loss: 21.9862
env1_first_0:                 episode reward: -60.3000,                 loss: nan
env1_second_0:                 episode reward: 60.3000,                 loss: nan
Episode: 6961/30000 (23.2033%),                 avg. length: 386.1,                last time consumption/overall running time: 77.2072s / 69790.6695 s
env0_first_0:                 episode reward: -75.8500,                 loss: 34.7517
env0_second_0:                 episode reward: 75.8500,                 loss: 35.6866
env1_first_0:                 episode reward: -72.6000,                 loss: nan
env1_second_0:                 episode reward: 72.6000,                 loss: nan
Episode: 6981/30000 (23.2700%),                 avg. length: 429.4,                last time consumption/overall running time: 76.5257s / 69867.1952 s
env0_first_0:                 episode reward: -67.4500,                 loss: 29.5648
env0_second_0:                 episode reward: 67.4500,                 loss: 32.1794
env1_first_0:                 episode reward: -73.3500,                 loss: nan
env1_second_0:                 episode reward: 73.3500,                 loss: nan
Episode: 7001/30000 (23.3367%),                 avg. length: 389.35,                last time consumption/overall running time: 75.9900s / 69943.1852 s
env0_first_0:                 episode reward: -82.0500,                 loss: 30.2663
env0_second_0:                 episode reward: 82.0500,                 loss: 32.2534
env1_first_0:                 episode reward: -78.8000,                 loss: nan
env1_second_0:                 episode reward: 78.8000,                 loss: nan
Episode: 7021/30000 (23.4033%),                 avg. length: 250.4,                last time consumption/overall running time: 49.3654s / 69992.5506 s
env0_first_0:                 episode reward: -91.6000,                 loss: 37.6880
env0_second_0:                 episode reward: 91.6000,                 loss: 34.3171
env1_first_0:                 episode reward: -81.9500,                 loss: nan
env1_second_0:                 episode reward: 81.9500,                 loss: nan
Episode: 7041/30000 (23.4700%),                 avg. length: 290.05,                last time consumption/overall running time: 57.8771s / 70050.4277 s
env0_first_0:                 episode reward: -86.2500,                 loss: 36.5388
env0_second_0:                 episode reward: 86.2500,                 loss: 37.3201
env1_first_0:                 episode reward: -72.5000,                 loss: nan
env1_second_0:                 episode reward: 72.5000,                 loss: nan
Episode: 7061/30000 (23.5367%),                 avg. length: 529.9,                last time consumption/overall running time: 94.1714s / 70144.5991 s
env0_first_0:                 episode reward: -71.9000,                 loss: 23.7934
env0_second_0:                 episode reward: 71.9000,                 loss: 25.5672
env1_first_0:                 episode reward: -70.9500,                 loss: nan
env1_second_0:                 episode reward: 70.9500,                 loss: nan
Episode: 7081/30000 (23.6033%),                 avg. length: 465.9,                last time consumption/overall running time: 87.6892s / 70232.2883 s
env0_first_0:                 episode reward: -78.7000,                 loss: 28.6309
env0_second_0:                 episode reward: 78.7000,                 loss: 31.0302
env1_first_0:                 episode reward: -69.0000,                 loss: nan
env1_second_0:                 episode reward: 69.0000,                 loss: nan
Episode: 7101/30000 (23.6700%),                 avg. length: 358.85,                last time consumption/overall running time: 69.9443s / 70302.2326 s
env0_first_0:                 episode reward: -85.7000,                 loss: 34.0940
env0_second_0:                 episode reward: 85.7000,                 loss: 43.0561
env1_first_0:                 episode reward: -79.3000,                 loss: nan
env1_second_0:                 episode reward: 79.3000,                 loss: nan
Episode: 7121/30000 (23.7367%),                 avg. length: 374.25,                last time consumption/overall running time: 72.9523s / 70375.1849 s
env0_first_0:                 episode reward: -77.7500,                 loss: 27.1725
env0_second_0:                 episode reward: 77.7500,                 loss: 30.1927
env1_first_0:                 episode reward: -89.2000,                 loss: nan
env1_second_0:                 episode reward: 89.2000,                 loss: nan
Episode: 7141/30000 (23.8033%),                 avg. length: 566.2,                last time consumption/overall running time: 104.8939s / 70480.0788 s
env0_first_0:                 episode reward: -68.6500,                 loss: 19.2434
env0_second_0:                 episode reward: 68.6500,                 loss: 23.4638
env1_first_0:                 episode reward: -74.0500,                 loss: nan
env1_second_0:                 episode reward: 74.0500,                 loss: nan
Episode: 7161/30000 (23.8700%),                 avg. length: 705.2,                last time consumption/overall running time: 129.4897s / 70609.5686 s
env0_first_0:                 episode reward: -59.3500,                 loss: 28.1971
env0_second_0:                 episode reward: 59.3500,                 loss: 31.9099
env1_first_0:                 episode reward: -47.4000,                 loss: nan
env1_second_0:                 episode reward: 47.4000,                 loss: nan
Episode: 7181/30000 (23.9367%),                 avg. length: 423.3,                last time consumption/overall running time: 81.0782s / 70690.6468 s
env0_first_0:                 episode reward: -63.2500,                 loss: 26.8737
env0_second_0:                 episode reward: 63.2500,                 loss: 30.2483
env1_first_0:                 episode reward: -78.4500,                 loss: nan
env1_second_0:                 episode reward: 78.4500,                 loss: nan
Episode: 7201/30000 (24.0033%),                 avg. length: 368.65,                last time consumption/overall running time: 71.4913s / 70762.1381 s
env0_first_0:                 episode reward: -75.5000,                 loss: 28.5033
env0_second_0:                 episode reward: 75.5000,                 loss: 32.2092
env1_first_0:                 episode reward: -69.8000,                 loss: nan
env1_second_0:                 episode reward: 69.8000,                 loss: nan
Episode: 7221/30000 (24.0700%),                 avg. length: 343.9,                last time consumption/overall running time: 67.0075s / 70829.1456 s
env0_first_0:                 episode reward: -83.7500,                 loss: 39.1264
env0_second_0:                 episode reward: 83.7500,                 loss: 41.6431
env1_first_0:                 episode reward: -64.3000,                 loss: nan
env1_second_0:                 episode reward: 64.3000,                 loss: nan
Episode: 7241/30000 (24.1367%),                 avg. length: 382.05,                last time consumption/overall running time: 69.0046s / 70898.1502 s
env0_first_0:                 episode reward: -72.5500,                 loss: 33.8304
env0_second_0:                 episode reward: 72.5500,                 loss: 35.2524
env1_first_0:                 episode reward: -71.1500,                 loss: nan
env1_second_0:                 episode reward: 71.1500,                 loss: nan
Episode: 7261/30000 (24.2033%),                 avg. length: 408.5,                last time consumption/overall running time: 77.5214s / 70975.6716 s
env0_first_0:                 episode reward: -76.9500,                 loss: 35.0252
env0_second_0:                 episode reward: 76.9500,                 loss: 36.8103
env1_first_0:                 episode reward: -56.1000,                 loss: nan
env1_second_0:                 episode reward: 56.1000,                 loss: nan
Episode: 7281/30000 (24.2700%),                 avg. length: 393.65,                last time consumption/overall running time: 76.7395s / 71052.4111 s
env0_first_0:                 episode reward: -70.9000,                 loss: 33.1380
env0_second_0:                 episode reward: 70.9000,                 loss: 35.1608
env1_first_0:                 episode reward: -83.7500,                 loss: nan
env1_second_0:                 episode reward: 83.7500,                 loss: nan
Episode: 7301/30000 (24.3367%),                 avg. length: 337.65,                last time consumption/overall running time: 66.7938s / 71119.2049 s
env0_first_0:                 episode reward: -69.4000,                 loss: 33.3278
env0_second_0:                 episode reward: 69.4000,                 loss: 35.2914
env1_first_0:                 episode reward: -85.0000,                 loss: nan
env1_second_0:                 episode reward: 85.0000,                 loss: nan
Episode: 7321/30000 (24.4033%),                 avg. length: 653.4,                last time consumption/overall running time: 116.9440s / 71236.1490 s
env0_first_0:                 episode reward: -68.7000,                 loss: 23.3357
env0_second_0:                 episode reward: 68.7000,                 loss: 24.1773
env1_first_0:                 episode reward: -65.3500,                 loss: nan
env1_second_0:                 episode reward: 65.3500,                 loss: nan
Episode: 7341/30000 (24.4700%),                 avg. length: 381.25,                last time consumption/overall running time: 72.2494s / 71308.3983 s
env0_first_0:                 episode reward: -58.0000,                 loss: 30.7854
env0_second_0:                 episode reward: 58.0000,                 loss: 30.4410
env1_first_0:                 episode reward: -81.1000,                 loss: nan
env1_second_0:                 episode reward: 81.1000,                 loss: nan
Episode: 7361/30000 (24.5367%),                 avg. length: 389.1,                last time consumption/overall running time: 74.6439s / 71383.0423 s
env0_first_0:                 episode reward: -65.6000,                 loss: 36.5124
env0_second_0:                 episode reward: 65.6000,                 loss: 36.1228
env1_first_0:                 episode reward: -73.1000,                 loss: nan
env1_second_0:                 episode reward: 73.1000,                 loss: nan
Episode: 7381/30000 (24.6033%),                 avg. length: 707.05,                last time consumption/overall running time: 121.5955s / 71504.6378 s
env0_first_0:                 episode reward: -65.0500,                 loss: 26.0643
env0_second_0:                 episode reward: 65.0500,                 loss: 30.7119
env1_first_0:                 episode reward: -62.8000,                 loss: nan
env1_second_0:                 episode reward: 62.8000,                 loss: nan
Episode: 7401/30000 (24.6700%),                 avg. length: 406.35,                last time consumption/overall running time: 79.4157s / 71584.0534 s
env0_first_0:                 episode reward: -82.9500,                 loss: 36.6565
env0_second_0:                 episode reward: 82.9500,                 loss: 39.1956
env1_first_0:                 episode reward: -64.5000,                 loss: nan
env1_second_0:                 episode reward: 64.5000,                 loss: nan
Episode: 7421/30000 (24.7367%),                 avg. length: 375.0,                last time consumption/overall running time: 74.5356s / 71658.5891 s
env0_first_0:                 episode reward: -67.1000,                 loss: 42.6574
env0_second_0:                 episode reward: 67.1000,                 loss: 45.8775
env1_first_0:                 episode reward: -66.5500,                 loss: nan
env1_second_0:                 episode reward: 66.5500,                 loss: nan
Episode: 7441/30000 (24.8033%),                 avg. length: 359.7,                last time consumption/overall running time: 77.3465s / 71735.9356 s
env0_first_0:                 episode reward: -74.6500,                 loss: 38.9999
env0_second_0:                 episode reward: 74.6500,                 loss: 41.8634
env1_first_0:                 episode reward: -79.9500,                 loss: nan
env1_second_0:                 episode reward: 79.9500,                 loss: nan
Episode: 7461/30000 (24.8700%),                 avg. length: 640.25,                last time consumption/overall running time: 119.2477s / 71855.1833 s
env0_first_0:                 episode reward: -71.7500,                 loss: 27.0092
env0_second_0:                 episode reward: 71.7500,                 loss: 29.4244
env1_first_0:                 episode reward: -72.8000,                 loss: nan
env1_second_0:                 episode reward: 72.8000,                 loss: nan
Episode: 7481/30000 (24.9367%),                 avg. length: 1384.25,                last time consumption/overall running time: 243.2976s / 72098.4809 s
env0_first_0:                 episode reward: -23.2500,                 loss: 11.8820
env0_second_0:                 episode reward: 23.2500,                 loss: 16.2660
env1_first_0:                 episode reward: -21.8000,                 loss: nan
env1_second_0:                 episode reward: 21.8000,                 loss: nan
Episode: 7501/30000 (25.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 312.8387s / 72411.3196 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.3232
env0_second_0:                 episode reward: 0.0000,                 loss: 4.3129
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7521/30000 (25.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 300.2372s / 72711.5568 s
env0_first_0:                 episode reward: -6.1500,                 loss: 1.1576
env0_second_0:                 episode reward: 6.1500,                 loss: 6.0891
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 7541/30000 (25.1367%),                 avg. length: 1115.55,                last time consumption/overall running time: 186.5959s / 72898.1527 s
env0_first_0:                 episode reward: -63.5500,                 loss: 12.7532
env0_second_0:                 episode reward: 63.5500,                 loss: 17.6564
env1_first_0:                 episode reward: -70.3000,                 loss: nan
env1_second_0:                 episode reward: 70.3000,                 loss: nan
Episode: 7561/30000 (25.2033%),                 avg. length: 500.85,                last time consumption/overall running time: 86.4705s / 72984.6233 s
env0_first_0:                 episode reward: -68.9500,                 loss: 29.1230
env0_second_0:                 episode reward: 68.9500,                 loss: 33.4834
env1_first_0:                 episode reward: -83.6500,                 loss: nan
env1_second_0:                 episode reward: 83.6500,                 loss: nan
Episode: 7581/30000 (25.2700%),                 avg. length: 503.1,                last time consumption/overall running time: 89.7970s / 73074.4202 s
env0_first_0:                 episode reward: -65.2000,                 loss: 22.1691
env0_second_0:                 episode reward: 65.2000,                 loss: 27.0386
env1_first_0:                 episode reward: -65.2500,                 loss: nan
env1_second_0:                 episode reward: 65.2500,                 loss: nan
Episode: 7601/30000 (25.3367%),                 avg. length: 353.15,                last time consumption/overall running time: 70.5159s / 73144.9361 s
env0_first_0:                 episode reward: -73.2000,                 loss: 37.5227
env0_second_0:                 episode reward: 73.2000,                 loss: 40.8198
env1_first_0:                 episode reward: -84.9500,                 loss: nan
env1_second_0:                 episode reward: 84.9500,                 loss: nan
Episode: 7621/30000 (25.4033%),                 avg. length: 296.7,                last time consumption/overall running time: 53.9345s / 73198.8706 s
env0_first_0:                 episode reward: -84.7500,                 loss: 39.3472
env0_second_0:                 episode reward: 84.7500,                 loss: 41.5080
env1_first_0:                 episode reward: -77.4500,                 loss: nan
env1_second_0:                 episode reward: 77.4500,                 loss: nan
Episode: 7641/30000 (25.4700%),                 avg. length: 325.0,                last time consumption/overall running time: 67.8218s / 73266.6925 s
env0_first_0:                 episode reward: -79.1500,                 loss: 38.5272
env0_second_0:                 episode reward: 79.1500,                 loss: 41.0549
env1_first_0:                 episode reward: -74.2000,                 loss: nan
env1_second_0:                 episode reward: 74.2000,                 loss: nan
Episode: 7661/30000 (25.5367%),                 avg. length: 316.2,                last time consumption/overall running time: 59.4265s / 73326.1189 s
env0_first_0:                 episode reward: -61.9500,                 loss: 32.9114
env0_second_0:                 episode reward: 61.9500,                 loss: 33.4267
env1_first_0:                 episode reward: -84.2500,                 loss: nan
env1_second_0:                 episode reward: 84.2500,                 loss: nan
Episode: 7681/30000 (25.6033%),                 avg. length: 324.05,                last time consumption/overall running time: 63.7091s / 73389.8280 s
env0_first_0:                 episode reward: -81.0500,                 loss: 38.8420
env0_second_0:                 episode reward: 81.0500,                 loss: 41.7743
env1_first_0:                 episode reward: -74.7000,                 loss: nan
env1_second_0:                 episode reward: 74.7000,                 loss: nan
Episode: 7701/30000 (25.6700%),                 avg. length: 298.2,                last time consumption/overall running time: 63.2173s / 73453.0453 s
env0_first_0:                 episode reward: -73.7500,                 loss: 43.8345
env0_second_0:                 episode reward: 73.7500,                 loss: 47.2030
env1_first_0:                 episode reward: -68.4000,                 loss: nan
env1_second_0:                 episode reward: 68.4000,                 loss: nan
Episode: 7721/30000 (25.7367%),                 avg. length: 245.75,                last time consumption/overall running time: 51.2543s / 73504.2996 s
env0_first_0:                 episode reward: -78.9500,                 loss: 42.9801
env0_second_0:                 episode reward: 78.9500,                 loss: 41.6134
env1_first_0:                 episode reward: -85.2000,                 loss: nan
env1_second_0:                 episode reward: 85.2000,                 loss: nan
Episode: 7741/30000 (25.8033%),                 avg. length: 820.7,                last time consumption/overall running time: 146.4661s / 73650.7657 s
env0_first_0:                 episode reward: -54.3000,                 loss: 23.7690
env0_second_0:                 episode reward: 54.3000,                 loss: 25.1026
env1_first_0:                 episode reward: -43.5000,                 loss: nan
env1_second_0:                 episode reward: 43.5000,                 loss: nan
Episode: 7761/30000 (25.8700%),                 avg. length: 1423.8,                last time consumption/overall running time: 233.0839s / 73883.8496 s
env0_first_0:                 episode reward: -19.3500,                 loss: 8.0230
env0_second_0:                 episode reward: 19.3500,                 loss: 11.4946
env1_first_0:                 episode reward: -23.5000,                 loss: nan
env1_second_0:                 episode reward: 23.5000,                 loss: nan
Episode: 7781/30000 (25.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 280.0752s / 74163.9247 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.2347
env0_second_0:                 episode reward: 0.4000,                 loss: 0.7448
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 7801/30000 (26.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 296.0683s / 74459.9930 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0872
env0_second_0:                 episode reward: 0.1000,                 loss: 0.4222
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 7821/30000 (26.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 290.6774s / 74750.6704 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0158
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3837
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 7841/30000 (26.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.4132s / 75050.0836 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0092
env0_second_0:                 episode reward: 0.0000,                 loss: 0.2549
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7861/30000 (26.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 288.7622s / 75338.8458 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0237
env0_second_0:                 episode reward: 0.0000,                 loss: 0.3683
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7881/30000 (26.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 297.0558s / 75635.9016 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0119
env0_second_0:                 episode reward: 0.0000,                 loss: 0.6510
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 7901/30000 (26.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 292.4671s / 75928.3687 s
env0_first_0:                 episode reward: 0.9000,                 loss: -0.0009
env0_second_0:                 episode reward: -0.9000,                 loss: 0.8071
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 7921/30000 (26.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 289.3946s / 76217.7633 s
env0_first_0:                 episode reward: 0.9000,                 loss: -0.0020
env0_second_0:                 episode reward: -0.9000,                 loss: 1.3944
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 7941/30000 (26.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 297.7475s / 76515.5108 s
env0_first_0:                 episode reward: 0.1500,                 loss: -0.0312
env0_second_0:                 episode reward: -0.1500,                 loss: 0.3557
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7961/30000 (26.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.4072s / 76810.9180 s
env0_first_0:                 episode reward: 1.5000,                 loss: -0.0291
env0_second_0:                 episode reward: -1.5000,                 loss: 0.7810
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 7981/30000 (26.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 303.8488s / 77114.7668 s
env0_first_0:                 episode reward: 0.6000,                 loss: -0.0176
env0_second_0:                 episode reward: -0.6000,                 loss: 0.7315
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 8001/30000 (26.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 296.1719s / 77410.9387 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0282
env0_second_0:                 episode reward: -1.3500,                 loss: 2.2353
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 8021/30000 (26.7367%),                 avg. length: 886.45,                last time consumption/overall running time: 152.1220s / 77563.0607 s
env0_first_0:                 episode reward: -51.7000,                 loss: 24.7559
env0_second_0:                 episode reward: 51.7000,                 loss: 28.6264
env1_first_0:                 episode reward: -57.2500,                 loss: nan
env1_second_0:                 episode reward: 57.2500,                 loss: nan
Episode: 8041/30000 (26.8033%),                 avg. length: 495.85,                last time consumption/overall running time: 86.7130s / 77649.7737 s
env0_first_0:                 episode reward: -50.2000,                 loss: 36.8023
env0_second_0:                 episode reward: 50.2000,                 loss: 36.7974
env1_first_0:                 episode reward: -76.2000,                 loss: nan
env1_second_0:                 episode reward: 76.2000,                 loss: nan
Episode: 8061/30000 (26.8700%),                 avg. length: 374.5,                last time consumption/overall running time: 65.7800s / 77715.5537 s
env0_first_0:                 episode reward: -62.5500,                 loss: 41.0140
env0_second_0:                 episode reward: 62.5500,                 loss: 41.9338
env1_first_0:                 episode reward: -55.6000,                 loss: nan
env1_second_0:                 episode reward: 55.6000,                 loss: nan
Episode: 8081/30000 (26.9367%),                 avg. length: 595.2,                last time consumption/overall running time: 99.2293s / 77814.7831 s
env0_first_0:                 episode reward: -46.8500,                 loss: 43.5873
env0_second_0:                 episode reward: 46.8500,                 loss: 48.1698
env1_first_0:                 episode reward: -71.6500,                 loss: nan
env1_second_0:                 episode reward: 71.6500,                 loss: nan
Episode: 8101/30000 (27.0033%),                 avg. length: 749.8,                last time consumption/overall running time: 127.9154s / 77942.6984 s
env0_first_0:                 episode reward: -56.4500,                 loss: 26.0477
env0_second_0:                 episode reward: 56.4500,                 loss: 29.1602
env1_first_0:                 episode reward: -53.0500,                 loss: nan
env1_second_0:                 episode reward: 53.0500,                 loss: nan
Episode: 8121/30000 (27.0700%),                 avg. length: 735.7,                last time consumption/overall running time: 135.0716s / 78077.7701 s
env0_first_0:                 episode reward: -67.7000,                 loss: 23.2678
env0_second_0:                 episode reward: 67.7000,                 loss: 26.1991
env1_first_0:                 episode reward: -62.7500,                 loss: nan
env1_second_0:                 episode reward: 62.7500,                 loss: nan
Episode: 8141/30000 (27.1367%),                 avg. length: 610.3,                last time consumption/overall running time: 108.5401s / 78186.3102 s
env0_first_0:                 episode reward: -70.3000,                 loss: 27.3304
env0_second_0:                 episode reward: 70.3000,                 loss: 27.4404
env1_first_0:                 episode reward: -62.8500,                 loss: nan
env1_second_0:                 episode reward: 62.8500,                 loss: nan
Episode: 8161/30000 (27.2033%),                 avg. length: 412.8,                last time consumption/overall running time: 79.3713s / 78265.6816 s
env0_first_0:                 episode reward: -72.6500,                 loss: 35.2700
env0_second_0:                 episode reward: 72.6500,                 loss: 36.4091
env1_first_0:                 episode reward: -56.4000,                 loss: nan
env1_second_0:                 episode reward: 56.4000,                 loss: nan
Episode: 8181/30000 (27.2700%),                 avg. length: 1350.0,                last time consumption/overall running time: 236.9468s / 78502.6284 s
env0_first_0:                 episode reward: -29.8500,                 loss: 13.4137
env0_second_0:                 episode reward: 29.8500,                 loss: 15.7882
env1_first_0:                 episode reward: -36.2000,                 loss: nan
env1_second_0:                 episode reward: 36.2000,                 loss: nan
Episode: 8201/30000 (27.3367%),                 avg. length: 354.75,                last time consumption/overall running time: 66.6282s / 78569.2566 s
env0_first_0:                 episode reward: -74.2000,                 loss: 28.5169
env0_second_0:                 episode reward: 74.2000,                 loss: 29.5770
env1_first_0:                 episode reward: -71.1000,                 loss: nan
env1_second_0:                 episode reward: 71.1000,                 loss: nan
Episode: 8221/30000 (27.4033%),                 avg. length: 475.5,                last time consumption/overall running time: 90.1884s / 78659.4450 s
env0_first_0:                 episode reward: -67.9000,                 loss: 25.6218
env0_second_0:                 episode reward: 67.9000,                 loss: 29.0563
env1_first_0:                 episode reward: -66.3500,                 loss: nan
env1_second_0:                 episode reward: 66.3500,                 loss: nan
Episode: 8241/30000 (27.4700%),                 avg. length: 844.15,                last time consumption/overall running time: 151.0394s / 78810.4843 s
env0_first_0:                 episode reward: -51.5000,                 loss: 28.0817
env0_second_0:                 episode reward: 51.5000,                 loss: 32.9007
env1_first_0:                 episode reward: -57.0000,                 loss: nan
env1_second_0:                 episode reward: 57.0000,                 loss: nan
Episode: 8261/30000 (27.5367%),                 avg. length: 1170.65,                last time consumption/overall running time: 200.9403s / 79011.4246 s
env0_first_0:                 episode reward: -49.4000,                 loss: 8.2013
env0_second_0:                 episode reward: 49.4000,                 loss: 12.8509
env1_first_0:                 episode reward: -54.7500,                 loss: nan
env1_second_0:                 episode reward: 54.7500,                 loss: nan
Episode: 8281/30000 (27.6033%),                 avg. length: 1243.95,                last time consumption/overall running time: 205.8882s / 79217.3128 s
env0_first_0:                 episode reward: -52.3000,                 loss: 6.9652
env0_second_0:                 episode reward: 52.3000,                 loss: 9.5463
env1_first_0:                 episode reward: -60.2500,                 loss: nan
env1_second_0:                 episode reward: 60.2500,                 loss: nan
Episode: 8301/30000 (27.6700%),                 avg. length: 1722.25,                last time consumption/overall running time: 284.1913s / 79501.5041 s
env0_first_0:                 episode reward: -48.0500,                 loss: 4.5434
env0_second_0:                 episode reward: 48.0500,                 loss: 8.6853
env1_first_0:                 episode reward: -47.9500,                 loss: nan
env1_second_0:                 episode reward: 47.9500,                 loss: nan
Episode: 8321/30000 (27.7367%),                 avg. length: 1770.55,                last time consumption/overall running time: 297.6687s / 79799.1728 s
env0_first_0:                 episode reward: -44.2500,                 loss: 3.5590
env0_second_0:                 episode reward: 44.2500,                 loss: 6.8407
env1_first_0:                 episode reward: -40.3000,                 loss: nan
env1_second_0:                 episode reward: 40.3000,                 loss: nan
Episode: 8341/30000 (27.8033%),                 avg. length: 966.1,                last time consumption/overall running time: 162.1759s / 79961.3487 s
env0_first_0:                 episode reward: -53.1500,                 loss: 20.7612
env0_second_0:                 episode reward: 53.1500,                 loss: 21.5451
env1_first_0:                 episode reward: -66.8000,                 loss: nan
env1_second_0:                 episode reward: 66.8000,                 loss: nan
Episode: 8361/30000 (27.8700%),                 avg. length: 1623.85,                last time consumption/overall running time: 262.6421s / 80223.9908 s
env0_first_0:                 episode reward: -17.4000,                 loss: 4.5949
env0_second_0:                 episode reward: 17.4000,                 loss: 6.5921
env1_first_0:                 episode reward: -16.3500,                 loss: nan
env1_second_0:                 episode reward: 16.3500,                 loss: nan
Episode: 8381/30000 (27.9367%),                 avg. length: 578.75,                last time consumption/overall running time: 104.9076s / 80328.8984 s
env0_first_0:                 episode reward: -62.3000,                 loss: 32.0183
env0_second_0:                 episode reward: 62.3000,                 loss: 34.0201
env1_first_0:                 episode reward: -72.5500,                 loss: nan
env1_second_0:                 episode reward: 72.5500,                 loss: nan
Episode: 8401/30000 (28.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.1294s / 80628.0278 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.5816
env0_second_0:                 episode reward: -0.5500,                 loss: 2.8298
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 8421/30000 (28.0700%),                 avg. length: 1635.05,                last time consumption/overall running time: 271.0060s / 80899.0338 s
env0_first_0:                 episode reward: -4.3000,                 loss: 3.7232
env0_second_0:                 episode reward: 4.3000,                 loss: 4.3496
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 8441/30000 (28.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 286.0598s / 81185.0936 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2996
env0_second_0:                 episode reward: 1.0500,                 loss: 0.7090
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 8461/30000 (28.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 281.0149s / 81466.1085 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0057
env0_second_0:                 episode reward: -0.6000,                 loss: 0.5400
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 8481/30000 (28.2700%),                 avg. length: 1628.3,                last time consumption/overall running time: 265.2243s / 81731.3328 s
env0_first_0:                 episode reward: -3.6000,                 loss: 7.0845
env0_second_0:                 episode reward: 3.6000,                 loss: 7.0378
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 8501/30000 (28.3367%),                 avg. length: 1478.45,                last time consumption/overall running time: 249.5383s / 81980.8710 s
env0_first_0:                 episode reward: -6.6500,                 loss: 13.1201
env0_second_0:                 episode reward: 6.6500,                 loss: 12.6161
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 8521/30000 (28.4033%),                 avg. length: 588.15,                last time consumption/overall running time: 107.0349s / 82087.9059 s
env0_first_0:                 episode reward: -63.4500,                 loss: 21.2267
env0_second_0:                 episode reward: 63.4500,                 loss: 21.0285
env1_first_0:                 episode reward: -52.7500,                 loss: nan
env1_second_0:                 episode reward: 52.7500,                 loss: nan
Episode: 8541/30000 (28.4700%),                 avg. length: 298.35,                last time consumption/overall running time: 58.5994s / 82146.5053 s
env0_first_0:                 episode reward: -76.6500,                 loss: 41.4418
env0_second_0:                 episode reward: 76.6500,                 loss: 37.0579
env1_first_0:                 episode reward: -75.4500,                 loss: nan
env1_second_0:                 episode reward: 75.4500,                 loss: nan
Episode: 8561/30000 (28.5367%),                 avg. length: 277.3,                last time consumption/overall running time: 57.0993s / 82203.6046 s
env0_first_0:                 episode reward: -83.7500,                 loss: 35.8649
env0_second_0:                 episode reward: 83.7500,                 loss: 34.0016
env1_first_0:                 episode reward: -82.7500,                 loss: nan
env1_second_0:                 episode reward: 82.7500,                 loss: nan
Episode: 8581/30000 (28.6033%),                 avg. length: 388.35,                last time consumption/overall running time: 75.1076s / 82278.7122 s
env0_first_0:                 episode reward: -78.9500,                 loss: 32.2076
env0_second_0:                 episode reward: 78.9500,                 loss: 33.5399
env1_first_0:                 episode reward: -76.3000,                 loss: nan
env1_second_0:                 episode reward: 76.3000,                 loss: nan
Episode: 8601/30000 (28.6700%),                 avg. length: 1025.5,                last time consumption/overall running time: 177.0342s / 82455.7464 s
env0_first_0:                 episode reward: -68.5000,                 loss: 19.1774
env0_second_0:                 episode reward: 68.5000,                 loss: 21.7583
env1_first_0:                 episode reward: -63.0000,                 loss: nan
env1_second_0:                 episode reward: 63.0000,                 loss: nan
Episode: 8621/30000 (28.7367%),                 avg. length: 1508.4,                last time consumption/overall running time: 259.5728s / 82715.3193 s
env0_first_0:                 episode reward: -49.3500,                 loss: 14.0232
env0_second_0:                 episode reward: 49.3500,                 loss: 16.4699
env1_first_0:                 episode reward: -51.3000,                 loss: nan
env1_second_0:                 episode reward: 51.3000,                 loss: nan
Episode: 8641/30000 (28.8033%),                 avg. length: 1067.45,                last time consumption/overall running time: 185.7410s / 82901.0603 s
env0_first_0:                 episode reward: -50.0000,                 loss: 11.6894
env0_second_0:                 episode reward: 50.0000,                 loss: 15.7280
env1_first_0:                 episode reward: -50.6000,                 loss: nan
env1_second_0:                 episode reward: 50.6000,                 loss: nan
Episode: 8661/30000 (28.8700%),                 avg. length: 398.1,                last time consumption/overall running time: 78.1145s / 82979.1748 s
env0_first_0:                 episode reward: -70.9000,                 loss: 32.2092
env0_second_0:                 episode reward: 70.9000,                 loss: 33.0992
env1_first_0:                 episode reward: -82.1000,                 loss: nan
env1_second_0:                 episode reward: 82.1000,                 loss: nan
Episode: 8681/30000 (28.9367%),                 avg. length: 322.85,                last time consumption/overall running time: 60.6372s / 83039.8120 s
env0_first_0:                 episode reward: -90.9500,                 loss: 39.6440
env0_second_0:                 episode reward: 90.9500,                 loss: 40.7338
env1_first_0:                 episode reward: -82.6500,                 loss: nan
env1_second_0:                 episode reward: 82.6500,                 loss: nan
Episode: 8701/30000 (29.0033%),                 avg. length: 527.55,                last time consumption/overall running time: 98.5498s / 83138.3618 s
env0_first_0:                 episode reward: -76.6500,                 loss: 25.4968
env0_second_0:                 episode reward: 76.6500,                 loss: 25.5545
env1_first_0:                 episode reward: -72.4500,                 loss: nan
env1_second_0:                 episode reward: 72.4500,                 loss: nan
Episode: 8721/30000 (29.0700%),                 avg. length: 719.15,                last time consumption/overall running time: 128.7624s / 83267.1242 s
env0_first_0:                 episode reward: -67.0500,                 loss: 22.6112
env0_second_0:                 episode reward: 67.0500,                 loss: 24.5073
env1_first_0:                 episode reward: -70.2500,                 loss: nan
env1_second_0:                 episode reward: 70.2500,                 loss: nan
Episode: 8741/30000 (29.1367%),                 avg. length: 401.55,                last time consumption/overall running time: 76.0822s / 83343.2064 s
env0_first_0:                 episode reward: -71.0000,                 loss: 39.2601
env0_second_0:                 episode reward: 71.0000,                 loss: 44.4573
env1_first_0:                 episode reward: -84.1000,                 loss: nan
env1_second_0:                 episode reward: 84.1000,                 loss: nan
Episode: 8761/30000 (29.2033%),                 avg. length: 495.1,                last time consumption/overall running time: 91.7609s / 83434.9673 s
env0_first_0:                 episode reward: -62.7000,                 loss: 33.7427
env0_second_0:                 episode reward: 62.7000,                 loss: 36.4469
env1_first_0:                 episode reward: -56.3500,                 loss: nan
env1_second_0:                 episode reward: 56.3500,                 loss: nan
Episode: 8781/30000 (29.2700%),                 avg. length: 570.05,                last time consumption/overall running time: 103.8484s / 83538.8157 s
env0_first_0:                 episode reward: -29.4500,                 loss: 33.4889
env0_second_0:                 episode reward: 29.4500,                 loss: 35.6703
env1_first_0:                 episode reward: -37.1000,                 loss: nan
env1_second_0:                 episode reward: 37.1000,                 loss: nan
Episode: 8801/30000 (29.3367%),                 avg. length: 648.05,                last time consumption/overall running time: 117.0590s / 83655.8747 s
env0_first_0:                 episode reward: -18.4500,                 loss: 32.6213
env0_second_0:                 episode reward: 18.4500,                 loss: 35.2987
env1_first_0:                 episode reward: -36.2500,                 loss: nan
env1_second_0:                 episode reward: 36.2500,                 loss: nan
Episode: 8821/30000 (29.4033%),                 avg. length: 1297.05,                last time consumption/overall running time: 223.5812s / 83879.4558 s
env0_first_0:                 episode reward: -14.7500,                 loss: 14.5258
env0_second_0:                 episode reward: 14.7500,                 loss: 16.6253
env1_first_0:                 episode reward: -17.9000,                 loss: nan
env1_second_0:                 episode reward: 17.9000,                 loss: nan
Episode: 8841/30000 (29.4700%),                 avg. length: 493.1,                last time consumption/overall running time: 93.7587s / 83973.2146 s
env0_first_0:                 episode reward: -64.5000,                 loss: 42.7729
env0_second_0:                 episode reward: 64.5000,                 loss: 45.2855
env1_first_0:                 episode reward: -42.1000,                 loss: nan
env1_second_0:                 episode reward: 42.1000,                 loss: nan
Episode: 8861/30000 (29.5367%),                 avg. length: 372.9,                last time consumption/overall running time: 71.5269s / 84044.7414 s
env0_first_0:                 episode reward: -66.1000,                 loss: 43.9384
env0_second_0:                 episode reward: 66.1000,                 loss: 45.8381
env1_first_0:                 episode reward: -71.7000,                 loss: nan
env1_second_0:                 episode reward: 71.7000,                 loss: nan
Episode: 8881/30000 (29.6033%),                 avg. length: 760.8,                last time consumption/overall running time: 138.7241s / 84183.4655 s
env0_first_0:                 episode reward: -71.6500,                 loss: 26.5868
env0_second_0:                 episode reward: 71.6500,                 loss: 36.7516
env1_first_0:                 episode reward: -53.4500,                 loss: nan
env1_second_0:                 episode reward: 53.4500,                 loss: nan
Episode: 8901/30000 (29.6700%),                 avg. length: 544.1,                last time consumption/overall running time: 103.2153s / 84286.6808 s
env0_first_0:                 episode reward: -71.3500,                 loss: 28.3266
env0_second_0:                 episode reward: 71.3500,                 loss: 32.7910
env1_first_0:                 episode reward: -73.7000,                 loss: nan
env1_second_0:                 episode reward: 73.7000,                 loss: nan
Episode: 8921/30000 (29.7367%),                 avg. length: 1068.55,                last time consumption/overall running time: 188.1721s / 84474.8529 s
env0_first_0:                 episode reward: -52.4500,                 loss: 13.1320
env0_second_0:                 episode reward: 52.4500,                 loss: 17.4177
env1_first_0:                 episode reward: -37.5000,                 loss: nan
env1_second_0:                 episode reward: 37.5000,                 loss: nan
Episode: 8941/30000 (29.8033%),                 avg. length: 757.35,                last time consumption/overall running time: 135.9749s / 84610.8278 s
env0_first_0:                 episode reward: -70.9500,                 loss: 24.9168
env0_second_0:                 episode reward: 70.9500,                 loss: 27.8557
env1_first_0:                 episode reward: -55.3000,                 loss: nan
env1_second_0:                 episode reward: 55.3000,                 loss: nan
Episode: 8961/30000 (29.8700%),                 avg. length: 524.35,                last time consumption/overall running time: 97.7990s / 84708.6268 s
env0_first_0:                 episode reward: -61.3500,                 loss: 45.1796
env0_second_0:                 episode reward: 61.3500,                 loss: 49.9037
env1_first_0:                 episode reward: -63.9500,                 loss: nan
env1_second_0:                 episode reward: 63.9500,                 loss: nan
Episode: 8981/30000 (29.9367%),                 avg. length: 391.25,                last time consumption/overall running time: 71.8236s / 84780.4505 s
env0_first_0:                 episode reward: -70.2500,                 loss: 47.3823
env0_second_0:                 episode reward: 70.2500,                 loss: 51.1884
env1_first_0:                 episode reward: -69.9500,                 loss: nan
env1_second_0:                 episode reward: 69.9500,                 loss: nan
Episode: 9001/30000 (30.0033%),                 avg. length: 414.2,                last time consumption/overall running time: 81.0721s / 84861.5225 s
env0_first_0:                 episode reward: -66.5000,                 loss: 38.5286
env0_second_0:                 episode reward: 66.5000,                 loss: 38.5783
env1_first_0:                 episode reward: -69.7000,                 loss: nan
env1_second_0:                 episode reward: 69.7000,                 loss: nan
Episode: 9021/30000 (30.0700%),                 avg. length: 372.75,                last time consumption/overall running time: 73.3162s / 84934.8387 s
env0_first_0:                 episode reward: -74.6000,                 loss: 35.9935
env0_second_0:                 episode reward: 74.6000,                 loss: 34.5921
env1_first_0:                 episode reward: -81.8500,                 loss: nan
env1_second_0:                 episode reward: 81.8500,                 loss: nan
Episode: 9041/30000 (30.1367%),                 avg. length: 551.05,                last time consumption/overall running time: 103.4113s / 85038.2500 s
env0_first_0:                 episode reward: -74.2500,                 loss: 35.5042
env0_second_0:                 episode reward: 74.2500,                 loss: 37.3389
env1_first_0:                 episode reward: -60.8500,                 loss: nan
env1_second_0:                 episode reward: 60.8500,                 loss: nan
Episode: 9061/30000 (30.2033%),                 avg. length: 682.2,                last time consumption/overall running time: 125.5708s / 85163.8208 s
env0_first_0:                 episode reward: -16.5500,                 loss: 32.1915
env0_second_0:                 episode reward: 16.5500,                 loss: 32.6873
env1_first_0:                 episode reward: -36.4500,                 loss: nan
env1_second_0:                 episode reward: 36.4500,                 loss: nan
Episode: 9081/30000 (30.2700%),                 avg. length: 724.2,                last time consumption/overall running time: 133.0796s / 85296.9005 s
env0_first_0:                 episode reward: -18.8500,                 loss: 33.7939
env0_second_0:                 episode reward: 18.8500,                 loss: 35.1520
env1_first_0:                 episode reward: -22.3000,                 loss: nan
env1_second_0:                 episode reward: 22.3000,                 loss: nan
Episode: 9101/30000 (30.3367%),                 avg. length: 1015.1,                last time consumption/overall running time: 179.2574s / 85476.1579 s
env0_first_0:                 episode reward: -32.9000,                 loss: 27.6077
env0_second_0:                 episode reward: 32.9000,                 loss: 28.1541
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
Episode: 9121/30000 (30.4033%),                 avg. length: 1699.25,                last time consumption/overall running time: 280.6050s / 85756.7630 s
env0_first_0:                 episode reward: -24.0500,                 loss: 6.9749
env0_second_0:                 episode reward: 24.0500,                 loss: 9.4254
env1_first_0:                 episode reward: -23.1500,                 loss: nan
env1_second_0:                 episode reward: 23.1500,                 loss: nan
Episode: 9141/30000 (30.4700%),                 avg. length: 1673.45,                last time consumption/overall running time: 279.5795s / 86036.3425 s
env0_first_0:                 episode reward: -27.5000,                 loss: 5.3048
env0_second_0:                 episode reward: 27.5000,                 loss: 7.4584
env1_first_0:                 episode reward: -37.1000,                 loss: nan
env1_second_0:                 episode reward: 37.1000,                 loss: nan
Episode: 9161/30000 (30.5367%),                 avg. length: 1045.2,                last time consumption/overall running time: 176.8211s / 86213.1635 s
env0_first_0:                 episode reward: -36.0000,                 loss: 10.1608
env0_second_0:                 episode reward: 36.0000,                 loss: 13.1827
env1_first_0:                 episode reward: -47.9000,                 loss: nan
env1_second_0:                 episode reward: 47.9000,                 loss: nan
Episode: 9181/30000 (30.6033%),                 avg. length: 521.45,                last time consumption/overall running time: 94.2724s / 86307.4360 s
env0_first_0:                 episode reward: -67.7000,                 loss: 29.5062
env0_second_0:                 episode reward: 67.7000,                 loss: 29.1518
env1_first_0:                 episode reward: -67.0500,                 loss: nan
env1_second_0:                 episode reward: 67.0500,                 loss: nan
Episode: 9201/30000 (30.6700%),                 avg. length: 309.65,                last time consumption/overall running time: 62.5081s / 86369.9441 s
env0_first_0:                 episode reward: -78.5000,                 loss: 41.9540
env0_second_0:                 episode reward: 78.5000,                 loss: 42.4592
env1_first_0:                 episode reward: -74.6000,                 loss: nan
env1_second_0:                 episode reward: 74.6000,                 loss: nan
Episode: 9221/30000 (30.7367%),                 avg. length: 278.4,                last time consumption/overall running time: 55.3923s / 86425.3364 s
env0_first_0:                 episode reward: -78.7000,                 loss: 37.7938
env0_second_0:                 episode reward: 78.7000,                 loss: 36.6485
env1_first_0:                 episode reward: -86.9000,                 loss: nan
env1_second_0:                 episode reward: 86.9000,                 loss: nan
Episode: 9241/30000 (30.8033%),                 avg. length: 300.3,                last time consumption/overall running time: 59.4496s / 86484.7860 s
env0_first_0:                 episode reward: -76.6000,                 loss: 31.0219
env0_second_0:                 episode reward: 76.6000,                 loss: 32.5435
env1_first_0:                 episode reward: -83.7000,                 loss: nan
env1_second_0:                 episode reward: 83.7000,                 loss: nan
Episode: 9261/30000 (30.8700%),                 avg. length: 387.1,                last time consumption/overall running time: 75.8196s / 86560.6056 s
env0_first_0:                 episode reward: -64.8000,                 loss: 36.2780
env0_second_0:                 episode reward: 64.8000,                 loss: 36.8159
env1_first_0:                 episode reward: -69.8500,                 loss: nan
env1_second_0:                 episode reward: 69.8500,                 loss: nan
Episode: 9281/30000 (30.9367%),                 avg. length: 597.9,                last time consumption/overall running time: 111.3923s / 86671.9979 s
env0_first_0:                 episode reward: -69.0000,                 loss: 31.7255
env0_second_0:                 episode reward: 69.0000,                 loss: 33.3604
env1_first_0:                 episode reward: -51.0500,                 loss: nan
env1_second_0:                 episode reward: 51.0500,                 loss: nan
Episode: 9301/30000 (31.0033%),                 avg. length: 422.65,                last time consumption/overall running time: 79.7766s / 86751.7744 s
env0_first_0:                 episode reward: -61.8500,                 loss: 36.9130
env0_second_0:                 episode reward: 61.8500,                 loss: 37.2820
env1_first_0:                 episode reward: -72.9500,                 loss: nan
env1_second_0:                 episode reward: 72.9500,                 loss: nan
Episode: 9321/30000 (31.0700%),                 avg. length: 1070.45,                last time consumption/overall running time: 183.2754s / 86935.0499 s
env0_first_0:                 episode reward: -32.3500,                 loss: 20.9662
env0_second_0:                 episode reward: 32.3500,                 loss: 20.6347
env1_first_0:                 episode reward: -36.7000,                 loss: nan
env1_second_0:                 episode reward: 36.7000,                 loss: nan
Episode: 9341/30000 (31.1367%),                 avg. length: 289.65,                last time consumption/overall running time: 60.7353s / 86995.7852 s
env0_first_0:                 episode reward: -77.6500,                 loss: 49.5421
env0_second_0:                 episode reward: 77.6500,                 loss: 46.9692
env1_first_0:                 episode reward: -67.4500,                 loss: nan
env1_second_0:                 episode reward: 67.4500,                 loss: nan
Episode: 9361/30000 (31.2033%),                 avg. length: 553.35,                last time consumption/overall running time: 97.8229s / 87093.6081 s
env0_first_0:                 episode reward: -45.4000,                 loss: 31.1498
env0_second_0:                 episode reward: 45.4000,                 loss: 29.5869
env1_first_0:                 episode reward: -74.9500,                 loss: nan
env1_second_0:                 episode reward: 74.9500,                 loss: nan
Episode: 9381/30000 (31.2700%),                 avg. length: 1120.15,                last time consumption/overall running time: 194.8962s / 87288.5043 s
env0_first_0:                 episode reward: -40.4000,                 loss: 20.4623
env0_second_0:                 episode reward: 40.4000,                 loss: 20.8535
env1_first_0:                 episode reward: -39.0000,                 loss: nan
env1_second_0:                 episode reward: 39.0000,                 loss: nan
Episode: 9401/30000 (31.3367%),                 avg. length: 1736.1,                last time consumption/overall running time: 298.3057s / 87586.8100 s
env0_first_0:                 episode reward: -9.7500,                 loss: 2.7635
env0_second_0:                 episode reward: 9.7500,                 loss: 4.0661
env1_first_0:                 episode reward: -6.8000,                 loss: nan
env1_second_0:                 episode reward: 6.8000,                 loss: nan
Episode: 9421/30000 (31.4033%),                 avg. length: 1562.4,                last time consumption/overall running time: 262.9705s / 87849.7804 s
env0_first_0:                 episode reward: -22.1000,                 loss: 3.7951
env0_second_0:                 episode reward: 22.1000,                 loss: 5.7134
env1_first_0:                 episode reward: -24.9000,                 loss: nan
env1_second_0:                 episode reward: 24.9000,                 loss: nan
Episode: 9441/30000 (31.4700%),                 avg. length: 1474.7,                last time consumption/overall running time: 245.1231s / 88094.9036 s
env0_first_0:                 episode reward: -14.3000,                 loss: 6.3000
env0_second_0:                 episode reward: 14.3000,                 loss: 9.2918
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 9461/30000 (31.5367%),                 avg. length: 1247.45,                last time consumption/overall running time: 206.2046s / 88301.1082 s
env0_first_0:                 episode reward: -30.0000,                 loss: 12.6820
env0_second_0:                 episode reward: 30.0000,                 loss: 14.4128
env1_first_0:                 episode reward: -32.6000,                 loss: nan
env1_second_0:                 episode reward: 32.6000,                 loss: nan
Episode: 9481/30000 (31.6033%),                 avg. length: 778.55,                last time consumption/overall running time: 138.2196s / 88439.3278 s
env0_first_0:                 episode reward: -35.8000,                 loss: 29.3158
env0_second_0:                 episode reward: 35.8000,                 loss: 31.1319
env1_first_0:                 episode reward: -55.0500,                 loss: nan
env1_second_0:                 episode reward: 55.0500,                 loss: nan
Episode: 9501/30000 (31.6700%),                 avg. length: 441.7,                last time consumption/overall running time: 85.6584s / 88524.9862 s
env0_first_0:                 episode reward: -65.5500,                 loss: 43.0886
env0_second_0:                 episode reward: 65.5500,                 loss: 42.1076
env1_first_0:                 episode reward: -69.7000,                 loss: nan
env1_second_0:                 episode reward: 69.7000,                 loss: nan
Episode: 9521/30000 (31.7367%),                 avg. length: 462.4,                last time consumption/overall running time: 79.9083s / 88604.8945 s
env0_first_0:                 episode reward: -72.3500,                 loss: 38.9232
env0_second_0:                 episode reward: 72.3500,                 loss: 46.0620
env1_first_0:                 episode reward: -61.9500,                 loss: nan
env1_second_0:                 episode reward: 61.9500,                 loss: nan
Episode: 9541/30000 (31.8033%),                 avg. length: 918.1,                last time consumption/overall running time: 156.2128s / 88761.1073 s
env0_first_0:                 episode reward: -48.9500,                 loss: 21.1112
env0_second_0:                 episode reward: 48.9500,                 loss: 24.8255
env1_first_0:                 episode reward: -47.4000,                 loss: nan
env1_second_0:                 episode reward: 47.4000,                 loss: nan
Episode: 9561/30000 (31.8700%),                 avg. length: 1121.45,                last time consumption/overall running time: 196.8444s / 88957.9517 s
env0_first_0:                 episode reward: -32.7000,                 loss: 13.3241
env0_second_0:                 episode reward: 32.7000,                 loss: 15.0144
env1_first_0:                 episode reward: -43.6000,                 loss: nan
env1_second_0:                 episode reward: 43.6000,                 loss: nan
Episode: 9581/30000 (31.9367%),                 avg. length: 438.4,                last time consumption/overall running time: 81.5975s / 89039.5492 s
env0_first_0:                 episode reward: -62.3500,                 loss: 37.7231
env0_second_0:                 episode reward: 62.3500,                 loss: 36.6808
env1_first_0:                 episode reward: -71.6500,                 loss: nan
env1_second_0:                 episode reward: 71.6500,                 loss: nan
Episode: 9601/30000 (32.0033%),                 avg. length: 487.15,                last time consumption/overall running time: 91.0805s / 89130.6297 s
env0_first_0:                 episode reward: -66.1500,                 loss: 34.1652
env0_second_0:                 episode reward: 66.1500,                 loss: 33.9977
env1_first_0:                 episode reward: -71.7500,                 loss: nan
env1_second_0:                 episode reward: 71.7500,                 loss: nan
Episode: 9621/30000 (32.0700%),                 avg. length: 344.8,                last time consumption/overall running time: 69.7915s / 89200.4212 s
env0_first_0:                 episode reward: -74.5000,                 loss: 36.6328
env0_second_0:                 episode reward: 74.5000,                 loss: 37.2675
env1_first_0:                 episode reward: -77.2000,                 loss: nan
env1_second_0:                 episode reward: 77.2000,                 loss: nan
Episode: 9641/30000 (32.1367%),                 avg. length: 341.6,                last time consumption/overall running time: 65.3304s / 89265.7517 s
env0_first_0:                 episode reward: -80.8500,                 loss: 35.7013
env0_second_0:                 episode reward: 80.8500,                 loss: 35.2540
env1_first_0:                 episode reward: -78.3500,                 loss: nan
env1_second_0:                 episode reward: 78.3500,                 loss: nan
Episode: 9661/30000 (32.2033%),                 avg. length: 335.55,                last time consumption/overall running time: 67.7361s / 89333.4878 s
env0_first_0:                 episode reward: -77.0500,                 loss: 35.7192
env0_second_0:                 episode reward: 77.0500,                 loss: 38.4482
env1_first_0:                 episode reward: -73.8000,                 loss: nan
env1_second_0:                 episode reward: 73.8000,                 loss: nan
Episode: 9681/30000 (32.2700%),                 avg. length: 472.35,                last time consumption/overall running time: 90.9517s / 89424.4395 s
env0_first_0:                 episode reward: -66.4000,                 loss: 31.5158
env0_second_0:                 episode reward: 66.4000,                 loss: 34.0893
env1_first_0:                 episode reward: -66.6500,                 loss: nan
env1_second_0:                 episode reward: 66.6500,                 loss: nan
Episode: 9701/30000 (32.3367%),                 avg. length: 386.6,                last time consumption/overall running time: 76.3053s / 89500.7448 s
env0_first_0:                 episode reward: -66.9500,                 loss: 40.0796
env0_second_0:                 episode reward: 66.9500,                 loss: 42.5162
env1_first_0:                 episode reward: -72.8500,                 loss: nan
env1_second_0:                 episode reward: 72.8500,                 loss: nan
Episode: 9721/30000 (32.4033%),                 avg. length: 343.7,                last time consumption/overall running time: 63.6716s / 89564.4164 s
env0_first_0:                 episode reward: -72.5500,                 loss: 32.6051
env0_second_0:                 episode reward: 72.5500,                 loss: 36.4979
env1_first_0:                 episode reward: -63.5500,                 loss: nan
env1_second_0:                 episode reward: 63.5500,                 loss: nan
Episode: 9741/30000 (32.4700%),                 avg. length: 372.25,                last time consumption/overall running time: 66.4863s / 89630.9027 s
env0_first_0:                 episode reward: -69.3000,                 loss: 38.1709
env0_second_0:                 episode reward: 69.3000,                 loss: 43.9865
env1_first_0:                 episode reward: -64.7500,                 loss: nan
env1_second_0:                 episode reward: 64.7500,                 loss: nan
Episode: 9761/30000 (32.5367%),                 avg. length: 312.35,                last time consumption/overall running time: 61.4916s / 89692.3943 s
env0_first_0:                 episode reward: -59.8000,                 loss: 33.6017
env0_second_0:                 episode reward: 59.8000,                 loss: 36.5365
env1_first_0:                 episode reward: -81.1000,                 loss: nan
env1_second_0:                 episode reward: 81.1000,                 loss: nan
Episode: 9781/30000 (32.6033%),                 avg. length: 281.35,                last time consumption/overall running time: 56.8179s / 89749.2122 s
env0_first_0:                 episode reward: -73.0000,                 loss: 34.8956
env0_second_0:                 episode reward: 73.0000,                 loss: 37.1453
env1_first_0:                 episode reward: -84.4000,                 loss: nan
env1_second_0:                 episode reward: 84.4000,                 loss: nan
Episode: 9801/30000 (32.6700%),                 avg. length: 341.55,                last time consumption/overall running time: 67.0637s / 89816.2758 s
env0_first_0:                 episode reward: -71.6500,                 loss: 33.6043
env0_second_0:                 episode reward: 71.6500,                 loss: 36.3677
env1_first_0:                 episode reward: -82.8500,                 loss: nan
env1_second_0:                 episode reward: 82.8500,                 loss: nan
Episode: 9821/30000 (32.7367%),                 avg. length: 336.85,                last time consumption/overall running time: 66.7266s / 89883.0024 s
env0_first_0:                 episode reward: -67.7000,                 loss: 36.2351
env0_second_0:                 episode reward: 67.7000,                 loss: 39.3994
env1_first_0:                 episode reward: -80.1000,                 loss: nan
env1_second_0:                 episode reward: 80.1000,                 loss: nan
Episode: 9841/30000 (32.8033%),                 avg. length: 335.2,                last time consumption/overall running time: 66.1626s / 89949.1650 s
env0_first_0:                 episode reward: -69.1500,                 loss: 35.6801
env0_second_0:                 episode reward: 69.1500,                 loss: 37.2162
env1_first_0:                 episode reward: -75.4500,                 loss: nan
env1_second_0:                 episode reward: 75.4500,                 loss: nan
Episode: 9861/30000 (32.8700%),                 avg. length: 689.4,                last time consumption/overall running time: 124.1612s / 90073.3263 s
env0_first_0:                 episode reward: -36.4500,                 loss: 20.9296
env0_second_0:                 episode reward: 36.4500,                 loss: 21.3945
env1_first_0:                 episode reward: -43.8000,                 loss: nan
env1_second_0:                 episode reward: 43.8000,                 loss: nan
Episode: 9881/30000 (32.9367%),                 avg. length: 508.1,                last time consumption/overall running time: 94.9319s / 90168.2582 s
env0_first_0:                 episode reward: -62.5000,                 loss: 31.2607
env0_second_0:                 episode reward: 62.5000,                 loss: 32.4505
env1_first_0:                 episode reward: -55.1500,                 loss: nan
env1_second_0:                 episode reward: 55.1500,                 loss: nan
Episode: 9901/30000 (33.0033%),                 avg. length: 358.95,                last time consumption/overall running time: 71.0103s / 90239.2685 s
env0_first_0:                 episode reward: -56.8000,                 loss: 37.2686
env0_second_0:                 episode reward: 56.8000,                 loss: 39.0906
env1_first_0:                 episode reward: -73.0500,                 loss: nan
env1_second_0:                 episode reward: 73.0500,                 loss: nan
Episode: 9921/30000 (33.0700%),                 avg. length: 392.95,                last time consumption/overall running time: 73.9824s / 90313.2509 s
env0_first_0:                 episode reward: -75.5500,                 loss: 38.4725
env0_second_0:                 episode reward: 75.5500,                 loss: 38.6301
env1_first_0:                 episode reward: -64.0500,                 loss: nan
env1_second_0:                 episode reward: 64.0500,                 loss: nan
Episode: 9941/30000 (33.1367%),                 avg. length: 494.85,                last time consumption/overall running time: 92.1528s / 90405.4037 s
env0_first_0:                 episode reward: -51.4500,                 loss: 32.2955
env0_second_0:                 episode reward: 51.4500,                 loss: 35.1606
env1_first_0:                 episode reward: -75.6000,                 loss: nan
env1_second_0:                 episode reward: 75.6000,                 loss: nan
Episode: 9961/30000 (33.2033%),                 avg. length: 411.6,                last time consumption/overall running time: 73.7998s / 90479.2035 s
env0_first_0:                 episode reward: -63.6500,                 loss: 35.2192
env0_second_0:                 episode reward: 63.6500,                 loss: 36.8490
env1_first_0:                 episode reward: -85.3000,                 loss: nan
env1_second_0:                 episode reward: 85.3000,                 loss: nan
Episode: 9981/30000 (33.2700%),                 avg. length: 478.6,                last time consumption/overall running time: 87.6588s / 90566.8622 s
env0_first_0:                 episode reward: -66.8000,                 loss: 30.6187
env0_second_0:                 episode reward: 66.8000,                 loss: 31.4395
env1_first_0:                 episode reward: -55.8500,                 loss: nan
env1_second_0:                 episode reward: 55.8500,                 loss: nan
Episode: 10001/30000 (33.3367%),                 avg. length: 692.45,                last time consumption/overall running time: 126.8613s / 90693.7235 s
env0_first_0:                 episode reward: -56.0000,                 loss: 26.3363
env0_second_0:                 episode reward: 56.0000,                 loss: 27.1419
env1_first_0:                 episode reward: -48.0000,                 loss: nan
env1_second_0:                 episode reward: 48.0000,                 loss: nan
Episode: 10021/30000 (33.4033%),                 avg. length: 647.2,                last time consumption/overall running time: 119.3529s / 90813.0765 s
env0_first_0:                 episode reward: -59.8500,                 loss: 32.4922
env0_second_0:                 episode reward: 59.8500,                 loss: 33.8390
env1_first_0:                 episode reward: -55.7000,                 loss: nan
env1_second_0:                 episode reward: 55.7000,                 loss: nan
Episode: 10041/30000 (33.4700%),                 avg. length: 580.05,                last time consumption/overall running time: 106.2455s / 90919.3220 s
env0_first_0:                 episode reward: -62.0000,                 loss: 32.8598
env0_second_0:                 episode reward: 62.0000,                 loss: 33.6283
env1_first_0:                 episode reward: -66.0500,                 loss: nan
env1_second_0:                 episode reward: 66.0500,                 loss: nan
Episode: 10061/30000 (33.5367%),                 avg. length: 932.35,                last time consumption/overall running time: 164.7891s / 91084.1111 s
env0_first_0:                 episode reward: -48.5500,                 loss: 34.7342
env0_second_0:                 episode reward: 48.5500,                 loss: 38.7767
env1_first_0:                 episode reward: -52.3500,                 loss: nan
env1_second_0:                 episode reward: 52.3500,                 loss: nan
Episode: 10081/30000 (33.6033%),                 avg. length: 1607.55,                last time consumption/overall running time: 279.2646s / 91363.3757 s
env0_first_0:                 episode reward: -12.8500,                 loss: 10.1966
env0_second_0:                 episode reward: 12.8500,                 loss: 12.3449
env1_first_0:                 episode reward: -20.1500,                 loss: nan
env1_second_0:                 episode reward: 20.1500,                 loss: nan
Episode: 10101/30000 (33.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 305.0874s / 91668.4631 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0721
env0_second_0:                 episode reward: 0.0000,                 loss: 2.8276
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 10121/30000 (33.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 307.1910s / 91975.6541 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.2076
env0_second_0:                 episode reward: 0.1000,                 loss: 3.1252
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 10141/30000 (33.8033%),                 avg. length: 1610.3,                last time consumption/overall running time: 267.7097s / 92243.3638 s
env0_first_0:                 episode reward: -29.7500,                 loss: 5.9376
env0_second_0:                 episode reward: 29.7500,                 loss: 8.5702
env1_first_0:                 episode reward: -25.0500,                 loss: nan
env1_second_0:                 episode reward: 25.0500,                 loss: nan
Episode: 10161/30000 (33.8700%),                 avg. length: 713.95,                last time consumption/overall running time: 125.9342s / 92369.2980 s
env0_first_0:                 episode reward: -61.8000,                 loss: 33.7228
env0_second_0:                 episode reward: 61.8000,                 loss: 36.1464
env1_first_0:                 episode reward: -59.9500,                 loss: nan
env1_second_0:                 episode reward: 59.9500,                 loss: nan
Episode: 10181/30000 (33.9367%),                 avg. length: 732.15,                last time consumption/overall running time: 130.9217s / 92500.2196 s
env0_first_0:                 episode reward: -69.3500,                 loss: 38.0074
env0_second_0:                 episode reward: 69.3500,                 loss: 41.5123
env1_first_0:                 episode reward: -68.4500,                 loss: nan
env1_second_0:                 episode reward: 68.4500,                 loss: nan
Episode: 10201/30000 (34.0033%),                 avg. length: 1690.05,                last time consumption/overall running time: 277.9220s / 92778.1416 s
env0_first_0:                 episode reward: -23.3000,                 loss: 9.7506
env0_second_0:                 episode reward: 23.3000,                 loss: 11.1988
env1_first_0:                 episode reward: -22.5000,                 loss: nan
env1_second_0:                 episode reward: 22.5000,                 loss: nan
Episode: 10221/30000 (34.0700%),                 avg. length: 890.6,                last time consumption/overall running time: 155.1085s / 92933.2501 s
env0_first_0:                 episode reward: -59.2500,                 loss: 29.9605
env0_second_0:                 episode reward: 59.2500,                 loss: 35.1947
env1_first_0:                 episode reward: -52.6500,                 loss: nan
env1_second_0:                 episode reward: 52.6500,                 loss: nan
Episode: 10241/30000 (34.1367%),                 avg. length: 853.8,                last time consumption/overall running time: 151.1846s / 93084.4347 s
env0_first_0:                 episode reward: -60.7000,                 loss: 28.4737
env0_second_0:                 episode reward: 60.7000,                 loss: 32.3626
env1_first_0:                 episode reward: -65.4500,                 loss: nan
env1_second_0:                 episode reward: 65.4500,                 loss: nan
Episode: 10261/30000 (34.2033%),                 avg. length: 1451.85,                last time consumption/overall running time: 247.0036s / 93331.4384 s
env0_first_0:                 episode reward: -38.8500,                 loss: 11.4994
env0_second_0:                 episode reward: 38.8500,                 loss: 12.8024
env1_first_0:                 episode reward: -29.1000,                 loss: nan
env1_second_0:                 episode reward: 29.1000,                 loss: nan
Episode: 10281/30000 (34.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 310.7968s / 93642.2352 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.2469
env0_second_0:                 episode reward: -0.3000,                 loss: 2.1942
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 10301/30000 (34.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.3180s / 93940.5532 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.8365
env0_second_0:                 episode reward: -0.3000,                 loss: 2.6267
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 10321/30000 (34.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 306.1335s / 94246.6866 s
env0_first_0:                 episode reward: -4.8000,                 loss: 2.5627
env0_second_0:                 episode reward: 4.8000,                 loss: 5.6121
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
Episode: 10341/30000 (34.4700%),                 avg. length: 1045.3,                last time consumption/overall running time: 174.8828s / 94421.5695 s
env0_first_0:                 episode reward: -55.2500,                 loss: 25.8952
env0_second_0:                 episode reward: 55.2500,                 loss: 29.3744
env1_first_0:                 episode reward: -71.0500,                 loss: nan
env1_second_0:                 episode reward: 71.0500,                 loss: nan
Episode: 10361/30000 (34.5367%),                 avg. length: 847.5,                last time consumption/overall running time: 144.8146s / 94566.3841 s
env0_first_0:                 episode reward: -70.7000,                 loss: 31.6249
env0_second_0:                 episode reward: 70.7000,                 loss: 31.8765
env1_first_0:                 episode reward: -67.6500,                 loss: nan
env1_second_0:                 episode reward: 67.6500,                 loss: nan
Episode: 10381/30000 (34.6033%),                 avg. length: 1275.8,                last time consumption/overall running time: 223.2002s / 94789.5843 s
env0_first_0:                 episode reward: -49.1000,                 loss: 17.7701
env0_second_0:                 episode reward: 49.1000,                 loss: 20.5459
env1_first_0:                 episode reward: -22.5500,                 loss: nan
env1_second_0:                 episode reward: 22.5500,                 loss: nan
Episode: 10401/30000 (34.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.1819s / 95084.7661 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0076
env0_second_0:                 episode reward: -0.1000,                 loss: 1.3183
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 10421/30000 (34.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 306.8260s / 95391.5922 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0398
env0_second_0:                 episode reward: -0.1000,                 loss: 1.9618
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 10441/30000 (34.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 307.0121s / 95698.6043 s
env0_first_0:                 episode reward: 0.1000,                 loss: -0.0415
env0_second_0:                 episode reward: -0.1000,                 loss: 0.6994
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 10461/30000 (34.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 312.5277s / 96011.1319 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0993
env0_second_0:                 episode reward: -0.7000,                 loss: 0.8552
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 10481/30000 (34.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 307.2237s / 96318.3556 s
env0_first_0:                 episode reward: -3.0000,                 loss: 1.1681
env0_second_0:                 episode reward: 3.0000,                 loss: 3.0891
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 10501/30000 (35.0033%),                 avg. length: 1004.65,                last time consumption/overall running time: 173.5554s / 96491.9111 s
env0_first_0:                 episode reward: -51.6000,                 loss: 28.2722
env0_second_0:                 episode reward: 51.6000,                 loss: 29.0220
env1_first_0:                 episode reward: -50.8500,                 loss: nan
env1_second_0:                 episode reward: 50.8500,                 loss: nan
Episode: 10521/30000 (35.0700%),                 avg. length: 338.7,                last time consumption/overall running time: 66.4032s / 96558.3142 s
env0_first_0:                 episode reward: -84.9500,                 loss: 47.8354
env0_second_0:                 episode reward: 84.9500,                 loss: 47.4177
env1_first_0:                 episode reward: -60.8000,                 loss: nan
env1_second_0:                 episode reward: 60.8000,                 loss: nan
Episode: 10541/30000 (35.1367%),                 avg. length: 333.4,                last time consumption/overall running time: 65.9247s / 96624.2389 s
env0_first_0:                 episode reward: -74.1500,                 loss: 45.8363
env0_second_0:                 episode reward: 74.1500,                 loss: 44.5051
env1_first_0:                 episode reward: -83.2000,                 loss: nan
env1_second_0:                 episode reward: 83.2000,                 loss: nan
Episode: 10561/30000 (35.2033%),                 avg. length: 721.55,                last time consumption/overall running time: 128.7319s / 96752.9709 s
env0_first_0:                 episode reward: -59.1000,                 loss: 31.9849
env0_second_0:                 episode reward: 59.1000,                 loss: 32.8452
env1_first_0:                 episode reward: -70.0500,                 loss: nan
env1_second_0:                 episode reward: 70.0500,                 loss: nan
Episode: 10581/30000 (35.2700%),                 avg. length: 653.2,                last time consumption/overall running time: 120.7852s / 96873.7561 s
env0_first_0:                 episode reward: -46.1500,                 loss: 29.9306
env0_second_0:                 episode reward: 46.1500,                 loss: 31.6335
env1_first_0:                 episode reward: -58.5500,                 loss: nan
env1_second_0:                 episode reward: 58.5500,                 loss: nan
Episode: 10601/30000 (35.3367%),                 avg. length: 316.5,                last time consumption/overall running time: 65.8698s / 96939.6258 s
env0_first_0:                 episode reward: -74.4000,                 loss: 43.7170
env0_second_0:                 episode reward: 74.4000,                 loss: 42.8095
env1_first_0:                 episode reward: -58.9000,                 loss: nan
env1_second_0:                 episode reward: 58.9000,                 loss: nan
Episode: 10621/30000 (35.4033%),                 avg. length: 350.65,                last time consumption/overall running time: 72.3692s / 97011.9950 s
env0_first_0:                 episode reward: -76.0000,                 loss: 34.7341
env0_second_0:                 episode reward: 76.0000,                 loss: 32.6027
env1_first_0:                 episode reward: -74.5500,                 loss: nan
env1_second_0:                 episode reward: 74.5500,                 loss: nan
Episode: 10641/30000 (35.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 310.5891s / 97322.5841 s
env0_first_0:                 episode reward: -4.3500,                 loss: 3.0388
env0_second_0:                 episode reward: 4.3500,                 loss: 3.5354
env1_first_0:                 episode reward: -3.6500,                 loss: nan
env1_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 10661/30000 (35.5367%),                 avg. length: 534.7,                last time consumption/overall running time: 102.2070s / 97424.7911 s
env0_first_0:                 episode reward: -70.2000,                 loss: 31.4787
env0_second_0:                 episode reward: 70.2000,                 loss: 30.0860
env1_first_0:                 episode reward: -70.6500,                 loss: nan
env1_second_0:                 episode reward: 70.6500,                 loss: nan
Episode: 10681/30000 (35.6033%),                 avg. length: 1173.3,                last time consumption/overall running time: 207.9595s / 97632.7506 s
env0_first_0:                 episode reward: -35.1500,                 loss: 16.2044
env0_second_0:                 episode reward: 35.1500,                 loss: 14.6704
env1_first_0:                 episode reward: -30.4500,                 loss: nan
env1_second_0:                 episode reward: 30.4500,                 loss: nan
Episode: 10701/30000 (35.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 311.1602s / 97943.9108 s
env0_first_0:                 episode reward: -6.7000,                 loss: 1.2292
env0_second_0:                 episode reward: 6.7000,                 loss: 1.6578
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
Episode: 10721/30000 (35.7367%),                 avg. length: 1566.0,                last time consumption/overall running time: 269.7573s / 98213.6682 s
env0_first_0:                 episode reward: -9.8500,                 loss: 7.7284
env0_second_0:                 episode reward: 9.8500,                 loss: 8.4889
env1_first_0:                 episode reward: -17.7500,                 loss: nan
env1_second_0:                 episode reward: 17.7500,                 loss: nan
Episode: 10741/30000 (35.8033%),                 avg. length: 356.75,                last time consumption/overall running time: 70.9479s / 98284.6160 s
env0_first_0:                 episode reward: -76.3500,                 loss: 34.5621
env0_second_0:                 episode reward: 76.3500,                 loss: 33.4972
env1_first_0:                 episode reward: -86.4500,                 loss: nan
env1_second_0:                 episode reward: 86.4500,                 loss: nan
Episode: 10761/30000 (35.8700%),                 avg. length: 282.15,                last time consumption/overall running time: 58.0977s / 98342.7137 s
env0_first_0:                 episode reward: -83.1500,                 loss: 37.0223
env0_second_0:                 episode reward: 83.1500,                 loss: 36.1598
env1_first_0:                 episode reward: -87.4500,                 loss: nan
env1_second_0:                 episode reward: 87.4500,                 loss: nan
Episode: 10781/30000 (35.9367%),                 avg. length: 949.25,                last time consumption/overall running time: 166.1198s / 98508.8335 s
env0_first_0:                 episode reward: -43.3000,                 loss: 28.5627
env0_second_0:                 episode reward: 43.3000,                 loss: 23.6828
env1_first_0:                 episode reward: -57.2000,                 loss: nan
env1_second_0:                 episode reward: 57.2000,                 loss: nan
Episode: 10801/30000 (36.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 308.4940s / 98817.3275 s
env0_first_0:                 episode reward: -7.7000,                 loss: 2.7672
env0_second_0:                 episode reward: 7.7000,                 loss: 6.1934
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 10821/30000 (36.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 320.1340s / 99137.4615 s
env0_first_0:                 episode reward: -7.2000,                 loss: 2.7766
env0_second_0:                 episode reward: 7.2000,                 loss: 5.3663
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 10841/30000 (36.1367%),                 avg. length: 855.5,                last time consumption/overall running time: 167.7612s / 99305.2227 s
env0_first_0:                 episode reward: -40.5000,                 loss: 21.6569
env0_second_0:                 episode reward: 40.5000,                 loss: 20.8398
env1_first_0:                 episode reward: -39.4500,                 loss: nan
env1_second_0:                 episode reward: 39.4500,                 loss: nan
Episode: 10861/30000 (36.2033%),                 avg. length: 320.55,                last time consumption/overall running time: 65.2419s / 99370.4646 s
env0_first_0:                 episode reward: -77.7500,                 loss: 44.8053
env0_second_0:                 episode reward: 77.7500,                 loss: 44.3760
env1_first_0:                 episode reward: -68.2000,                 loss: nan
env1_second_0:                 episode reward: 68.2000,                 loss: nan
Episode: 10881/30000 (36.2700%),                 avg. length: 1492.1,                last time consumption/overall running time: 279.1881s / 99649.6527 s
env0_first_0:                 episode reward: -16.6000,                 loss: 11.3990
env0_second_0:                 episode reward: 16.6000,                 loss: 14.5155
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 10901/30000 (36.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 322.1347s / 99971.7874 s
env0_first_0:                 episode reward: -4.6000,                 loss: 2.1750
env0_second_0:                 episode reward: 4.6000,                 loss: 4.5426
env1_first_0:                 episode reward: -5.5500,                 loss: nan
env1_second_0:                 episode reward: 5.5500,                 loss: nan
Episode: 10921/30000 (36.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 315.5732s / 100287.3606 s
env0_first_0:                 episode reward: -3.9000,                 loss: 2.0316
env0_second_0:                 episode reward: 3.9000,                 loss: 4.2909
env1_first_0:                 episode reward: -6.9000,                 loss: nan
env1_second_0:                 episode reward: 6.9000,                 loss: nan
Episode: 10941/30000 (36.4700%),                 avg. length: 1655.35,                last time consumption/overall running time: 290.8518s / 100578.2124 s
env0_first_0:                 episode reward: -6.1500,                 loss: 3.1633
env0_second_0:                 episode reward: 6.1500,                 loss: 6.4551
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 10961/30000 (36.5367%),                 avg. length: 900.15,                last time consumption/overall running time: 171.9454s / 100750.1578 s
env0_first_0:                 episode reward: -44.0000,                 loss: 21.2188
env0_second_0:                 episode reward: 44.0000,                 loss: 22.8818
env1_first_0:                 episode reward: -68.7000,                 loss: nan
env1_second_0:                 episode reward: 68.7000,                 loss: nan
Episode: 10981/30000 (36.6033%),                 avg. length: 1010.25,                last time consumption/overall running time: 181.2120s / 100931.3697 s
env0_first_0:                 episode reward: -52.9000,                 loss: 29.6316
env0_second_0:                 episode reward: 52.9000,                 loss: 28.9263
env1_first_0:                 episode reward: -53.1500,                 loss: nan
env1_second_0:                 episode reward: 53.1500,                 loss: nan
Episode: 11001/30000 (36.6700%),                 avg. length: 1322.1,                last time consumption/overall running time: 231.3912s / 101162.7609 s
env0_first_0:                 episode reward: -50.8500,                 loss: 20.3267
env0_second_0:                 episode reward: 50.8500,                 loss: 23.3269
env1_first_0:                 episode reward: -50.2500,                 loss: nan
env1_second_0:                 episode reward: 50.2500,                 loss: nan
Episode: 11021/30000 (36.7367%),                 avg. length: 807.3,                last time consumption/overall running time: 152.8572s / 101315.6181 s
env0_first_0:                 episode reward: -54.9000,                 loss: 40.1562
env0_second_0:                 episode reward: 54.9000,                 loss: 42.9234
env1_first_0:                 episode reward: -55.2000,                 loss: nan
env1_second_0:                 episode reward: 55.2000,                 loss: nan
Episode: 11041/30000 (36.8033%),                 avg. length: 727.75,                last time consumption/overall running time: 138.7910s / 101454.4091 s
env0_first_0:                 episode reward: -64.3000,                 loss: 31.1828
env0_second_0:                 episode reward: 64.3000,                 loss: 33.8161
env1_first_0:                 episode reward: -53.6000,                 loss: nan
env1_second_0:                 episode reward: 53.6000,                 loss: nan
Episode: 11061/30000 (36.8700%),                 avg. length: 1353.0,                last time consumption/overall running time: 246.9619s / 101701.3710 s
env0_first_0:                 episode reward: -13.1500,                 loss: 9.9150
env0_second_0:                 episode reward: 13.1500,                 loss: 12.4459
env1_first_0:                 episode reward: -20.7500,                 loss: nan
env1_second_0:                 episode reward: 20.7500,                 loss: nan
Episode: 11081/30000 (36.9367%),                 avg. length: 357.4,                last time consumption/overall running time: 68.7032s / 101770.0742 s
env0_first_0:                 episode reward: -62.6500,                 loss: 46.4199
env0_second_0:                 episode reward: 62.6500,                 loss: 46.9455
env1_first_0:                 episode reward: -66.5000,                 loss: nan
env1_second_0:                 episode reward: 66.5000,                 loss: nan
Episode: 11101/30000 (37.0033%),                 avg. length: 291.15,                last time consumption/overall running time: 61.0113s / 101831.0855 s
env0_first_0:                 episode reward: -66.1500,                 loss: 50.5884
env0_second_0:                 episode reward: 66.1500,                 loss: 50.4747
env1_first_0:                 episode reward: -69.1500,                 loss: nan
env1_second_0:                 episode reward: 69.1500,                 loss: nan
Episode: 11121/30000 (37.0700%),                 avg. length: 375.85,                last time consumption/overall running time: 75.5439s / 101906.6294 s
env0_first_0:                 episode reward: -78.5500,                 loss: 43.1555
env0_second_0:                 episode reward: 78.5500,                 loss: 42.2295
env1_first_0:                 episode reward: -76.1000,                 loss: nan
env1_second_0:                 episode reward: 76.1000,                 loss: nan
Episode: 11141/30000 (37.1367%),                 avg. length: 1640.0,                last time consumption/overall running time: 273.7118s / 102180.3412 s
env0_first_0:                 episode reward: -7.7500,                 loss: 6.6993
env0_second_0:                 episode reward: 7.7500,                 loss: 7.7110
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 11161/30000 (37.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.9068s / 102480.2479 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.1893
env0_second_0:                 episode reward: 1.6500,                 loss: 2.1055
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 11181/30000 (37.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 297.8673s / 102778.1152 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.1556
env0_second_0:                 episode reward: 2.9500,                 loss: 2.8716
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 11201/30000 (37.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.6905s / 103076.8057 s
env0_first_0:                 episode reward: -4.6500,                 loss: 0.3571
env0_second_0:                 episode reward: 4.6500,                 loss: 2.2837
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 11221/30000 (37.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 293.6204s / 103370.4261 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0434
env0_second_0:                 episode reward: 0.3000,                 loss: 1.4753
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 11241/30000 (37.4700%),                 avg. length: 1510.7,                last time consumption/overall running time: 253.9133s / 103624.3394 s
env0_first_0:                 episode reward: -18.8500,                 loss: 13.8419
env0_second_0:                 episode reward: 18.8500,                 loss: 15.1383
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 11261/30000 (37.5367%),                 avg. length: 547.6,                last time consumption/overall running time: 92.2593s / 103716.5987 s
env0_first_0:                 episode reward: -69.9500,                 loss: 26.1988
env0_second_0:                 episode reward: 69.9500,                 loss: 27.4312
env1_first_0:                 episode reward: -74.1500,                 loss: nan
env1_second_0:                 episode reward: 74.1500,                 loss: nan
Episode: 11281/30000 (37.6033%),                 avg. length: 349.5,                last time consumption/overall running time: 67.1762s / 103783.7749 s
env0_first_0:                 episode reward: -77.9500,                 loss: 31.5382
env0_second_0:                 episode reward: 77.9500,                 loss: 31.9883
env1_first_0:                 episode reward: -76.6000,                 loss: nan
env1_second_0:                 episode reward: 76.6000,                 loss: nan
Episode: 11301/30000 (37.6700%),                 avg. length: 306.75,                last time consumption/overall running time: 60.9762s / 103844.7512 s
env0_first_0:                 episode reward: -84.4000,                 loss: 37.8134
env0_second_0:                 episode reward: 84.4000,                 loss: 35.3902
env1_first_0:                 episode reward: -82.5500,                 loss: nan
env1_second_0:                 episode reward: 82.5500,                 loss: nan
Episode: 11321/30000 (37.7367%),                 avg. length: 696.8,                last time consumption/overall running time: 122.8309s / 103967.5821 s
env0_first_0:                 episode reward: -52.6500,                 loss: 36.3380
env0_second_0:                 episode reward: 52.6500,                 loss: 35.8238
env1_first_0:                 episode reward: -70.2500,                 loss: nan
env1_second_0:                 episode reward: 70.2500,                 loss: nan
Episode: 11341/30000 (37.8033%),                 avg. length: 941.6,                last time consumption/overall running time: 169.3725s / 104136.9546 s
env0_first_0:                 episode reward: -56.2000,                 loss: 17.0033
env0_second_0:                 episode reward: 56.2000,                 loss: 18.8270
env1_first_0:                 episode reward: -57.8000,                 loss: nan
env1_second_0:                 episode reward: 57.8000,                 loss: nan
Episode: 11361/30000 (37.8700%),                 avg. length: 325.4,                last time consumption/overall running time: 65.8914s / 104202.8460 s
env0_first_0:                 episode reward: -76.3000,                 loss: 54.2524
env0_second_0:                 episode reward: 76.3000,                 loss: 50.6563
env1_first_0:                 episode reward: -85.4500,                 loss: nan
env1_second_0:                 episode reward: 85.4500,                 loss: nan
Episode: 11381/30000 (37.9367%),                 avg. length: 328.0,                last time consumption/overall running time: 67.0108s / 104269.8568 s
env0_first_0:                 episode reward: -72.5000,                 loss: 45.2207
env0_second_0:                 episode reward: 72.5000,                 loss: 46.0183
env1_first_0:                 episode reward: -77.6500,                 loss: nan
env1_second_0:                 episode reward: 77.6500,                 loss: nan
Episode: 11401/30000 (38.0033%),                 avg. length: 487.4,                last time consumption/overall running time: 92.8997s / 104362.7565 s
env0_first_0:                 episode reward: -81.8500,                 loss: 42.0082
env0_second_0:                 episode reward: 81.8500,                 loss: 43.9293
env1_first_0:                 episode reward: -58.8500,                 loss: nan
env1_second_0:                 episode reward: 58.8500,                 loss: nan
Episode: 11421/30000 (38.0700%),                 avg. length: 295.85,                last time consumption/overall running time: 60.3109s / 104423.0674 s
env0_first_0:                 episode reward: -80.2500,                 loss: 47.6462
env0_second_0:                 episode reward: 80.2500,                 loss: 48.7301
env1_first_0:                 episode reward: -82.0000,                 loss: nan
env1_second_0:                 episode reward: 82.0000,                 loss: nan
Episode: 11441/30000 (38.1367%),                 avg. length: 485.3,                last time consumption/overall running time: 92.2418s / 104515.3092 s
env0_first_0:                 episode reward: -70.2500,                 loss: 46.2869
env0_second_0:                 episode reward: 70.2500,                 loss: 48.8178
env1_first_0:                 episode reward: -66.1500,                 loss: nan
env1_second_0:                 episode reward: 66.1500,                 loss: nan
Episode: 11461/30000 (38.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 309.7423s / 104825.0515 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.6455
env0_second_0:                 episode reward: 0.1500,                 loss: 3.9313
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 11481/30000 (38.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 304.6679s / 105129.7194 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.4375
env0_second_0:                 episode reward: 0.9500,                 loss: 3.8035
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 11501/30000 (38.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.9361s / 105431.6555 s
env0_first_0:                 episode reward: -5.3000,                 loss: 0.5965
env0_second_0:                 episode reward: 5.3000,                 loss: 3.0483
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 11521/30000 (38.4033%),                 avg. length: 742.1,                last time consumption/overall running time: 132.0224s / 105563.6779 s
env0_first_0:                 episode reward: -57.2500,                 loss: 39.0066
env0_second_0:                 episode reward: 57.2500,                 loss: 49.9123
env1_first_0:                 episode reward: -58.5000,                 loss: nan
env1_second_0:                 episode reward: 58.5000,                 loss: nan
Episode: 11541/30000 (38.4700%),                 avg. length: 744.05,                last time consumption/overall running time: 134.7781s / 105698.4560 s
env0_first_0:                 episode reward: -56.4500,                 loss: 37.2806
env0_second_0:                 episode reward: 56.4500,                 loss: 41.3329
env1_first_0:                 episode reward: -34.8500,                 loss: nan
env1_second_0:                 episode reward: 34.8500,                 loss: nan
Episode: 11561/30000 (38.5367%),                 avg. length: 1239.7,                last time consumption/overall running time: 213.4464s / 105911.9025 s
env0_first_0:                 episode reward: -45.4500,                 loss: 18.8460
env0_second_0:                 episode reward: 45.4500,                 loss: 26.6090
env1_first_0:                 episode reward: -45.7500,                 loss: nan
env1_second_0:                 episode reward: 45.7500,                 loss: nan
Episode: 11581/30000 (38.6033%),                 avg. length: 1182.75,                last time consumption/overall running time: 205.2663s / 106117.1688 s
env0_first_0:                 episode reward: -24.1000,                 loss: 25.7396
env0_second_0:                 episode reward: 24.1000,                 loss: 28.9738
env1_first_0:                 episode reward: -34.4000,                 loss: nan
env1_second_0:                 episode reward: 34.4000,                 loss: nan
Episode: 11601/30000 (38.6700%),                 avg. length: 1117.05,                last time consumption/overall running time: 191.7977s / 106308.9665 s
env0_first_0:                 episode reward: -9.6500,                 loss: 17.9425
env0_second_0:                 episode reward: 9.6500,                 loss: 20.3148
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 11621/30000 (38.7367%),                 avg. length: 563.85,                last time consumption/overall running time: 106.9438s / 106415.9102 s
env0_first_0:                 episode reward: -57.2500,                 loss: 51.7283
env0_second_0:                 episode reward: 57.2500,                 loss: 54.0982
env1_first_0:                 episode reward: -37.7500,                 loss: nan
env1_second_0:                 episode reward: 37.7500,                 loss: nan
Episode: 11641/30000 (38.8033%),                 avg. length: 895.7,                last time consumption/overall running time: 158.2189s / 106574.1292 s
env0_first_0:                 episode reward: -43.8000,                 loss: 35.7128
env0_second_0:                 episode reward: 43.8000,                 loss: 37.6406
env1_first_0:                 episode reward: -40.2000,                 loss: nan
env1_second_0:                 episode reward: 40.2000,                 loss: nan
Episode: 11661/30000 (38.8700%),                 avg. length: 533.55,                last time consumption/overall running time: 98.3078s / 106672.4369 s
env0_first_0:                 episode reward: -44.3000,                 loss: 48.2728
env0_second_0:                 episode reward: 44.3000,                 loss: 46.6902
env1_first_0:                 episode reward: -50.7000,                 loss: nan
env1_second_0:                 episode reward: 50.7000,                 loss: nan
Episode: 11681/30000 (38.9367%),                 avg. length: 707.2,                last time consumption/overall running time: 124.4029s / 106796.8398 s
env0_first_0:                 episode reward: -46.5500,                 loss: 36.2569
env0_second_0:                 episode reward: 46.5500,                 loss: 37.9237
env1_first_0:                 episode reward: -62.9500,                 loss: nan
env1_second_0:                 episode reward: 62.9500,                 loss: nan
Episode: 11701/30000 (39.0033%),                 avg. length: 765.95,                last time consumption/overall running time: 132.1092s / 106928.9490 s
env0_first_0:                 episode reward: -52.0500,                 loss: 37.8292
env0_second_0:                 episode reward: 52.0500,                 loss: 40.4669
env1_first_0:                 episode reward: -47.6500,                 loss: nan
env1_second_0:                 episode reward: 47.6500,                 loss: nan
Episode: 11721/30000 (39.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.9187s / 107230.8677 s
env0_first_0:                 episode reward: 0.5500,                 loss: 2.0978
env0_second_0:                 episode reward: -0.5500,                 loss: 4.1510
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 11741/30000 (39.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.5301s / 107533.3978 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.9169
env0_second_0:                 episode reward: -3.1500,                 loss: 3.7059
env1_first_0:                 episode reward: 4.9500,                 loss: nan
env1_second_0:                 episode reward: -4.9500,                 loss: nan
Episode: 11761/30000 (39.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.5183s / 107828.9161 s
env0_first_0:                 episode reward: 12.3500,                 loss: 1.5923
env0_second_0:                 episode reward: -12.3500,                 loss: 3.6414
env1_first_0:                 episode reward: 7.7000,                 loss: nan
env1_second_0:                 episode reward: -7.7000,                 loss: nan
Episode: 11781/30000 (39.2700%),                 avg. length: 1743.05,                last time consumption/overall running time: 291.3610s / 108120.2771 s
env0_first_0:                 episode reward: -4.2500,                 loss: 4.9477
env0_second_0:                 episode reward: 4.2500,                 loss: 7.4493
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 11801/30000 (39.3367%),                 avg. length: 619.95,                last time consumption/overall running time: 113.3912s / 108233.6683 s
env0_first_0:                 episode reward: -54.5500,                 loss: 46.5245
env0_second_0:                 episode reward: 54.5500,                 loss: 49.1799
env1_first_0:                 episode reward: -59.4000,                 loss: nan
env1_second_0:                 episode reward: 59.4000,                 loss: nan
Episode: 11821/30000 (39.4033%),                 avg. length: 576.4,                last time consumption/overall running time: 107.4480s / 108341.1163 s
env0_first_0:                 episode reward: -54.4000,                 loss: 47.0420
env0_second_0:                 episode reward: 54.4000,                 loss: 48.6744
env1_first_0:                 episode reward: -70.1500,                 loss: nan
env1_second_0:                 episode reward: 70.1500,                 loss: nan
Episode: 11841/30000 (39.4700%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.4417s / 108642.5580 s
env0_first_0:                 episode reward: -1.3500,                 loss: 1.9113
env0_second_0:                 episode reward: 1.3500,                 loss: 2.3058
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 11861/30000 (39.5367%),                 avg. length: 1784.0,                last time consumption/overall running time: 292.4394s / 108934.9973 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.2819
env0_second_0:                 episode reward: 1.5000,                 loss: 1.0282
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 11881/30000 (39.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 285.8460s / 109220.8433 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0823
env0_second_0:                 episode reward: 1.7000,                 loss: 1.6667
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 11901/30000 (39.6700%),                 avg. length: 702.7,                last time consumption/overall running time: 122.1162s / 109342.9595 s
env0_first_0:                 episode reward: -66.1000,                 loss: 22.7787
env0_second_0:                 episode reward: 66.1000,                 loss: 25.4536
env1_first_0:                 episode reward: -56.5000,                 loss: nan
env1_second_0:                 episode reward: 56.5000,                 loss: nan
Episode: 11921/30000 (39.7367%),                 avg. length: 593.15,                last time consumption/overall running time: 104.0249s / 109446.9844 s
env0_first_0:                 episode reward: -42.6500,                 loss: 37.3164
env0_second_0:                 episode reward: 42.6500,                 loss: 44.8116
env1_first_0:                 episode reward: -66.3500,                 loss: nan
env1_second_0:                 episode reward: 66.3500,                 loss: nan
Episode: 11941/30000 (39.8033%),                 avg. length: 619.5,                last time consumption/overall running time: 115.4953s / 109562.4797 s
env0_first_0:                 episode reward: -41.8000,                 loss: 37.0136
env0_second_0:                 episode reward: 41.8000,                 loss: 40.4160
env1_first_0:                 episode reward: -58.1500,                 loss: nan
env1_second_0:                 episode reward: 58.1500,                 loss: nan
Episode: 11961/30000 (39.8700%),                 avg. length: 389.9,                last time consumption/overall running time: 75.7701s / 109638.2498 s
env0_first_0:                 episode reward: -81.4500,                 loss: 43.9155
env0_second_0:                 episode reward: 81.4500,                 loss: 49.5329
env1_first_0:                 episode reward: -70.0000,                 loss: nan
env1_second_0:                 episode reward: 70.0000,                 loss: nan
Episode: 11981/30000 (39.9367%),                 avg. length: 334.6,                last time consumption/overall running time: 65.5703s / 109703.8201 s
env0_first_0:                 episode reward: -62.5500,                 loss: 38.7021
env0_second_0:                 episode reward: 62.5500,                 loss: 43.5151
env1_first_0:                 episode reward: -82.2500,                 loss: nan
env1_second_0:                 episode reward: 82.2500,                 loss: nan
Episode: 12001/30000 (40.0033%),                 avg. length: 413.0,                last time consumption/overall running time: 83.3196s / 109787.1397 s
env0_first_0:                 episode reward: -61.0000,                 loss: 46.0636
env0_second_0:                 episode reward: 61.0000,                 loss: 49.1217
env1_first_0:                 episode reward: -64.5500,                 loss: nan
env1_second_0:                 episode reward: 64.5500,                 loss: nan
Episode: 12021/30000 (40.0700%),                 avg. length: 456.85,                last time consumption/overall running time: 87.6483s / 109874.7879 s
env0_first_0:                 episode reward: -77.1500,                 loss: 35.4068
env0_second_0:                 episode reward: 77.1500,                 loss: 38.0257
env1_first_0:                 episode reward: -61.0000,                 loss: nan
env1_second_0:                 episode reward: 61.0000,                 loss: nan
Episode: 12041/30000 (40.1367%),                 avg. length: 403.25,                last time consumption/overall running time: 74.1878s / 109948.9757 s
env0_first_0:                 episode reward: -77.5500,                 loss: 37.3784
env0_second_0:                 episode reward: 77.5500,                 loss: 38.5003
env1_first_0:                 episode reward: -56.2000,                 loss: nan
env1_second_0:                 episode reward: 56.2000,                 loss: nan
Episode: 12061/30000 (40.2033%),                 avg. length: 426.25,                last time consumption/overall running time: 81.5473s / 110030.5230 s
env0_first_0:                 episode reward: -76.0000,                 loss: 31.5919
env0_second_0:                 episode reward: 76.0000,                 loss: 33.4284
env1_first_0:                 episode reward: -82.1000,                 loss: nan
env1_second_0:                 episode reward: 82.1000,                 loss: nan
Episode: 12081/30000 (40.2700%),                 avg. length: 364.2,                last time consumption/overall running time: 68.5297s / 110099.0528 s
env0_first_0:                 episode reward: -71.2000,                 loss: 32.7408
env0_second_0:                 episode reward: 71.2000,                 loss: 35.0855
env1_first_0:                 episode reward: -84.1500,                 loss: nan
env1_second_0:                 episode reward: 84.1500,                 loss: nan
Episode: 12101/30000 (40.3367%),                 avg. length: 762.9,                last time consumption/overall running time: 133.7865s / 110232.8392 s
env0_first_0:                 episode reward: -59.8500,                 loss: 24.2299
env0_second_0:                 episode reward: 59.8500,                 loss: 30.2079
env1_first_0:                 episode reward: -64.7000,                 loss: nan
env1_second_0:                 episode reward: 64.7000,                 loss: nan
Episode: 12121/30000 (40.4033%),                 avg. length: 588.25,                last time consumption/overall running time: 102.3865s / 110335.2257 s
env0_first_0:                 episode reward: -58.8500,                 loss: 35.7836
env0_second_0:                 episode reward: 58.8500,                 loss: 37.3034
env1_first_0:                 episode reward: -77.9500,                 loss: nan
env1_second_0:                 episode reward: 77.9500,                 loss: nan
Episode: 12141/30000 (40.4700%),                 avg. length: 571.45,                last time consumption/overall running time: 102.5645s / 110437.7903 s
env0_first_0:                 episode reward: -64.9500,                 loss: 39.9912
env0_second_0:                 episode reward: 64.9500,                 loss: 42.7267
env1_first_0:                 episode reward: -54.7000,                 loss: nan
env1_second_0:                 episode reward: 54.7000,                 loss: nan
Episode: 12161/30000 (40.5367%),                 avg. length: 1662.1,                last time consumption/overall running time: 269.1326s / 110706.9229 s
env0_first_0:                 episode reward: -9.9000,                 loss: 3.4552
env0_second_0:                 episode reward: 9.9000,                 loss: 4.9211
env1_first_0:                 episode reward: -9.1000,                 loss: nan
env1_second_0:                 episode reward: 9.1000,                 loss: nan
Episode: 12181/30000 (40.6033%),                 avg. length: 1706.4,                last time consumption/overall running time: 280.9048s / 110987.8277 s
env0_first_0:                 episode reward: -8.9000,                 loss: 4.7645
env0_second_0:                 episode reward: 8.9000,                 loss: 6.9308
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 12201/30000 (40.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.9754s / 111286.8031 s
env0_first_0:                 episode reward: -3.9000,                 loss: 0.9461
env0_second_0:                 episode reward: 3.9000,                 loss: 2.2320
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 12221/30000 (40.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 298.1700s / 111584.9731 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.2648
env0_second_0:                 episode reward: 0.5000,                 loss: 1.1679
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 12241/30000 (40.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 297.8128s / 111882.7859 s
env0_first_0:                 episode reward: -0.6500,                 loss: -0.0200
env0_second_0:                 episode reward: 0.6500,                 loss: 0.9410
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 12261/30000 (40.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.8878s / 112178.6737 s
env0_first_0:                 episode reward: 0.4000,                 loss: -0.1051
env0_second_0:                 episode reward: -0.4000,                 loss: 4.6753
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 12281/30000 (40.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.6909s / 112478.3646 s
env0_first_0:                 episode reward: 0.5500,                 loss: -0.1086
env0_second_0:                 episode reward: -0.5500,                 loss: 1.6230
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 12301/30000 (41.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 299.7418s / 112778.1064 s
env0_first_0:                 episode reward: 0.7500,                 loss: -0.1292
env0_second_0:                 episode reward: -0.7500,                 loss: 1.3657
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 12321/30000 (41.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.6092s / 113079.7156 s
env0_first_0:                 episode reward: 0.7000,                 loss: -0.0924
env0_second_0:                 episode reward: -0.7000,                 loss: 4.8141
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 12341/30000 (41.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.5068s / 113375.2224 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0267
env0_second_0:                 episode reward: 0.5500,                 loss: 1.6099
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 12361/30000 (41.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 291.5547s / 113666.7771 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0084
env0_second_0:                 episode reward: -1.3500,                 loss: 1.6002
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 12381/30000 (41.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.3372s / 113969.1143 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.6870
env0_second_0:                 episode reward: 1.4000,                 loss: 3.3280
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 12401/30000 (41.3367%),                 avg. length: 725.1,                last time consumption/overall running time: 131.1194s / 114100.2337 s
env0_first_0:                 episode reward: -47.1500,                 loss: 30.8041
env0_second_0:                 episode reward: 47.1500,                 loss: 33.2271
env1_first_0:                 episode reward: -58.7500,                 loss: nan
env1_second_0:                 episode reward: 58.7500,                 loss: nan
Episode: 12421/30000 (41.4033%),                 avg. length: 499.85,                last time consumption/overall running time: 94.3393s / 114194.5729 s
env0_first_0:                 episode reward: -74.2000,                 loss: 43.7580
env0_second_0:                 episode reward: 74.2000,                 loss: 47.2299
env1_first_0:                 episode reward: -71.5500,                 loss: nan
env1_second_0:                 episode reward: 71.5500,                 loss: nan
Episode: 12441/30000 (41.4700%),                 avg. length: 355.45,                last time consumption/overall running time: 65.6667s / 114260.2396 s
env0_first_0:                 episode reward: -70.9500,                 loss: 42.0868
env0_second_0:                 episode reward: 70.9500,                 loss: 45.4159
env1_first_0:                 episode reward: -70.0000,                 loss: nan
env1_second_0:                 episode reward: 70.0000,                 loss: nan
Episode: 12461/30000 (41.5367%),                 avg. length: 446.7,                last time consumption/overall running time: 85.7502s / 114345.9899 s
env0_first_0:                 episode reward: -62.1000,                 loss: 37.8629
env0_second_0:                 episode reward: 62.1000,                 loss: 40.5830
env1_first_0:                 episode reward: -75.7000,                 loss: nan
env1_second_0:                 episode reward: 75.7000,                 loss: nan
Episode: 12481/30000 (41.6033%),                 avg. length: 554.75,                last time consumption/overall running time: 103.7777s / 114449.7675 s
env0_first_0:                 episode reward: -62.4500,                 loss: 35.0473
env0_second_0:                 episode reward: 62.4500,                 loss: 37.6855
env1_first_0:                 episode reward: -70.5000,                 loss: nan
env1_second_0:                 episode reward: 70.5000,                 loss: nan
Episode: 12501/30000 (41.6700%),                 avg. length: 264.0,                last time consumption/overall running time: 53.9401s / 114503.7076 s
env0_first_0:                 episode reward: -74.3000,                 loss: 38.2169
env0_second_0:                 episode reward: 74.3000,                 loss: 39.9857
env1_first_0:                 episode reward: -79.9000,                 loss: nan
env1_second_0:                 episode reward: 79.9000,                 loss: nan
Episode: 12521/30000 (41.7367%),                 avg. length: 351.85,                last time consumption/overall running time: 66.6165s / 114570.3241 s
env0_first_0:                 episode reward: -79.5500,                 loss: 32.7381
env0_second_0:                 episode reward: 79.5500,                 loss: 36.3205
env1_first_0:                 episode reward: -77.2500,                 loss: nan
env1_second_0:                 episode reward: 77.2500,                 loss: nan
Episode: 12541/30000 (41.8033%),                 avg. length: 507.85,                last time consumption/overall running time: 93.5750s / 114663.8992 s
env0_first_0:                 episode reward: -64.2000,                 loss: 39.1104
env0_second_0:                 episode reward: 64.2000,                 loss: 40.1892
env1_first_0:                 episode reward: -50.3000,                 loss: nan
env1_second_0:                 episode reward: 50.3000,                 loss: nan
Episode: 12561/30000 (41.8700%),                 avg. length: 419.05,                last time consumption/overall running time: 80.1521s / 114744.0513 s
env0_first_0:                 episode reward: -63.6500,                 loss: 48.4478
env0_second_0:                 episode reward: 63.6500,                 loss: 51.9322
env1_first_0:                 episode reward: -72.2000,                 loss: nan
env1_second_0:                 episode reward: 72.2000,                 loss: nan
Episode: 12581/30000 (41.9367%),                 avg. length: 389.2,                last time consumption/overall running time: 74.7254s / 114818.7767 s
env0_first_0:                 episode reward: -86.2500,                 loss: 50.5100
env0_second_0:                 episode reward: 86.2500,                 loss: 53.7604
env1_first_0:                 episode reward: -56.2500,                 loss: nan
env1_second_0:                 episode reward: 56.2500,                 loss: nan
Episode: 12601/30000 (42.0033%),                 avg. length: 522.9,                last time consumption/overall running time: 97.3419s / 114916.1186 s
env0_first_0:                 episode reward: -67.5000,                 loss: 34.8317
env0_second_0:                 episode reward: 67.5000,                 loss: 34.2801
env1_first_0:                 episode reward: -72.3500,                 loss: nan
env1_second_0:                 episode reward: 72.3500,                 loss: nan
Episode: 12621/30000 (42.0700%),                 avg. length: 1052.75,                last time consumption/overall running time: 183.1011s / 115099.2198 s
env0_first_0:                 episode reward: -45.0000,                 loss: 21.8922
env0_second_0:                 episode reward: 45.0000,                 loss: 22.9752
env1_first_0:                 episode reward: -49.7500,                 loss: nan
env1_second_0:                 episode reward: 49.7500,                 loss: nan
Episode: 12641/30000 (42.1367%),                 avg. length: 764.7,                last time consumption/overall running time: 136.0361s / 115235.2559 s
env0_first_0:                 episode reward: -35.5000,                 loss: 36.5532
env0_second_0:                 episode reward: 35.5000,                 loss: 37.5791
env1_first_0:                 episode reward: -75.9000,                 loss: nan
env1_second_0:                 episode reward: 75.9000,                 loss: nan
Episode: 12661/30000 (42.2033%),                 avg. length: 428.95,                last time consumption/overall running time: 81.4896s / 115316.7455 s
env0_first_0:                 episode reward: -74.1000,                 loss: 44.9782
env0_second_0:                 episode reward: 74.1000,                 loss: 46.1955
env1_first_0:                 episode reward: -78.7500,                 loss: nan
env1_second_0:                 episode reward: 78.7500,                 loss: nan
Episode: 12681/30000 (42.2700%),                 avg. length: 351.0,                last time consumption/overall running time: 70.0780s / 115386.8235 s
env0_first_0:                 episode reward: -73.1000,                 loss: 46.4081
env0_second_0:                 episode reward: 73.1000,                 loss: 47.8821
env1_first_0:                 episode reward: -78.1000,                 loss: nan
env1_second_0:                 episode reward: 78.1000,                 loss: nan
Episode: 12701/30000 (42.3367%),                 avg. length: 408.6,                last time consumption/overall running time: 79.0219s / 115465.8454 s
env0_first_0:                 episode reward: -67.3500,                 loss: 38.7001
env0_second_0:                 episode reward: 67.3500,                 loss: 217.4847
env1_first_0:                 episode reward: -75.8000,                 loss: nan
env1_second_0:                 episode reward: 75.8000,                 loss: nan
Episode: 12721/30000 (42.4033%),                 avg. length: 277.25,                last time consumption/overall running time: 56.4149s / 115522.2603 s
env0_first_0:                 episode reward: -74.8000,                 loss: 37.9646
env0_second_0:                 episode reward: 74.8000,                 loss: 39.1898
env1_first_0:                 episode reward: -80.3500,                 loss: nan
env1_second_0:                 episode reward: 80.3500,                 loss: nan
Episode: 12741/30000 (42.4700%),                 avg. length: 349.15,                last time consumption/overall running time: 69.0759s / 115591.3362 s
env0_first_0:                 episode reward: -66.0500,                 loss: 32.4551
env0_second_0:                 episode reward: 66.0500,                 loss: 34.5563
env1_first_0:                 episode reward: -76.2500,                 loss: nan
env1_second_0:                 episode reward: 76.2500,                 loss: nan
Episode: 12761/30000 (42.5367%),                 avg. length: 267.15,                last time consumption/overall running time: 54.3152s / 115645.6514 s
env0_first_0:                 episode reward: -83.2500,                 loss: 32.0403
env0_second_0:                 episode reward: 83.2500,                 loss: 35.2210
env1_first_0:                 episode reward: -70.7000,                 loss: nan
env1_second_0:                 episode reward: 70.7000,                 loss: nan
Episode: 12781/30000 (42.6033%),                 avg. length: 260.3,                last time consumption/overall running time: 54.1484s / 115699.7998 s
env0_first_0:                 episode reward: -88.8500,                 loss: 26.9116
env0_second_0:                 episode reward: 88.8500,                 loss: 28.9157
env1_first_0:                 episode reward: -92.4000,                 loss: nan
env1_second_0:                 episode reward: 92.4000,                 loss: nan
Episode: 12801/30000 (42.6700%),                 avg. length: 531.45,                last time consumption/overall running time: 97.2483s / 115797.0482 s
env0_first_0:                 episode reward: -61.0000,                 loss: 33.0048
env0_second_0:                 episode reward: 61.0000,                 loss: 36.2440
env1_first_0:                 episode reward: -60.5500,                 loss: nan
env1_second_0:                 episode reward: 60.5500,                 loss: nan
Episode: 12821/30000 (42.7367%),                 avg. length: 920.95,                last time consumption/overall running time: 161.9526s / 115959.0008 s
env0_first_0:                 episode reward: -49.2000,                 loss: 19.1915
env0_second_0:                 episode reward: 49.2000,                 loss: 21.9879
env1_first_0:                 episode reward: -38.7000,                 loss: nan
env1_second_0:                 episode reward: 38.7000,                 loss: nan
Episode: 12841/30000 (42.8033%),                 avg. length: 449.25,                last time consumption/overall running time: 85.0013s / 116044.0021 s
env0_first_0:                 episode reward: -74.4000,                 loss: 37.1706
env0_second_0:                 episode reward: 74.4000,                 loss: 38.2505
env1_first_0:                 episode reward: -58.4000,                 loss: nan
env1_second_0:                 episode reward: 58.4000,                 loss: nan
Episode: 12861/30000 (42.8700%),                 avg. length: 1106.2,                last time consumption/overall running time: 195.2990s / 116239.3012 s
env0_first_0:                 episode reward: -22.2500,                 loss: 20.1170
env0_second_0:                 episode reward: 22.2500,                 loss: 22.0801
env1_first_0:                 episode reward: -23.0500,                 loss: nan
env1_second_0:                 episode reward: 23.0500,                 loss: nan
Episode: 12881/30000 (42.9367%),                 avg. length: 1334.15,                last time consumption/overall running time: 236.0074s / 116475.3086 s
env0_first_0:                 episode reward: 1.2000,                 loss: 6.8888
env0_second_0:                 episode reward: -1.2000,                 loss: 8.2669
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 12901/30000 (43.0033%),                 avg. length: 1272.6,                last time consumption/overall running time: 225.5152s / 116700.8238 s
env0_first_0:                 episode reward: -3.5500,                 loss: 6.6535
env0_second_0:                 episode reward: 3.5500,                 loss: 8.2715
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 12921/30000 (43.0700%),                 avg. length: 954.65,                last time consumption/overall running time: 172.4429s / 116873.2667 s
env0_first_0:                 episode reward: -7.1500,                 loss: 13.0519
env0_second_0:                 episode reward: 7.1500,                 loss: 13.9944
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 12941/30000 (43.1367%),                 avg. length: 871.3,                last time consumption/overall running time: 157.0966s / 117030.3633 s
env0_first_0:                 episode reward: 12.1500,                 loss: 17.8041
env0_second_0:                 episode reward: -12.1500,                 loss: 19.6739
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 12961/30000 (43.2033%),                 avg. length: 614.7,                last time consumption/overall running time: 113.0350s / 117143.3983 s
env0_first_0:                 episode reward: -41.2500,                 loss: 37.0829
env0_second_0:                 episode reward: 41.2500,                 loss: 35.6507
env1_first_0:                 episode reward: -40.6500,                 loss: nan
env1_second_0:                 episode reward: 40.6500,                 loss: nan
Episode: 12981/30000 (43.2700%),                 avg. length: 465.15,                last time consumption/overall running time: 89.3493s / 117232.7475 s
env0_first_0:                 episode reward: -61.0500,                 loss: 50.7692
env0_second_0:                 episode reward: 61.0500,                 loss: 49.1434
env1_first_0:                 episode reward: -59.3500,                 loss: nan
env1_second_0:                 episode reward: 59.3500,                 loss: nan
Episode: 13001/30000 (43.3367%),                 avg. length: 775.75,                last time consumption/overall running time: 141.4225s / 117374.1700 s
env0_first_0:                 episode reward: -40.2000,                 loss: 30.2691
env0_second_0:                 episode reward: 40.2000,                 loss: 29.4271
env1_first_0:                 episode reward: -36.9000,                 loss: nan
env1_second_0:                 episode reward: 36.9000,                 loss: nan
Episode: 13021/30000 (43.4033%),                 avg. length: 398.5,                last time consumption/overall running time: 77.4572s / 117451.6272 s
env0_first_0:                 episode reward: -60.4500,                 loss: 41.6010
env0_second_0:                 episode reward: 60.4500,                 loss: 43.4536
env1_first_0:                 episode reward: -74.4000,                 loss: nan
env1_second_0:                 episode reward: 74.4000,                 loss: nan
Episode: 13041/30000 (43.4700%),                 avg. length: 318.85,                last time consumption/overall running time: 62.8749s / 117514.5021 s
env0_first_0:                 episode reward: -68.3000,                 loss: 36.8681
env0_second_0:                 episode reward: 68.3000,                 loss: 39.3040
env1_first_0:                 episode reward: -87.1500,                 loss: nan
env1_second_0:                 episode reward: 87.1500,                 loss: nan
Episode: 13061/30000 (43.5367%),                 avg. length: 239.6,                last time consumption/overall running time: 49.5748s / 117564.0769 s
env0_first_0:                 episode reward: -91.7000,                 loss: 35.0597
env0_second_0:                 episode reward: 91.7000,                 loss: 33.8109
env1_first_0:                 episode reward: -84.7000,                 loss: nan
env1_second_0:                 episode reward: 84.7000,                 loss: nan
Episode: 13081/30000 (43.6033%),                 avg. length: 278.7,                last time consumption/overall running time: 56.9331s / 117621.0100 s
env0_first_0:                 episode reward: -81.1000,                 loss: 31.2016
env0_second_0:                 episode reward: 81.1000,                 loss: 29.4687
env1_first_0:                 episode reward: -81.4000,                 loss: nan
env1_second_0:                 episode reward: 81.4000,                 loss: nan
Episode: 13101/30000 (43.6700%),                 avg. length: 236.95,                last time consumption/overall running time: 49.9071s / 117670.9171 s
env0_first_0:                 episode reward: -85.3500,                 loss: 33.0481
env0_second_0:                 episode reward: 85.3500,                 loss: 34.3873
env1_first_0:                 episode reward: -86.4500,                 loss: nan
env1_second_0:                 episode reward: 86.4500,                 loss: nan
Episode: 13121/30000 (43.7367%),                 avg. length: 300.35,                last time consumption/overall running time: 61.5149s / 117732.4320 s
env0_first_0:                 episode reward: -78.1500,                 loss: 36.9209
env0_second_0:                 episode reward: 78.1500,                 loss: 38.1712
env1_first_0:                 episode reward: -75.0500,                 loss: nan
env1_second_0:                 episode reward: 75.0500,                 loss: nan
Episode: 13141/30000 (43.8033%),                 avg. length: 273.1,                last time consumption/overall running time: 56.1599s / 117788.5919 s
env0_first_0:                 episode reward: -83.0000,                 loss: 36.6422
env0_second_0:                 episode reward: 83.0000,                 loss: 40.1111
env1_first_0:                 episode reward: -79.3500,                 loss: nan
env1_second_0:                 episode reward: 79.3500,                 loss: nan
Episode: 13161/30000 (43.8700%),                 avg. length: 726.05,                last time consumption/overall running time: 132.1834s / 117920.7753 s
env0_first_0:                 episode reward: -47.3500,                 loss: 28.2430
env0_second_0:                 episode reward: 47.3500,                 loss: 29.2062
env1_first_0:                 episode reward: -53.5500,                 loss: nan
env1_second_0:                 episode reward: 53.5500,                 loss: nan
Episode: 13181/30000 (43.9367%),                 avg. length: 306.15,                last time consumption/overall running time: 62.7263s / 117983.5016 s
env0_first_0:                 episode reward: -70.8500,                 loss: 44.3968
env0_second_0:                 episode reward: 70.8500,                 loss: 45.6734
env1_first_0:                 episode reward: -69.2500,                 loss: nan
env1_second_0:                 episode reward: 69.2500,                 loss: nan
Episode: 13201/30000 (44.0033%),                 avg. length: 919.55,                last time consumption/overall running time: 167.0070s / 118150.5086 s
env0_first_0:                 episode reward: -44.1000,                 loss: 24.7512
env0_second_0:                 episode reward: 44.1000,                 loss: 26.9374
env1_first_0:                 episode reward: -35.0500,                 loss: nan
env1_second_0:                 episode reward: 35.0500,                 loss: nan
Episode: 13221/30000 (44.0700%),                 avg. length: 397.2,                last time consumption/overall running time: 78.7151s / 118229.2237 s
env0_first_0:                 episode reward: -69.0500,                 loss: 38.0861
env0_second_0:                 episode reward: 69.0500,                 loss: 39.8428
env1_first_0:                 episode reward: -68.1500,                 loss: nan
env1_second_0:                 episode reward: 68.1500,                 loss: nan
Episode: 13241/30000 (44.1367%),                 avg. length: 390.25,                last time consumption/overall running time: 77.1679s / 118306.3916 s
env0_first_0:                 episode reward: -58.1500,                 loss: 44.6212
env0_second_0:                 episode reward: 58.1500,                 loss: 46.4892
env1_first_0:                 episode reward: -74.4000,                 loss: nan
env1_second_0:                 episode reward: 74.4000,                 loss: nan
Episode: 13261/30000 (44.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 302.5632s / 118608.9549 s
env0_first_0:                 episode reward: -0.9500,                 loss: 2.7175
env0_second_0:                 episode reward: 0.9500,                 loss: 3.8728
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 13281/30000 (44.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.2511s / 118910.2059 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.6221
env0_second_0:                 episode reward: 1.2500,                 loss: 1.6810
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 13301/30000 (44.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 301.6761s / 119211.8820 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.5607
env0_second_0:                 episode reward: 0.1500,                 loss: 2.5280
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 13321/30000 (44.4033%),                 avg. length: 1784.0,                last time consumption/overall running time: 295.7423s / 119507.6243 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.4670
env0_second_0:                 episode reward: 1.0000,                 loss: 2.6526
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 13341/30000 (44.4700%),                 avg. length: 1648.95,                last time consumption/overall running time: 269.3294s / 119776.9536 s
env0_first_0:                 episode reward: -10.4500,                 loss: 4.6716
env0_second_0:                 episode reward: 10.4500,                 loss: 7.7085
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 13361/30000 (44.5367%),                 avg. length: 840.95,                last time consumption/overall running time: 143.8372s / 119920.7908 s
env0_first_0:                 episode reward: -54.1500,                 loss: 25.7737
env0_second_0:                 episode reward: 54.1500,                 loss: 29.4238
env1_first_0:                 episode reward: -53.6000,                 loss: nan
env1_second_0:                 episode reward: 53.6000,                 loss: nan
Episode: 13381/30000 (44.6033%),                 avg. length: 1784.0,                last time consumption/overall running time: 288.4830s / 120209.2739 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.2053
env0_second_0:                 episode reward: 0.0000,                 loss: 3.1460
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 13401/30000 (44.6700%),                 avg. length: 1784.0,                last time consumption/overall running time: 289.0519s / 120498.3258 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0290
env0_second_0:                 episode reward: 0.0000,                 loss: 2.3955
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13421/30000 (44.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 291.0244s / 120789.3502 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0132
env0_second_0:                 episode reward: 0.0000,                 loss: 2.1062
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13441/30000 (44.8033%),                 avg. length: 1784.0,                last time consumption/overall running time: 291.6559s / 121081.0061 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0318
env0_second_0:                 episode reward: 0.0000,                 loss: 2.4029
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13461/30000 (44.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 291.7579s / 121372.7641 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0341
env0_second_0:                 episode reward: 0.0000,                 loss: 2.3072
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13481/30000 (44.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 285.0164s / 121657.7805 s
env0_first_0:                 episode reward: 0.0000,                 loss: -0.0254
env0_second_0:                 episode reward: 0.0000,                 loss: 2.2064
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 13501/30000 (45.0033%),                 avg. length: 306.25,                last time consumption/overall running time: 58.5180s / 121716.2985 s
env0_first_0:                 episode reward: -90.0000,                 loss: 33.8369
env0_second_0:                 episode reward: 90.0000,                 loss: 31.4009
env1_first_0:                 episode reward: -89.4500,                 loss: nan
env1_second_0:                 episode reward: 89.4500,                 loss: nan
Episode: 13521/30000 (45.0700%),                 avg. length: 392.8,                last time consumption/overall running time: 73.7099s / 121790.0084 s
env0_first_0:                 episode reward: -61.0000,                 loss: 29.4233
env0_second_0:                 episode reward: 61.0000,                 loss: 31.0013
env1_first_0:                 episode reward: -68.2500,                 loss: nan
env1_second_0:                 episode reward: 68.2500,                 loss: nan
Episode: 13541/30000 (45.1367%),                 avg. length: 817.35,                last time consumption/overall running time: 140.6293s / 121930.6378 s
env0_first_0:                 episode reward: -17.2500,                 loss: 23.5744
env0_second_0:                 episode reward: 17.2500,                 loss: 27.2585
env1_first_0:                 episode reward: -22.2500,                 loss: nan
env1_second_0:                 episode reward: 22.2500,                 loss: nan
Episode: 13561/30000 (45.2033%),                 avg. length: 923.7,                last time consumption/overall running time: 156.0027s / 122086.6405 s
env0_first_0:                 episode reward: 24.1500,                 loss: 17.4260
env0_second_0:                 episode reward: -24.1500,                 loss: 20.6829
env1_first_0:                 episode reward: 15.6500,                 loss: nan
env1_second_0:                 episode reward: -15.6500,                 loss: nan
Episode: 13581/30000 (45.2700%),                 avg. length: 752.6,                last time consumption/overall running time: 128.9674s / 122215.6078 s
env0_first_0:                 episode reward: -63.7500,                 loss: 28.3259
env0_second_0:                 episode reward: 63.7500,                 loss: 31.0789
env1_first_0:                 episode reward: -39.5500,                 loss: nan
env1_second_0:                 episode reward: 39.5500,                 loss: nan
Episode: 13601/30000 (45.3367%),                 avg. length: 530.6,                last time consumption/overall running time: 97.0556s / 122312.6634 s
env0_first_0:                 episode reward: -60.9500,                 loss: 35.3728
env0_second_0:                 episode reward: 60.9500,                 loss: 37.4936
env1_first_0:                 episode reward: -49.2500,                 loss: nan
env1_second_0:                 episode reward: 49.2500,                 loss: nan
Episode: 13621/30000 (45.4033%),                 avg. length: 1261.7,                last time consumption/overall running time: 214.4788s / 122527.1422 s
env0_first_0:                 episode reward: -25.0500,                 loss: 12.3217
env0_second_0:                 episode reward: 25.0500,                 loss: 13.3447
env1_first_0:                 episode reward: -17.2000,                 loss: nan
env1_second_0:                 episode reward: 17.2000,                 loss: nan
Episode: 13641/30000 (45.4700%),                 avg. length: 426.55,                last time consumption/overall running time: 79.4559s / 122606.5982 s
env0_first_0:                 episode reward: -58.9000,                 loss: 40.5588
env0_second_0:                 episode reward: 58.9000,                 loss: 41.4315
env1_first_0:                 episode reward: -59.9500,                 loss: nan
env1_second_0:                 episode reward: 59.9500,                 loss: nan
Episode: 13661/30000 (45.5367%),                 avg. length: 382.45,                last time consumption/overall running time: 72.9546s / 122679.5527 s
env0_first_0:                 episode reward: -60.1500,                 loss: 46.7027
env0_second_0:                 episode reward: 60.1500,                 loss: 50.3780
env1_first_0:                 episode reward: -50.0000,                 loss: nan
env1_second_0:                 episode reward: 50.0000,                 loss: nan
Episode: 13681/30000 (45.6033%),                 avg. length: 1450.8,                last time consumption/overall running time: 239.3159s / 122918.8686 s
env0_first_0:                 episode reward: -9.4000,                 loss: 12.5152
env0_second_0:                 episode reward: 9.4000,                 loss: 14.3465
env1_first_0:                 episode reward: -17.1000,                 loss: nan
env1_second_0:                 episode reward: 17.1000,                 loss: nan
Episode: 13701/30000 (45.6700%),                 avg. length: 1147.4,                last time consumption/overall running time: 190.9928s / 123109.8614 s
env0_first_0:                 episode reward: 22.3000,                 loss: 12.3070
env0_second_0:                 episode reward: -22.3000,                 loss: 14.3483
env1_first_0:                 episode reward: 16.1000,                 loss: nan
env1_second_0:                 episode reward: -16.1000,                 loss: nan
Episode: 13721/30000 (45.7367%),                 avg. length: 659.25,                last time consumption/overall running time: 114.5616s / 123224.4230 s
env0_first_0:                 episode reward: -23.8500,                 loss: 39.4973
env0_second_0:                 episode reward: 23.8500,                 loss: 42.5161
env1_first_0:                 episode reward: -20.4500,                 loss: nan
env1_second_0:                 episode reward: 20.4500,                 loss: nan
Episode: 13741/30000 (45.8033%),                 avg. length: 845.85,                last time consumption/overall running time: 143.4544s / 123367.8774 s
env0_first_0:                 episode reward: -36.4000,                 loss: 38.0932
env0_second_0:                 episode reward: 36.4000,                 loss: 39.1989
env1_first_0:                 episode reward: -43.5000,                 loss: nan
env1_second_0:                 episode reward: 43.5000,                 loss: nan
Episode: 13761/30000 (45.8700%),                 avg. length: 1095.05,                last time consumption/overall running time: 182.4631s / 123550.3405 s
env0_first_0:                 episode reward: -45.6500,                 loss: 26.0759
env0_second_0:                 episode reward: 45.6500,                 loss: 27.9492
env1_first_0:                 episode reward: -23.0500,                 loss: nan
env1_second_0:                 episode reward: 23.0500,                 loss: nan
Episode: 13781/30000 (45.9367%),                 avg. length: 391.3,                last time consumption/overall running time: 73.7333s / 123624.0738 s
env0_first_0:                 episode reward: -48.2500,                 loss: 53.8305
env0_second_0:                 episode reward: 48.2500,                 loss: 56.0675
env1_first_0:                 episode reward: -71.0000,                 loss: nan
env1_second_0:                 episode reward: 71.0000,                 loss: nan
Episode: 13801/30000 (46.0033%),                 avg. length: 437.15,                last time consumption/overall running time: 82.1817s / 123706.2554 s
env0_first_0:                 episode reward: -51.0500,                 loss: 52.0715
env0_second_0:                 episode reward: 51.0500,                 loss: 52.3599
env1_first_0:                 episode reward: -64.1500,                 loss: nan
env1_second_0:                 episode reward: 64.1500,                 loss: nan
Episode: 13821/30000 (46.0700%),                 avg. length: 670.65,                last time consumption/overall running time: 119.1362s / 123825.3917 s
env0_first_0:                 episode reward: -28.8000,                 loss: 42.0861
env0_second_0:                 episode reward: 28.8000,                 loss: 45.2160
env1_first_0:                 episode reward: -39.2000,                 loss: nan
env1_second_0:                 episode reward: 39.2000,                 loss: nan
Episode: 13841/30000 (46.1367%),                 avg. length: 725.5,                last time consumption/overall running time: 128.8281s / 123954.2198 s
env0_first_0:                 episode reward: -31.9000,                 loss: 32.9926
env0_second_0:                 episode reward: 31.9000,                 loss: 34.7889
env1_first_0:                 episode reward: -31.4000,                 loss: nan
env1_second_0:                 episode reward: 31.4000,                 loss: nan
Episode: 13861/30000 (46.2033%),                 avg. length: 630.9,                last time consumption/overall running time: 112.5247s / 124066.7444 s
env0_first_0:                 episode reward: -48.2000,                 loss: 33.6302
env0_second_0:                 episode reward: 48.2000,                 loss: 33.5837
env1_first_0:                 episode reward: -43.3500,                 loss: nan
env1_second_0:                 episode reward: 43.3500,                 loss: nan
Episode: 13881/30000 (46.2700%),                 avg. length: 704.4,                last time consumption/overall running time: 127.8151s / 124194.5595 s
env0_first_0:                 episode reward: -7.0000,                 loss: 25.7133
env0_second_0:                 episode reward: 7.0000,                 loss: 28.3544
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 13901/30000 (46.3367%),                 avg. length: 772.95,                last time consumption/overall running time: 142.2635s / 124336.8230 s
env0_first_0:                 episode reward: -42.3000,                 loss: 19.1660
env0_second_0:                 episode reward: 42.3000,                 loss: 20.9009
env1_first_0:                 episode reward: -30.9000,                 loss: nan
env1_second_0:                 episode reward: 30.9000,                 loss: nan
Episode: 13921/30000 (46.4033%),                 avg. length: 1071.95,                last time consumption/overall running time: 182.4774s / 124519.3004 s
env0_first_0:                 episode reward: -26.0500,                 loss: 13.5292
env0_second_0:                 episode reward: 26.0500,                 loss: 16.1219
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 13941/30000 (46.4700%),                 avg. length: 1034.2,                last time consumption/overall running time: 174.9931s / 124694.2935 s
env0_first_0:                 episode reward: 8.7000,                 loss: 13.9999
env0_second_0:                 episode reward: -8.7000,                 loss: 17.3329
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 13961/30000 (46.5367%),                 avg. length: 1271.7,                last time consumption/overall running time: 213.9621s / 124908.2556 s
env0_first_0:                 episode reward: -14.8000,                 loss: 13.4294
env0_second_0:                 episode reward: 14.8000,                 loss: 16.6381
env1_first_0:                 episode reward: 4.9500,                 loss: nan
env1_second_0:                 episode reward: -4.9500,                 loss: nan
Episode: 13981/30000 (46.6033%),                 avg. length: 1441.45,                last time consumption/overall running time: 238.4607s / 125146.7163 s
env0_first_0:                 episode reward: -26.7000,                 loss: 7.5235
env0_second_0:                 episode reward: 26.7000,                 loss: 10.8862
env1_first_0:                 episode reward: -25.7000,                 loss: nan
env1_second_0:                 episode reward: 25.7000,                 loss: nan
Episode: 14001/30000 (46.6700%),                 avg. length: 1548.3,                last time consumption/overall running time: 251.4616s / 125398.1779 s
env0_first_0:                 episode reward: -18.3000,                 loss: 4.8727
env0_second_0:                 episode reward: 18.3000,                 loss: 7.3095
env1_first_0:                 episode reward: -17.1000,                 loss: nan
env1_second_0:                 episode reward: 17.1000,                 loss: nan
Episode: 14021/30000 (46.7367%),                 avg. length: 1784.0,                last time consumption/overall running time: 288.9332s / 125687.1111 s
env0_first_0:                 episode reward: 5.9000,                 loss: 0.2991
env0_second_0:                 episode reward: -5.9000,                 loss: 2.0477
env1_first_0:                 episode reward: 6.4000,                 loss: nan
env1_second_0:                 episode reward: -6.4000,                 loss: nan
Episode: 14041/30000 (46.8033%),                 avg. length: 1778.7,                last time consumption/overall running time: 278.8458s / 125965.9570 s
env0_first_0:                 episode reward: 22.6500,                 loss: 1.4609
env0_second_0:                 episode reward: -22.6500,                 loss: 3.3926
env1_first_0:                 episode reward: 21.6000,                 loss: nan
env1_second_0:                 episode reward: -21.6000,                 loss: nan
Episode: 14061/30000 (46.8700%),                 avg. length: 1784.0,                last time consumption/overall running time: 274.7686s / 126240.7256 s
env0_first_0:                 episode reward: 15.6000,                 loss: 1.3569
env0_second_0:                 episode reward: -15.6000,                 loss: 3.2044
env1_first_0:                 episode reward: 16.3000,                 loss: nan
env1_second_0:                 episode reward: -16.3000,                 loss: nan
Episode: 14081/30000 (46.9367%),                 avg. length: 1784.0,                last time consumption/overall running time: 272.7308s / 126513.4564 s
env0_first_0:                 episode reward: 9.5000,                 loss: 0.8644
env0_second_0:                 episode reward: -9.5000,                 loss: 4.5502
env1_first_0:                 episode reward: 10.1000,                 loss: nan
env1_second_0:                 episode reward: -10.1000,                 loss: nan
Episode: 14101/30000 (47.0033%),                 avg. length: 1784.0,                last time consumption/overall running time: 271.5948s / 126785.0513 s
env0_first_0:                 episode reward: 12.3500,                 loss: 0.6085
env0_second_0:                 episode reward: -12.3500,                 loss: 2.6631
env1_first_0:                 episode reward: 11.3000,                 loss: nan
env1_second_0:                 episode reward: -11.3000,                 loss: nan
Episode: 14121/30000 (47.0700%),                 avg. length: 1784.0,                last time consumption/overall running time: 272.3224s / 127057.3737 s
env0_first_0:                 episode reward: 4.7500,                 loss: 0.3101
env0_second_0:                 episode reward: -4.7500,                 loss: 1.6353
env1_first_0:                 episode reward: 6.5500,                 loss: nan
env1_second_0:                 episode reward: -6.5500,                 loss: nan
Episode: 14141/30000 (47.1367%),                 avg. length: 1784.0,                last time consumption/overall running time: 266.4065s / 127323.7802 s
env0_first_0:                 episode reward: 4.5000,                 loss: 0.4095
env0_second_0:                 episode reward: -4.5000,                 loss: 1.5690
env1_first_0:                 episode reward: 7.5000,                 loss: nan
env1_second_0:                 episode reward: -7.5000,                 loss: nan
Episode: 14161/30000 (47.2033%),                 avg. length: 1784.0,                last time consumption/overall running time: 260.0915s / 127583.8716 s
env0_first_0:                 episode reward: 7.2000,                 loss: 0.4635
env0_second_0:                 episode reward: -7.2000,                 loss: 1.4793
env1_first_0:                 episode reward: 4.2500,                 loss: nan
env1_second_0:                 episode reward: -4.2500,                 loss: nan
Episode: 14181/30000 (47.2700%),                 avg. length: 1784.0,                last time consumption/overall running time: 260.4055s / 127844.2772 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0807
env0_second_0:                 episode reward: -1.1500,                 loss: 1.1223
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 14201/30000 (47.3367%),                 avg. length: 1784.0,                last time consumption/overall running time: 264.1008s / 128108.3780 s