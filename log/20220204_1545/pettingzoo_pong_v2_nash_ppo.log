pygame 2.0.1 (SDL 2.0.14, Python 3.7.0)
Hello from the pygame community. https://www.pygame.org/contribute.html
pong_v2 pettingzoo
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.
  warn("Converting G to a CSC matrix; may take a while.")
/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.
  warn("Converting A to a CSC matrix; may take a while.")
random seed: [91, 69]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'pong_v2', 'env_type': 'pettingzoo', 'num_envs': 2, 'ram': True, 'seed': 'random', 'algorithm': 'NashPPO', 'algorithm_spec': {'episodic_update': True, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'lambda': 0.95, 'eps_clip': 0.2, 'K_epoch': 4, 'GAE': True}, 'num_process': 1, 'batch_size': 128, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'multiprocess': False, 'eval_models': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False, 'policy': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': 'Softmax'}, 'value': {'hidden_dim_list': [128, 128, 128, 128], 'hidden_activation': 'ReLU', 'output_activation': False}}, 'marl_method': 'nash_ppo', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': True}}
Save models to : /home/zihan/research/MARS/data/model/20220204_1545/pettingzoo_pong_v2_nash_ppo. 
 Save logs to: /home/zihan/research/MARS/data/log/20220204_1545/pettingzoo_pong_v2_nash_ppo.
Episode: 1/30000 (0.0033%),                 avg. length: 1122.0,                last time consumption/overall running time: 7.3972s / 7.3972 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.2828
env0_second_0:                 episode reward: -2.0000,                 loss: 0.2771
env1_first_0:                 episode reward: -16.0000,                 loss: nan
env1_second_0:                 episode reward: 16.0000,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 1192.2,                last time consumption/overall running time: 146.1351s / 153.5323 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.3314
env0_second_0:                 episode reward: -1.0500,                 loss: 0.3300
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 1142.6,                last time consumption/overall running time: 140.4245s / 293.9568 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.6177
env0_second_0:                 episode reward: -0.4000,                 loss: 0.6010
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 1132.75,                last time consumption/overall running time: 146.6693s / 440.6260 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.7319
env0_second_0:                 episode reward: -1.1500,                 loss: 0.7423
env1_first_0:                 episode reward: 6.2500,                 loss: nan
env1_second_0:                 episode reward: -6.2500,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 1160.6,                last time consumption/overall running time: 148.5744s / 589.2005 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.6451
env0_second_0:                 episode reward: -0.6500,                 loss: 0.6439
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 990.1,                last time consumption/overall running time: 121.1453s / 710.3457 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.6273
env0_second_0:                 episode reward: 6.7500,                 loss: 0.6243
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 1065.1,                last time consumption/overall running time: 136.4956s / 846.8413 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.6708
env0_second_0:                 episode reward: -1.2500,                 loss: 0.6702
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 1247.95,                last time consumption/overall running time: 151.8339s / 998.6752 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.6688
env0_second_0:                 episode reward: -3.6000,                 loss: 0.6798
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 1123.3,                last time consumption/overall running time: 129.9481s / 1128.6234 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.6807
env0_second_0:                 episode reward: -3.4500,                 loss: 0.6693
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 1093.55,                last time consumption/overall running time: 138.3048s / 1266.9282 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.7166
env0_second_0:                 episode reward: -3.6500,                 loss: 0.6990
env1_first_0:                 episode reward: 3.8500,                 loss: nan
env1_second_0:                 episode reward: -3.8500,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 1188.15,                last time consumption/overall running time: 143.6652s / 1410.5934 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.7515
env0_second_0:                 episode reward: -0.3000,                 loss: 0.7381
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 1120.2,                last time consumption/overall running time: 132.0656s / 1542.6590 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.7567
env0_second_0:                 episode reward: 0.9000,                 loss: 0.7492
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 1141.25,                last time consumption/overall running time: 145.3199s / 1687.9788 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.7014
env0_second_0:                 episode reward: 0.3500,                 loss: 0.6807
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 1098.4,                last time consumption/overall running time: 141.9917s / 1829.9705 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.7333
env0_second_0:                 episode reward: -0.7500,                 loss: 0.7219
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 1154.05,                last time consumption/overall running time: 146.4726s / 1976.4431 s
env0_first_0:                 episode reward: 4.2500,                 loss: 0.7212
env0_second_0:                 episode reward: -4.2500,                 loss: 0.7111
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 948.0,                last time consumption/overall running time: 119.5928s / 2096.0359 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.6743
env0_second_0:                 episode reward: 2.6500,                 loss: 0.6735
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 1109.2,                last time consumption/overall running time: 140.1536s / 2236.1895 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.6784
env0_second_0:                 episode reward: 2.4000,                 loss: 0.6593
env1_first_0:                 episode reward: -4.2500,                 loss: nan
env1_second_0:                 episode reward: 4.2500,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 1026.5,                last time consumption/overall running time: 134.7655s / 2370.9551 s
env0_first_0:                 episode reward: 0.9500,                 loss: 0.6955
env0_second_0:                 episode reward: -0.9500,                 loss: 0.6886
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 1195.3,                last time consumption/overall running time: 154.8276s / 2525.7827 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.7248
env0_second_0:                 episode reward: 1.2000,                 loss: 0.7144
env1_first_0:                 episode reward: 5.5500,                 loss: nan
env1_second_0:                 episode reward: -5.5500,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 1161.4,                last time consumption/overall running time: 149.3275s / 2675.1102 s
env0_first_0:                 episode reward: 5.4500,                 loss: 0.7262
env0_second_0:                 episode reward: -5.4500,                 loss: 0.7148
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 1131.45,                last time consumption/overall running time: 144.8460s / 2819.9562 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.6926
env0_second_0:                 episode reward: -0.7000,                 loss: 0.6848
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 1252.7,                last time consumption/overall running time: 159.1262s / 2979.0824 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.6829
env0_second_0:                 episode reward: 4.1000,                 loss: 0.6775
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 1118.8,                last time consumption/overall running time: 141.5200s / 3120.6024 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.6489
env0_second_0:                 episode reward: 6.7500,                 loss: 0.6450
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 1186.35,                last time consumption/overall running time: 152.8053s / 3273.4077 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.6587
env0_second_0:                 episode reward: 1.2000,                 loss: 0.6495
env1_first_0:                 episode reward: -6.2000,                 loss: nan
env1_second_0:                 episode reward: 6.2000,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 1162.65,                last time consumption/overall running time: 155.1784s / 3428.5861 s
env0_first_0:                 episode reward: -5.3500,                 loss: 0.6479
env0_second_0:                 episode reward: 5.3500,                 loss: 0.6466
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 1157.95,                last time consumption/overall running time: 144.0717s / 3572.6578 s
env0_first_0:                 episode reward: -6.8000,                 loss: 0.6498
env0_second_0:                 episode reward: 6.8000,                 loss: 0.6430
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 1138.0,                last time consumption/overall running time: 142.7280s / 3715.3858 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.5256
env0_second_0:                 episode reward: 8.6000,                 loss: 0.5272
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 1210.0,                last time consumption/overall running time: 157.7334s / 3873.1191 s
env0_first_0:                 episode reward: -10.2000,                 loss: 0.4919
env0_second_0:                 episode reward: 10.2000,                 loss: 0.4933
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 1178.2,                last time consumption/overall running time: 157.3920s / 4030.5111 s
env0_first_0:                 episode reward: -9.3000,                 loss: 0.4383
env0_second_0:                 episode reward: 9.3000,                 loss: 0.4325
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 1198.8,                last time consumption/overall running time: 147.6365s / 4178.1476 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.4488
env0_second_0:                 episode reward: 12.3000,                 loss: 0.4483
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 1129.9,                last time consumption/overall running time: 133.8858s / 4312.0334 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.4400
env0_second_0:                 episode reward: 11.6000,                 loss: 0.4583
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 1124.65,                last time consumption/overall running time: 136.1654s / 4448.1988 s
env0_first_0:                 episode reward: -14.5000,                 loss: 0.4197
env0_second_0:                 episode reward: 14.5000,                 loss: 0.4157
env1_first_0:                 episode reward: -11.3000,                 loss: nan
env1_second_0:                 episode reward: 11.3000,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 1216.95,                last time consumption/overall running time: 154.3403s / 4602.5392 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.3916
env0_second_0:                 episode reward: 12.1000,                 loss: 0.3902
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 1380.8,                last time consumption/overall running time: 171.4315s / 4773.9707 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.4051
env0_second_0:                 episode reward: 10.9500,                 loss: 0.4152
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 1741.7,                last time consumption/overall running time: 219.1585s / 4993.1292 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.3557
env0_second_0:                 episode reward: 1.9000,                 loss: 0.3757
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 1806.35,                last time consumption/overall running time: 218.3209s / 5211.4501 s
env0_first_0:                 episode reward: 3.7500,                 loss: 0.3285
env0_second_0:                 episode reward: -3.7500,                 loss: 0.3451
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 1765.95,                last time consumption/overall running time: 217.8574s / 5429.3075 s
env0_first_0:                 episode reward: 4.2000,                 loss: 0.3074
env0_second_0:                 episode reward: -4.2000,                 loss: 0.3246
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 1946.45,                last time consumption/overall running time: 240.1293s / 5669.4368 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.2762
env0_second_0:                 episode reward: -0.7000,                 loss: 0.2993
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 1906.6,                last time consumption/overall running time: 240.3313s / 5909.7681 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.3123
env0_second_0:                 episode reward: 0.1000,                 loss: 0.3223
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 1761.25,                last time consumption/overall running time: 211.6679s / 6121.4361 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.3199
env0_second_0:                 episode reward: 4.8000,                 loss: 0.3320
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 1831.15,                last time consumption/overall running time: 216.5270s / 6337.9630 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.3519
env0_second_0:                 episode reward: 3.3000,                 loss: 0.3664
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 1884.3,                last time consumption/overall running time: 230.4006s / 6568.3636 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.3186
env0_second_0:                 episode reward: 4.8000,                 loss: 0.3290
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 1965.65,                last time consumption/overall running time: 215.1707s / 6783.5344 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.3075
env0_second_0:                 episode reward: -0.8500,                 loss: 0.3133
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 1861.7,                last time consumption/overall running time: 232.1637s / 7015.6981 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2870
env0_second_0:                 episode reward: -0.7500,                 loss: 0.2947
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 1966.05,                last time consumption/overall running time: 246.4755s / 7262.1736 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.2591
env0_second_0:                 episode reward: -2.4000,                 loss: 0.2583
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2006.45,                last time consumption/overall running time: 252.2789s / 7514.4525 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.2543
env0_second_0:                 episode reward: -2.6500,                 loss: 0.2581
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 1854.4,                last time consumption/overall running time: 234.2698s / 7748.7223 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.2632
env0_second_0:                 episode reward: -2.8500,                 loss: 0.2728
env1_first_0:                 episode reward: 6.2500,                 loss: nan
env1_second_0:                 episode reward: -6.2500,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 1903.25,                last time consumption/overall running time: 221.2638s / 7969.9861 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.2559
env0_second_0:                 episode reward: 1.0500,                 loss: 0.2669
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2006.4,                last time consumption/overall running time: 249.3468s / 8219.3328 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.2453
env0_second_0:                 episode reward: 2.8000,                 loss: 0.2606
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2037.1,                last time consumption/overall running time: 257.4547s / 8476.7875 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.2488
env0_second_0:                 episode reward: 0.4500,                 loss: 0.2433
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 1905.1,                last time consumption/overall running time: 238.2936s / 8715.0811 s
env0_first_0:                 episode reward: 3.8500,                 loss: 0.2422
env0_second_0:                 episode reward: -3.8500,                 loss: 0.2373
env1_first_0:                 episode reward: 1.8500,                 loss: nan
env1_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 1951.15,                last time consumption/overall running time: 244.9421s / 8960.0231 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.2329
env0_second_0:                 episode reward: -1.6500,                 loss: 0.2409
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2037.6,                last time consumption/overall running time: 254.7006s / 9214.7238 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.2391
env0_second_0:                 episode reward: 0.3500,                 loss: 0.2438
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 1918.65,                last time consumption/overall running time: 238.9438s / 9453.6675 s
env0_first_0:                 episode reward: 3.4500,                 loss: 0.2817
env0_second_0:                 episode reward: -3.4500,                 loss: 0.2967
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 1937.9,                last time consumption/overall running time: 247.4950s / 9701.1626 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2516
env0_second_0:                 episode reward: -0.5000,                 loss: 0.2680
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 1958.55,                last time consumption/overall running time: 245.8447s / 9947.0072 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2489
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2447
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2050.25,                last time consumption/overall running time: 263.6375s / 10210.6447 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.2256
env0_second_0:                 episode reward: -2.9500,                 loss: 0.2317
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 1954.45,                last time consumption/overall running time: 254.2086s / 10464.8533 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.2401
env0_second_0:                 episode reward: -3.7000,                 loss: 0.2446
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2057.8,                last time consumption/overall running time: 263.8349s / 10728.6882 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2522
env0_second_0:                 episode reward: -0.4000,                 loss: 0.2634
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2050.25,                last time consumption/overall running time: 261.2039s / 10989.8921 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.2189
env0_second_0:                 episode reward: 3.2000,                 loss: 0.2298
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 1933.3,                last time consumption/overall running time: 241.8712s / 11231.7633 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.2695
env0_second_0:                 episode reward: 0.9500,                 loss: 0.2793
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2049.8,                last time consumption/overall running time: 253.4856s / 11485.2489 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.2107
env0_second_0:                 episode reward: 4.5000,                 loss: 0.2338
env1_first_0:                 episode reward: -4.4000,                 loss: nan
env1_second_0:                 episode reward: 4.4000,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 1981.35,                last time consumption/overall running time: 248.2038s / 11733.4527 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.2267
env0_second_0:                 episode reward: 6.4500,                 loss: 0.2473
env1_first_0:                 episode reward: -6.7000,                 loss: nan
env1_second_0:                 episode reward: 6.7000,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2014.35,                last time consumption/overall running time: 248.5221s / 11981.9749 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.2292
env0_second_0:                 episode reward: 6.3000,                 loss: 0.2446
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 1888.9,                last time consumption/overall running time: 238.2958s / 12220.2707 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.2193
env0_second_0:                 episode reward: 8.1500,                 loss: 0.2592
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2015.5,                last time consumption/overall running time: 247.5778s / 12467.8484 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.2270
env0_second_0:                 episode reward: 8.0500,                 loss: 0.2458
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 1981.65,                last time consumption/overall running time: 254.6947s / 12722.5432 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.2252
env0_second_0:                 episode reward: 8.2000,                 loss: 0.2565
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 1804.85,                last time consumption/overall running time: 222.2170s / 12944.7602 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.1972
env0_second_0:                 episode reward: 12.1000,                 loss: 0.2084
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 1938.0,                last time consumption/overall running time: 240.2516s / 13185.0118 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.1731
env0_second_0:                 episode reward: 9.3500,                 loss: 0.1993
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2026.85,                last time consumption/overall running time: 228.5259s / 13413.5377 s
env0_first_0:                 episode reward: -4.8000,                 loss: 0.2187
env0_second_0:                 episode reward: 4.8000,                 loss: 0.2466
env1_first_0:                 episode reward: -7.6500,                 loss: nan
env1_second_0:                 episode reward: 7.6500,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2032.3,                last time consumption/overall running time: 225.3450s / 13638.8827 s
env0_first_0:                 episode reward: -5.3000,                 loss: 0.2522
env0_second_0:                 episode reward: 5.3000,                 loss: 0.2698
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 1919.1,                last time consumption/overall running time: 217.6256s / 13856.5084 s
env0_first_0:                 episode reward: -8.9500,                 loss: 0.2054
env0_second_0:                 episode reward: 8.9500,                 loss: 0.2314
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 1990.15,                last time consumption/overall running time: 239.3486s / 14095.8569 s
env0_first_0:                 episode reward: -6.7500,                 loss: 0.2410
env0_second_0:                 episode reward: 6.7500,                 loss: 0.2545
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 1982.15,                last time consumption/overall running time: 237.2611s / 14333.1180 s
env0_first_0:                 episode reward: -5.9000,                 loss: 0.2624
env0_second_0:                 episode reward: 5.9000,                 loss: 0.2744
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 1980.7,                last time consumption/overall running time: 244.9552s / 14578.0733 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.2465
env0_second_0:                 episode reward: 6.3000,                 loss: 0.2653
env1_first_0:                 episode reward: -7.2500,                 loss: nan
env1_second_0:                 episode reward: 7.2500,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2025.95,                last time consumption/overall running time: 258.5631s / 14836.6364 s
env0_first_0:                 episode reward: -4.9000,                 loss: 0.2472
env0_second_0:                 episode reward: 4.9000,                 loss: 0.2764
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 1944.0,                last time consumption/overall running time: 229.1542s / 15065.7906 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.2361
env0_second_0:                 episode reward: 5.2500,                 loss: 0.3237
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 1898.8,                last time consumption/overall running time: 236.0700s / 15301.8605 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.2489
env0_second_0:                 episode reward: 7.5500,                 loss: 0.2657
env1_first_0:                 episode reward: -7.4500,                 loss: nan
env1_second_0:                 episode reward: 7.4500,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 1937.95,                last time consumption/overall running time: 227.0833s / 15528.9438 s
env0_first_0:                 episode reward: -5.3000,                 loss: 0.2465
env0_second_0:                 episode reward: 5.3000,                 loss: 0.2603
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 1896.2,                last time consumption/overall running time: 215.6404s / 15744.5842 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.2090
env0_second_0:                 episode reward: 9.6500,                 loss: 0.2398
env1_first_0:                 episode reward: -7.0500,                 loss: nan
env1_second_0:                 episode reward: 7.0500,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 1866.8,                last time consumption/overall running time: 228.4784s / 15973.0626 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.2139
env0_second_0:                 episode reward: 10.0000,                 loss: 0.2313
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 1874.65,                last time consumption/overall running time: 227.7197s / 16200.7822 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.1569
env0_second_0:                 episode reward: 10.8500,                 loss: 0.1751
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 1797.8,                last time consumption/overall running time: 220.0658s / 16420.8480 s
env0_first_0:                 episode reward: -13.4500,                 loss: 0.2471
env0_second_0:                 episode reward: 13.4500,                 loss: 0.2877
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 1746.3,                last time consumption/overall running time: 204.2522s / 16625.1002 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.1551
env0_second_0:                 episode reward: 13.6500,                 loss: 0.1976
env1_first_0:                 episode reward: -14.2000,                 loss: nan
env1_second_0:                 episode reward: 14.2000,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 1830.0,                last time consumption/overall running time: 211.3112s / 16836.4114 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.1459
env0_second_0:                 episode reward: 13.5500,                 loss: 0.1702
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 1802.2,                last time consumption/overall running time: 196.0972s / 17032.5086 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.1415
env0_second_0:                 episode reward: 13.1500,                 loss: 0.1555
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 1744.6,                last time consumption/overall running time: 194.4812s / 17226.9899 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.1271
env0_second_0:                 episode reward: 13.7500,                 loss: 0.1409
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 1795.7,                last time consumption/overall running time: 209.9898s / 17436.9797 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.1515
env0_second_0:                 episode reward: 13.2000,                 loss: 0.1791
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 1734.9,                last time consumption/overall running time: 213.4752s / 17650.4549 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.1609
env0_second_0:                 episode reward: 14.7500,                 loss: 0.1678
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 1741.15,                last time consumption/overall running time: 226.1711s / 17876.6260 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.1849
env0_second_0:                 episode reward: 12.1000,                 loss: 0.1782
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 1747.15,                last time consumption/overall running time: 231.0656s / 18107.6916 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.1659
env0_second_0:                 episode reward: 13.7500,                 loss: 0.2091
env1_first_0:                 episode reward: -13.1000,                 loss: nan
env1_second_0:                 episode reward: 13.1000,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 1766.25,                last time consumption/overall running time: 231.4018s / 18339.0934 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.1101
env0_second_0:                 episode reward: 15.2500,                 loss: 0.1258
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 1714.2,                last time consumption/overall running time: 221.7997s / 18560.8930 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.2008
env0_second_0:                 episode reward: 12.8500,                 loss: 0.2006
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 1744.7,                last time consumption/overall running time: 221.1190s / 18782.0120 s
env0_first_0:                 episode reward: -14.4000,                 loss: 0.1574
env0_second_0:                 episode reward: 14.4000,                 loss: 0.2381
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 1456.6,                last time consumption/overall running time: 171.0613s / 18953.0733 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.2981
env0_second_0:                 episode reward: 2.4000,                 loss: 0.3189
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 818.35,                last time consumption/overall running time: 108.8126s / 19061.8859 s
env0_first_0:                 episode reward: 17.6000,                 loss: 0.2559
env0_second_0:                 episode reward: -17.6000,                 loss: 0.4702
env1_first_0:                 episode reward: 18.9000,                 loss: nan
env1_second_0:                 episode reward: -18.9000,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 1327.6,                last time consumption/overall running time: 164.4675s / 19226.3535 s
env0_first_0:                 episode reward: 10.8000,                 loss: 0.4905
env0_second_0:                 episode reward: -10.8000,                 loss: 0.5224
env1_first_0:                 episode reward: 9.8000,                 loss: nan
env1_second_0:                 episode reward: -9.8000,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 1542.4,                last time consumption/overall running time: 184.5565s / 19410.9100 s
env0_first_0:                 episode reward: 8.1500,                 loss: 0.4305
env0_second_0:                 episode reward: -8.1500,                 loss: 0.4225
env1_first_0:                 episode reward: 4.2000,                 loss: nan
env1_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 1849.95,                last time consumption/overall running time: 225.1698s / 19636.0797 s
env0_first_0:                 episode reward: -8.2000,                 loss: 0.2464
env0_second_0:                 episode reward: 8.2000,                 loss: 0.2860
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 1830.1,                last time consumption/overall running time: 213.7496s / 19849.8293 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.1587
env0_second_0:                 episode reward: 12.9000,                 loss: 0.1723
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 1830.4,                last time consumption/overall running time: 205.5536s / 20055.3829 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.1343
env0_second_0:                 episode reward: 13.2500,                 loss: 0.1515
env1_first_0:                 episode reward: -13.6000,                 loss: nan
env1_second_0:                 episode reward: 13.6000,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 1806.25,                last time consumption/overall running time: 198.5073s / 20253.8903 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.1474
env0_second_0:                 episode reward: 12.9500,                 loss: 0.1572
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 1760.5,                last time consumption/overall running time: 208.9128s / 20462.8031 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.1504
env0_second_0:                 episode reward: 14.9500,                 loss: 0.1663
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 1775.45,                last time consumption/overall running time: 193.8659s / 20656.6690 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.1260
env0_second_0:                 episode reward: 14.0000,                 loss: 0.1765
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 1750.55,                last time consumption/overall running time: 217.3101s / 20873.9791 s
env0_first_0:                 episode reward: -14.1500,                 loss: 0.1094
env0_second_0:                 episode reward: 14.1500,                 loss: 3.5922
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 1774.55,                last time consumption/overall running time: 222.4183s / 21096.3974 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.2095
env0_second_0:                 episode reward: 12.9500,                 loss: 3.7300
env1_first_0:                 episode reward: -12.6000,                 loss: nan
env1_second_0:                 episode reward: 12.6000,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 1844.65,                last time consumption/overall running time: 228.5949s / 21324.9923 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.1743
env0_second_0:                 episode reward: 12.5500,                 loss: 5.8199
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 1791.85,                last time consumption/overall running time: 230.9010s / 21555.8933 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.1444
env0_second_0:                 episode reward: 14.1000,                 loss: 2.5605
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 1968.5,                last time consumption/overall running time: 240.4691s / 21796.3625 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.1626
env0_second_0:                 episode reward: 10.0000,                 loss: 2.7968
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 1773.25,                last time consumption/overall running time: 196.5422s / 21992.9047 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.3342
env0_second_0:                 episode reward: -1.2000,                 loss: 2.7812
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 2010.9,                last time consumption/overall running time: 245.6530s / 22238.5577 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.1848
env0_second_0:                 episode reward: 8.4000,                 loss: 2.8861
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 1723.3,                last time consumption/overall running time: 220.3019s / 22458.8595 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.1291
env0_second_0:                 episode reward: 11.9000,                 loss: 2.5722
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 1785.4,                last time consumption/overall running time: 224.1875s / 22683.0470 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.1540
env0_second_0:                 episode reward: 12.7500,                 loss: 2.3154
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 1770.9,                last time consumption/overall running time: 221.0435s / 22904.0905 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.1925
env0_second_0:                 episode reward: 13.0000,                 loss: 2.0340
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 1771.5,                last time consumption/overall running time: 221.6642s / 23125.7547 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.1132
env0_second_0:                 episode reward: 14.9500,                 loss: 2.0183
env1_first_0:                 episode reward: -13.9000,                 loss: nan
env1_second_0:                 episode reward: 13.9000,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 1651.8,                last time consumption/overall running time: 218.0767s / 23343.8314 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.2941
env0_second_0:                 episode reward: 11.7000,                 loss: 3.5412
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 1882.05,                last time consumption/overall running time: 215.8279s / 23559.6593 s
env0_first_0:                 episode reward: -9.9000,                 loss: 0.2297
env0_second_0:                 episode reward: 9.9000,                 loss: 3.9485
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 1758.1,                last time consumption/overall running time: 198.3184s / 23757.9778 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.1916
env0_second_0:                 episode reward: 12.8500,                 loss: 3.9618
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 1972.85,                last time consumption/overall running time: 230.6955s / 23988.6733 s
env0_first_0:                 episode reward: -9.4000,                 loss: 0.1806
env0_second_0:                 episode reward: 9.4000,                 loss: 3.6267
env1_first_0:                 episode reward: -10.6500,                 loss: nan
env1_second_0:                 episode reward: 10.6500,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 1883.85,                last time consumption/overall running time: 235.5379s / 24224.2112 s
env0_first_0:                 episode reward: -7.0000,                 loss: 0.2607
env0_second_0:                 episode reward: 7.0000,                 loss: 3.2518
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 1852.35,                last time consumption/overall running time: 228.5715s / 24452.7827 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.1401
env0_second_0:                 episode reward: 13.7000,                 loss: 2.6514
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 1797.85,                last time consumption/overall running time: 219.2654s / 24672.0481 s
env0_first_0:                 episode reward: -13.9000,                 loss: 0.1411
env0_second_0:                 episode reward: 13.9000,                 loss: 2.2026
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 1934.9,                last time consumption/overall running time: 254.1017s / 24926.1498 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.1272
env0_second_0:                 episode reward: 13.2000,                 loss: 3.5602
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 1958.15,                last time consumption/overall running time: 259.7217s / 25185.8715 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.1576
env0_second_0:                 episode reward: 11.1500,                 loss: 3.1040
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 1857.2,                last time consumption/overall running time: 235.1348s / 25421.0064 s
env0_first_0:                 episode reward: -15.4500,                 loss: 0.1541
env0_second_0:                 episode reward: 15.4500,                 loss: 3.0977
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 1911.45,                last time consumption/overall running time: 249.3390s / 25670.3454 s
env0_first_0:                 episode reward: -14.7000,                 loss: 0.1216
env0_second_0:                 episode reward: 14.7000,                 loss: 1.7927
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 1967.55,                last time consumption/overall running time: 237.0268s / 25907.3722 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.1167
env0_second_0:                 episode reward: 13.1500,                 loss: 2.3880
env1_first_0:                 episode reward: -14.2500,                 loss: nan
env1_second_0:                 episode reward: 14.2500,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 1114.85,                last time consumption/overall running time: 127.0302s / 26034.4025 s
env0_first_0:                 episode reward: 10.5500,                 loss: 0.3143
env0_second_0:                 episode reward: -10.5500,                 loss: 2.1643
env1_first_0:                 episode reward: 9.6500,                 loss: nan
env1_second_0:                 episode reward: -9.6500,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2081.65,                last time consumption/overall running time: 248.9444s / 26283.3468 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.2946
env0_second_0:                 episode reward: -1.0500,                 loss: 1.6804
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2197.45,                last time consumption/overall running time: 281.4671s / 26564.8139 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.1647
env0_second_0:                 episode reward: 9.8000,                 loss: 1.9580
env1_first_0:                 episode reward: -9.3000,                 loss: nan
env1_second_0:                 episode reward: 9.3000,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 2195.85,                last time consumption/overall running time: 253.8167s / 26818.6307 s
env0_first_0:                 episode reward: -10.1000,                 loss: 0.1863
env0_second_0:                 episode reward: 10.1000,                 loss: 1.8642
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2209.0,                last time consumption/overall running time: 254.9444s / 27073.5751 s
env0_first_0:                 episode reward: -5.3500,                 loss: 0.2641
env0_second_0:                 episode reward: 5.3500,                 loss: 1.2116
env1_first_0:                 episode reward: -7.1500,                 loss: nan
env1_second_0:                 episode reward: 7.1500,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2022.45,                last time consumption/overall running time: 229.1608s / 27302.7359 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.2278
env0_second_0:                 episode reward: 11.0500,                 loss: 2.4580
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2123.05,                last time consumption/overall running time: 243.5343s / 27546.2701 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.1303
env0_second_0:                 episode reward: 11.2500,                 loss: 2.3081
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2218.25,                last time consumption/overall running time: 270.8284s / 27817.0986 s
env0_first_0:                 episode reward: -11.3000,                 loss: 0.1279
env0_second_0:                 episode reward: 11.3000,                 loss: 2.6865
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 1880.65,                last time consumption/overall running time: 216.5551s / 28033.6537 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.2414
env0_second_0:                 episode reward: 7.2000,                 loss: 1.8343
env1_first_0:                 episode reward: -7.4000,                 loss: nan
env1_second_0:                 episode reward: 7.4000,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 1431.9,                last time consumption/overall running time: 177.1606s / 28210.8143 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.3023
env0_second_0:                 episode reward: 0.2500,                 loss: 2.4689
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2144.8,                last time consumption/overall running time: 246.5069s / 28457.3212 s
env0_first_0:                 episode reward: -10.9000,                 loss: 0.2438
env0_second_0:                 episode reward: 10.9000,                 loss: 2.0535
env1_first_0:                 episode reward: -8.0500,                 loss: nan
env1_second_0:                 episode reward: 8.0500,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 746.15,                last time consumption/overall running time: 96.1614s / 28553.4827 s
env0_first_0:                 episode reward: 19.7500,                 loss: 0.0945
env0_second_0:                 episode reward: -19.7500,                 loss: 1.6791
env1_first_0:                 episode reward: 20.3000,                 loss: nan
env1_second_0:                 episode reward: -20.3000,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 729.05,                last time consumption/overall running time: 93.9161s / 28647.3988 s
env0_first_0:                 episode reward: 20.4500,                 loss: 0.0605
env0_second_0:                 episode reward: -20.4500,                 loss: 2.3405
env1_first_0:                 episode reward: 20.5500,                 loss: nan
env1_second_0:                 episode reward: -20.5500,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 1180.9,                last time consumption/overall running time: 146.1996s / 28793.5984 s
env0_first_0:                 episode reward: 9.8500,                 loss: 0.4345
env0_second_0:                 episode reward: -9.8500,                 loss: 1.8779
env1_first_0:                 episode reward: 9.0000,                 loss: nan
env1_second_0:                 episode reward: -9.0000,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 879.05,                last time consumption/overall running time: 102.8725s / 28896.4709 s
env0_first_0:                 episode reward: -14.4500,                 loss: 0.3457
env0_second_0:                 episode reward: 14.4500,                 loss: 0.7643
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 1503.5,                last time consumption/overall running time: 174.4005s / 29070.8714 s
env0_first_0:                 episode reward: 3.7000,                 loss: 0.4716
env0_second_0:                 episode reward: -3.7000,                 loss: 1.4442
env1_first_0:                 episode reward: 4.8000,                 loss: nan
env1_second_0:                 episode reward: -4.8000,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 1733.85,                last time consumption/overall running time: 200.3487s / 29271.2201 s
env0_first_0:                 episode reward: 7.6000,                 loss: 0.3000
env0_second_0:                 episode reward: -7.6000,                 loss: 1.7640
env1_first_0:                 episode reward: 9.2000,                 loss: nan
env1_second_0:                 episode reward: -9.2000,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2180.15,                last time consumption/overall running time: 258.3651s / 29529.5852 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.2529
env0_second_0:                 episode reward: -2.4000,                 loss: 1.8477
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2239.3,                last time consumption/overall running time: 254.0909s / 29783.6761 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.2322
env0_second_0:                 episode reward: 3.3500,                 loss: 0.8131
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2292.05,                last time consumption/overall running time: 268.5787s / 30052.2548 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.2206
env0_second_0:                 episode reward: 4.2500,                 loss: 0.5665
env1_first_0:                 episode reward: -3.0500,                 loss: nan
env1_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2456.2,                last time consumption/overall running time: 299.6123s / 30351.8672 s
env0_first_0:                 episode reward: -2.9000,                 loss: 0.2231
env0_second_0:                 episode reward: 2.9000,                 loss: 0.4920
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2425.65,                last time consumption/overall running time: 275.7402s / 30627.6073 s
env0_first_0:                 episode reward: -4.7000,                 loss: 0.2115
env0_second_0:                 episode reward: 4.7000,                 loss: 0.8587
env1_first_0:                 episode reward: -6.0000,                 loss: nan
env1_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2370.15,                last time consumption/overall running time: 266.0111s / 30893.6184 s
env0_first_0:                 episode reward: -8.0500,                 loss: 0.2001
env0_second_0:                 episode reward: 8.0500,                 loss: 0.4558
env1_first_0:                 episode reward: -4.7000,                 loss: nan
env1_second_0:                 episode reward: 4.7000,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2348.7,                last time consumption/overall running time: 279.9033s / 31173.5217 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.1905
env0_second_0:                 episode reward: 6.2500,                 loss: 0.4614
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2316.35,                last time consumption/overall running time: 268.9781s / 31442.4998 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.1995
env0_second_0:                 episode reward: 6.1500,                 loss: 0.4083
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2462.95,                last time consumption/overall running time: 301.0814s / 31743.5812 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.1968
env0_second_0:                 episode reward: 7.8500,                 loss: 0.9828
env1_first_0:                 episode reward: -5.7500,                 loss: nan
env1_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2283.3,                last time consumption/overall running time: 277.7367s / 32021.3179 s
env0_first_0:                 episode reward: -6.6500,                 loss: 0.1946
env0_second_0:                 episode reward: 6.6500,                 loss: 1.7235
env1_first_0:                 episode reward: -8.1000,                 loss: nan
env1_second_0:                 episode reward: 8.1000,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2343.2,                last time consumption/overall running time: 277.9181s / 32299.2361 s
env0_first_0:                 episode reward: -8.7000,                 loss: 0.1929
env0_second_0:                 episode reward: 8.7000,                 loss: 1.2525
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2127.55,                last time consumption/overall running time: 274.8121s / 32574.0481 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.1807
env0_second_0:                 episode reward: 11.6500,                 loss: 3.0092
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2197.75,                last time consumption/overall running time: 275.7887s / 32849.8369 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.1444
env0_second_0:                 episode reward: 13.0500,                 loss: 2.4433
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2150.65,                last time consumption/overall running time: 265.3407s / 33115.1776 s
env0_first_0:                 episode reward: -11.3500,                 loss: 0.1345
env0_second_0:                 episode reward: 11.3500,                 loss: 1.6807
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2089.85,                last time consumption/overall running time: 243.5672s / 33358.7447 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.1260
env0_second_0:                 episode reward: 13.0000,                 loss: 1.9776
env1_first_0:                 episode reward: -14.1500,                 loss: nan
env1_second_0:                 episode reward: 14.1500,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2169.35,                last time consumption/overall running time: 261.2597s / 33620.0045 s
env0_first_0:                 episode reward: -12.1500,                 loss: 0.2077
env0_second_0:                 episode reward: 12.1500,                 loss: 2.0145
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2139.3,                last time consumption/overall running time: 269.0535s / 33889.0580 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.1188
env0_second_0:                 episode reward: 13.6500,                 loss: 2.9107
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 2095.5,                last time consumption/overall running time: 253.0783s / 34142.1363 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.1664
env0_second_0:                 episode reward: 13.0000,                 loss: 2.4323
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 1861.5,                last time consumption/overall running time: 217.2354s / 34359.3717 s
env0_first_0:                 episode reward: -18.0000,                 loss: 0.0856
env0_second_0:                 episode reward: 18.0000,                 loss: 2.2684
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 1893.05,                last time consumption/overall running time: 224.1968s / 34583.5685 s
env0_first_0:                 episode reward: -15.0500,                 loss: 0.0962
env0_second_0:                 episode reward: 15.0500,                 loss: 2.7637
env1_first_0:                 episode reward: -16.4000,                 loss: nan
env1_second_0:                 episode reward: 16.4000,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 1981.0,                last time consumption/overall running time: 249.5348s / 34833.1033 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.1060
env0_second_0:                 episode reward: 15.1500,                 loss: 1.4764
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 1969.75,                last time consumption/overall running time: 224.9485s / 35058.0519 s
env0_first_0:                 episode reward: -12.4500,                 loss: 0.2175
env0_second_0:                 episode reward: 12.4500,                 loss: 1.3309
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 834.65,                last time consumption/overall running time: 104.8860s / 35162.9379 s
env0_first_0:                 episode reward: 12.9000,                 loss: 0.4799
env0_second_0:                 episode reward: -12.9000,                 loss: 2.8657
env1_first_0:                 episode reward: 14.4500,                 loss: nan
env1_second_0:                 episode reward: -14.4500,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 1364.5,                last time consumption/overall running time: 158.0450s / 35320.9829 s
env0_first_0:                 episode reward: -15.1000,                 loss: 0.4035
env0_second_0:                 episode reward: 15.1000,                 loss: 4.3263
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 3361/30000 (11.2033%),                 avg. length: 1368.85,                last time consumption/overall running time: 182.4347s / 35503.4176 s
env0_first_0:                 episode reward: -16.1500,                 loss: 0.2148
env0_second_0:                 episode reward: 16.1500,                 loss: 2.6069
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 3381/30000 (11.2700%),                 avg. length: 1513.1,                last time consumption/overall running time: 188.5973s / 35692.0149 s
env0_first_0:                 episode reward: -15.4000,                 loss: 0.2397
env0_second_0:                 episode reward: 15.4000,                 loss: 1.5655
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 3401/30000 (11.3367%),                 avg. length: 1521.6,                last time consumption/overall running time: 182.0176s / 35874.0325 s
env0_first_0:                 episode reward: -14.1500,                 loss: 0.2750
env0_second_0:                 episode reward: 14.1500,                 loss: 1.1787
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 3421/30000 (11.4033%),                 avg. length: 1797.8,                last time consumption/overall running time: 218.5321s / 36092.5645 s
env0_first_0:                 episode reward: -15.3000,                 loss: 0.1677
env0_second_0:                 episode reward: 15.3000,                 loss: 0.9848
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 3441/30000 (11.4700%),                 avg. length: 1905.4,                last time consumption/overall running time: 221.8441s / 36314.4087 s
env0_first_0:                 episode reward: -15.9000,                 loss: 0.0782
env0_second_0:                 episode reward: 15.9000,                 loss: 0.4986
env1_first_0:                 episode reward: -15.3000,                 loss: nan
env1_second_0:                 episode reward: 15.3000,                 loss: nan
Episode: 3461/30000 (11.5367%),                 avg. length: 2093.45,                last time consumption/overall running time: 234.9857s / 36549.3944 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.1577
env0_second_0:                 episode reward: 13.5500,                 loss: 1.7778
env1_first_0:                 episode reward: -14.1500,                 loss: nan
env1_second_0:                 episode reward: 14.1500,                 loss: nan
Episode: 3481/30000 (11.6033%),                 avg. length: 1671.9,                last time consumption/overall running time: 202.4413s / 36751.8357 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.2582
env0_second_0:                 episode reward: 5.7500,                 loss: 1.6243
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 3501/30000 (11.6700%),                 avg. length: 952.3,                last time consumption/overall running time: 117.1338s / 36868.9695 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.3160
env0_second_0:                 episode reward: -1.3500,                 loss: 1.7737
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 3521/30000 (11.7367%),                 avg. length: 1273.2,                last time consumption/overall running time: 154.0124s / 37022.9819 s
env0_first_0:                 episode reward: -17.6500,                 loss: 0.0390
env0_second_0:                 episode reward: 17.6500,                 loss: 1.3240
env1_first_0:                 episode reward: -17.5500,                 loss: nan
env1_second_0:                 episode reward: 17.5500,                 loss: nan
Episode: 3541/30000 (11.8033%),                 avg. length: 1254.3,                last time consumption/overall running time: 151.0679s / 37174.0498 s
env0_first_0:                 episode reward: -17.4500,                 loss: 0.0582
env0_second_0:                 episode reward: 17.4500,                 loss: 0.4178
env1_first_0:                 episode reward: -16.9000,                 loss: nan
env1_second_0:                 episode reward: 16.9000,                 loss: nan
Episode: 3561/30000 (11.8700%),                 avg. length: 1183.55,                last time consumption/overall running time: 143.1105s / 37317.1603 s
env0_first_0:                 episode reward: -4.9500,                 loss: 0.2882
env0_second_0:                 episode reward: 4.9500,                 loss: 0.9991
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 3581/30000 (11.9367%),                 avg. length: 838.75,                last time consumption/overall running time: 103.7036s / 37420.8638 s
env0_first_0:                 episode reward: 14.6000,                 loss: 0.3080
env0_second_0:                 episode reward: -14.6000,                 loss: 1.0064
env1_first_0:                 episode reward: 15.6500,                 loss: nan
env1_second_0:                 episode reward: -15.6500,                 loss: nan
Episode: 3601/30000 (12.0033%),                 avg. length: 1112.45,                last time consumption/overall running time: 135.1805s / 37556.0443 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.5284
env0_second_0:                 episode reward: -0.6000,                 loss: 2.0761
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 3621/30000 (12.0700%),                 avg. length: 2072.15,                last time consumption/overall running time: 236.1395s / 37792.1839 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.2008
env0_second_0:                 episode reward: 12.6000,                 loss: 2.5532
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 3641/30000 (12.1367%),                 avg. length: 2201.25,                last time consumption/overall running time: 264.2623s / 38056.4462 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.1724
env0_second_0:                 episode reward: 11.2500,                 loss: 2.3345
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 3661/30000 (12.2033%),                 avg. length: 2179.75,                last time consumption/overall running time: 265.4080s / 38321.8542 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.2620
env0_second_0:                 episode reward: 8.2500,                 loss: 4.2550
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 3681/30000 (12.2700%),                 avg. length: 731.75,                last time consumption/overall running time: 93.1150s / 38414.9692 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.1181
env0_second_0:                 episode reward: -20.7500,                 loss: 4.7417
env1_first_0:                 episode reward: 20.3500,                 loss: nan
env1_second_0:                 episode reward: -20.3500,                 loss: nan
Episode: 3701/30000 (12.3367%),                 avg. length: 730.0,                last time consumption/overall running time: 92.2921s / 38507.2613 s
env0_first_0:                 episode reward: 20.4000,                 loss: 0.0947
env0_second_0:                 episode reward: -20.4000,                 loss: 3.3445
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 3721/30000 (12.4033%),                 avg. length: 728.85,                last time consumption/overall running time: 89.1036s / 38596.3649 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0474
env0_second_0:                 episode reward: -20.8000,                 loss: 2.1614
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 3741/30000 (12.4700%),                 avg. length: 728.4,                last time consumption/overall running time: 91.7616s / 38688.1265 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0419
env0_second_0:                 episode reward: -20.7000,                 loss: 1.5347
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 3761/30000 (12.5367%),                 avg. length: 728.6,                last time consumption/overall running time: 92.3005s / 38780.4270 s
env0_first_0:                 episode reward: 20.5500,                 loss: 0.0012
env0_second_0:                 episode reward: -20.5500,                 loss: 1.5686
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 3781/30000 (12.6033%),                 avg. length: 729.15,                last time consumption/overall running time: 89.8531s / 38870.2801 s
env0_first_0:                 episode reward: 20.5500,                 loss: 0.0054
env0_second_0:                 episode reward: -20.5500,                 loss: 1.3343
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 3801/30000 (12.6700%),                 avg. length: 729.35,                last time consumption/overall running time: 93.2114s / 38963.4915 s
env0_first_0:                 episode reward: 20.4500,                 loss: 0.0212
env0_second_0:                 episode reward: -20.4500,                 loss: 1.4691
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 3821/30000 (12.7367%),                 avg. length: 728.4,                last time consumption/overall running time: 90.0861s / 39053.5776 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0170
env0_second_0:                 episode reward: -20.7500,                 loss: 1.3776
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 3841/30000 (12.8033%),                 avg. length: 728.4,                last time consumption/overall running time: 90.8441s / 39144.4216 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0387
env0_second_0:                 episode reward: -20.7500,                 loss: 1.5133
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 3861/30000 (12.8700%),                 avg. length: 729.1,                last time consumption/overall running time: 92.7721s / 39237.1938 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.0314
env0_second_0:                 episode reward: -20.6500,                 loss: 1.6678
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 3881/30000 (12.9367%),                 avg. length: 728.25,                last time consumption/overall running time: 87.5240s / 39324.7178 s
env0_first_0:                 episode reward: 20.7000,                 loss: -0.0001
env0_second_0:                 episode reward: -20.7000,                 loss: 1.2358
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 3901/30000 (13.0033%),                 avg. length: 728.1,                last time consumption/overall running time: 92.2093s / 39416.9271 s
env0_first_0:                 episode reward: 20.6000,                 loss: 0.0421
env0_second_0:                 episode reward: -20.6000,                 loss: 1.3559
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 3921/30000 (13.0700%),                 avg. length: 728.1,                last time consumption/overall running time: 89.9061s / 39506.8332 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0568
env0_second_0:                 episode reward: -21.0000,                 loss: 3.0894
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 3941/30000 (13.1367%),                 avg. length: 728.0,                last time consumption/overall running time: 91.6776s / 39598.5108 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0680
env0_second_0:                 episode reward: -20.9500,                 loss: 3.6690
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 3961/30000 (13.2033%),                 avg. length: 728.0,                last time consumption/overall running time: 93.8044s / 39692.3152 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0440
env0_second_0:                 episode reward: -21.0000,                 loss: 2.3751
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 3981/30000 (13.2700%),                 avg. length: 746.3,                last time consumption/overall running time: 96.4402s / 39788.7554 s
env0_first_0:                 episode reward: 19.7500,                 loss: 0.1097
env0_second_0:                 episode reward: -19.7500,                 loss: 4.0373
env1_first_0:                 episode reward: 20.4500,                 loss: nan
env1_second_0:                 episode reward: -20.4500,                 loss: nan
Episode: 4001/30000 (13.3367%),                 avg. length: 1300.4,                last time consumption/overall running time: 166.0665s / 39954.8219 s
env0_first_0:                 episode reward: 4.8500,                 loss: 0.5419
env0_second_0:                 episode reward: -4.8500,                 loss: 4.4580
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 4021/30000 (13.4033%),                 avg. length: 1424.05,                last time consumption/overall running time: 173.5205s / 40128.3424 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.2890
env0_second_0:                 episode reward: 13.3000,                 loss: 1.6276
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 4041/30000 (13.4700%),                 avg. length: 1448.85,                last time consumption/overall running time: 179.6006s / 40307.9430 s
env0_first_0:                 episode reward: -13.5000,                 loss: 0.1718
env0_second_0:                 episode reward: 13.5000,                 loss: 0.8499
env1_first_0:                 episode reward: -16.8000,                 loss: nan
env1_second_0:                 episode reward: 16.8000,                 loss: nan
Episode: 4061/30000 (13.5367%),                 avg. length: 1612.25,                last time consumption/overall running time: 199.9540s / 40507.8971 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.1603
env0_second_0:                 episode reward: 13.9500,                 loss: 0.6738
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 4081/30000 (13.6033%),                 avg. length: 1936.55,                last time consumption/overall running time: 237.9425s / 40745.8395 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.1706
env0_second_0:                 episode reward: 10.5500,                 loss: 1.4976
env1_first_0:                 episode reward: -13.4500,                 loss: nan
env1_second_0:                 episode reward: 13.4500,                 loss: nan
Episode: 4101/30000 (13.6700%),                 avg. length: 2016.35,                last time consumption/overall running time: 246.4104s / 40992.2499 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.1795
env0_second_0:                 episode reward: 14.2000,                 loss: 2.7115
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 4121/30000 (13.7367%),                 avg. length: 2176.9,                last time consumption/overall running time: 257.8686s / 41250.1185 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.1500
env0_second_0:                 episode reward: 12.0500,                 loss: 3.7296
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 4141/30000 (13.8033%),                 avg. length: 2173.55,                last time consumption/overall running time: 260.2371s / 41510.3555 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.1355
env0_second_0:                 episode reward: 11.7500,                 loss: 5.9485
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 4161/30000 (13.8700%),                 avg. length: 2262.45,                last time consumption/overall running time: 271.7340s / 41782.0895 s
env0_first_0:                 episode reward: -12.5000,                 loss: 0.1301
env0_second_0:                 episode reward: 12.5000,                 loss: 4.7695
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 4181/30000 (13.9367%),                 avg. length: 2307.35,                last time consumption/overall running time: 272.4773s / 42054.5668 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.1645
env0_second_0:                 episode reward: 10.5500,                 loss: 2.5691
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 4201/30000 (14.0033%),                 avg. length: 2172.25,                last time consumption/overall running time: 255.5361s / 42310.1029 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.1235
env0_second_0:                 episode reward: 13.6500,                 loss: 1.1344
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 4221/30000 (14.0700%),                 avg. length: 2205.25,                last time consumption/overall running time: 266.3631s / 42576.4660 s
env0_first_0:                 episode reward: -12.3500,                 loss: 0.0998
env0_second_0:                 episode reward: 12.3500,                 loss: 3.6721
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 4241/30000 (14.1367%),                 avg. length: 2186.35,                last time consumption/overall running time: 256.7619s / 42833.2278 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.1052
env0_second_0:                 episode reward: 11.7500,                 loss: 1.5752
env1_first_0:                 episode reward: -14.5500,                 loss: nan
env1_second_0:                 episode reward: 14.5500,                 loss: nan
Episode: 4261/30000 (14.2033%),                 avg. length: 2338.95,                last time consumption/overall running time: 269.4594s / 43102.6873 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0718
env0_second_0:                 episode reward: 12.7000,                 loss: 1.8483
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 4281/30000 (14.2700%),                 avg. length: 2126.25,                last time consumption/overall running time: 255.9845s / 43358.6718 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.1229
env0_second_0:                 episode reward: 13.3000,                 loss: 1.6449
env1_first_0:                 episode reward: -12.9500,                 loss: nan
env1_second_0:                 episode reward: 12.9500,                 loss: nan
Episode: 4301/30000 (14.3367%),                 avg. length: 2207.45,                last time consumption/overall running time: 265.6754s / 43624.3472 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.1028
env0_second_0:                 episode reward: 13.2500,                 loss: 2.1513
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 4321/30000 (14.4033%),                 avg. length: 2100.8,                last time consumption/overall running time: 252.1531s / 43876.5003 s
env0_first_0:                 episode reward: -9.3000,                 loss: 0.2423
env0_second_0:                 episode reward: 9.3000,                 loss: 3.7733
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 4341/30000 (14.4700%),                 avg. length: 2151.25,                last time consumption/overall running time: 244.6351s / 44121.1354 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.1071
env0_second_0:                 episode reward: 13.8000,                 loss: 1.3832
env1_first_0:                 episode reward: -12.7000,                 loss: nan
env1_second_0:                 episode reward: 12.7000,                 loss: nan
Episode: 4361/30000 (14.5367%),                 avg. length: 1566.65,                last time consumption/overall running time: 198.1268s / 44319.2622 s
env0_first_0:                 episode reward: 0.4000,                 loss: 0.2420
env0_second_0:                 episode reward: -0.4000,                 loss: 1.2884
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 4381/30000 (14.6033%),                 avg. length: 1449.5,                last time consumption/overall running time: 176.7943s / 44496.0565 s
env0_first_0:                 episode reward: 5.3000,                 loss: 0.4026
env0_second_0:                 episode reward: -5.3000,                 loss: 3.1709
env1_first_0:                 episode reward: 8.7000,                 loss: nan
env1_second_0:                 episode reward: -8.7000,                 loss: nan
Episode: 4401/30000 (14.6700%),                 avg. length: 1783.85,                last time consumption/overall running time: 213.1371s / 44709.1936 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.2495
env0_second_0:                 episode reward: 9.0000,                 loss: 2.0654
env1_first_0:                 episode reward: -9.2000,                 loss: nan
env1_second_0:                 episode reward: 9.2000,                 loss: nan
Episode: 4421/30000 (14.7367%),                 avg. length: 1721.3,                last time consumption/overall running time: 205.9982s / 44915.1918 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.1448
env0_second_0:                 episode reward: 12.5500,                 loss: 2.0656
env1_first_0:                 episode reward: -13.6500,                 loss: nan
env1_second_0:                 episode reward: 13.6500,                 loss: nan
Episode: 4441/30000 (14.8033%),                 avg. length: 1733.3,                last time consumption/overall running time: 211.9088s / 45127.1006 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.1344
env0_second_0:                 episode reward: 13.2000,                 loss: 1.8046
env1_first_0:                 episode reward: -15.3500,                 loss: nan
env1_second_0:                 episode reward: 15.3500,                 loss: nan
Episode: 4461/30000 (14.8700%),                 avg. length: 1684.0,                last time consumption/overall running time: 215.6353s / 45342.7360 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.1660
env0_second_0:                 episode reward: 15.5500,                 loss: 1.9564
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 4481/30000 (14.9367%),                 avg. length: 1542.1,                last time consumption/overall running time: 196.6496s / 45539.3856 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.3081
env0_second_0:                 episode reward: 4.1000,                 loss: 1.5287
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 4501/30000 (15.0033%),                 avg. length: 1969.25,                last time consumption/overall running time: 234.9823s / 45774.3679 s
env0_first_0:                 episode reward: -6.6000,                 loss: 0.2294
env0_second_0:                 episode reward: 6.6000,                 loss: 1.3841
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 4521/30000 (15.0700%),                 avg. length: 1734.05,                last time consumption/overall running time: 223.3089s / 45997.6768 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.1113
env0_second_0:                 episode reward: 13.7500,                 loss: 1.2156
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 4541/30000 (15.1367%),                 avg. length: 1675.95,                last time consumption/overall running time: 213.4134s / 46211.0902 s
env0_first_0:                 episode reward: -17.3000,                 loss: 0.1055
env0_second_0:                 episode reward: 17.3000,                 loss: 1.9691
env1_first_0:                 episode reward: -14.7500,                 loss: nan
env1_second_0:                 episode reward: 14.7500,                 loss: nan
Episode: 4561/30000 (15.2033%),                 avg. length: 1653.65,                last time consumption/overall running time: 205.1301s / 46416.2203 s
env0_first_0:                 episode reward: -16.2000,                 loss: 0.1175
env0_second_0:                 episode reward: 16.2000,                 loss: 2.1728
env1_first_0:                 episode reward: -15.3500,                 loss: nan
env1_second_0:                 episode reward: 15.3500,                 loss: nan
Episode: 4581/30000 (15.2700%),                 avg. length: 1529.9,                last time consumption/overall running time: 200.8391s / 46617.0594 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.4493
env0_second_0:                 episode reward: -0.3500,                 loss: 1.9986
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 4601/30000 (15.3367%),                 avg. length: 1787.4,                last time consumption/overall running time: 220.3826s / 46837.4420 s
env0_first_0:                 episode reward: -12.4000,                 loss: 0.1564
env0_second_0:                 episode reward: 12.4000,                 loss: 1.3108
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 4621/30000 (15.4033%),                 avg. length: 1750.35,                last time consumption/overall running time: 228.4748s / 47065.9168 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.1158
env0_second_0:                 episode reward: 14.6000,                 loss: 0.8264
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 4641/30000 (15.4700%),                 avg. length: 1640.3,                last time consumption/overall running time: 212.8524s / 47278.7691 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.2967
env0_second_0:                 episode reward: 12.3000,                 loss: 1.3664
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 4661/30000 (15.5367%),                 avg. length: 1595.8,                last time consumption/overall running time: 208.5270s / 47487.2962 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.1989
env0_second_0:                 episode reward: 13.1500,                 loss: 1.6915
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 4681/30000 (15.6033%),                 avg. length: 1298.45,                last time consumption/overall running time: 159.5209s / 47646.8170 s
env0_first_0:                 episode reward: 7.6000,                 loss: 0.3084
env0_second_0:                 episode reward: -7.6000,                 loss: 1.4293
env1_first_0:                 episode reward: 7.1000,                 loss: nan
env1_second_0:                 episode reward: -7.1000,                 loss: nan
Episode: 4701/30000 (15.6700%),                 avg. length: 1756.6,                last time consumption/overall running time: 205.1882s / 47852.0052 s
env0_first_0:                 episode reward: -14.4500,                 loss: 0.1455
env0_second_0:                 episode reward: 14.4500,                 loss: 1.5146
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 4721/30000 (15.7367%),                 avg. length: 1236.9,                last time consumption/overall running time: 165.6344s / 48017.6397 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.1939
env0_second_0:                 episode reward: 0.4500,                 loss: 2.1773
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 4741/30000 (15.8033%),                 avg. length: 729.3,                last time consumption/overall running time: 93.5311s / 48111.1707 s
env0_first_0:                 episode reward: 20.5500,                 loss: 0.0747
env0_second_0:                 episode reward: -20.5500,                 loss: 2.4880
env1_first_0:                 episode reward: 20.3000,                 loss: nan
env1_second_0:                 episode reward: -20.3000,                 loss: nan
Episode: 4761/30000 (15.8700%),                 avg. length: 1547.75,                last time consumption/overall running time: 196.8149s / 48307.9857 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.4720
env0_second_0:                 episode reward: -0.6000,                 loss: 2.1701
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 4781/30000 (15.9367%),                 avg. length: 1610.35,                last time consumption/overall running time: 203.9118s / 48511.8974 s
env0_first_0:                 episode reward: -6.1500,                 loss: 0.4088
env0_second_0:                 episode reward: 6.1500,                 loss: 2.2196
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 4801/30000 (16.0033%),                 avg. length: 1623.2,                last time consumption/overall running time: 211.3224s / 48723.2198 s
env0_first_0:                 episode reward: -7.8500,                 loss: 0.3166
env0_second_0:                 episode reward: 7.8500,                 loss: 1.8039
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 4821/30000 (16.0700%),                 avg. length: 1583.35,                last time consumption/overall running time: 205.7094s / 48928.9292 s
env0_first_0:                 episode reward: -9.8500,                 loss: 0.3423
env0_second_0:                 episode reward: 9.8500,                 loss: 1.5753
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 4841/30000 (16.1367%),                 avg. length: 1718.15,                last time consumption/overall running time: 218.3280s / 49147.2572 s
env0_first_0:                 episode reward: -9.4500,                 loss: 0.3248
env0_second_0:                 episode reward: 9.4500,                 loss: 1.3221
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 4861/30000 (16.2033%),                 avg. length: 1613.7,                last time consumption/overall running time: 205.0685s / 49352.3257 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.2675
env0_second_0:                 episode reward: 12.0000,                 loss: 1.1461
env1_first_0:                 episode reward: -11.4500,                 loss: nan
env1_second_0:                 episode reward: 11.4500,                 loss: nan
Episode: 4881/30000 (16.2700%),                 avg. length: 1554.0,                last time consumption/overall running time: 198.6181s / 49550.9439 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.2670
env0_second_0:                 episode reward: 10.7000,                 loss: 0.8439
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 4901/30000 (16.3367%),                 avg. length: 1604.75,                last time consumption/overall running time: 203.8423s / 49754.7861 s
env0_first_0:                 episode reward: -11.7500,                 loss: 0.2911
env0_second_0:                 episode reward: 11.7500,                 loss: 1.0339
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 4921/30000 (16.4033%),                 avg. length: 1333.0,                last time consumption/overall running time: 163.9601s / 49918.7462 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.3515
env0_second_0:                 episode reward: 3.1000,                 loss: 1.1142
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 4941/30000 (16.4700%),                 avg. length: 1009.05,                last time consumption/overall running time: 121.2587s / 50040.0049 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.5243
env0_second_0:                 episode reward: -1.6500,                 loss: 2.1254
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 4961/30000 (16.5367%),                 avg. length: 1596.95,                last time consumption/overall running time: 203.1619s / 50243.1668 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.4208
env0_second_0:                 episode reward: 7.2500,                 loss: 1.6429
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
Episode: 4981/30000 (16.6033%),                 avg. length: 1575.95,                last time consumption/overall running time: 186.7691s / 50429.9359 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.3412
env0_second_0:                 episode reward: 9.6500,                 loss: 1.5263
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 5001/30000 (16.6700%),                 avg. length: 1529.0,                last time consumption/overall running time: 184.4456s / 50614.3815 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.2516
env0_second_0:                 episode reward: 13.3500,                 loss: 1.2002
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 5021/30000 (16.7367%),                 avg. length: 1413.2,                last time consumption/overall running time: 172.0953s / 50786.4768 s
env0_first_0:                 episode reward: -15.9000,                 loss: 0.2387
env0_second_0:                 episode reward: 15.9000,                 loss: 1.0614
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 5041/30000 (16.8033%),                 avg. length: 1327.8,                last time consumption/overall running time: 171.1655s / 50957.6423 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.2413
env0_second_0:                 episode reward: 14.6500,                 loss: 0.8332
env1_first_0:                 episode reward: -17.2500,                 loss: nan
env1_second_0:                 episode reward: 17.2500,                 loss: nan
Episode: 5061/30000 (16.8700%),                 avg. length: 796.4,                last time consumption/overall running time: 106.1080s / 51063.7503 s
env0_first_0:                 episode reward: 16.9500,                 loss: 0.2200
env0_second_0:                 episode reward: -16.9500,                 loss: 0.7650
env1_first_0:                 episode reward: 16.8000,                 loss: nan
env1_second_0:                 episode reward: -16.8000,                 loss: nan
Episode: 5081/30000 (16.9367%),                 avg. length: 1184.6,                last time consumption/overall running time: 153.3504s / 51217.1007 s
env0_first_0:                 episode reward: 6.3000,                 loss: 0.5144
env0_second_0:                 episode reward: -6.3000,                 loss: 1.7868
env1_first_0:                 episode reward: 11.4500,                 loss: nan
env1_second_0:                 episode reward: -11.4500,                 loss: nan
Episode: 5101/30000 (17.0033%),                 avg. length: 1573.95,                last time consumption/overall running time: 195.5401s / 51412.6408 s
env0_first_0:                 episode reward: -6.3000,                 loss: 0.4396
env0_second_0:                 episode reward: 6.3000,                 loss: 1.4316
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 5121/30000 (17.0700%),                 avg. length: 1488.55,                last time consumption/overall running time: 172.7434s / 51585.3842 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.2930
env0_second_0:                 episode reward: 13.3000,                 loss: 1.1816
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 5141/30000 (17.1367%),                 avg. length: 1345.05,                last time consumption/overall running time: 163.6902s / 51749.0744 s
env0_first_0:                 episode reward: -15.1000,                 loss: 0.2666
env0_second_0:                 episode reward: 15.1000,                 loss: 1.2539
env1_first_0:                 episode reward: -16.6000,                 loss: nan
env1_second_0:                 episode reward: 16.6000,                 loss: nan
Episode: 5161/30000 (17.2033%),                 avg. length: 1455.75,                last time consumption/overall running time: 183.2412s / 51932.3156 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.3605
env0_second_0:                 episode reward: 13.2500,                 loss: 1.3501
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 5181/30000 (17.2700%),                 avg. length: 1377.3,                last time consumption/overall running time: 168.4636s / 52100.7792 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.6019
env0_second_0:                 episode reward: 0.2500,                 loss: 1.5770
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 5201/30000 (17.3367%),                 avg. length: 1900.7,                last time consumption/overall running time: 240.5154s / 52341.2947 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.4262
env0_second_0:                 episode reward: 0.7500,                 loss: 1.6710
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 5221/30000 (17.4033%),                 avg. length: 1937.2,                last time consumption/overall running time: 243.6858s / 52584.9805 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.3709
env0_second_0:                 episode reward: -1.0000,                 loss: 1.4407
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 5241/30000 (17.4700%),                 avg. length: 1878.55,                last time consumption/overall running time: 220.3311s / 52805.3115 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.4074
env0_second_0:                 episode reward: -3.1500,                 loss: 1.4767
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 5261/30000 (17.5367%),                 avg. length: 1681.4,                last time consumption/overall running time: 210.4915s / 53015.8030 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.4557
env0_second_0:                 episode reward: -3.6500,                 loss: 1.0085
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 5281/30000 (17.6033%),                 avg. length: 1940.95,                last time consumption/overall running time: 243.1004s / 53258.9035 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.3758
env0_second_0:                 episode reward: 3.3000,                 loss: 0.9067
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 5301/30000 (17.6700%),                 avg. length: 1627.6,                last time consumption/overall running time: 185.7541s / 53444.6576 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.4403
env0_second_0:                 episode reward: 8.4000,                 loss: 1.6674
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 5321/30000 (17.7367%),                 avg. length: 1595.25,                last time consumption/overall running time: 183.6258s / 53628.2834 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.6166
env0_second_0:                 episode reward: 1.7000,                 loss: 2.0578
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 5341/30000 (17.8033%),                 avg. length: 1603.6,                last time consumption/overall running time: 202.4714s / 53830.7547 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.2948
env0_second_0:                 episode reward: 13.2500,                 loss: 1.4832
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 5361/30000 (17.8700%),                 avg. length: 1715.1,                last time consumption/overall running time: 208.3975s / 54039.1522 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.2132
env0_second_0:                 episode reward: 12.6000,                 loss: 0.9040
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 5381/30000 (17.9367%),                 avg. length: 1733.5,                last time consumption/overall running time: 218.5931s / 54257.7453 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.1802
env0_second_0:                 episode reward: 11.6000,                 loss: 1.0037
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 5401/30000 (18.0033%),                 avg. length: 1504.5,                last time consumption/overall running time: 193.0895s / 54450.8348 s
env0_first_0:                 episode reward: -15.3000,                 loss: 0.1523
env0_second_0:                 episode reward: 15.3000,                 loss: 0.9256
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 5421/30000 (18.0700%),                 avg. length: 1497.05,                last time consumption/overall running time: 191.0654s / 54641.9002 s
env0_first_0:                 episode reward: -15.9000,                 loss: 0.1779
env0_second_0:                 episode reward: 15.9000,                 loss: 1.1330
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 5441/30000 (18.1367%),                 avg. length: 740.05,                last time consumption/overall running time: 101.2968s / 54743.1970 s
env0_first_0:                 episode reward: 19.9000,                 loss: 0.1823
env0_second_0:                 episode reward: -19.9000,                 loss: 0.9378
env1_first_0:                 episode reward: 20.2000,                 loss: nan
env1_second_0:                 episode reward: -20.2000,                 loss: nan
Episode: 5461/30000 (18.2033%),                 avg. length: 729.75,                last time consumption/overall running time: 97.5771s / 54840.7741 s
env0_first_0:                 episode reward: 20.4500,                 loss: 0.0117
env0_second_0:                 episode reward: -20.4500,                 loss: 0.4024
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 5481/30000 (18.2700%),                 avg. length: 728.9,                last time consumption/overall running time: 91.3151s / 54932.0892 s
env0_first_0:                 episode reward: 20.6000,                 loss: 0.0402
env0_second_0:                 episode reward: -20.6000,                 loss: 0.4006
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 5501/30000 (18.3367%),                 avg. length: 1373.35,                last time consumption/overall running time: 168.9099s / 55100.9991 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.4434
env0_second_0:                 episode reward: 0.8000,                 loss: 0.5823
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 5521/30000 (18.4033%),                 avg. length: 1734.9,                last time consumption/overall running time: 209.2225s / 55310.2216 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.2376
env0_second_0:                 episode reward: 11.2500,                 loss: 0.4772
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 5541/30000 (18.4700%),                 avg. length: 1694.95,                last time consumption/overall running time: 204.6985s / 55514.9201 s
env0_first_0:                 episode reward: -10.8500,                 loss: 0.1940
env0_second_0:                 episode reward: 10.8500,                 loss: 0.5971
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 5561/30000 (18.5367%),                 avg. length: 1529.35,                last time consumption/overall running time: 199.0742s / 55713.9942 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.1408
env0_second_0:                 episode reward: 15.1500,                 loss: 0.6123
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 5581/30000 (18.6033%),                 avg. length: 1331.7,                last time consumption/overall running time: 173.7001s / 55887.6943 s
env0_first_0:                 episode reward: -5.4500,                 loss: 0.3178
env0_second_0:                 episode reward: 5.4500,                 loss: 1.2364
env1_first_0:                 episode reward: -6.2500,                 loss: nan
env1_second_0:                 episode reward: 6.2500,                 loss: nan
Episode: 5601/30000 (18.6700%),                 avg. length: 1540.95,                last time consumption/overall running time: 200.4510s / 56088.1453 s
env0_first_0:                 episode reward: -9.6500,                 loss: 0.4062
env0_second_0:                 episode reward: 9.6500,                 loss: 1.7052
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 5621/30000 (18.7367%),                 avg. length: 1542.8,                last time consumption/overall running time: 202.4236s / 56290.5688 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.2349
env0_second_0:                 episode reward: 13.4000,                 loss: 0.9225
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 5641/30000 (18.8033%),                 avg. length: 1554.5,                last time consumption/overall running time: 200.4891s / 56491.0580 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.1978
env0_second_0:                 episode reward: 12.7500,                 loss: 0.7730
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 5661/30000 (18.8700%),                 avg. length: 1101.9,                last time consumption/overall running time: 145.4904s / 56636.5483 s
env0_first_0:                 episode reward: 5.2000,                 loss: 0.4270
env0_second_0:                 episode reward: -5.2000,                 loss: 1.9527
env1_first_0:                 episode reward: 4.3000,                 loss: nan
env1_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 5681/30000 (18.9367%),                 avg. length: 899.35,                last time consumption/overall running time: 118.2205s / 56754.7688 s
env0_first_0:                 episode reward: 4.8500,                 loss: 0.3687
env0_second_0:                 episode reward: -4.8500,                 loss: 1.8589
env1_first_0:                 episode reward: 7.5500,                 loss: nan
env1_second_0:                 episode reward: -7.5500,                 loss: nan
Episode: 5701/30000 (19.0033%),                 avg. length: 728.0,                last time consumption/overall running time: 101.1366s / 56855.9054 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0766
env0_second_0:                 episode reward: -20.9500,                 loss: 1.8479
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 5721/30000 (19.0700%),                 avg. length: 728.05,                last time consumption/overall running time: 98.0870s / 56953.9924 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.0774
env0_second_0:                 episode reward: -20.8500,                 loss: 0.9335
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 5741/30000 (19.1367%),                 avg. length: 728.0,                last time consumption/overall running time: 97.2797s / 57051.2720 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.0607
env0_second_0:                 episode reward: -20.8500,                 loss: 0.4225
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 5761/30000 (19.2033%),                 avg. length: 728.25,                last time consumption/overall running time: 99.1630s / 57150.4350 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0144
env0_second_0:                 episode reward: -20.7000,                 loss: 0.3703
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 5781/30000 (19.2700%),                 avg. length: 728.35,                last time consumption/overall running time: 93.6975s / 57244.1326 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0506
env0_second_0:                 episode reward: -20.7500,                 loss: 1.2358
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 5801/30000 (19.3367%),                 avg. length: 1181.5,                last time consumption/overall running time: 154.7403s / 57398.8728 s
env0_first_0:                 episode reward: 10.8500,                 loss: 0.5409
env0_second_0:                 episode reward: -10.8500,                 loss: 4.5092
env1_first_0:                 episode reward: 6.7000,                 loss: nan
env1_second_0:                 episode reward: -6.7000,                 loss: nan
Episode: 5821/30000 (19.4033%),                 avg. length: 1689.65,                last time consumption/overall running time: 206.4301s / 57605.3029 s
env0_first_0:                 episode reward: 2.2500,                 loss: 0.3811
env0_second_0:                 episode reward: -2.2500,                 loss: 3.6920
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 5841/30000 (19.4700%),                 avg. length: 775.35,                last time consumption/overall running time: 103.9880s / 57709.2909 s
env0_first_0:                 episode reward: 9.6000,                 loss: 0.2699
env0_second_0:                 episode reward: -9.6000,                 loss: 1.4059
env1_first_0:                 episode reward: 11.9000,                 loss: nan
env1_second_0:                 episode reward: -11.9000,                 loss: nan
Episode: 5861/30000 (19.5367%),                 avg. length: 800.3,                last time consumption/overall running time: 105.5647s / 57814.8556 s
env0_first_0:                 episode reward: -18.2000,                 loss: 0.2843
env0_second_0:                 episode reward: 18.2000,                 loss: 1.2588
env1_first_0:                 episode reward: -17.3000,                 loss: nan
env1_second_0:                 episode reward: 17.3000,                 loss: nan
Episode: 5881/30000 (19.6033%),                 avg. length: 981.0,                last time consumption/overall running time: 123.2478s / 57938.1034 s
env0_first_0:                 episode reward: -16.5000,                 loss: 0.2988
env0_second_0:                 episode reward: 16.5000,                 loss: 2.1275
env1_first_0:                 episode reward: -16.6000,                 loss: nan
env1_second_0:                 episode reward: 16.6000,                 loss: nan
Episode: 5901/30000 (19.6700%),                 avg. length: 862.05,                last time consumption/overall running time: 114.6724s / 58052.7759 s
env0_first_0:                 episode reward: 14.3000,                 loss: 0.3622
env0_second_0:                 episode reward: -14.3000,                 loss: 2.3073
env1_first_0:                 episode reward: 14.4000,                 loss: nan
env1_second_0:                 episode reward: -14.4000,                 loss: nan
Episode: 5921/30000 (19.7367%),                 avg. length: 1587.55,                last time consumption/overall running time: 189.8096s / 58242.5854 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.4737
env0_second_0:                 episode reward: 3.7000,                 loss: 1.6240
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 5941/30000 (19.8033%),                 avg. length: 1514.0,                last time consumption/overall running time: 196.4610s / 58439.0464 s
env0_first_0:                 episode reward: -13.4500,                 loss: 0.3489
env0_second_0:                 episode reward: 13.4500,                 loss: 1.1711
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 5961/30000 (19.8700%),                 avg. length: 1676.85,                last time consumption/overall running time: 221.4747s / 58660.5211 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.2463
env0_second_0:                 episode reward: 11.1000,                 loss: 1.0112
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 5981/30000 (19.9367%),                 avg. length: 1728.6,                last time consumption/overall running time: 223.0333s / 58883.5544 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.2125
env0_second_0:                 episode reward: 12.7500,                 loss: 0.9834
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 6001/30000 (20.0033%),                 avg. length: 1682.65,                last time consumption/overall running time: 218.7000s / 59102.2544 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.1948
env0_second_0:                 episode reward: 11.4500,                 loss: 0.7810
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 6021/30000 (20.0700%),                 avg. length: 1629.65,                last time consumption/overall running time: 209.1721s / 59311.4265 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.1698
env0_second_0:                 episode reward: 14.2000,                 loss: 0.7161
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 6041/30000 (20.1367%),                 avg. length: 885.2,                last time consumption/overall running time: 118.0263s / 59429.4528 s
env0_first_0:                 episode reward: 13.4500,                 loss: 0.2715
env0_second_0:                 episode reward: -13.4500,                 loss: 2.3336
env1_first_0:                 episode reward: 12.9500,                 loss: nan
env1_second_0:                 episode reward: -12.9500,                 loss: nan
Episode: 6061/30000 (20.2033%),                 avg. length: 728.1,                last time consumption/overall running time: 97.2405s / 59526.6933 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.0257
env0_second_0:                 episode reward: -20.8500,                 loss: 2.4248
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 6081/30000 (20.2700%),                 avg. length: 758.75,                last time consumption/overall running time: 98.7736s / 59625.4669 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.1755
env0_second_0:                 episode reward: -1.6500,                 loss: 1.4167
env1_first_0:                 episode reward: 5.1000,                 loss: nan
env1_second_0:                 episode reward: -5.1000,                 loss: nan
Episode: 6101/30000 (20.3367%),                 avg. length: 797.45,                last time consumption/overall running time: 109.1732s / 59734.6401 s
env0_first_0:                 episode reward: -18.3500,                 loss: 0.1569
env0_second_0:                 episode reward: 18.3500,                 loss: 1.1829
env1_first_0:                 episode reward: -18.5000,                 loss: nan
env1_second_0:                 episode reward: 18.5000,                 loss: nan
Episode: 6121/30000 (20.4033%),                 avg. length: 843.7,                last time consumption/overall running time: 107.6341s / 59842.2742 s
env0_first_0:                 episode reward: -18.1500,                 loss: 0.1661
env0_second_0:                 episode reward: 18.1500,                 loss: 1.0457
env1_first_0:                 episode reward: -18.0500,                 loss: nan
env1_second_0:                 episode reward: 18.0500,                 loss: nan
Episode: 6141/30000 (20.4700%),                 avg. length: 1039.5,                last time consumption/overall running time: 132.7480s / 59975.0223 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.4748
env0_second_0:                 episode reward: 13.3500,                 loss: 2.0419
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 6161/30000 (20.5367%),                 avg. length: 1161.2,                last time consumption/overall running time: 148.7775s / 60123.7997 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.3302
env0_second_0:                 episode reward: 14.3500,                 loss: 1.8161
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 6181/30000 (20.6033%),                 avg. length: 1402.95,                last time consumption/overall running time: 172.9336s / 60296.7334 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.3452
env0_second_0:                 episode reward: 13.7000,                 loss: 1.2861
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 6201/30000 (20.6700%),                 avg. length: 1626.95,                last time consumption/overall running time: 196.7350s / 60493.4684 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.2481
env0_second_0:                 episode reward: 13.1000,                 loss: 0.7644
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 6221/30000 (20.7367%),                 avg. length: 1452.1,                last time consumption/overall running time: 181.6781s / 60675.1465 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.2068
env0_second_0:                 episode reward: 14.1000,                 loss: 0.7609
env1_first_0:                 episode reward: -15.6000,                 loss: nan
env1_second_0:                 episode reward: 15.6000,                 loss: nan
Episode: 6241/30000 (20.8033%),                 avg. length: 1559.6,                last time consumption/overall running time: 192.8650s / 60868.0116 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.3999
env0_second_0:                 episode reward: 11.7000,                 loss: 0.6697
env1_first_0:                 episode reward: -10.0000,                 loss: nan
env1_second_0:                 episode reward: 10.0000,                 loss: nan
Episode: 6261/30000 (20.8700%),                 avg. length: 1648.75,                last time consumption/overall running time: 206.2584s / 61074.2700 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.2620
env0_second_0:                 episode reward: 11.9000,                 loss: 0.5003
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 6281/30000 (20.9367%),                 avg. length: 1643.1,                last time consumption/overall running time: 206.2865s / 61280.5565 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.2254
env0_second_0:                 episode reward: 13.8000,                 loss: 0.7175
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 6301/30000 (21.0033%),                 avg. length: 1648.6,                last time consumption/overall running time: 203.4342s / 61483.9906 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.2538
env0_second_0:                 episode reward: 13.4000,                 loss: 0.6045
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 6321/30000 (21.0700%),                 avg. length: 1552.55,                last time consumption/overall running time: 197.9489s / 61681.9395 s
env0_first_0:                 episode reward: -16.0500,                 loss: 0.1664
env0_second_0:                 episode reward: 16.0500,                 loss: 0.4796
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 6341/30000 (21.1367%),                 avg. length: 1320.05,                last time consumption/overall running time: 169.3221s / 61851.2616 s
env0_first_0:                 episode reward: -18.0000,                 loss: 0.1360
env0_second_0:                 episode reward: 18.0000,                 loss: 0.3760
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 6361/30000 (21.2033%),                 avg. length: 1478.65,                last time consumption/overall running time: 189.3503s / 62040.6118 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.3018
env0_second_0:                 episode reward: 13.9500,                 loss: 0.6034
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 6381/30000 (21.2700%),                 avg. length: 1340.5,                last time consumption/overall running time: 161.5083s / 62202.1201 s
env0_first_0:                 episode reward: 3.1000,                 loss: 0.5645
env0_second_0:                 episode reward: -3.1000,                 loss: 1.6655
env1_first_0:                 episode reward: 5.6000,                 loss: nan
env1_second_0:                 episode reward: -5.6000,                 loss: nan
Episode: 6401/30000 (21.3367%),                 avg. length: 1332.6,                last time consumption/overall running time: 157.0757s / 62359.1957 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.3125
env0_second_0:                 episode reward: 13.8500,                 loss: 0.9434
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 6421/30000 (21.4033%),                 avg. length: 2284.8,                last time consumption/overall running time: 245.8988s / 62605.0946 s
env0_first_0:                 episode reward: -8.8000,                 loss: 0.2044
env0_second_0:                 episode reward: 8.8000,                 loss: 0.5420
env1_first_0:                 episode reward: -7.3000,                 loss: nan
env1_second_0:                 episode reward: 7.3000,                 loss: nan
Episode: 6441/30000 (21.4700%),                 avg. length: 1445.25,                last time consumption/overall running time: 185.5945s / 62790.6891 s
env0_first_0:                 episode reward: -14.5500,                 loss: 0.2089
env0_second_0:                 episode reward: 14.5500,                 loss: 0.5835
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 6461/30000 (21.5367%),                 avg. length: 1280.6,                last time consumption/overall running time: 160.0699s / 62950.7590 s
env0_first_0:                 episode reward: -17.6500,                 loss: 0.1260
env0_second_0:                 episode reward: 17.6500,                 loss: 0.5230
env1_first_0:                 episode reward: -16.6000,                 loss: nan
env1_second_0:                 episode reward: 16.6000,                 loss: nan
Episode: 6481/30000 (21.6033%),                 avg. length: 1325.6,                last time consumption/overall running time: 161.1481s / 63111.9072 s
env0_first_0:                 episode reward: -17.1000,                 loss: 0.1684
env0_second_0:                 episode reward: 17.1000,                 loss: 0.4722
env1_first_0:                 episode reward: -14.1000,                 loss: nan
env1_second_0:                 episode reward: 14.1000,                 loss: nan
Episode: 6501/30000 (21.6700%),                 avg. length: 1478.3,                last time consumption/overall running time: 188.9227s / 63300.8299 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.1289
env0_second_0:                 episode reward: 14.6500,                 loss: 0.4732
env1_first_0:                 episode reward: -15.8000,                 loss: nan
env1_second_0:                 episode reward: 15.8000,                 loss: nan
Episode: 6521/30000 (21.7367%),                 avg. length: 1532.85,                last time consumption/overall running time: 195.8285s / 63496.6583 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.1506
env0_second_0:                 episode reward: 12.8000,                 loss: 0.4730
env1_first_0:                 episode reward: -16.3500,                 loss: nan
env1_second_0:                 episode reward: 16.3500,                 loss: nan
Episode: 6541/30000 (21.8033%),                 avg. length: 1238.7,                last time consumption/overall running time: 151.9062s / 63648.5646 s
env0_first_0:                 episode reward: -15.3000,                 loss: 0.2111
env0_second_0:                 episode reward: 15.3000,                 loss: 0.4257
env1_first_0:                 episode reward: -14.2000,                 loss: nan
env1_second_0:                 episode reward: 14.2000,                 loss: nan
Episode: 6561/30000 (21.8700%),                 avg. length: 1557.65,                last time consumption/overall running time: 200.3081s / 63848.8727 s
env0_first_0:                 episode reward: -14.3000,                 loss: 0.1863
env0_second_0:                 episode reward: 14.3000,                 loss: 0.4809
env1_first_0:                 episode reward: -15.2500,                 loss: nan
env1_second_0:                 episode reward: 15.2500,                 loss: nan
Episode: 6581/30000 (21.9367%),                 avg. length: 1576.8,                last time consumption/overall running time: 198.1201s / 64046.9928 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.2547
env0_second_0:                 episode reward: 13.0500,                 loss: 0.6358
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 6601/30000 (22.0033%),                 avg. length: 1567.55,                last time consumption/overall running time: 197.3750s / 64244.3678 s
env0_first_0:                 episode reward: -15.3500,                 loss: 0.1704
env0_second_0:                 episode reward: 15.3500,                 loss: 0.5511
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 6621/30000 (22.0700%),                 avg. length: 1676.25,                last time consumption/overall running time: 201.3772s / 64445.7450 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.1117
env0_second_0:                 episode reward: 14.9500,                 loss: 0.4297
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 6641/30000 (22.1367%),                 avg. length: 1530.95,                last time consumption/overall running time: 189.3186s / 64635.0636 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.3367
env0_second_0:                 episode reward: 2.1500,                 loss: 0.8098
env1_first_0:                 episode reward: -5.8000,                 loss: nan
env1_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 6661/30000 (22.2033%),                 avg. length: 1579.25,                last time consumption/overall running time: 200.8587s / 64835.9223 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.1407
env0_second_0:                 episode reward: 14.8500,                 loss: 0.6949
env1_first_0:                 episode reward: -15.5500,                 loss: nan
env1_second_0:                 episode reward: 15.5500,                 loss: nan
Episode: 6681/30000 (22.2700%),                 avg. length: 1547.7,                last time consumption/overall running time: 194.4151s / 65030.3373 s
env0_first_0:                 episode reward: -15.7000,                 loss: 0.1185
env0_second_0:                 episode reward: 15.7000,                 loss: 0.8840
env1_first_0:                 episode reward: -16.9500,                 loss: nan
env1_second_0:                 episode reward: 16.9500,                 loss: nan
Episode: 6701/30000 (22.3367%),                 avg. length: 1743.0,                last time consumption/overall running time: 211.5740s / 65241.9114 s
env0_first_0:                 episode reward: -13.1500,                 loss: 0.1547
env0_second_0:                 episode reward: 13.1500,                 loss: 0.8832
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 6721/30000 (22.4033%),                 avg. length: 1612.1,                last time consumption/overall running time: 205.2900s / 65447.2014 s
env0_first_0:                 episode reward: -14.6500,                 loss: 0.1415
env0_second_0:                 episode reward: 14.6500,                 loss: 0.7392
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 6741/30000 (22.4700%),                 avg. length: 1775.1,                last time consumption/overall running time: 209.5112s / 65656.7125 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.1839
env0_second_0:                 episode reward: 11.4500,                 loss: 0.8928
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 6761/30000 (22.5367%),                 avg. length: 1587.35,                last time consumption/overall running time: 193.0898s / 65849.8023 s
env0_first_0:                 episode reward: -15.9500,                 loss: 0.1183
env0_second_0:                 episode reward: 15.9500,                 loss: 1.0077
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 6781/30000 (22.6033%),                 avg. length: 1391.8,                last time consumption/overall running time: 177.8871s / 66027.6894 s
env0_first_0:                 episode reward: -16.1500,                 loss: 0.0880
env0_second_0:                 episode reward: 16.1500,                 loss: 0.9730
env1_first_0:                 episode reward: -18.4000,                 loss: nan
env1_second_0:                 episode reward: 18.4000,                 loss: nan
Episode: 6801/30000 (22.6700%),                 avg. length: 1503.9,                last time consumption/overall running time: 191.9934s / 66219.6828 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.1362
env0_second_0:                 episode reward: 14.7500,                 loss: 1.0700
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 6821/30000 (22.7367%),                 avg. length: 914.05,                last time consumption/overall running time: 119.7587s / 66339.4415 s
env0_first_0:                 episode reward: 14.5500,                 loss: 0.3507
env0_second_0:                 episode reward: -14.5500,                 loss: 1.1827
env1_first_0:                 episode reward: 15.6000,                 loss: nan
env1_second_0:                 episode reward: -15.6000,                 loss: nan
Episode: 6841/30000 (22.8033%),                 avg. length: 849.55,                last time consumption/overall running time: 109.0872s / 66448.5287 s
env0_first_0:                 episode reward: 15.6500,                 loss: 0.2193
env0_second_0:                 episode reward: -15.6500,                 loss: 0.7664
env1_first_0:                 episode reward: 18.4000,                 loss: nan
env1_second_0:                 episode reward: -18.4000,                 loss: nan
Episode: 6861/30000 (22.8700%),                 avg. length: 1779.95,                last time consumption/overall running time: 224.4830s / 66673.0117 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.4042
env0_second_0:                 episode reward: -0.0500,                 loss: 1.4954
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 6881/30000 (22.9367%),                 avg. length: 1822.9,                last time consumption/overall running time: 221.4159s / 66894.4276 s
env0_first_0:                 episode reward: -7.5000,                 loss: 0.2459
env0_second_0:                 episode reward: 7.5000,                 loss: 1.4849
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 6901/30000 (23.0033%),                 avg. length: 1677.7,                last time consumption/overall running time: 204.9034s / 67099.3310 s
env0_first_0:                 episode reward: -13.3000,                 loss: 0.1943
env0_second_0:                 episode reward: 13.3000,                 loss: 1.3727
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 6921/30000 (23.0700%),                 avg. length: 1844.35,                last time consumption/overall running time: 234.6177s / 67333.9487 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.1809
env0_second_0:                 episode reward: 12.2000,                 loss: 2.2441
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 6941/30000 (23.1367%),                 avg. length: 1855.7,                last time consumption/overall running time: 236.8260s / 67570.7747 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.3096
env0_second_0:                 episode reward: -1.0000,                 loss: 2.1498
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6961/30000 (23.2033%),                 avg. length: 1709.1,                last time consumption/overall running time: 210.7129s / 67781.4876 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.1480
env0_second_0:                 episode reward: 15.2000,                 loss: 1.6611
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 6981/30000 (23.2700%),                 avg. length: 1768.95,                last time consumption/overall running time: 222.3261s / 68003.8137 s
env0_first_0:                 episode reward: -16.1000,                 loss: 0.1480
env0_second_0:                 episode reward: 16.1000,                 loss: 1.5899
env1_first_0:                 episode reward: -15.8500,                 loss: nan
env1_second_0:                 episode reward: 15.8500,                 loss: nan
Episode: 7001/30000 (23.3367%),                 avg. length: 1875.1,                last time consumption/overall running time: 233.3093s / 68237.1229 s
env0_first_0:                 episode reward: -15.4500,                 loss: 0.1617
env0_second_0:                 episode reward: 15.4500,                 loss: 1.6069
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 7021/30000 (23.4033%),                 avg. length: 1828.7,                last time consumption/overall running time: 228.5633s / 68465.6862 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.1378
env0_second_0:                 episode reward: 15.5500,                 loss: 1.4550
env1_first_0:                 episode reward: -16.4500,                 loss: nan
env1_second_0:                 episode reward: 16.4500,                 loss: nan
Episode: 7041/30000 (23.4700%),                 avg. length: 1985.75,                last time consumption/overall running time: 250.4148s / 68716.1009 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.1413
env0_second_0:                 episode reward: 15.5500,                 loss: 1.4207
env1_first_0:                 episode reward: -14.0500,                 loss: nan
env1_second_0:                 episode reward: 14.0500,                 loss: nan
Episode: 7061/30000 (23.5367%),                 avg. length: 1902.25,                last time consumption/overall running time: 239.8043s / 68955.9052 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.1458
env0_second_0:                 episode reward: 14.7500,                 loss: 3.2147
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 7081/30000 (23.6033%),                 avg. length: 2299.35,                last time consumption/overall running time: 272.0371s / 69227.9423 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.1275
env0_second_0:                 episode reward: 13.4000,                 loss: 1.5004
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 7101/30000 (23.6700%),                 avg. length: 2373.15,                last time consumption/overall running time: 267.1321s / 69495.0744 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.1456
env0_second_0:                 episode reward: 11.8000,                 loss: 1.6290
env1_first_0:                 episode reward: -13.2500,                 loss: nan
env1_second_0:                 episode reward: 13.2500,                 loss: nan
Episode: 7121/30000 (23.7367%),                 avg. length: 2447.75,                last time consumption/overall running time: 295.6568s / 69790.7311 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.1180
env0_second_0:                 episode reward: 13.3500,                 loss: 1.4299
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 7141/30000 (23.8033%),                 avg. length: 2246.0,                last time consumption/overall running time: 282.3474s / 70073.0785 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.0907
env0_second_0:                 episode reward: 14.9000,                 loss: 1.4852
env1_first_0:                 episode reward: -14.6000,                 loss: nan
env1_second_0:                 episode reward: 14.6000,                 loss: nan
Episode: 7161/30000 (23.8700%),                 avg. length: 2131.0,                last time consumption/overall running time: 263.6301s / 70336.7086 s
env0_first_0:                 episode reward: -7.9000,                 loss: 0.3341
env0_second_0:                 episode reward: 7.9000,                 loss: 2.3128
env1_first_0:                 episode reward: -8.5000,                 loss: nan
env1_second_0:                 episode reward: 8.5000,                 loss: nan
Episode: 7181/30000 (23.9367%),                 avg. length: 2151.8,                last time consumption/overall running time: 262.5241s / 70599.2327 s
env0_first_0:                 episode reward: -15.5000,                 loss: 0.0953
env0_second_0:                 episode reward: 15.5000,                 loss: 1.5243
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 7201/30000 (24.0033%),                 avg. length: 2045.85,                last time consumption/overall running time: 259.6999s / 70858.9325 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.3318
env0_second_0:                 episode reward: 9.1000,                 loss: 1.9142
env1_first_0:                 episode reward: -8.2500,                 loss: nan
env1_second_0:                 episode reward: 8.2500,                 loss: nan
Episode: 7221/30000 (24.0700%),                 avg. length: 2401.9,                last time consumption/overall running time: 294.0601s / 71152.9926 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.1300
env0_second_0:                 episode reward: 13.3500,                 loss: 1.5435
env1_first_0:                 episode reward: -12.3500,                 loss: nan
env1_second_0:                 episode reward: 12.3500,                 loss: nan
Episode: 7241/30000 (24.1367%),                 avg. length: 2124.7,                last time consumption/overall running time: 274.6558s / 71427.6484 s
env0_first_0:                 episode reward: -15.4500,                 loss: 0.1161
env0_second_0:                 episode reward: 15.4500,                 loss: 1.3883
env1_first_0:                 episode reward: -12.9000,                 loss: nan
env1_second_0:                 episode reward: 12.9000,                 loss: nan
Episode: 7261/30000 (24.2033%),                 avg. length: 2351.55,                last time consumption/overall running time: 295.1290s / 71722.7774 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.1217
env0_second_0:                 episode reward: 10.9500,                 loss: 1.3718
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 7281/30000 (24.2700%),                 avg. length: 2452.2,                last time consumption/overall running time: 306.5970s / 72029.3744 s
env0_first_0:                 episode reward: -12.7500,                 loss: 0.1092
env0_second_0:                 episode reward: 12.7500,                 loss: 1.3423
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 7301/30000 (24.3367%),                 avg. length: 2127.75,                last time consumption/overall running time: 264.5722s / 72293.9466 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.1696
env0_second_0:                 episode reward: 12.0500,                 loss: 1.6703
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 7321/30000 (24.4033%),                 avg. length: 2464.9,                last time consumption/overall running time: 309.6771s / 72603.6237 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.1046
env0_second_0:                 episode reward: 13.8500,                 loss: 2.3850
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 7341/30000 (24.4700%),                 avg. length: 2454.85,                last time consumption/overall running time: 306.9627s / 72910.5864 s
env0_first_0:                 episode reward: -14.2500,                 loss: 0.0665
env0_second_0:                 episode reward: 14.2500,                 loss: 2.1025
env1_first_0:                 episode reward: -15.0500,                 loss: nan
env1_second_0:                 episode reward: 15.0500,                 loss: nan
Episode: 7361/30000 (24.5367%),                 avg. length: 2730.95,                last time consumption/overall running time: 321.8949s / 73232.4812 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.0628
env0_second_0:                 episode reward: 13.1000,                 loss: 2.4977
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 7381/30000 (24.6033%),                 avg. length: 2593.1,                last time consumption/overall running time: 324.0455s / 73556.5267 s
env0_first_0:                 episode reward: -14.2500,                 loss: 0.0795
env0_second_0:                 episode reward: 14.2500,                 loss: 1.6167
env1_first_0:                 episode reward: -11.4000,                 loss: nan
env1_second_0:                 episode reward: 11.4000,                 loss: nan
Episode: 7401/30000 (24.6700%),                 avg. length: 2562.05,                last time consumption/overall running time: 321.2030s / 73877.7297 s
env0_first_0:                 episode reward: -15.7000,                 loss: 0.0610
env0_second_0:                 episode reward: 15.7000,                 loss: 1.2987
env1_first_0:                 episode reward: -14.5500,                 loss: nan
env1_second_0:                 episode reward: 14.5500,                 loss: nan
Episode: 7421/30000 (24.7367%),                 avg. length: 2553.95,                last time consumption/overall running time: 321.9980s / 74199.7277 s
env0_first_0:                 episode reward: -14.1500,                 loss: 0.0844
env0_second_0:                 episode reward: 14.1500,                 loss: 1.3700
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 7441/30000 (24.8033%),                 avg. length: 2734.6,                last time consumption/overall running time: 342.6780s / 74542.4057 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.1044
env0_second_0:                 episode reward: 13.7500,                 loss: 1.3747
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 7461/30000 (24.8700%),                 avg. length: 2645.35,                last time consumption/overall running time: 320.8783s / 74863.2840 s
env0_first_0:                 episode reward: -12.3500,                 loss: 0.1207
env0_second_0:                 episode reward: 12.3500,                 loss: 1.4781
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 7481/30000 (24.9367%),                 avg. length: 3009.45,                last time consumption/overall running time: 320.6155s / 75183.8995 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.1046
env0_second_0:                 episode reward: 9.9500,                 loss: 1.3095
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 7501/30000 (25.0033%),                 avg. length: 2847.85,                last time consumption/overall running time: 334.8794s / 75518.7789 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.0963
env0_second_0:                 episode reward: 13.5500,                 loss: 1.2953
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 7521/30000 (25.0700%),                 avg. length: 2556.4,                last time consumption/overall running time: 320.2569s / 75839.0359 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.1161
env0_second_0:                 episode reward: 12.9500,                 loss: 1.3461
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 7541/30000 (25.1367%),                 avg. length: 2423.95,                last time consumption/overall running time: 304.3490s / 76143.3848 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.1214
env0_second_0:                 episode reward: 13.7500,                 loss: 1.3859
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 7561/30000 (25.2033%),                 avg. length: 2660.45,                last time consumption/overall running time: 326.8017s / 76470.1866 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.0740
env0_second_0:                 episode reward: 14.2000,                 loss: 1.3092
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 7581/30000 (25.2700%),                 avg. length: 2655.8,                last time consumption/overall running time: 320.0874s / 76790.2740 s
env0_first_0:                 episode reward: -14.2000,                 loss: 0.1123
env0_second_0:                 episode reward: 14.2000,                 loss: 1.9341
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 7601/30000 (25.3367%),                 avg. length: 2419.0,                last time consumption/overall running time: 302.5761s / 77092.8501 s
env0_first_0:                 episode reward: -11.2500,                 loss: 0.3162
env0_second_0:                 episode reward: 11.2500,                 loss: 2.5340
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 7621/30000 (25.4033%),                 avg. length: 2498.2,                last time consumption/overall running time: 314.1079s / 77406.9579 s
env0_first_0:                 episode reward: -14.5000,                 loss: 0.1245
env0_second_0:                 episode reward: 14.5000,                 loss: 2.1887
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 7641/30000 (25.4700%),                 avg. length: 3007.5,                last time consumption/overall running time: 375.5365s / 77782.4944 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.0852
env0_second_0:                 episode reward: 13.2500,                 loss: 1.7856
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 7661/30000 (25.5367%),                 avg. length: 2902.25,                last time consumption/overall running time: 359.4487s / 78141.9432 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.0867
env0_second_0:                 episode reward: 15.0000,                 loss: 1.7519
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 7681/30000 (25.6033%),                 avg. length: 2647.7,                last time consumption/overall running time: 333.8767s / 78475.8199 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.1194
env0_second_0:                 episode reward: 12.6500,                 loss: 1.9239
env1_first_0:                 episode reward: -13.9000,                 loss: nan
env1_second_0:                 episode reward: 13.9000,                 loss: nan
Episode: 7701/30000 (25.6700%),                 avg. length: 3105.55,                last time consumption/overall running time: 390.0703s / 78865.8902 s
env0_first_0:                 episode reward: -8.7500,                 loss: 0.1254
env0_second_0:                 episode reward: 8.7500,                 loss: 2.0089
env1_first_0:                 episode reward: -8.8000,                 loss: nan
env1_second_0:                 episode reward: 8.8000,                 loss: nan
Episode: 7721/30000 (25.7367%),                 avg. length: 2889.25,                last time consumption/overall running time: 364.9317s / 79230.8219 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.1294
env0_second_0:                 episode reward: 12.6500,                 loss: 1.7811
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 7741/30000 (25.8033%),                 avg. length: 3047.4,                last time consumption/overall running time: 380.0071s / 79610.8290 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.1252
env0_second_0:                 episode reward: 10.6000,                 loss: 1.5752
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 7761/30000 (25.8700%),                 avg. length: 2040.05,                last time consumption/overall running time: 256.2598s / 79867.0888 s
env0_first_0:                 episode reward: 7.3000,                 loss: 0.4634
env0_second_0:                 episode reward: -7.3000,                 loss: 2.0959
env1_first_0:                 episode reward: 4.8000,                 loss: nan
env1_second_0:                 episode reward: -4.8000,                 loss: nan
Episode: 7781/30000 (25.9367%),                 avg. length: 2726.05,                last time consumption/overall running time: 330.1381s / 80197.2269 s
env0_first_0:                 episode reward: -9.9500,                 loss: 0.1578
env0_second_0:                 episode reward: 9.9500,                 loss: 1.6365
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 7801/30000 (26.0033%),                 avg. length: 2559.9,                last time consumption/overall running time: 321.0769s / 80518.3038 s
env0_first_0:                 episode reward: -9.6000,                 loss: 0.1531
env0_second_0:                 episode reward: 9.6000,                 loss: 1.6478
env1_first_0:                 episode reward: -10.4000,                 loss: nan
env1_second_0:                 episode reward: 10.4000,                 loss: nan
Episode: 7821/30000 (26.0700%),                 avg. length: 2810.2,                last time consumption/overall running time: 344.2292s / 80862.5330 s
env0_first_0:                 episode reward: -9.6000,                 loss: 0.1408
env0_second_0:                 episode reward: 9.6000,                 loss: 1.6134
env1_first_0:                 episode reward: -8.1500,                 loss: nan
env1_second_0:                 episode reward: 8.1500,                 loss: nan
Episode: 7841/30000 (26.1367%),                 avg. length: 2716.1,                last time consumption/overall running time: 306.1294s / 81168.6623 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.1018
env0_second_0:                 episode reward: 12.6000,                 loss: 1.4908
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 7861/30000 (26.2033%),                 avg. length: 2921.95,                last time consumption/overall running time: 351.1675s / 81519.8298 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.1383
env0_second_0:                 episode reward: 13.0000,                 loss: 1.4696
env1_first_0:                 episode reward: -9.8500,                 loss: nan
env1_second_0:                 episode reward: 9.8500,                 loss: nan
Episode: 7881/30000 (26.2700%),                 avg. length: 2664.4,                last time consumption/overall running time: 318.0437s / 81837.8735 s
env0_first_0:                 episode reward: -11.8500,                 loss: 0.1391
env0_second_0:                 episode reward: 11.8500,                 loss: 1.5197
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 7901/30000 (26.3367%),                 avg. length: 2693.75,                last time consumption/overall running time: 319.2835s / 82157.1570 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.1507
env0_second_0:                 episode reward: 10.6000,                 loss: 1.5862
env1_first_0:                 episode reward: -11.2000,                 loss: nan
env1_second_0:                 episode reward: 11.2000,                 loss: nan
Episode: 7921/30000 (26.4033%),                 avg. length: 2493.2,                last time consumption/overall running time: 287.7284s / 82444.8853 s
env0_first_0:                 episode reward: -8.5000,                 loss: 0.3696
env0_second_0:                 episode reward: 8.5000,                 loss: 2.0030
env1_first_0:                 episode reward: -8.6000,                 loss: nan
env1_second_0:                 episode reward: 8.6000,                 loss: nan
Episode: 7941/30000 (26.4700%),                 avg. length: 2673.6,                last time consumption/overall running time: 334.9476s / 82779.8329 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.1200
env0_second_0:                 episode reward: 10.9500,                 loss: 1.7686
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 7961/30000 (26.5367%),                 avg. length: 3094.9,                last time consumption/overall running time: 381.5223s / 83161.3552 s
env0_first_0:                 episode reward: -9.2500,                 loss: 0.0899
env0_second_0:                 episode reward: 9.2500,                 loss: 1.0192
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 7981/30000 (26.6033%),                 avg. length: 3184.85,                last time consumption/overall running time: 391.9076s / 83553.2629 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.0939
env0_second_0:                 episode reward: 8.9000,                 loss: 1.1089
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 8001/30000 (26.6700%),                 avg. length: 2966.15,                last time consumption/overall running time: 371.2012s / 83924.4640 s
env0_first_0:                 episode reward: -8.7500,                 loss: 0.1145
env0_second_0:                 episode reward: 8.7500,                 loss: 1.1866
env1_first_0:                 episode reward: -10.4500,                 loss: nan
env1_second_0:                 episode reward: 10.4500,                 loss: nan
Episode: 8021/30000 (26.7367%),                 avg. length: 3050.15,                last time consumption/overall running time: 378.8437s / 84303.3077 s
env0_first_0:                 episode reward: -10.8000,                 loss: 0.1082
env0_second_0:                 episode reward: 10.8000,                 loss: 1.0873
env1_first_0:                 episode reward: -9.2500,                 loss: nan
env1_second_0:                 episode reward: 9.2500,                 loss: nan
Episode: 8041/30000 (26.8033%),                 avg. length: 2850.05,                last time consumption/overall running time: 349.7313s / 84653.0390 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.1102
env0_second_0:                 episode reward: 12.0500,                 loss: 0.8716
env1_first_0:                 episode reward: -13.0500,                 loss: nan
env1_second_0:                 episode reward: 13.0500,                 loss: nan
Episode: 8061/30000 (26.8700%),                 avg. length: 2978.45,                last time consumption/overall running time: 374.4552s / 85027.4941 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.1021
env0_second_0:                 episode reward: 12.7000,                 loss: 1.0751
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 8081/30000 (26.9367%),                 avg. length: 2963.55,                last time consumption/overall running time: 371.6035s / 85399.0976 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.1228
env0_second_0:                 episode reward: 12.0000,                 loss: 1.0541
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 8101/30000 (27.0033%),                 avg. length: 3371.5,                last time consumption/overall running time: 420.3142s / 85819.4118 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.1235
env0_second_0:                 episode reward: 9.1000,                 loss: 0.9279
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 8121/30000 (27.0700%),                 avg. length: 3157.3,                last time consumption/overall running time: 390.4244s / 86209.8362 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.0892
env0_second_0:                 episode reward: 11.9000,                 loss: 1.1643
env1_first_0:                 episode reward: -9.5000,                 loss: nan
env1_second_0:                 episode reward: 9.5000,                 loss: nan
Episode: 8141/30000 (27.1367%),                 avg. length: 3270.2,                last time consumption/overall running time: 378.4815s / 86588.3177 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.0976
env0_second_0:                 episode reward: 9.3500,                 loss: 1.2558
env1_first_0:                 episode reward: -10.7500,                 loss: nan
env1_second_0:                 episode reward: 10.7500,                 loss: nan
Episode: 8161/30000 (27.2033%),                 avg. length: 3249.4,                last time consumption/overall running time: 386.6473s / 86974.9650 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.1250
env0_second_0:                 episode reward: 8.1500,                 loss: 1.0506
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 8181/30000 (27.2700%),                 avg. length: 3357.95,                last time consumption/overall running time: 416.5000s / 87391.4650 s
env0_first_0:                 episode reward: -8.4000,                 loss: 0.1109
env0_second_0:                 episode reward: 8.4000,                 loss: 1.0274
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 8201/30000 (27.3367%),                 avg. length: 3400.75,                last time consumption/overall running time: 424.6521s / 87816.1171 s
env0_first_0:                 episode reward: -8.3000,                 loss: 0.1169
env0_second_0:                 episode reward: 8.3000,                 loss: 0.9715
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 8221/30000 (27.4033%),                 avg. length: 3257.65,                last time consumption/overall running time: 410.6360s / 88226.7531 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.0961
env0_second_0:                 episode reward: 10.7500,                 loss: 0.8451
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 8241/30000 (27.4700%),                 avg. length: 3336.15,                last time consumption/overall running time: 416.0464s / 88642.7995 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.0785
env0_second_0:                 episode reward: 11.1000,                 loss: 0.8273
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 8261/30000 (27.5367%),                 avg. length: 3164.8,                last time consumption/overall running time: 395.5310s / 89038.3305 s
env0_first_0:                 episode reward: -8.9500,                 loss: 0.1314
env0_second_0:                 episode reward: 8.9500,                 loss: 0.9364
env1_first_0:                 episode reward: -11.5000,                 loss: nan
env1_second_0:                 episode reward: 11.5000,                 loss: nan
Episode: 8281/30000 (27.6033%),                 avg. length: 3069.65,                last time consumption/overall running time: 384.9849s / 89423.3154 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.0836
env0_second_0:                 episode reward: 11.0500,                 loss: 1.1425
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 8301/30000 (27.6700%),                 avg. length: 3234.05,                last time consumption/overall running time: 389.7025s / 89813.0179 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.1180
env0_second_0:                 episode reward: 9.1500,                 loss: 1.3009
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 8321/30000 (27.7367%),                 avg. length: 3379.35,                last time consumption/overall running time: 421.8340s / 90234.8519 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.1214
env0_second_0:                 episode reward: 11.4000,                 loss: 2.0375
env1_first_0:                 episode reward: -10.5500,                 loss: nan
env1_second_0:                 episode reward: 10.5500,                 loss: nan
Episode: 8341/30000 (27.8033%),                 avg. length: 1024.6,                last time consumption/overall running time: 133.2073s / 90368.0592 s
env0_first_0:                 episode reward: 15.5500,                 loss: 0.4055
env0_second_0:                 episode reward: -15.5500,                 loss: 2.7946
env1_first_0:                 episode reward: 16.9000,                 loss: nan
env1_second_0:                 episode reward: -16.9000,                 loss: nan
Episode: 8361/30000 (27.8700%),                 avg. length: 751.2,                last time consumption/overall running time: 95.9707s / 90464.0299 s
env0_first_0:                 episode reward: 14.9500,                 loss: 0.1957
env0_second_0:                 episode reward: -14.9500,                 loss: 1.4543
env1_first_0:                 episode reward: 18.7500,                 loss: nan
env1_second_0:                 episode reward: -18.7500,                 loss: nan
Episode: 8381/30000 (27.9367%),                 avg. length: 2016.9,                last time consumption/overall running time: 237.9183s / 90701.9482 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.5141
env0_second_0:                 episode reward: 2.3000,                 loss: 2.4336
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 8401/30000 (28.0033%),                 avg. length: 2536.6,                last time consumption/overall running time: 318.2992s / 91020.2474 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.2424
env0_second_0:                 episode reward: 2.7000,                 loss: 1.5785
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 8421/30000 (28.0700%),                 avg. length: 2672.25,                last time consumption/overall running time: 334.2251s / 91354.4725 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.1918
env0_second_0:                 episode reward: 4.5000,                 loss: 2.6744
env1_first_0:                 episode reward: -4.8000,                 loss: nan
env1_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 8441/30000 (28.1367%),                 avg. length: 2457.6,                last time consumption/overall running time: 304.5196s / 91658.9921 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.2214
env0_second_0:                 episode reward: 6.4500,                 loss: 2.1780
env1_first_0:                 episode reward: -4.8500,                 loss: nan
env1_second_0:                 episode reward: 4.8500,                 loss: nan
Episode: 8461/30000 (28.2033%),                 avg. length: 2366.5,                last time consumption/overall running time: 290.0849s / 91949.0770 s
env0_first_0:                 episode reward: -7.1000,                 loss: 0.2015
env0_second_0:                 episode reward: 7.1000,                 loss: 1.4117
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 8481/30000 (28.2700%),                 avg. length: 2461.1,                last time consumption/overall running time: 299.0759s / 92248.1530 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.1684
env0_second_0:                 episode reward: 10.2500,                 loss: 1.1542
env1_first_0:                 episode reward: -11.0500,                 loss: nan
env1_second_0:                 episode reward: 11.0500,                 loss: nan
Episode: 8501/30000 (28.3367%),                 avg. length: 2401.35,                last time consumption/overall running time: 303.5096s / 92551.6626 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.2121
env0_second_0:                 episode reward: 11.1500,                 loss: 1.1374
env1_first_0:                 episode reward: -6.4500,                 loss: nan
env1_second_0:                 episode reward: 6.4500,                 loss: nan
Episode: 8521/30000 (28.4033%),                 avg. length: 2262.8,                last time consumption/overall running time: 284.3100s / 92835.9726 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.3593
env0_second_0:                 episode reward: 5.7000,                 loss: 1.3939
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 8541/30000 (28.4700%),                 avg. length: 1741.15,                last time consumption/overall running time: 220.0104s / 93055.9829 s
env0_first_0:                 episode reward: 8.9000,                 loss: 0.2997
env0_second_0:                 episode reward: -8.9000,                 loss: 1.5369
env1_first_0:                 episode reward: 8.5500,                 loss: nan
env1_second_0:                 episode reward: -8.5500,                 loss: nan
Episode: 8561/30000 (28.5367%),                 avg. length: 791.2,                last time consumption/overall running time: 105.0596s / 93161.0425 s
env0_first_0:                 episode reward: 19.3500,                 loss: 0.2828
env0_second_0:                 episode reward: -19.3500,                 loss: 1.1562
env1_first_0:                 episode reward: 18.3500,                 loss: nan
env1_second_0:                 episode reward: -18.3500,                 loss: nan
Episode: 8581/30000 (28.6033%),                 avg. length: 777.1,                last time consumption/overall running time: 95.3606s / 93256.4031 s
env0_first_0:                 episode reward: 12.3000,                 loss: 0.4870
env0_second_0:                 episode reward: -12.3000,                 loss: 1.6252
env1_first_0:                 episode reward: 6.4000,                 loss: nan
env1_second_0:                 episode reward: -6.4000,                 loss: nan
Episode: 8601/30000 (28.6700%),                 avg. length: 824.8,                last time consumption/overall running time: 103.4494s / 93359.8525 s
env0_first_0:                 episode reward: -14.4500,                 loss: 0.4788
env0_second_0:                 episode reward: 14.4500,                 loss: 1.8073
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 8621/30000 (28.7367%),                 avg. length: 988.4,                last time consumption/overall running time: 129.4357s / 93489.2882 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.6952
env0_second_0:                 episode reward: 1.8000,                 loss: 2.6859
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 8641/30000 (28.8033%),                 avg. length: 1260.95,                last time consumption/overall running time: 157.0240s / 93646.3122 s
env0_first_0:                 episode reward: -10.4000,                 loss: 0.5048
env0_second_0:                 episode reward: 10.4000,                 loss: 1.5743
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 8661/30000 (28.8700%),                 avg. length: 1280.55,                last time consumption/overall running time: 164.2400s / 93810.5521 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.5620
env0_second_0:                 episode reward: 13.8500,                 loss: 1.5458
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 8681/30000 (28.9367%),                 avg. length: 1352.5,                last time consumption/overall running time: 173.4686s / 93984.0207 s
env0_first_0:                 episode reward: -12.4500,                 loss: 0.4609
env0_second_0:                 episode reward: 12.4500,                 loss: 1.2326
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 8701/30000 (29.0033%),                 avg. length: 1498.3,                last time consumption/overall running time: 191.5311s / 94175.5518 s
env0_first_0:                 episode reward: -14.1500,                 loss: 0.2639
env0_second_0:                 episode reward: 14.1500,                 loss: 1.4886
env1_first_0:                 episode reward: -15.5500,                 loss: nan
env1_second_0:                 episode reward: 15.5500,                 loss: nan
Episode: 8721/30000 (29.0700%),                 avg. length: 1597.15,                last time consumption/overall running time: 202.2988s / 94377.8506 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.4012
env0_second_0:                 episode reward: 11.0500,                 loss: 1.8052
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 8741/30000 (29.1367%),                 avg. length: 1712.45,                last time consumption/overall running time: 217.1155s / 94594.9660 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.2762
env0_second_0:                 episode reward: 14.3500,                 loss: 1.6690
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 8761/30000 (29.2033%),                 avg. length: 1396.75,                last time consumption/overall running time: 178.9932s / 94773.9593 s
env0_first_0:                 episode reward: -16.6500,                 loss: 0.1939
env0_second_0:                 episode reward: 16.6500,                 loss: 1.4051
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 8781/30000 (29.2700%),                 avg. length: 1433.6,                last time consumption/overall running time: 185.4458s / 94959.4050 s
env0_first_0:                 episode reward: -15.8500,                 loss: 0.3084
env0_second_0:                 episode reward: 15.8500,                 loss: 1.7127
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 8801/30000 (29.3367%),                 avg. length: 1013.35,                last time consumption/overall running time: 134.6328s / 95094.0378 s
env0_first_0:                 episode reward: 9.3500,                 loss: 0.4374
env0_second_0:                 episode reward: -9.3500,                 loss: 2.3314
env1_first_0:                 episode reward: 8.8500,                 loss: nan
env1_second_0:                 episode reward: -8.8500,                 loss: nan
Episode: 8821/30000 (29.4033%),                 avg. length: 804.85,                last time consumption/overall running time: 106.5438s / 95200.5816 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.3112
env0_second_0:                 episode reward: 1.3500,                 loss: 1.5421
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 8841/30000 (29.4700%),                 avg. length: 808.7,                last time consumption/overall running time: 106.9461s / 95307.5278 s
env0_first_0:                 episode reward: -17.8500,                 loss: 0.2051
env0_second_0:                 episode reward: 17.8500,                 loss: 0.9754
env1_first_0:                 episode reward: -17.7000,                 loss: nan
env1_second_0:                 episode reward: 17.7000,                 loss: nan
Episode: 8861/30000 (29.5367%),                 avg. length: 762.4,                last time consumption/overall running time: 102.9218s / 95410.4496 s
env0_first_0:                 episode reward: -14.7000,                 loss: 0.2166
env0_second_0:                 episode reward: 14.7000,                 loss: 1.3428
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 8881/30000 (29.6033%),                 avg. length: 779.45,                last time consumption/overall running time: 104.7951s / 95515.2447 s
env0_first_0:                 episode reward: -20.1000,                 loss: 0.1493
env0_second_0:                 episode reward: 20.1000,                 loss: 1.3893
env1_first_0:                 episode reward: -19.5000,                 loss: nan
env1_second_0:                 episode reward: 19.5000,                 loss: nan
Episode: 8901/30000 (29.6700%),                 avg. length: 786.65,                last time consumption/overall running time: 104.5770s / 95619.8218 s
env0_first_0:                 episode reward: -17.9000,                 loss: 0.0815
env0_second_0:                 episode reward: 17.9000,                 loss: 1.2842
env1_first_0:                 episode reward: -19.8500,                 loss: nan
env1_second_0:                 episode reward: 19.8500,                 loss: nan
Episode: 8921/30000 (29.7367%),                 avg. length: 786.0,                last time consumption/overall running time: 98.3283s / 95718.1501 s
env0_first_0:                 episode reward: -16.1000,                 loss: 0.2151
env0_second_0:                 episode reward: 16.1000,                 loss: 0.9522
env1_first_0:                 episode reward: -18.9000,                 loss: nan
env1_second_0:                 episode reward: 18.9000,                 loss: nan
Episode: 8941/30000 (29.8033%),                 avg. length: 751.7,                last time consumption/overall running time: 97.1184s / 95815.2685 s
env0_first_0:                 episode reward: 4.7000,                 loss: 0.4126
env0_second_0:                 episode reward: -4.7000,                 loss: 2.2441
env1_first_0:                 episode reward: 4.2000,                 loss: nan
env1_second_0:                 episode reward: -4.2000,                 loss: nan
Episode: 8961/30000 (29.8700%),                 avg. length: 728.0,                last time consumption/overall running time: 94.2822s / 95909.5507 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1096
env0_second_0:                 episode reward: -21.0000,                 loss: 1.6131
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 8981/30000 (29.9367%),                 avg. length: 809.3,                last time consumption/overall running time: 102.9841s / 96012.5349 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.2686
env0_second_0:                 episode reward: 11.4500,                 loss: 1.0842
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 9001/30000 (30.0033%),                 avg. length: 784.65,                last time consumption/overall running time: 103.0407s / 96115.5756 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.0880
env0_second_0:                 episode reward: 11.5500,                 loss: 1.0858
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 9021/30000 (30.0700%),                 avg. length: 756.35,                last time consumption/overall running time: 101.2199s / 96216.7955 s
env0_first_0:                 episode reward: -16.7000,                 loss: 0.1050
env0_second_0:                 episode reward: 16.7000,                 loss: 1.3257
env1_first_0:                 episode reward: -18.3000,                 loss: nan
env1_second_0:                 episode reward: 18.3000,                 loss: nan
Episode: 9041/30000 (30.1367%),                 avg. length: 758.5,                last time consumption/overall running time: 97.3159s / 96314.1114 s
env0_first_0:                 episode reward: -17.4500,                 loss: 0.1445
env0_second_0:                 episode reward: 17.4500,                 loss: 1.3754
env1_first_0:                 episode reward: -16.2500,                 loss: nan
env1_second_0:                 episode reward: 16.2500,                 loss: nan
Episode: 9061/30000 (30.2033%),                 avg. length: 754.6,                last time consumption/overall running time: 88.0347s / 96402.1461 s
env0_first_0:                 episode reward: -12.2000,                 loss: 0.1816
env0_second_0:                 episode reward: 12.2000,                 loss: 1.5894
env1_first_0:                 episode reward: -10.0500,                 loss: nan
env1_second_0:                 episode reward: 10.0500,                 loss: nan
Episode: 9081/30000 (30.2700%),                 avg. length: 754.1,                last time consumption/overall running time: 88.2114s / 96490.3575 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.2927
env0_second_0:                 episode reward: 14.0000,                 loss: 1.5949
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 9101/30000 (30.3367%),                 avg. length: 760.05,                last time consumption/overall running time: 97.7290s / 96588.0864 s
env0_first_0:                 episode reward: -16.6500,                 loss: 0.0902
env0_second_0:                 episode reward: 16.6500,                 loss: 1.3687
env1_first_0:                 episode reward: -18.3500,                 loss: nan
env1_second_0:                 episode reward: 18.3500,                 loss: nan
Episode: 9121/30000 (30.4033%),                 avg. length: 816.4,                last time consumption/overall running time: 93.4408s / 96681.5273 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.3543
env0_second_0:                 episode reward: 13.8500,                 loss: 1.5690
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 9141/30000 (30.4700%),                 avg. length: 766.65,                last time consumption/overall running time: 96.8107s / 96778.3379 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.2759
env0_second_0:                 episode reward: 14.7500,                 loss: 1.3775
env1_first_0:                 episode reward: -17.6500,                 loss: nan
env1_second_0:                 episode reward: 17.6500,                 loss: nan
Episode: 9161/30000 (30.5367%),                 avg. length: 816.3,                last time consumption/overall running time: 108.6395s / 96886.9774 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.4205
env0_second_0:                 episode reward: 11.6500,                 loss: 2.5041
env1_first_0:                 episode reward: -4.5500,                 loss: nan
env1_second_0:                 episode reward: 4.5500,                 loss: nan
Episode: 9181/30000 (30.6033%),                 avg. length: 801.0,                last time consumption/overall running time: 106.3016s / 96993.2789 s
env0_first_0:                 episode reward: -15.0500,                 loss: 0.2361
env0_second_0:                 episode reward: 15.0500,                 loss: 1.8285
env1_first_0:                 episode reward: -17.0500,                 loss: nan
env1_second_0:                 episode reward: 17.0500,                 loss: nan
Episode: 9201/30000 (30.6700%),                 avg. length: 797.7,                last time consumption/overall running time: 105.9338s / 97099.2127 s
env0_first_0:                 episode reward: -17.2500,                 loss: 0.1885
env0_second_0:                 episode reward: 17.2500,                 loss: 2.7019
env1_first_0:                 episode reward: -18.6000,                 loss: nan
env1_second_0:                 episode reward: 18.6000,                 loss: nan
Episode: 9221/30000 (30.7367%),                 avg. length: 781.45,                last time consumption/overall running time: 102.4025s / 97201.6152 s
env0_first_0:                 episode reward: -19.3500,                 loss: 0.1135
env0_second_0:                 episode reward: 19.3500,                 loss: 1.5271
env1_first_0:                 episode reward: -19.1000,                 loss: nan
env1_second_0:                 episode reward: 19.1000,                 loss: nan
Episode: 9241/30000 (30.8033%),                 avg. length: 773.25,                last time consumption/overall running time: 102.8948s / 97304.5100 s
env0_first_0:                 episode reward: -19.7000,                 loss: 0.0460
env0_second_0:                 episode reward: 19.7000,                 loss: 1.6522
env1_first_0:                 episode reward: -19.9000,                 loss: nan
env1_second_0:                 episode reward: 19.9000,                 loss: nan
Episode: 9261/30000 (30.8700%),                 avg. length: 759.05,                last time consumption/overall running time: 99.2958s / 97403.8058 s
env0_first_0:                 episode reward: -5.6500,                 loss: 0.4587
env0_second_0:                 episode reward: 5.6500,                 loss: 2.6143
env1_first_0:                 episode reward: -5.7000,                 loss: nan
env1_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 9281/30000 (30.9367%),                 avg. length: 764.0,                last time consumption/overall running time: 93.5798s / 97497.3856 s
env0_first_0:                 episode reward: -20.2500,                 loss: 0.0759
env0_second_0:                 episode reward: 20.2500,                 loss: 1.3956
env1_first_0:                 episode reward: -20.7000,                 loss: nan
env1_second_0:                 episode reward: 20.7000,                 loss: nan
Episode: 9301/30000 (31.0033%),                 avg. length: 763.0,                last time consumption/overall running time: 94.6082s / 97591.9938 s
env0_first_0:                 episode reward: -20.7000,                 loss: 0.0082
env0_second_0:                 episode reward: 20.7000,                 loss: 1.7073
env1_first_0:                 episode reward: -20.9000,                 loss: nan
env1_second_0:                 episode reward: 20.9000,                 loss: nan
Episode: 9321/30000 (31.0700%),                 avg. length: 787.45,                last time consumption/overall running time: 104.1613s / 97696.1551 s
env0_first_0:                 episode reward: -18.8500,                 loss: 0.2002
env0_second_0:                 episode reward: 18.8500,                 loss: 1.4892
env1_first_0:                 episode reward: -16.8000,                 loss: nan
env1_second_0:                 episode reward: 16.8000,                 loss: nan
Episode: 9341/30000 (31.1367%),                 avg. length: 763.65,                last time consumption/overall running time: 101.5771s / 97797.7321 s
env0_first_0:                 episode reward: -20.5500,                 loss: 0.0057
env0_second_0:                 episode reward: 20.5500,                 loss: 1.5069
env1_first_0:                 episode reward: -20.3000,                 loss: nan
env1_second_0:                 episode reward: 20.3000,                 loss: nan
Episode: 9361/30000 (31.2033%),                 avg. length: 773.05,                last time consumption/overall running time: 102.8141s / 97900.5463 s
env0_first_0:                 episode reward: -17.2000,                 loss: 0.1570
env0_second_0:                 episode reward: 17.2000,                 loss: 1.5764
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 9381/30000 (31.2700%),                 avg. length: 761.85,                last time consumption/overall running time: 101.2470s / 98001.7932 s
env0_first_0:                 episode reward: -16.4000,                 loss: 0.1711
env0_second_0:                 episode reward: 16.4000,                 loss: 1.4783
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 9401/30000 (31.3367%),                 avg. length: 762.15,                last time consumption/overall running time: 101.2942s / 98103.0874 s
env0_first_0:                 episode reward: 5.1500,                 loss: 0.2992
env0_second_0:                 episode reward: -5.1500,                 loss: 1.3383
env1_first_0:                 episode reward: 5.2000,                 loss: nan
env1_second_0:                 episode reward: -5.2000,                 loss: nan
Episode: 9421/30000 (31.4033%),                 avg. length: 728.05,                last time consumption/overall running time: 96.7920s / 98199.8794 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.1300
env0_second_0:                 episode reward: -20.8500,                 loss: 0.9603
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9441/30000 (31.4700%),                 avg. length: 728.1,                last time consumption/overall running time: 97.4483s / 98297.3277 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.1150
env0_second_0:                 episode reward: -20.8500,                 loss: 0.9835
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9461/30000 (31.5367%),                 avg. length: 728.7,                last time consumption/overall running time: 98.3658s / 98395.6935 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.0734
env0_second_0:                 episode reward: -20.8500,                 loss: 1.2863
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 9481/30000 (31.6033%),                 avg. length: 728.35,                last time consumption/overall running time: 97.6759s / 98493.3694 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0884
env0_second_0:                 episode reward: -20.9000,                 loss: 1.0019
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 9501/30000 (31.6700%),                 avg. length: 728.1,                last time consumption/overall running time: 97.2447s / 98590.6141 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0929
env0_second_0:                 episode reward: -20.8000,                 loss: 1.5021
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 9521/30000 (31.7367%),                 avg. length: 728.0,                last time consumption/overall running time: 96.9380s / 98687.5521 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1550
env0_second_0:                 episode reward: -21.0000,                 loss: 1.2942
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9541/30000 (31.8033%),                 avg. length: 728.0,                last time consumption/overall running time: 97.7036s / 98785.2557 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1058
env0_second_0:                 episode reward: -21.0000,                 loss: 2.5560
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9561/30000 (31.8700%),                 avg. length: 728.0,                last time consumption/overall running time: 97.6630s / 98882.9188 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1365
env0_second_0:                 episode reward: -21.0000,                 loss: 1.6229
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9581/30000 (31.9367%),                 avg. length: 728.0,                last time consumption/overall running time: 97.3366s / 98980.2553 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1321
env0_second_0:                 episode reward: -21.0000,                 loss: 1.9832
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9601/30000 (32.0033%),                 avg. length: 728.0,                last time consumption/overall running time: 95.3580s / 99075.6134 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1295
env0_second_0:                 episode reward: -21.0000,                 loss: 1.5114
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 9621/30000 (32.0700%),                 avg. length: 734.5,                last time consumption/overall running time: 93.9753s / 99169.5887 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.1423
env0_second_0:                 episode reward: -20.8000,                 loss: 1.3359
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 9641/30000 (32.1367%),                 avg. length: 728.0,                last time consumption/overall running time: 84.9619s / 99254.5505 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1554
env0_second_0:                 episode reward: -21.0000,                 loss: 2.1658
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9661/30000 (32.2033%),                 avg. length: 728.0,                last time consumption/overall running time: 97.4338s / 99351.9844 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0529
env0_second_0:                 episode reward: -21.0000,                 loss: 1.1239
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9681/30000 (32.2700%),                 avg. length: 728.0,                last time consumption/overall running time: 97.4102s / 99449.3946 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.1264
env0_second_0:                 episode reward: -20.9000,                 loss: 1.4754
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 9701/30000 (32.3367%),                 avg. length: 728.0,                last time consumption/overall running time: 92.4329s / 99541.8275 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0467
env0_second_0:                 episode reward: -20.9500,                 loss: 2.3155
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9721/30000 (32.4033%),                 avg. length: 728.0,                last time consumption/overall running time: 84.5437s / 99626.3712 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0890
env0_second_0:                 episode reward: -20.9500,                 loss: 1.7296
env1_first_0:                 episode reward: 20.3500,                 loss: nan
env1_second_0:                 episode reward: -20.3500,                 loss: nan
Episode: 9741/30000 (32.4700%),                 avg. length: 728.55,                last time consumption/overall running time: 88.6062s / 99714.9774 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.1079
env0_second_0:                 episode reward: -20.7000,                 loss: 1.6459
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 9761/30000 (32.5367%),                 avg. length: 728.0,                last time consumption/overall running time: 97.5673s / 99812.5447 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0600
env0_second_0:                 episode reward: -21.0000,                 loss: 2.0984
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 9781/30000 (32.6033%),                 avg. length: 728.0,                last time consumption/overall running time: 97.1483s / 99909.6929 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0650
env0_second_0:                 episode reward: -21.0000,                 loss: 2.4113
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9801/30000 (32.6700%),                 avg. length: 728.0,                last time consumption/overall running time: 88.3817s / 99998.0747 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0437
env0_second_0:                 episode reward: -21.0000,                 loss: 5.5630
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 9821/30000 (32.7367%),                 avg. length: 757.25,                last time consumption/overall running time: 96.8608s / 100094.9354 s
env0_first_0:                 episode reward: 20.1000,                 loss: 0.2052
env0_second_0:                 episode reward: -20.1000,                 loss: 1.8727
env1_first_0:                 episode reward: 20.2000,                 loss: nan
env1_second_0:                 episode reward: -20.2000,                 loss: nan
Episode: 9841/30000 (32.8033%),                 avg. length: 728.05,                last time consumption/overall running time: 84.2954s / 100179.2308 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0433
env0_second_0:                 episode reward: -21.0000,                 loss: 2.9367
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 9861/30000 (32.8700%),                 avg. length: 728.2,                last time consumption/overall running time: 93.8297s / 100273.0604 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0763
env0_second_0:                 episode reward: -20.7500,                 loss: 3.5775
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 9881/30000 (32.9367%),                 avg. length: 728.65,                last time consumption/overall running time: 97.3216s / 100370.3821 s
env0_first_0:                 episode reward: 20.5500,                 loss: 0.0631
env0_second_0:                 episode reward: -20.5500,                 loss: 3.8575
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 9901/30000 (33.0033%),                 avg. length: 728.65,                last time consumption/overall running time: 97.5029s / 100467.8850 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.1270
env0_second_0:                 episode reward: -20.6500,                 loss: 4.0134
env1_first_0:                 episode reward: 20.5500,                 loss: nan
env1_second_0:                 episode reward: -20.5500,                 loss: nan
Episode: 9921/30000 (33.0700%),                 avg. length: 730.45,                last time consumption/overall running time: 97.6825s / 100565.5675 s
env0_first_0:                 episode reward: 20.3500,                 loss: 0.1309
env0_second_0:                 episode reward: -20.3500,                 loss: 2.7342
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 9941/30000 (33.1367%),                 avg. length: 728.5,                last time consumption/overall running time: 97.4418s / 100663.0093 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.0030
env0_second_0:                 episode reward: -20.7500,                 loss: 2.5167
env1_first_0:                 episode reward: 20.4500,                 loss: nan
env1_second_0:                 episode reward: -20.4500,                 loss: nan
Episode: 9961/30000 (33.2033%),                 avg. length: 769.85,                last time consumption/overall running time: 102.5156s / 100765.5249 s
env0_first_0:                 episode reward: 11.8000,                 loss: 0.1464
env0_second_0:                 episode reward: -11.8000,                 loss: 1.7668
env1_first_0:                 episode reward: 13.4500,                 loss: nan
env1_second_0:                 episode reward: -13.4500,                 loss: nan
Episode: 9981/30000 (33.2700%),                 avg. length: 806.15,                last time consumption/overall running time: 106.2229s / 100871.7478 s
env0_first_0:                 episode reward: -16.9000,                 loss: 0.2408
env0_second_0:                 episode reward: 16.9000,                 loss: 1.2749
env1_first_0:                 episode reward: -17.0000,                 loss: nan
env1_second_0:                 episode reward: 17.0000,                 loss: nan
Episode: 10001/30000 (33.3367%),                 avg. length: 751.7,                last time consumption/overall running time: 99.9494s / 100971.6973 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.1998
env0_second_0:                 episode reward: 2.7000,                 loss: 1.4131
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 10021/30000 (33.4033%),                 avg. length: 1222.05,                last time consumption/overall running time: 157.7081s / 101129.4054 s
env0_first_0:                 episode reward: -4.3500,                 loss: 0.6949
env0_second_0:                 episode reward: 4.3500,                 loss: 3.5701
env1_first_0:                 episode reward: -6.3000,                 loss: nan
env1_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 10041/30000 (33.4700%),                 avg. length: 976.1,                last time consumption/overall running time: 127.0690s / 101256.4744 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.4835
env0_second_0:                 episode reward: 13.2500,                 loss: 2.6056
env1_first_0:                 episode reward: -14.5000,                 loss: nan
env1_second_0:                 episode reward: 14.5000,                 loss: nan
Episode: 10061/30000 (33.5367%),                 avg. length: 896.95,                last time consumption/overall running time: 118.1979s / 101374.6723 s
env0_first_0:                 episode reward: -16.3500,                 loss: 0.3426
env0_second_0:                 episode reward: 16.3500,                 loss: 2.1228
env1_first_0:                 episode reward: -16.4500,                 loss: nan
env1_second_0:                 episode reward: 16.4500,                 loss: nan
Episode: 10081/30000 (33.6033%),                 avg. length: 796.0,                last time consumption/overall running time: 105.4663s / 101480.1386 s
env0_first_0:                 episode reward: -19.3500,                 loss: 0.2074
env0_second_0:                 episode reward: 19.3500,                 loss: 1.7188
env1_first_0:                 episode reward: -17.4000,                 loss: nan
env1_second_0:                 episode reward: 17.4000,                 loss: nan
Episode: 10101/30000 (33.6700%),                 avg. length: 963.0,                last time consumption/overall running time: 126.5946s / 101606.7332 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.3630
env0_second_0:                 episode reward: 14.8500,                 loss: 2.1619
env1_first_0:                 episode reward: -15.9500,                 loss: nan
env1_second_0:                 episode reward: 15.9500,                 loss: nan
Episode: 10121/30000 (33.7367%),                 avg. length: 1912.85,                last time consumption/overall running time: 234.2326s / 101840.9658 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.4278
env0_second_0:                 episode reward: 2.9500,                 loss: 2.5847
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 10141/30000 (33.8033%),                 avg. length: 2099.85,                last time consumption/overall running time: 250.1873s / 102091.1531 s
env0_first_0:                 episode reward: -9.1000,                 loss: 0.2702
env0_second_0:                 episode reward: 9.1000,                 loss: 2.1599
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 10161/30000 (33.8700%),                 avg. length: 2102.0,                last time consumption/overall running time: 264.2429s / 102355.3960 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.2133
env0_second_0:                 episode reward: 12.0000,                 loss: 1.3402
env1_first_0:                 episode reward: -11.1000,                 loss: nan
env1_second_0:                 episode reward: 11.1000,                 loss: nan
Episode: 10181/30000 (33.9367%),                 avg. length: 2271.35,                last time consumption/overall running time: 288.1936s / 102643.5896 s
env0_first_0:                 episode reward: -10.8000,                 loss: 0.2324
env0_second_0:                 episode reward: 10.8000,                 loss: 1.3424
env1_first_0:                 episode reward: -9.6500,                 loss: nan
env1_second_0:                 episode reward: 9.6500,                 loss: nan
Episode: 10201/30000 (34.0033%),                 avg. length: 2133.45,                last time consumption/overall running time: 271.0380s / 102914.6276 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.2275
env0_second_0:                 episode reward: 12.8000,                 loss: 1.4076
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 10221/30000 (34.0700%),                 avg. length: 2155.4,                last time consumption/overall running time: 272.5142s / 103187.1418 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.1851
env0_second_0:                 episode reward: 13.2000,                 loss: 1.3251
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 10241/30000 (34.1367%),                 avg. length: 2204.95,                last time consumption/overall running time: 277.3413s / 103464.4831 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.2289
env0_second_0:                 episode reward: 11.4000,                 loss: 1.2945
env1_first_0:                 episode reward: -12.0500,                 loss: nan
env1_second_0:                 episode reward: 12.0500,                 loss: nan
Episode: 10261/30000 (34.2033%),                 avg. length: 2379.5,                last time consumption/overall running time: 296.4012s / 103760.8843 s
env0_first_0:                 episode reward: -10.2500,                 loss: 0.2246
env0_second_0:                 episode reward: 10.2500,                 loss: 1.3230
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 10281/30000 (34.2700%),                 avg. length: 2122.3,                last time consumption/overall running time: 265.1646s / 104026.0489 s
env0_first_0:                 episode reward: -12.4000,                 loss: 0.2330
env0_second_0:                 episode reward: 12.4000,                 loss: 1.3292
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 10301/30000 (34.3367%),                 avg. length: 2289.65,                last time consumption/overall running time: 284.1885s / 104310.2375 s
env0_first_0:                 episode reward: -10.7500,                 loss: 0.2214
env0_second_0:                 episode reward: 10.7500,                 loss: 1.8739
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 10321/30000 (34.4033%),                 avg. length: 2377.95,                last time consumption/overall running time: 297.9264s / 104608.1638 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.2058
env0_second_0:                 episode reward: 10.9500,                 loss: 1.5246
env1_first_0:                 episode reward: -11.6500,                 loss: nan
env1_second_0:                 episode reward: 11.6500,                 loss: nan
Episode: 10341/30000 (34.4700%),                 avg. length: 2185.7,                last time consumption/overall running time: 268.3095s / 104876.4733 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.1906
env0_second_0:                 episode reward: 11.6000,                 loss: 2.4922
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 10361/30000 (34.5367%),                 avg. length: 2365.4,                last time consumption/overall running time: 276.4582s / 105152.9315 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.1823
env0_second_0:                 episode reward: 11.5000,                 loss: 3.3515
env1_first_0:                 episode reward: -12.6500,                 loss: nan
env1_second_0:                 episode reward: 12.6500,                 loss: nan
Episode: 10381/30000 (34.6033%),                 avg. length: 2132.15,                last time consumption/overall running time: 245.1357s / 105398.0672 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.1394
env0_second_0:                 episode reward: 13.6500,                 loss: 2.9648
env1_first_0:                 episode reward: -14.7000,                 loss: nan
env1_second_0:                 episode reward: 14.7000,                 loss: nan
Episode: 10401/30000 (34.6700%),                 avg. length: 2211.6,                last time consumption/overall running time: 250.2381s / 105648.3053 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.1049
env0_second_0:                 episode reward: 15.5500,                 loss: 2.6716
env1_first_0:                 episode reward: -16.5000,                 loss: nan
env1_second_0:                 episode reward: 16.5000,                 loss: nan
Episode: 10421/30000 (34.7367%),                 avg. length: 2074.65,                last time consumption/overall running time: 258.2149s / 105906.5202 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.0947
env0_second_0:                 episode reward: 12.7000,                 loss: 2.1729
env1_first_0:                 episode reward: -17.4500,                 loss: nan
env1_second_0:                 episode reward: 17.4500,                 loss: nan
Episode: 10441/30000 (34.8033%),                 avg. length: 2143.55,                last time consumption/overall running time: 270.4557s / 106176.9759 s
env0_first_0:                 episode reward: -17.3500,                 loss: 0.0769
env0_second_0:                 episode reward: 17.3500,                 loss: 2.8443
env1_first_0:                 episode reward: -14.5000,                 loss: nan
env1_second_0:                 episode reward: 14.5000,                 loss: nan
Episode: 10461/30000 (34.8700%),                 avg. length: 2050.75,                last time consumption/overall running time: 249.9399s / 106426.9158 s
env0_first_0:                 episode reward: -16.0000,                 loss: 0.0734
env0_second_0:                 episode reward: 16.0000,                 loss: 1.0871
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 10481/30000 (34.9367%),                 avg. length: 1942.7,                last time consumption/overall running time: 243.1484s / 106670.0642 s
env0_first_0:                 episode reward: -16.1000,                 loss: 0.1166
env0_second_0:                 episode reward: 16.1000,                 loss: 0.4322
env1_first_0:                 episode reward: -16.5500,                 loss: nan
env1_second_0:                 episode reward: 16.5500,                 loss: nan
Episode: 10501/30000 (35.0033%),                 avg. length: 1890.6,                last time consumption/overall running time: 209.3560s / 106879.4202 s
env0_first_0:                 episode reward: -17.3000,                 loss: 0.0905
env0_second_0:                 episode reward: 17.3000,                 loss: 0.3586
env1_first_0:                 episode reward: -16.6500,                 loss: nan
env1_second_0:                 episode reward: 16.6500,                 loss: nan
Episode: 10521/30000 (35.0700%),                 avg. length: 1946.25,                last time consumption/overall running time: 243.2257s / 107122.6458 s
env0_first_0:                 episode reward: -16.5000,                 loss: 0.0746
env0_second_0:                 episode reward: 16.5000,                 loss: 0.3116
env1_first_0:                 episode reward: -17.2000,                 loss: nan
env1_second_0:                 episode reward: 17.2000,                 loss: nan
Episode: 10541/30000 (35.1367%),                 avg. length: 1907.0,                last time consumption/overall running time: 218.6341s / 107341.2799 s
env0_first_0:                 episode reward: -18.2500,                 loss: 0.0568
env0_second_0:                 episode reward: 18.2500,                 loss: 0.3409
env1_first_0:                 episode reward: -17.0000,                 loss: nan
env1_second_0:                 episode reward: 17.0000,                 loss: nan
Episode: 10561/30000 (35.2033%),                 avg. length: 1831.55,                last time consumption/overall running time: 223.4248s / 107564.7047 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.3860
env0_second_0:                 episode reward: 11.4500,                 loss: 0.8009
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 10581/30000 (35.2700%),                 avg. length: 1924.4,                last time consumption/overall running time: 220.9207s / 107785.6254 s
env0_first_0:                 episode reward: -11.6000,                 loss: 0.2902
env0_second_0:                 episode reward: 11.6000,                 loss: 0.9300
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 10601/30000 (35.3367%),                 avg. length: 2056.5,                last time consumption/overall running time: 236.7258s / 108022.3512 s
env0_first_0:                 episode reward: -17.7500,                 loss: 0.1001
env0_second_0:                 episode reward: 17.7500,                 loss: 0.5668
env1_first_0:                 episode reward: -17.5000,                 loss: nan
env1_second_0:                 episode reward: 17.5000,                 loss: nan
Episode: 10621/30000 (35.4033%),                 avg. length: 2026.45,                last time consumption/overall running time: 255.4465s / 108277.7977 s
env0_first_0:                 episode reward: -14.2500,                 loss: 0.1061
env0_second_0:                 episode reward: 14.2500,                 loss: 0.6096
env1_first_0:                 episode reward: -16.9500,                 loss: nan
env1_second_0:                 episode reward: 16.9500,                 loss: nan
Episode: 10641/30000 (35.4700%),                 avg. length: 1871.05,                last time consumption/overall running time: 227.5257s / 108505.3235 s
env0_first_0:                 episode reward: -17.0500,                 loss: 0.1120
env0_second_0:                 episode reward: 17.0500,                 loss: 0.5440
env1_first_0:                 episode reward: -17.0500,                 loss: nan
env1_second_0:                 episode reward: 17.0500,                 loss: nan
Episode: 10661/30000 (35.5367%),                 avg. length: 1982.3,                last time consumption/overall running time: 247.2643s / 108752.5878 s
env0_first_0:                 episode reward: -18.0000,                 loss: 0.0747
env0_second_0:                 episode reward: 18.0000,                 loss: 1.3574
env1_first_0:                 episode reward: -16.2500,                 loss: nan
env1_second_0:                 episode reward: 16.2500,                 loss: nan
Episode: 10681/30000 (35.6033%),                 avg. length: 2012.9,                last time consumption/overall running time: 254.6146s / 109007.2024 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.1665
env0_second_0:                 episode reward: 13.3500,                 loss: 0.8611
env1_first_0:                 episode reward: -11.9500,                 loss: nan
env1_second_0:                 episode reward: 11.9500,                 loss: nan
Episode: 10701/30000 (35.6700%),                 avg. length: 967.55,                last time consumption/overall running time: 127.8177s / 109135.0201 s
env0_first_0:                 episode reward: 7.0000,                 loss: 0.4462
env0_second_0:                 episode reward: -7.0000,                 loss: 1.3140
env1_first_0:                 episode reward: 6.8500,                 loss: nan
env1_second_0:                 episode reward: -6.8500,                 loss: nan
Episode: 10721/30000 (35.7367%),                 avg. length: 728.0,                last time consumption/overall running time: 97.2483s / 109232.2684 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1747
env0_second_0:                 episode reward: -21.0000,                 loss: 0.5537
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 10741/30000 (35.8033%),                 avg. length: 728.05,                last time consumption/overall running time: 97.0171s / 109329.2855 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.1912
env0_second_0:                 episode reward: -20.8000,                 loss: 0.7739
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 10761/30000 (35.8700%),                 avg. length: 768.3,                last time consumption/overall running time: 102.5628s / 109431.8483 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.2700
env0_second_0:                 episode reward: 0.1500,                 loss: 0.8425
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 10781/30000 (35.9367%),                 avg. length: 767.7,                last time consumption/overall running time: 102.3816s / 109534.2299 s
env0_first_0:                 episode reward: -18.5500,                 loss: 0.2276
env0_second_0:                 episode reward: 18.5500,                 loss: 0.9127
env1_first_0:                 episode reward: -18.6500,                 loss: nan
env1_second_0:                 episode reward: 18.6500,                 loss: nan
Episode: 10801/30000 (36.0033%),                 avg. length: 777.95,                last time consumption/overall running time: 103.0992s / 109637.3291 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.3740
env0_second_0:                 episode reward: 13.7500,                 loss: 2.1117
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 10821/30000 (36.0700%),                 avg. length: 730.2,                last time consumption/overall running time: 98.2130s / 109735.5421 s
env0_first_0:                 episode reward: 18.8000,                 loss: 0.2724
env0_second_0:                 episode reward: -18.8000,                 loss: 1.7839
env1_first_0:                 episode reward: 18.7500,                 loss: nan
env1_second_0:                 episode reward: -18.7500,                 loss: nan
Episode: 10841/30000 (36.1367%),                 avg. length: 728.2,                last time consumption/overall running time: 98.3166s / 109833.8586 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.1103
env0_second_0:                 episode reward: -20.8500,                 loss: 2.4558
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 10861/30000 (36.2033%),                 avg. length: 728.0,                last time consumption/overall running time: 98.5585s / 109932.4171 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1192
env0_second_0:                 episode reward: -21.0000,                 loss: 2.2075
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 10881/30000 (36.2700%),                 avg. length: 728.0,                last time consumption/overall running time: 96.1771s / 110028.5942 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.1254
env0_second_0:                 episode reward: -21.0000,                 loss: 2.2739
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 10901/30000 (36.3367%),                 avg. length: 728.0,                last time consumption/overall running time: 96.3610s / 110124.9552 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.1256
env0_second_0:                 episode reward: -21.0000,                 loss: 2.1408
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 10921/30000 (36.4033%),                 avg. length: 728.0,                last time consumption/overall running time: 96.5227s / 110221.4780 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0345
env0_second_0:                 episode reward: -20.9500,                 loss: 1.9700
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 10941/30000 (36.4700%),                 avg. length: 728.0,                last time consumption/overall running time: 96.8908s / 110318.3688 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0281
env0_second_0:                 episode reward: -20.9500,                 loss: 2.2862
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 10961/30000 (36.5367%),                 avg. length: 728.0,                last time consumption/overall running time: 94.7588s / 110413.1275 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0213
env0_second_0:                 episode reward: -21.0000,                 loss: 2.1126
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 10981/30000 (36.6033%),                 avg. length: 728.0,                last time consumption/overall running time: 97.5436s / 110510.6711 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0142
env0_second_0:                 episode reward: -20.9500,                 loss: 3.9483
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 11001/30000 (36.6700%),                 avg. length: 728.0,                last time consumption/overall running time: 98.1790s / 110608.8501 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0168
env0_second_0:                 episode reward: -21.0000,                 loss: 1.5803
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11021/30000 (36.7367%),                 avg. length: 728.0,                last time consumption/overall running time: 94.2186s / 110703.0688 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0400
env0_second_0:                 episode reward: -21.0000,                 loss: 0.4109
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11041/30000 (36.8033%),                 avg. length: 728.15,                last time consumption/overall running time: 96.5007s / 110799.5695 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0236
env0_second_0:                 episode reward: -20.9000,                 loss: 0.7989
env1_first_0:                 episode reward: 20.8000,                 loss: nan
env1_second_0:                 episode reward: -20.8000,                 loss: nan
Episode: 11061/30000 (36.8700%),                 avg. length: 728.0,                last time consumption/overall running time: 99.7955s / 110899.3649 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0127
env0_second_0:                 episode reward: -20.9000,                 loss: 1.2976
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 11081/30000 (36.9367%),                 avg. length: 728.1,                last time consumption/overall running time: 97.8853s / 110997.2502 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.0535
env0_second_0:                 episode reward: -20.8000,                 loss: 4.1629
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 11101/30000 (37.0033%),                 avg. length: 740.35,                last time consumption/overall running time: 97.5516s / 111094.8018 s
env0_first_0:                 episode reward: 16.4500,                 loss: 0.1097
env0_second_0:                 episode reward: -16.4500,                 loss: 4.0164
env1_first_0:                 episode reward: 15.3000,                 loss: nan
env1_second_0:                 episode reward: -15.3000,                 loss: nan
Episode: 11121/30000 (37.0700%),                 avg. length: 761.35,                last time consumption/overall running time: 98.3073s / 111193.1090 s
env0_first_0:                 episode reward: -6.4500,                 loss: 0.2722
env0_second_0:                 episode reward: 6.4500,                 loss: 5.8215
env1_first_0:                 episode reward: -7.5000,                 loss: nan
env1_second_0:                 episode reward: 7.5000,                 loss: nan
Episode: 11141/30000 (37.1367%),                 avg. length: 787.35,                last time consumption/overall running time: 96.0500s / 111289.1591 s
env0_first_0:                 episode reward: 11.8500,                 loss: 0.3321
env0_second_0:                 episode reward: -11.8500,                 loss: 4.7204
env1_first_0:                 episode reward: 11.3000,                 loss: nan
env1_second_0:                 episode reward: -11.3000,                 loss: nan
Episode: 11161/30000 (37.2033%),                 avg. length: 1416.0,                last time consumption/overall running time: 161.0163s / 111450.1754 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.6074
env0_second_0:                 episode reward: -2.8000,                 loss: 5.5038
env1_first_0:                 episode reward: 7.2500,                 loss: nan
env1_second_0:                 episode reward: -7.2500,                 loss: nan
Episode: 11181/30000 (37.2700%),                 avg. length: 1494.75,                last time consumption/overall running time: 189.2613s / 111639.4366 s
env0_first_0:                 episode reward: -6.1000,                 loss: 0.4484
env0_second_0:                 episode reward: 6.1000,                 loss: 2.8495
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 11201/30000 (37.3367%),                 avg. length: 950.8,                last time consumption/overall running time: 121.8852s / 111761.3218 s
env0_first_0:                 episode reward: 15.1000,                 loss: 0.3981
env0_second_0:                 episode reward: -15.1000,                 loss: 2.0220
env1_first_0:                 episode reward: 15.7000,                 loss: nan
env1_second_0:                 episode reward: -15.7000,                 loss: nan
Episode: 11221/30000 (37.4033%),                 avg. length: 749.9,                last time consumption/overall running time: 95.6862s / 111857.0080 s
env0_first_0:                 episode reward: 20.4000,                 loss: 0.0955
env0_second_0:                 episode reward: -20.4000,                 loss: 0.8989
env1_first_0:                 episode reward: 18.4500,                 loss: nan
env1_second_0:                 episode reward: -18.4500,                 loss: nan
Episode: 11241/30000 (37.4700%),                 avg. length: 741.45,                last time consumption/overall running time: 99.0587s / 111956.0667 s
env0_first_0:                 episode reward: 19.9000,                 loss: 0.0482
env0_second_0:                 episode reward: -19.9000,                 loss: 1.1036
env1_first_0:                 episode reward: 20.2000,                 loss: nan
env1_second_0:                 episode reward: -20.2000,                 loss: nan
Episode: 11261/30000 (37.5367%),                 avg. length: 728.4,                last time consumption/overall running time: 96.9458s / 112053.0125 s
env0_first_0:                 episode reward: 20.4500,                 loss: 0.0747
env0_second_0:                 episode reward: -20.4500,                 loss: 0.6176
env1_first_0:                 episode reward: 19.9000,                 loss: nan
env1_second_0:                 episode reward: -19.9000,                 loss: nan
Episode: 11281/30000 (37.6033%),                 avg. length: 740.45,                last time consumption/overall running time: 96.7272s / 112149.7397 s
env0_first_0:                 episode reward: 16.9500,                 loss: 0.1314
env0_second_0:                 episode reward: -16.9500,                 loss: 0.3849
env1_first_0:                 episode reward: 18.9500,                 loss: nan
env1_second_0:                 episode reward: -18.9500,                 loss: nan
Episode: 11301/30000 (37.6700%),                 avg. length: 761.95,                last time consumption/overall running time: 94.1708s / 112243.9105 s
env0_first_0:                 episode reward: 17.5000,                 loss: 0.2094
env0_second_0:                 episode reward: -17.5000,                 loss: 0.3630
env1_first_0:                 episode reward: 19.0500,                 loss: nan
env1_second_0:                 episode reward: -19.0500,                 loss: nan
Episode: 11321/30000 (37.7367%),                 avg. length: 731.15,                last time consumption/overall running time: 93.6089s / 112337.5194 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.1264
env0_second_0:                 episode reward: -20.7000,                 loss: 0.2607
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 11341/30000 (37.8033%),                 avg. length: 738.85,                last time consumption/overall running time: 91.4347s / 112428.9541 s
env0_first_0:                 episode reward: 16.3500,                 loss: 0.4818
env0_second_0:                 episode reward: -16.3500,                 loss: 1.9446
env1_first_0:                 episode reward: 16.4500,                 loss: nan
env1_second_0:                 episode reward: -16.4500,                 loss: nan
Episode: 11361/30000 (37.8700%),                 avg. length: 779.75,                last time consumption/overall running time: 101.7763s / 112530.7304 s
env0_first_0:                 episode reward: 18.7000,                 loss: 0.5579
env0_second_0:                 episode reward: -18.7000,                 loss: 3.2932
env1_first_0:                 episode reward: 16.5000,                 loss: nan
env1_second_0:                 episode reward: -16.5000,                 loss: nan
Episode: 11381/30000 (37.9367%),                 avg. length: 1254.0,                last time consumption/overall running time: 154.7541s / 112685.4845 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.4616
env0_second_0:                 episode reward: -2.0000,                 loss: 3.2687
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 11401/30000 (38.0033%),                 avg. length: 735.8,                last time consumption/overall running time: 94.8811s / 112780.3656 s
env0_first_0:                 episode reward: 20.5500,                 loss: 0.2700
env0_second_0:                 episode reward: -20.5500,                 loss: 1.6646
env1_first_0:                 episode reward: 20.4500,                 loss: nan
env1_second_0:                 episode reward: -20.4500,                 loss: nan
Episode: 11421/30000 (38.0700%),                 avg. length: 729.1,                last time consumption/overall running time: 96.4933s / 112876.8589 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.1242
env0_second_0:                 episode reward: -20.8000,                 loss: 0.9478
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 11441/30000 (38.1367%),                 avg. length: 728.1,                last time consumption/overall running time: 97.3181s / 112974.1770 s
env0_first_0:                 episode reward: 20.8000,                 loss: 0.1962
env0_second_0:                 episode reward: -20.8000,                 loss: 2.3083
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 11461/30000 (38.2033%),                 avg. length: 730.0,                last time consumption/overall running time: 96.9278s / 113071.1048 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.0457
env0_second_0:                 episode reward: -20.6500,                 loss: 0.2401
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 11481/30000 (38.2700%),                 avg. length: 728.25,                last time consumption/overall running time: 97.2683s / 113168.3731 s
env0_first_0:                 episode reward: 20.7000,                 loss: 0.0687
env0_second_0:                 episode reward: -20.7000,                 loss: 0.2822
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 11501/30000 (38.3367%),                 avg. length: 728.0,                last time consumption/overall running time: 93.2868s / 113261.6599 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0710
env0_second_0:                 episode reward: -21.0000,                 loss: 0.4123
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 11521/30000 (38.4033%),                 avg. length: 728.0,                last time consumption/overall running time: 97.7114s / 113359.3713 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0651
env0_second_0:                 episode reward: -20.9500,                 loss: 0.4302
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 11541/30000 (38.4700%),                 avg. length: 728.0,                last time consumption/overall running time: 96.6732s / 113456.0445 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0402
env0_second_0:                 episode reward: -20.9500,                 loss: 0.1579
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 11561/30000 (38.5367%),                 avg. length: 728.05,                last time consumption/overall running time: 97.3360s / 113553.3804 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0281
env0_second_0:                 episode reward: -20.9500,                 loss: 0.0928
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 11581/30000 (38.6033%),                 avg. length: 728.0,                last time consumption/overall running time: 92.8430s / 113646.2234 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.0451
env0_second_0:                 episode reward: -20.6500,                 loss: 0.9335
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 11601/30000 (38.6700%),                 avg. length: 755.75,                last time consumption/overall running time: 91.0183s / 113737.2418 s
env0_first_0:                 episode reward: 19.6500,                 loss: 0.1306
env0_second_0:                 episode reward: -19.6500,                 loss: 3.0302
env1_first_0:                 episode reward: 18.1500,                 loss: nan
env1_second_0:                 episode reward: -18.1500,                 loss: nan
Episode: 11621/30000 (38.7367%),                 avg. length: 752.45,                last time consumption/overall running time: 85.8885s / 113823.1303 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.2300
env0_second_0:                 episode reward: -20.9000,                 loss: 4.2312
env1_first_0:                 episode reward: 19.1500,                 loss: nan
env1_second_0:                 episode reward: -19.1500,                 loss: nan
Episode: 11641/30000 (38.8033%),                 avg. length: 731.0,                last time consumption/overall running time: 84.9789s / 113908.1092 s
env0_first_0:                 episode reward: 20.9500,                 loss: 0.0752
env0_second_0:                 episode reward: -20.9500,                 loss: 1.3874
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11661/30000 (38.8700%),                 avg. length: 728.0,                last time consumption/overall running time: 97.8944s / 114006.0035 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0467
env0_second_0:                 episode reward: -21.0000,                 loss: 0.8621
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 11681/30000 (38.9367%),                 avg. length: 728.0,                last time consumption/overall running time: 96.6424s / 114102.6459 s
env0_first_0:                 episode reward: 20.9000,                 loss: 0.0389
env0_second_0:                 episode reward: -20.9000,                 loss: 0.1160
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11701/30000 (39.0033%),                 avg. length: 728.0,                last time consumption/overall running time: 97.4870s / 114200.1329 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0587
env0_second_0:                 episode reward: -21.0000,                 loss: 0.2079
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 11721/30000 (39.0700%),                 avg. length: 728.0,                last time consumption/overall running time: 97.1614s / 114297.2943 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0331
env0_second_0:                 episode reward: -21.0000,                 loss: 0.1390
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 11741/30000 (39.1367%),                 avg. length: 736.25,                last time consumption/overall running time: 97.7470s / 114395.0413 s
env0_first_0:                 episode reward: 19.3000,                 loss: 0.1557
env0_second_0:                 episode reward: -19.3000,                 loss: 0.2423
env1_first_0:                 episode reward: 17.2500,                 loss: nan
env1_second_0:                 episode reward: -17.2500,                 loss: nan
Episode: 11761/30000 (39.2033%),                 avg. length: 728.0,                last time consumption/overall running time: 96.8869s / 114491.9282 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0259
env0_second_0:                 episode reward: -21.0000,                 loss: 0.2329
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11781/30000 (39.2700%),                 avg. length: 728.0,                last time consumption/overall running time: 97.3976s / 114589.3258 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0687
env0_second_0:                 episode reward: -21.0000,                 loss: 1.4259
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11801/30000 (39.3367%),                 avg. length: 728.0,                last time consumption/overall running time: 91.2268s / 114680.5526 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0343
env0_second_0:                 episode reward: -21.0000,                 loss: 2.8738
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11821/30000 (39.4033%),                 avg. length: 728.0,                last time consumption/overall running time: 88.3170s / 114768.8696 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0382
env0_second_0:                 episode reward: -21.0000,                 loss: 4.2041
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 11841/30000 (39.4700%),                 avg. length: 728.0,                last time consumption/overall running time: 94.4346s / 114863.3042 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0272
env0_second_0:                 episode reward: -21.0000,                 loss: 3.2918
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11861/30000 (39.5367%),                 avg. length: 728.0,                last time consumption/overall running time: 97.4029s / 114960.7071 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0209
env0_second_0:                 episode reward: -21.0000,                 loss: 4.8059
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11881/30000 (39.6033%),                 avg. length: 728.0,                last time consumption/overall running time: 88.0143s / 115048.7215 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0653
env0_second_0:                 episode reward: -21.0000,                 loss: 4.4582
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11901/30000 (39.6700%),                 avg. length: 728.0,                last time consumption/overall running time: 87.1776s / 115135.8991 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0614
env0_second_0:                 episode reward: -21.0000,                 loss: 3.9861
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11921/30000 (39.7367%),                 avg. length: 728.0,                last time consumption/overall running time: 100.7436s / 115236.6427 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0642
env0_second_0:                 episode reward: -21.0000,                 loss: 4.0930
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11941/30000 (39.8033%),                 avg. length: 728.0,                last time consumption/overall running time: 88.5830s / 115325.2257 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0187
env0_second_0:                 episode reward: -21.0000,                 loss: 4.1648
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11961/30000 (39.8700%),                 avg. length: 728.0,                last time consumption/overall running time: 85.9048s / 115411.1305 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0449
env0_second_0:                 episode reward: -21.0000,                 loss: 4.4604
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 11981/30000 (39.9367%),                 avg. length: 728.0,                last time consumption/overall running time: 91.4662s / 115502.5967 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0330
env0_second_0:                 episode reward: -21.0000,                 loss: 4.2435
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 12001/30000 (40.0033%),                 avg. length: 806.65,                last time consumption/overall running time: 102.8895s / 115605.4861 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.3063
env0_second_0:                 episode reward: 2.0500,                 loss: 2.5492
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 12021/30000 (40.0700%),                 avg. length: 768.45,                last time consumption/overall running time: 100.5283s / 115706.0145 s
env0_first_0:                 episode reward: 4.7500,                 loss: 0.2377
env0_second_0:                 episode reward: -4.7500,                 loss: 2.0047
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
Episode: 12041/30000 (40.1367%),                 avg. length: 789.2,                last time consumption/overall running time: 100.3215s / 115806.3360 s
env0_first_0:                 episode reward: -11.0500,                 loss: 0.2924
env0_second_0:                 episode reward: 11.0500,                 loss: 0.5927
env1_first_0:                 episode reward: -18.5500,                 loss: nan
env1_second_0:                 episode reward: 18.5500,                 loss: nan
Episode: 12061/30000 (40.2033%),                 avg. length: 818.75,                last time consumption/overall running time: 107.4311s / 115913.7671 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.3619
env0_second_0:                 episode reward: 13.2500,                 loss: 0.5103
env1_first_0:                 episode reward: -13.1500,                 loss: nan
env1_second_0:                 episode reward: 13.1500,                 loss: nan
Episode: 12081/30000 (40.2700%),                 avg. length: 850.65,                last time consumption/overall running time: 114.7155s / 116028.4825 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.4093
env0_second_0:                 episode reward: 13.4000,                 loss: 0.5084
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 12101/30000 (40.3367%),                 avg. length: 814.9,                last time consumption/overall running time: 108.1203s / 116136.6028 s
env0_first_0:                 episode reward: -17.3000,                 loss: 0.2733
env0_second_0:                 episode reward: 17.3000,                 loss: 0.3552
env1_first_0:                 episode reward: -15.0000,                 loss: nan
env1_second_0:                 episode reward: 15.0000,                 loss: nan
Episode: 12121/30000 (40.4033%),                 avg. length: 820.4,                last time consumption/overall running time: 108.5342s / 116245.1370 s
env0_first_0:                 episode reward: -14.8500,                 loss: 0.2572
env0_second_0:                 episode reward: 14.8500,                 loss: 0.5365
env1_first_0:                 episode reward: -16.0000,                 loss: nan
env1_second_0:                 episode reward: 16.0000,                 loss: nan
Episode: 12141/30000 (40.4700%),                 avg. length: 730.05,                last time consumption/overall running time: 96.2214s / 116341.3584 s
env0_first_0:                 episode reward: 18.1500,                 loss: 0.1528
env0_second_0:                 episode reward: -18.1500,                 loss: 0.4126
env1_first_0:                 episode reward: 17.7000,                 loss: nan
env1_second_0:                 episode reward: -17.7000,                 loss: nan
Episode: 12161/30000 (40.5367%),                 avg. length: 813.55,                last time consumption/overall running time: 109.2169s / 116450.5753 s
env0_first_0:                 episode reward: -11.9500,                 loss: 0.3343
env0_second_0:                 episode reward: 11.9500,                 loss: 0.6120
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 12181/30000 (40.6033%),                 avg. length: 794.3,                last time consumption/overall running time: 107.2803s / 116557.8556 s
env0_first_0:                 episode reward: -18.9000,                 loss: 0.1537
env0_second_0:                 episode reward: 18.9000,                 loss: 0.3496
env1_first_0:                 episode reward: -16.7500,                 loss: nan
env1_second_0:                 episode reward: 16.7500,                 loss: nan
Episode: 12201/30000 (40.6700%),                 avg. length: 799.9,                last time consumption/overall running time: 107.1830s / 116665.0386 s
env0_first_0:                 episode reward: -18.4000,                 loss: 0.1661
env0_second_0:                 episode reward: 18.4000,                 loss: 0.3219
env1_first_0:                 episode reward: -16.3500,                 loss: nan
env1_second_0:                 episode reward: 16.3500,                 loss: nan
Episode: 12221/30000 (40.7367%),                 avg. length: 780.9,                last time consumption/overall running time: 95.3068s / 116760.3455 s
env0_first_0:                 episode reward: -19.3500,                 loss: 0.1136
env0_second_0:                 episode reward: 19.3500,                 loss: 0.3714
env1_first_0:                 episode reward: -17.8500,                 loss: nan
env1_second_0:                 episode reward: 17.8500,                 loss: nan
Episode: 12241/30000 (40.8033%),                 avg. length: 776.1,                last time consumption/overall running time: 102.3202s / 116862.6657 s
env0_first_0:                 episode reward: -19.6000,                 loss: 0.0729
env0_second_0:                 episode reward: 19.6000,                 loss: 0.6964
env1_first_0:                 episode reward: -18.8500,                 loss: nan
env1_second_0:                 episode reward: 18.8500,                 loss: nan
Episode: 12261/30000 (40.8700%),                 avg. length: 778.55,                last time consumption/overall running time: 103.6070s / 116966.2727 s
env0_first_0:                 episode reward: -19.4500,                 loss: 0.0811
env0_second_0:                 episode reward: 19.4500,                 loss: 0.5592
env1_first_0:                 episode reward: -19.7500,                 loss: nan
env1_second_0:                 episode reward: 19.7500,                 loss: nan
Episode: 12281/30000 (40.9367%),                 avg. length: 778.1,                last time consumption/overall running time: 103.0687s / 117069.3414 s
env0_first_0:                 episode reward: -19.1000,                 loss: 0.0179
env0_second_0:                 episode reward: 19.1000,                 loss: 0.2208
env1_first_0:                 episode reward: -20.1500,                 loss: nan
env1_second_0:                 episode reward: 20.1500,                 loss: nan
Episode: 12301/30000 (41.0033%),                 avg. length: 778.05,                last time consumption/overall running time: 104.2815s / 117173.6229 s
env0_first_0:                 episode reward: -19.7000,                 loss: 0.0363
env0_second_0:                 episode reward: 19.7000,                 loss: 0.2440
env1_first_0:                 episode reward: -19.7000,                 loss: nan
env1_second_0:                 episode reward: 19.7000,                 loss: nan
Episode: 12321/30000 (41.0700%),                 avg. length: 828.0,                last time consumption/overall running time: 109.1053s / 117282.7282 s
env0_first_0:                 episode reward: -18.1500,                 loss: 0.0695
env0_second_0:                 episode reward: 18.1500,                 loss: 0.5989
env1_first_0:                 episode reward: -17.7500,                 loss: nan
env1_second_0:                 episode reward: 17.7500,                 loss: nan
Episode: 12341/30000 (41.1367%),                 avg. length: 813.65,                last time consumption/overall running time: 108.7540s / 117391.4822 s
env0_first_0:                 episode reward: -15.5000,                 loss: 0.1617
env0_second_0:                 episode reward: 15.5000,                 loss: 0.4713
env1_first_0:                 episode reward: -15.9000,                 loss: nan
env1_second_0:                 episode reward: 15.9000,                 loss: nan
Episode: 12361/30000 (41.2033%),                 avg. length: 833.6,                last time consumption/overall running time: 110.6164s / 117502.0986 s
env0_first_0:                 episode reward: -18.6000,                 loss: 0.1668
env0_second_0:                 episode reward: 18.6000,                 loss: 0.9578
env1_first_0:                 episode reward: -18.0500,                 loss: nan
env1_second_0:                 episode reward: 18.0500,                 loss: nan
Episode: 12381/30000 (41.2700%),                 avg. length: 901.65,                last time consumption/overall running time: 120.6904s / 117622.7890 s
env0_first_0:                 episode reward: -15.0500,                 loss: 0.3418
env0_second_0:                 episode reward: 15.0500,                 loss: 1.3770
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 12401/30000 (41.3367%),                 avg. length: 961.6,                last time consumption/overall running time: 126.1162s / 117748.9053 s
env0_first_0:                 episode reward: -16.4500,                 loss: 0.2572
env0_second_0:                 episode reward: 16.4500,                 loss: 1.1996
env1_first_0:                 episode reward: -16.0500,                 loss: nan
env1_second_0:                 episode reward: 16.0500,                 loss: nan
Episode: 12421/30000 (41.4033%),                 avg. length: 970.95,                last time consumption/overall running time: 121.5548s / 117870.4601 s
env0_first_0:                 episode reward: -16.3000,                 loss: 0.2478
env0_second_0:                 episode reward: 16.3000,                 loss: 0.3998
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 12441/30000 (41.4700%),                 avg. length: 1117.05,                last time consumption/overall running time: 140.7324s / 118011.1924 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.2931
env0_second_0:                 episode reward: 13.7000,                 loss: 0.3783
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 12461/30000 (41.5367%),                 avg. length: 1328.25,                last time consumption/overall running time: 168.7507s / 118179.9432 s
env0_first_0:                 episode reward: -10.9500,                 loss: 0.3081
env0_second_0:                 episode reward: 10.9500,                 loss: 0.8515
env1_first_0:                 episode reward: -12.3000,                 loss: nan
env1_second_0:                 episode reward: 12.3000,                 loss: nan
Episode: 12481/30000 (41.6033%),                 avg. length: 1657.45,                last time consumption/overall running time: 212.4108s / 118392.3539 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.3670
env0_second_0:                 episode reward: 8.1500,                 loss: 0.7099
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
Episode: 12501/30000 (41.6700%),                 avg. length: 1540.9,                last time consumption/overall running time: 197.8017s / 118590.1556 s
env0_first_0:                 episode reward: -5.2500,                 loss: 0.5104
env0_second_0:                 episode reward: 5.2500,                 loss: 0.6116
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 12521/30000 (41.7367%),                 avg. length: 1861.75,                last time consumption/overall running time: 237.9621s / 118828.1178 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.3074
env0_second_0:                 episode reward: 3.5000,                 loss: 0.3895
env1_first_0:                 episode reward: -7.8000,                 loss: nan
env1_second_0:                 episode reward: 7.8000,                 loss: nan
Episode: 12541/30000 (41.8033%),                 avg. length: 1903.0,                last time consumption/overall running time: 240.9171s / 119069.0349 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.2578
env0_second_0:                 episode reward: 8.1500,                 loss: 0.3277
env1_first_0:                 episode reward: -8.7000,                 loss: nan
env1_second_0:                 episode reward: 8.7000,                 loss: nan
Episode: 12561/30000 (41.8700%),                 avg. length: 1974.65,                last time consumption/overall running time: 246.6650s / 119315.6999 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.2310
env0_second_0:                 episode reward: 7.5500,                 loss: 0.2985
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 12581/30000 (41.9367%),                 avg. length: 2032.1,                last time consumption/overall running time: 250.5711s / 119566.2710 s
env0_first_0:                 episode reward: -8.4500,                 loss: 0.1899
env0_second_0:                 episode reward: 8.4500,                 loss: 0.2825
env1_first_0:                 episode reward: -8.4500,                 loss: nan
env1_second_0:                 episode reward: 8.4500,                 loss: nan
Episode: 12601/30000 (42.0033%),                 avg. length: 1852.95,                last time consumption/overall running time: 234.0731s / 119800.3441 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.1783
env0_second_0:                 episode reward: 10.7000,                 loss: 0.2480
env1_first_0:                 episode reward: -11.7500,                 loss: nan
env1_second_0:                 episode reward: 11.7500,                 loss: nan
Episode: 12621/30000 (42.0700%),                 avg. length: 1999.4,                last time consumption/overall running time: 252.5560s / 120052.9001 s
env0_first_0:                 episode reward: -7.5500,                 loss: 0.2153
env0_second_0:                 episode reward: 7.5500,                 loss: 0.2830
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 12641/30000 (42.1367%),                 avg. length: 1147.3,                last time consumption/overall running time: 148.0975s / 120200.9976 s
env0_first_0:                 episode reward: 13.4500,                 loss: 0.4273
env0_second_0:                 episode reward: -13.4500,                 loss: 0.4805
env1_first_0:                 episode reward: 14.1000,                 loss: nan
env1_second_0:                 episode reward: -14.1000,                 loss: nan
Episode: 12661/30000 (42.2033%),                 avg. length: 1757.7,                last time consumption/overall running time: 222.0649s / 120423.0625 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.3537
env0_second_0:                 episode reward: -3.6500,                 loss: 0.4644
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 12681/30000 (42.2700%),                 avg. length: 2110.2,                last time consumption/overall running time: 265.5436s / 120688.6061 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.2068
env0_second_0:                 episode reward: 7.6000,                 loss: 0.4959
env1_first_0:                 episode reward: -9.5500,                 loss: nan
env1_second_0:                 episode reward: 9.5500,                 loss: nan
Episode: 12701/30000 (42.3367%),                 avg. length: 1826.55,                last time consumption/overall running time: 229.6117s / 120918.2179 s
env0_first_0:                 episode reward: 6.3000,                 loss: 0.3258
env0_second_0:                 episode reward: -6.3000,                 loss: 0.4875
env1_first_0:                 episode reward: 6.4500,                 loss: nan
env1_second_0:                 episode reward: -6.4500,                 loss: nan
Episode: 12721/30000 (42.4033%),                 avg. length: 2195.45,                last time consumption/overall running time: 275.8101s / 121194.0280 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.2438
env0_second_0:                 episode reward: 4.5000,                 loss: 0.3833
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 12741/30000 (42.4700%),                 avg. length: 2149.4,                last time consumption/overall running time: 270.1574s / 121464.1854 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.1780
env0_second_0:                 episode reward: 10.3000,                 loss: 0.2991
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 12761/30000 (42.5367%),                 avg. length: 1998.2,                last time consumption/overall running time: 252.6668s / 121716.8523 s
env0_first_0:                 episode reward: -9.9000,                 loss: 0.1842
env0_second_0:                 episode reward: 9.9000,                 loss: 0.3096
env1_first_0:                 episode reward: -8.8500,                 loss: nan
env1_second_0:                 episode reward: 8.8500,                 loss: nan
Episode: 12781/30000 (42.6033%),                 avg. length: 1972.2,                last time consumption/overall running time: 249.9744s / 121966.8267 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.1527
env0_second_0:                 episode reward: 11.8000,                 loss: 0.6413
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 12801/30000 (42.6700%),                 avg. length: 2056.0,                last time consumption/overall running time: 258.7012s / 122225.5279 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.1271
env0_second_0:                 episode reward: 11.5500,                 loss: 0.2653
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 12821/30000 (42.7367%),                 avg. length: 1835.45,                last time consumption/overall running time: 232.0869s / 122457.6148 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.1626
env0_second_0:                 episode reward: 13.0000,                 loss: 0.2700
env1_first_0:                 episode reward: -13.9000,                 loss: nan
env1_second_0:                 episode reward: 13.9000,                 loss: nan
Episode: 12841/30000 (42.8033%),                 avg. length: 1810.0,                last time consumption/overall running time: 228.5796s / 122686.1944 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.2200
env0_second_0:                 episode reward: 12.8500,                 loss: 0.3198
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 12861/30000 (42.8700%),                 avg. length: 1783.05,                last time consumption/overall running time: 225.5780s / 122911.7724 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.2855
env0_second_0:                 episode reward: 13.2000,                 loss: 0.9653
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 12881/30000 (42.9367%),                 avg. length: 1722.55,                last time consumption/overall running time: 218.3612s / 123130.1336 s
env0_first_0:                 episode reward: -13.5500,                 loss: 0.2245
env0_second_0:                 episode reward: 13.5500,                 loss: 0.5750
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 12901/30000 (43.0033%),                 avg. length: 1338.35,                last time consumption/overall running time: 171.4663s / 123301.5999 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.3533
env0_second_0:                 episode reward: -0.7000,                 loss: 0.7640
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 12921/30000 (43.0700%),                 avg. length: 1008.65,                last time consumption/overall running time: 131.5677s / 123433.1676 s
env0_first_0:                 episode reward: 16.1000,                 loss: 0.2776
env0_second_0:                 episode reward: -16.1000,                 loss: 1.5705
env1_first_0:                 episode reward: 16.2500,                 loss: nan
env1_second_0:                 episode reward: -16.2500,                 loss: nan
Episode: 12941/30000 (43.1367%),                 avg. length: 1853.95,                last time consumption/overall running time: 234.2522s / 123667.4199 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.2691
env0_second_0:                 episode reward: 8.9000,                 loss: 1.9849
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 12961/30000 (43.2033%),                 avg. length: 1835.9,                last time consumption/overall running time: 232.0097s / 123899.4295 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.1525
env0_second_0:                 episode reward: 14.9500,                 loss: 1.2824
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 12981/30000 (43.2700%),                 avg. length: 1769.0,                last time consumption/overall running time: 224.5761s / 124124.0056 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.1330
env0_second_0:                 episode reward: 15.2500,                 loss: 0.6231
env1_first_0:                 episode reward: -15.0000,                 loss: nan
env1_second_0:                 episode reward: 15.0000,                 loss: nan
Episode: 13001/30000 (43.3367%),                 avg. length: 1635.85,                last time consumption/overall running time: 208.0907s / 124332.0963 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.2293
env0_second_0:                 episode reward: 12.9000,                 loss: 0.8139
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 13021/30000 (43.4033%),                 avg. length: 1632.85,                last time consumption/overall running time: 207.7434s / 124539.8397 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.1721
env0_second_0:                 episode reward: 14.7500,                 loss: 0.5146
env1_first_0:                 episode reward: -15.0500,                 loss: nan
env1_second_0:                 episode reward: 15.0500,                 loss: nan
Episode: 13041/30000 (43.4700%),                 avg. length: 1632.85,                last time consumption/overall running time: 207.3823s / 124747.2220 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.2350
env0_second_0:                 episode reward: 11.8000,                 loss: 1.0206
env1_first_0:                 episode reward: -13.1000,                 loss: nan
env1_second_0:                 episode reward: 13.1000,                 loss: nan
Episode: 13061/30000 (43.5367%),                 avg. length: 1617.55,                last time consumption/overall running time: 205.7267s / 124952.9487 s
env0_first_0:                 episode reward: -14.9500,                 loss: 0.1427
env0_second_0:                 episode reward: 14.9500,                 loss: 0.3615
env1_first_0:                 episode reward: -16.8000,                 loss: nan
env1_second_0:                 episode reward: 16.8000,                 loss: nan
Episode: 13081/30000 (43.6033%),                 avg. length: 1575.35,                last time consumption/overall running time: 200.4393s / 125153.3880 s
env0_first_0:                 episode reward: -14.8000,                 loss: 0.1774
env0_second_0:                 episode reward: 14.8000,                 loss: 0.6875
env1_first_0:                 episode reward: -13.7000,                 loss: nan
env1_second_0:                 episode reward: 13.7000,                 loss: nan
Episode: 13101/30000 (43.6700%),                 avg. length: 1556.9,                last time consumption/overall running time: 198.3135s / 125351.7015 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.1495
env0_second_0:                 episode reward: 14.1000,                 loss: 0.3632
env1_first_0:                 episode reward: -15.7500,                 loss: nan
env1_second_0:                 episode reward: 15.7500,                 loss: nan
Episode: 13121/30000 (43.7367%),                 avg. length: 1705.25,                last time consumption/overall running time: 215.7247s / 125567.4263 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.2278
env0_second_0:                 episode reward: 12.8500,                 loss: 0.4558
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 13141/30000 (43.8033%),                 avg. length: 1764.75,                last time consumption/overall running time: 223.8677s / 125791.2939 s
env0_first_0:                 episode reward: -14.4000,                 loss: 0.1490
env0_second_0:                 episode reward: 14.4000,                 loss: 2.0457
env1_first_0:                 episode reward: -13.8500,                 loss: nan
env1_second_0:                 episode reward: 13.8500,                 loss: nan
Episode: 13161/30000 (43.8700%),                 avg. length: 1585.75,                last time consumption/overall running time: 203.2593s / 125994.5533 s
env0_first_0:                 episode reward: -7.2500,                 loss: 0.3698
env0_second_0:                 episode reward: 7.2500,                 loss: 1.8794
env1_first_0:                 episode reward: -6.3500,                 loss: nan
env1_second_0:                 episode reward: 6.3500,                 loss: nan
Episode: 13181/30000 (43.9367%),                 avg. length: 1715.25,                last time consumption/overall running time: 219.1518s / 126213.7050 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.1830
env0_second_0:                 episode reward: 13.8500,                 loss: 1.2243
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 13201/30000 (44.0033%),                 avg. length: 1698.3,                last time consumption/overall running time: 218.1826s / 126431.8877 s
env0_first_0:                 episode reward: -14.7000,                 loss: 0.1301
env0_second_0:                 episode reward: 14.7000,                 loss: 4.8252
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 13221/30000 (44.0700%),                 avg. length: 1789.8,                last time consumption/overall running time: 229.1998s / 126661.0874 s
env0_first_0:                 episode reward: -10.0000,                 loss: 0.2998
env0_second_0:                 episode reward: 10.0000,                 loss: 0.6187
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 13241/30000 (44.1367%),                 avg. length: 1671.7,                last time consumption/overall running time: 212.9773s / 126874.0647 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.3031
env0_second_0:                 episode reward: 9.3500,                 loss: 0.4761
env1_first_0:                 episode reward: -9.8000,                 loss: nan
env1_second_0:                 episode reward: 9.8000,                 loss: nan
Episode: 13261/30000 (44.2033%),                 avg. length: 1554.15,                last time consumption/overall running time: 197.1611s / 127071.2258 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.3844
env0_second_0:                 episode reward: 1.8500,                 loss: 0.5506
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 13281/30000 (44.2700%),                 avg. length: 1752.45,                last time consumption/overall running time: 220.7693s / 127291.9951 s
env0_first_0:                 episode reward: -9.0000,                 loss: 0.2645
env0_second_0:                 episode reward: 9.0000,                 loss: 0.4553
env1_first_0:                 episode reward: -9.6000,                 loss: nan
env1_second_0:                 episode reward: 9.6000,                 loss: nan
Episode: 13301/30000 (44.3367%),                 avg. length: 1667.45,                last time consumption/overall running time: 216.0180s / 127508.0130 s
env0_first_0:                 episode reward: -11.1000,                 loss: 0.2747
env0_second_0:                 episode reward: 11.1000,                 loss: 0.4893
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 13321/30000 (44.4033%),                 avg. length: 1347.35,                last time consumption/overall running time: 186.9001s / 127694.9131 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.3539
env0_second_0:                 episode reward: 13.8000,                 loss: 1.0616
env1_first_0:                 episode reward: -10.8500,                 loss: nan
env1_second_0:                 episode reward: 10.8500,                 loss: nan
Episode: 13341/30000 (44.4700%),                 avg. length: 1398.75,                last time consumption/overall running time: 188.7659s / 127883.6790 s
env0_first_0:                 episode reward: -13.6500,                 loss: 0.2359
env0_second_0:                 episode reward: 13.6500,                 loss: 0.8464
env1_first_0:                 episode reward: -12.2500,                 loss: nan
env1_second_0:                 episode reward: 12.2500,                 loss: nan
Episode: 13361/30000 (44.5367%),                 avg. length: 1499.2,                last time consumption/overall running time: 204.4305s / 128088.1095 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.2285
env0_second_0:                 episode reward: 14.0000,                 loss: 0.7413
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 13381/30000 (44.6033%),                 avg. length: 1484.85,                last time consumption/overall running time: 202.0047s / 128290.1142 s
env0_first_0:                 episode reward: -14.5000,                 loss: 0.1839
env0_second_0:                 episode reward: 14.5000,                 loss: 0.5743
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 13401/30000 (44.6700%),                 avg. length: 1399.0,                last time consumption/overall running time: 191.6593s / 128481.7735 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.1572
env0_second_0:                 episode reward: 15.5500,                 loss: 0.6410
env1_first_0:                 episode reward: -15.0500,                 loss: nan
env1_second_0:                 episode reward: 15.0500,                 loss: nan
Episode: 13421/30000 (44.7367%),                 avg. length: 1458.1,                last time consumption/overall running time: 198.7578s / 128680.5312 s
env0_first_0:                 episode reward: -14.8000,                 loss: 0.2134
env0_second_0:                 episode reward: 14.8000,                 loss: 1.6187
env1_first_0:                 episode reward: -14.8500,                 loss: nan
env1_second_0:                 episode reward: 14.8500,                 loss: nan
Episode: 13441/30000 (44.8033%),                 avg. length: 1560.95,                last time consumption/overall running time: 210.8761s / 128891.4074 s
env0_first_0:                 episode reward: -10.3000,                 loss: 0.2534
env0_second_0:                 episode reward: 10.3000,                 loss: 1.0394
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 13461/30000 (44.8700%),                 avg. length: 1447.7,                last time consumption/overall running time: 194.5388s / 129085.9462 s
env0_first_0:                 episode reward: -12.7000,                 loss: 0.3911
env0_second_0:                 episode reward: 12.7000,                 loss: 1.8830
env1_first_0:                 episode reward: -10.2500,                 loss: nan
env1_second_0:                 episode reward: 10.2500,                 loss: nan
Episode: 13481/30000 (44.9367%),                 avg. length: 1391.45,                last time consumption/overall running time: 182.4055s / 129268.3516 s
env0_first_0:                 episode reward: -15.9500,                 loss: 0.2012
env0_second_0:                 episode reward: 15.9500,                 loss: 0.7905
env1_first_0:                 episode reward: -14.0000,                 loss: nan
env1_second_0:                 episode reward: 14.0000,                 loss: nan
Episode: 13501/30000 (45.0033%),                 avg. length: 1482.0,                last time consumption/overall running time: 189.6706s / 129458.0222 s
env0_first_0:                 episode reward: -7.7000,                 loss: 0.4817
env0_second_0:                 episode reward: 7.7000,                 loss: 0.9548
env1_first_0:                 episode reward: -9.4500,                 loss: nan
env1_second_0:                 episode reward: 9.4500,                 loss: nan
Episode: 13521/30000 (45.0700%),                 avg. length: 1506.8,                last time consumption/overall running time: 195.8401s / 129653.8623 s
env0_first_0:                 episode reward: -12.1000,                 loss: 0.2914
env0_second_0:                 episode reward: 12.1000,                 loss: 0.6177
env1_first_0:                 episode reward: -14.3000,                 loss: nan
env1_second_0:                 episode reward: 14.3000,                 loss: nan
Episode: 13541/30000 (45.1367%),                 avg. length: 1433.65,                last time consumption/overall running time: 186.0882s / 129839.9505 s
env0_first_0:                 episode reward: -15.2000,                 loss: 0.1891
env0_second_0:                 episode reward: 15.2000,                 loss: 0.4997
env1_first_0:                 episode reward: -14.9500,                 loss: nan
env1_second_0:                 episode reward: 14.9500,                 loss: nan
Episode: 13561/30000 (45.2033%),                 avg. length: 918.05,                last time consumption/overall running time: 116.6752s / 129956.6256 s
env0_first_0:                 episode reward: 9.0000,                 loss: 0.2298
env0_second_0:                 episode reward: -9.0000,                 loss: 0.6316
env1_first_0:                 episode reward: 9.6000,                 loss: nan
env1_second_0:                 episode reward: -9.6000,                 loss: nan
Episode: 13581/30000 (45.2700%),                 avg. length: 810.0,                last time consumption/overall running time: 104.8542s / 130061.4799 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.3308
env0_second_0:                 episode reward: -2.9000,                 loss: 0.7153
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 13601/30000 (45.3367%),                 avg. length: 1336.75,                last time consumption/overall running time: 170.9744s / 130232.4543 s
env0_first_0:                 episode reward: -7.3500,                 loss: 0.5939
env0_second_0:                 episode reward: 7.3500,                 loss: 1.6282
env1_first_0:                 episode reward: -5.9000,                 loss: nan
env1_second_0:                 episode reward: 5.9000,                 loss: nan
Episode: 13621/30000 (45.4033%),                 avg. length: 1900.85,                last time consumption/overall running time: 241.6296s / 130474.0839 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.4109
env0_second_0:                 episode reward: 1.3000,                 loss: 0.7110
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 13641/30000 (45.4700%),                 avg. length: 2347.3,                last time consumption/overall running time: 287.7145s / 130761.7984 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.2544
env0_second_0:                 episode reward: 2.3500,                 loss: 0.5768
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 13661/30000 (45.5367%),                 avg. length: 1983.55,                last time consumption/overall running time: 245.9447s / 131007.7431 s
env0_first_0:                 episode reward: -6.8500,                 loss: 0.2948
env0_second_0:                 episode reward: 6.8500,                 loss: 1.0366
env1_first_0:                 episode reward: -5.5000,                 loss: nan
env1_second_0:                 episode reward: 5.5000,                 loss: nan
Episode: 13681/30000 (45.6033%),                 avg. length: 1866.9,                last time consumption/overall running time: 229.8710s / 131237.6141 s
env0_first_0:                 episode reward: -9.7500,                 loss: 0.3035
env0_second_0:                 episode reward: 9.7500,                 loss: 0.6183
env1_first_0:                 episode reward: -7.2000,                 loss: nan
env1_second_0:                 episode reward: 7.2000,                 loss: nan
Episode: 13701/30000 (45.6700%),                 avg. length: 1769.55,                last time consumption/overall running time: 218.8779s / 131456.4920 s
env0_first_0:                 episode reward: -14.5000,                 loss: 0.1623
env0_second_0:                 episode reward: 14.5000,                 loss: 0.5387
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 13721/30000 (45.7367%),                 avg. length: 1693.35,                last time consumption/overall running time: 213.7334s / 131670.2255 s
env0_first_0:                 episode reward: -15.7500,                 loss: 0.1510
env0_second_0:                 episode reward: 15.7500,                 loss: 1.8305
env1_first_0:                 episode reward: -16.4500,                 loss: nan
env1_second_0:                 episode reward: 16.4500,                 loss: nan
Episode: 13741/30000 (45.8033%),                 avg. length: 1453.25,                last time consumption/overall running time: 184.8913s / 131855.1168 s
env0_first_0:                 episode reward: -5.7500,                 loss: 0.1894
env0_second_0:                 episode reward: 5.7500,                 loss: 5.8765
env1_first_0:                 episode reward: -8.0000,                 loss: nan
env1_second_0:                 episode reward: 8.0000,                 loss: nan
Episode: 13761/30000 (45.8700%),                 avg. length: 1635.65,                last time consumption/overall running time: 213.3920s / 132068.5088 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.4711
env0_second_0:                 episode reward: 0.3500,                 loss: 3.6209
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 13781/30000 (45.9367%),                 avg. length: 1691.6,                last time consumption/overall running time: 213.4031s / 132281.9119 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.2907
env0_second_0:                 episode reward: 12.0500,                 loss: 2.9362
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 13801/30000 (46.0033%),                 avg. length: 1881.45,                last time consumption/overall running time: 239.8355s / 132521.7474 s
env0_first_0:                 episode reward: -12.3000,                 loss: 0.1944
env0_second_0:                 episode reward: 12.3000,                 loss: 2.3620
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 13821/30000 (46.0700%),                 avg. length: 1947.95,                last time consumption/overall running time: 241.9028s / 132763.6502 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.1477
env0_second_0:                 episode reward: 13.1000,                 loss: 2.4363
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 13841/30000 (46.1367%),                 avg. length: 1982.05,                last time consumption/overall running time: 243.8555s / 133007.5057 s
env0_first_0:                 episode reward: -15.3500,                 loss: 0.0803
env0_second_0:                 episode reward: 15.3500,                 loss: 1.9818
env1_first_0:                 episode reward: -15.5000,                 loss: nan
env1_second_0:                 episode reward: 15.5000,                 loss: nan
Episode: 13861/30000 (46.2033%),                 avg. length: 2123.45,                last time consumption/overall running time: 276.1396s / 133283.6453 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.0811
env0_second_0:                 episode reward: 13.2000,                 loss: 1.8479
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 13881/30000 (46.2700%),                 avg. length: 2050.6,                last time consumption/overall running time: 261.9418s / 133545.5871 s
env0_first_0:                 episode reward: -15.7500,                 loss: 0.0477
env0_second_0:                 episode reward: 15.7500,                 loss: 1.6203
env1_first_0:                 episode reward: -15.8000,                 loss: nan
env1_second_0:                 episode reward: 15.8000,                 loss: nan
Episode: 13901/30000 (46.3367%),                 avg. length: 2111.7,                last time consumption/overall running time: 270.2014s / 133815.7885 s
env0_first_0:                 episode reward: -16.4500,                 loss: 0.0110
env0_second_0:                 episode reward: 16.4500,                 loss: 1.9160
env1_first_0:                 episode reward: -16.9000,                 loss: nan
env1_second_0:                 episode reward: 16.9000,                 loss: nan
Episode: 13921/30000 (46.4033%),                 avg. length: 2112.85,                last time consumption/overall running time: 281.0399s / 134096.8284 s
env0_first_0:                 episode reward: -16.8000,                 loss: 0.0291
env0_second_0:                 episode reward: 16.8000,                 loss: 1.6708
env1_first_0:                 episode reward: -16.9500,                 loss: nan
env1_second_0:                 episode reward: 16.9500,                 loss: nan
Episode: 13941/30000 (46.4700%),                 avg. length: 2138.95,                last time consumption/overall running time: 273.1418s / 134369.9703 s
env0_first_0:                 episode reward: -15.9000,                 loss: 0.0040
env0_second_0:                 episode reward: 15.9000,                 loss: 1.8886
env1_first_0:                 episode reward: -18.1000,                 loss: nan
env1_second_0:                 episode reward: 18.1000,                 loss: nan
Episode: 13961/30000 (46.5367%),                 avg. length: 2111.4,                last time consumption/overall running time: 276.4839s / 134646.4541 s
env0_first_0:                 episode reward: -17.7000,                 loss: 0.0047
env0_second_0:                 episode reward: 17.7000,                 loss: 1.4886
env1_first_0:                 episode reward: -16.6500,                 loss: nan
env1_second_0:                 episode reward: 16.6500,                 loss: nan
Episode: 13981/30000 (46.6033%),                 avg. length: 2141.75,                last time consumption/overall running time: 283.3690s / 134929.8232 s
env0_first_0:                 episode reward: -17.1500,                 loss: -0.0017
env0_second_0:                 episode reward: 17.1500,                 loss: 1.5704
env1_first_0:                 episode reward: -18.3000,                 loss: nan
env1_second_0:                 episode reward: 18.3000,                 loss: nan
Episode: 14001/30000 (46.6700%),                 avg. length: 2186.7,                last time consumption/overall running time: 280.3567s / 135210.1798 s
env0_first_0:                 episode reward: -13.0500,                 loss: 0.0609
env0_second_0:                 episode reward: 13.0500,                 loss: 1.6580
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 14021/30000 (46.7367%),                 avg. length: 1482.65,                last time consumption/overall running time: 192.3100s / 135402.4899 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.1982
env0_second_0:                 episode reward: 14.9000,                 loss: 3.0996
env1_first_0:                 episode reward: -15.3500,                 loss: nan
env1_second_0:                 episode reward: 15.3500,                 loss: nan
Episode: 14041/30000 (46.8033%),                 avg. length: 1582.1,                last time consumption/overall running time: 202.6197s / 135605.1096 s
env0_first_0:                 episode reward: -13.7000,                 loss: 0.2864
env0_second_0:                 episode reward: 13.7000,                 loss: 2.0057
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 14061/30000 (46.8700%),                 avg. length: 1410.95,                last time consumption/overall running time: 181.0602s / 135786.1697 s
env0_first_0:                 episode reward: -15.5500,                 loss: 0.1732
env0_second_0:                 episode reward: 15.5500,                 loss: 1.6406
env1_first_0:                 episode reward: -17.2000,                 loss: nan
env1_second_0:                 episode reward: 17.2000,                 loss: nan
Episode: 14081/30000 (46.9367%),                 avg. length: 1358.35,                last time consumption/overall running time: 180.4672s / 135966.6369 s
env0_first_0:                 episode reward: -15.5000,                 loss: 0.2049
env0_second_0:                 episode reward: 15.5000,                 loss: 6.4374
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 14101/30000 (47.0033%),                 avg. length: 1391.1,                last time consumption/overall running time: 189.5505s / 136156.1874 s
env0_first_0:                 episode reward: -17.7500,                 loss: 0.1541
env0_second_0:                 episode reward: 17.7500,                 loss: 3.1872
env1_first_0:                 episode reward: -15.1000,                 loss: nan
env1_second_0:                 episode reward: 15.1000,                 loss: nan
Episode: 14121/30000 (47.0700%),                 avg. length: 1470.0,                last time consumption/overall running time: 198.3436s / 136354.5310 s
env0_first_0:                 episode reward: -15.8500,                 loss: 0.2526
env0_second_0:                 episode reward: 15.8500,                 loss: 3.5183
env1_first_0:                 episode reward: -14.8000,                 loss: nan
env1_second_0:                 episode reward: 14.8000,                 loss: nan
Episode: 14141/30000 (47.1367%),                 avg. length: 1250.35,                last time consumption/overall running time: 161.5761s / 136516.1071 s
env0_first_0:                 episode reward: -16.9000,                 loss: 0.1775
env0_second_0:                 episode reward: 16.9000,                 loss: 3.1187
env1_first_0:                 episode reward: -17.3500,                 loss: nan
env1_second_0:                 episode reward: 17.3500,                 loss: nan
Episode: 14161/30000 (47.2033%),                 avg. length: 1068.6,                last time consumption/overall running time: 133.9458s / 136650.0529 s
env0_first_0:                 episode reward: -13.9500,                 loss: 0.3486
env0_second_0:                 episode reward: 13.9500,                 loss: 2.9694
env1_first_0:                 episode reward: -14.3500,                 loss: nan
env1_second_0:                 episode reward: 14.3500,                 loss: nan
Episode: 14181/30000 (47.2700%),                 avg. length: 920.65,                last time consumption/overall running time: 125.3575s / 136775.4104 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.5663
env0_second_0:                 episode reward: 1.9500,                 loss: 2.3472
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
Episode: 14201/30000 (47.3367%),                 avg. length: 1504.3,                last time consumption/overall running time: 199.8302s / 136975.2406 s
env0_first_0:                 episode reward: -11.5000,                 loss: 0.4001
env0_second_0:                 episode reward: 11.5000,                 loss: 2.1096
env1_first_0:                 episode reward: -10.6000,                 loss: nan
env1_second_0:                 episode reward: 10.6000,                 loss: nan
Episode: 14221/30000 (47.4033%),                 avg. length: 1415.9,                last time consumption/overall running time: 187.6319s / 137162.8725 s
env0_first_0:                 episode reward: -15.9500,                 loss: 0.2510
env0_second_0:                 episode reward: 15.9500,                 loss: 1.7127
env1_first_0:                 episode reward: -13.7500,                 loss: nan
env1_second_0:                 episode reward: 13.7500,                 loss: nan
Episode: 14241/30000 (47.4700%),                 avg. length: 1330.65,                last time consumption/overall running time: 173.7665s / 137336.6390 s
env0_first_0:                 episode reward: -13.8500,                 loss: 0.2776
env0_second_0:                 episode reward: 13.8500,                 loss: 2.4662
env1_first_0:                 episode reward: -14.5500,                 loss: nan
env1_second_0:                 episode reward: 14.5500,                 loss: nan
Episode: 14261/30000 (47.5367%),                 avg. length: 1199.5,                last time consumption/overall running time: 156.6892s / 137493.3282 s
env0_first_0:                 episode reward: -9.5500,                 loss: 0.3881
env0_second_0:                 episode reward: 9.5500,                 loss: 1.8856
env1_first_0:                 episode reward: -9.7500,                 loss: nan
env1_second_0:                 episode reward: 9.7500,                 loss: nan
Episode: 14281/30000 (47.6033%),                 avg. length: 1834.35,                last time consumption/overall running time: 235.0820s / 137728.4102 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.4398
env0_second_0:                 episode reward: 1.9500,                 loss: 2.6996
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 14301/30000 (47.6700%),                 avg. length: 1895.35,                last time consumption/overall running time: 242.4634s / 137970.8736 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.2624
env0_second_0:                 episode reward: 7.2000,                 loss: 2.3460
env1_first_0:                 episode reward: -10.3000,                 loss: nan
env1_second_0:                 episode reward: 10.3000,                 loss: nan
Episode: 14321/30000 (47.7367%),                 avg. length: 1705.45,                last time consumption/overall running time: 218.3467s / 138189.2203 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.2603
env0_second_0:                 episode reward: 7.6000,                 loss: 2.4189
env1_first_0:                 episode reward: -10.9500,                 loss: nan
env1_second_0:                 episode reward: 10.9500,                 loss: nan
Episode: 14341/30000 (47.8033%),                 avg. length: 1611.85,                last time consumption/overall running time: 204.7452s / 138393.9655 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.2781
env0_second_0:                 episode reward: 10.4500,                 loss: 1.9535
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 14361/30000 (47.8700%),                 avg. length: 1318.0,                last time consumption/overall running time: 169.2106s / 138563.1762 s
env0_first_0:                 episode reward: -13.6000,                 loss: 0.3101
env0_second_0:                 episode reward: 13.6000,                 loss: 1.3532
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 14381/30000 (47.9367%),                 avg. length: 1495.5,                last time consumption/overall running time: 190.3060s / 138753.4821 s
env0_first_0:                 episode reward: -9.8000,                 loss: 0.3139
env0_second_0:                 episode reward: 9.8000,                 loss: 0.8716
env1_first_0:                 episode reward: -12.0000,                 loss: nan
env1_second_0:                 episode reward: 12.0000,                 loss: nan
Episode: 14401/30000 (48.0033%),                 avg. length: 1532.0,                last time consumption/overall running time: 195.8225s / 138949.3046 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.2670
env0_second_0:                 episode reward: 11.4000,                 loss: 1.0059
env1_first_0:                 episode reward: -12.8000,                 loss: nan
env1_second_0:                 episode reward: 12.8000,                 loss: nan
Episode: 14421/30000 (48.0700%),                 avg. length: 1551.95,                last time consumption/overall running time: 203.0201s / 139152.3247 s
env0_first_0:                 episode reward: -8.2500,                 loss: 0.3340
env0_second_0:                 episode reward: 8.2500,                 loss: 0.8962
env1_first_0:                 episode reward: -11.7000,                 loss: nan
env1_second_0:                 episode reward: 11.7000,                 loss: nan
Episode: 14441/30000 (48.1367%),                 avg. length: 1462.65,                last time consumption/overall running time: 191.1275s / 139343.4522 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.2822
env0_second_0:                 episode reward: 12.5500,                 loss: 0.7943
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 14461/30000 (48.2033%),                 avg. length: 1576.75,                last time consumption/overall running time: 199.2976s / 139542.7498 s
env0_first_0:                 episode reward: -11.4000,                 loss: 0.2335
env0_second_0:                 episode reward: 11.4000,                 loss: 1.3673
env1_first_0:                 episode reward: -12.2000,                 loss: nan
env1_second_0:                 episode reward: 12.2000,                 loss: nan
Episode: 14481/30000 (48.2700%),                 avg. length: 1400.1,                last time consumption/overall running time: 183.9991s / 139726.7489 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.2275
env0_second_0:                 episode reward: 14.0000,                 loss: 1.8821
env1_first_0:                 episode reward: -14.1000,                 loss: nan
env1_second_0:                 episode reward: 14.1000,                 loss: nan
Episode: 14501/30000 (48.3367%),                 avg. length: 1527.55,                last time consumption/overall running time: 194.1550s / 139920.9038 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.2571
env0_second_0:                 episode reward: 11.8000,                 loss: 0.8973
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 14521/30000 (48.4033%),                 avg. length: 1781.25,                last time consumption/overall running time: 229.9100s / 140150.8139 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.1722
env0_second_0:                 episode reward: 12.8500,                 loss: 1.3918
env1_first_0:                 episode reward: -12.4000,                 loss: nan
env1_second_0:                 episode reward: 12.4000,                 loss: nan
Episode: 14541/30000 (48.4700%),                 avg. length: 1645.4,                last time consumption/overall running time: 202.3110s / 140353.1249 s
env0_first_0:                 episode reward: -13.3500,                 loss: 0.2024
env0_second_0:                 episode reward: 13.3500,                 loss: 1.0728
env1_first_0:                 episode reward: -13.5500,                 loss: nan
env1_second_0:                 episode reward: 13.5500,                 loss: nan
Episode: 14561/30000 (48.5367%),                 avg. length: 1591.4,                last time consumption/overall running time: 203.6903s / 140556.8152 s
env0_first_0:                 episode reward: -15.0500,                 loss: 0.1507
env0_second_0:                 episode reward: 15.0500,                 loss: 1.0673
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 14581/30000 (48.6033%),                 avg. length: 1500.35,                last time consumption/overall running time: 194.1547s / 140750.9699 s
env0_first_0:                 episode reward: -17.0000,                 loss: 0.0988
env0_second_0:                 episode reward: 17.0000,                 loss: 1.1105
env1_first_0:                 episode reward: -16.3000,                 loss: nan
env1_second_0:                 episode reward: 16.3000,                 loss: nan
Episode: 14601/30000 (48.6700%),                 avg. length: 1539.55,                last time consumption/overall running time: 196.5093s / 140947.4792 s
env0_first_0:                 episode reward: -14.7000,                 loss: 0.1455
env0_second_0:                 episode reward: 14.7000,                 loss: 1.0516
env1_first_0:                 episode reward: -16.4000,                 loss: nan
env1_second_0:                 episode reward: 16.4000,                 loss: nan
Episode: 14621/30000 (48.7367%),                 avg. length: 1694.9,                last time consumption/overall running time: 221.3490s / 141168.8282 s
env0_first_0:                 episode reward: -15.6000,                 loss: 0.1295
env0_second_0:                 episode reward: 15.6000,                 loss: 1.0131
env1_first_0:                 episode reward: -14.4500,                 loss: nan
env1_second_0:                 episode reward: 14.4500,                 loss: nan
Episode: 14641/30000 (48.8033%),                 avg. length: 1517.65,                last time consumption/overall running time: 195.1175s / 141363.9457 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.2159
env0_second_0:                 episode reward: 5.7000,                 loss: 1.4698
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 14661/30000 (48.8700%),                 avg. length: 730.8,                last time consumption/overall running time: 101.3721s / 141465.3178 s
env0_first_0:                 episode reward: 19.2500,                 loss: 0.1056
env0_second_0:                 episode reward: -19.2500,                 loss: 1.9668
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 14681/30000 (48.9367%),                 avg. length: 761.05,                last time consumption/overall running time: 104.1249s / 141569.4427 s
env0_first_0:                 episode reward: 20.0500,                 loss: 0.2826
env0_second_0:                 episode reward: -20.0500,                 loss: 1.8270
env1_first_0:                 episode reward: 19.8500,                 loss: nan
env1_second_0:                 episode reward: -19.8500,                 loss: nan
Episode: 14701/30000 (49.0033%),                 avg. length: 730.75,                last time consumption/overall running time: 96.6263s / 141666.0690 s
env0_first_0:                 episode reward: 20.4500,                 loss: -0.0227
env0_second_0:                 episode reward: -20.4500,                 loss: 1.2972
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 14721/30000 (49.0700%),                 avg. length: 730.5,                last time consumption/overall running time: 100.7030s / 141766.7721 s
env0_first_0:                 episode reward: 20.6500,                 loss: -0.0239
env0_second_0:                 episode reward: -20.6500,                 loss: 1.4864
env1_first_0:                 episode reward: 20.5500,                 loss: nan
env1_second_0:                 episode reward: -20.5500,                 loss: nan
Episode: 14741/30000 (49.1367%),                 avg. length: 728.5,                last time consumption/overall running time: 97.3445s / 141864.1166 s
env0_first_0:                 episode reward: 20.6000,                 loss: -0.0585
env0_second_0:                 episode reward: -20.6000,                 loss: 1.5288
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 14761/30000 (49.2033%),                 avg. length: 730.8,                last time consumption/overall running time: 98.4642s / 141962.5807 s
env0_first_0:                 episode reward: 20.6000,                 loss: -0.0647
env0_second_0:                 episode reward: -20.6000,                 loss: 0.9974
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 14781/30000 (49.2700%),                 avg. length: 735.45,                last time consumption/overall running time: 102.3090s / 142064.8897 s
env0_first_0:                 episode reward: 18.6500,                 loss: 0.0086
env0_second_0:                 episode reward: -18.6500,                 loss: 0.9761
env1_first_0:                 episode reward: 18.6000,                 loss: nan
env1_second_0:                 episode reward: -18.6000,                 loss: nan
Episode: 14801/30000 (49.3367%),                 avg. length: 730.55,                last time consumption/overall running time: 100.2141s / 142165.1038 s
env0_first_0:                 episode reward: 20.5000,                 loss: -0.0397
env0_second_0:                 episode reward: -20.5000,                 loss: 0.8739
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 14821/30000 (49.4033%),                 avg. length: 730.3,                last time consumption/overall running time: 100.7530s / 142265.8567 s
env0_first_0:                 episode reward: 20.6000,                 loss: -0.0541
env0_second_0:                 episode reward: -20.6000,                 loss: 0.4486
env1_first_0:                 episode reward: 20.6500,                 loss: nan
env1_second_0:                 episode reward: -20.6500,                 loss: nan
Episode: 14841/30000 (49.4700%),                 avg. length: 728.85,                last time consumption/overall running time: 95.8671s / 142361.7239 s
env0_first_0:                 episode reward: 20.5500,                 loss: -0.0023
env0_second_0:                 episode reward: -20.5500,                 loss: 0.3605
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 14861/30000 (49.5367%),                 avg. length: 1013.1,                last time consumption/overall running time: 134.4522s / 142496.1760 s
env0_first_0:                 episode reward: 13.7000,                 loss: 0.3999
env0_second_0:                 episode reward: -13.7000,                 loss: 2.4919
env1_first_0:                 episode reward: 14.1500,                 loss: nan
env1_second_0:                 episode reward: -14.1500,                 loss: nan
Episode: 14881/30000 (49.6033%),                 avg. length: 764.35,                last time consumption/overall running time: 106.0077s / 142602.1837 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.2202
env0_second_0:                 episode reward: 4.1500,                 loss: 4.7104
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 14901/30000 (49.6700%),                 avg. length: 758.7,                last time consumption/overall running time: 105.6063s / 142707.7900 s
env0_first_0:                 episode reward: 0.7500,                 loss: 0.2045
env0_second_0:                 episode reward: -0.7500,                 loss: 1.9032
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 14921/30000 (49.7367%),                 avg. length: 728.95,                last time consumption/overall running time: 98.1916s / 142805.9816 s
env0_first_0:                 episode reward: 20.7500,                 loss: 0.1092
env0_second_0:                 episode reward: -20.7500,                 loss: 1.1644
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 14941/30000 (49.8033%),                 avg. length: 728.7,                last time consumption/overall running time: 104.1093s / 142910.0909 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.0626
env0_second_0:                 episode reward: -20.6500,                 loss: 0.7712
env1_first_0:                 episode reward: 20.6000,                 loss: nan
env1_second_0:                 episode reward: -20.6000,                 loss: nan
Episode: 14961/30000 (49.8700%),                 avg. length: 728.65,                last time consumption/overall running time: 100.2916s / 143010.3825 s
env0_first_0:                 episode reward: 20.6500,                 loss: 0.0138
env0_second_0:                 episode reward: -20.6500,                 loss: 0.8512
env1_first_0:                 episode reward: 20.7500,                 loss: nan
env1_second_0:                 episode reward: -20.7500,                 loss: nan
Episode: 14981/30000 (49.9367%),                 avg. length: 728.0,                last time consumption/overall running time: 98.4081s / 143108.7906 s
env0_first_0:                 episode reward: 20.8500,                 loss: 0.2115
env0_second_0:                 episode reward: -20.8500,                 loss: 0.7569
env1_first_0:                 episode reward: 20.9500,                 loss: nan
env1_second_0:                 episode reward: -20.9500,                 loss: nan
Episode: 15001/30000 (50.0033%),                 avg. length: 728.0,                last time consumption/overall running time: 98.4497s / 143207.2402 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0629
env0_second_0:                 episode reward: -21.0000,                 loss: 1.1147
env1_first_0:                 episode reward: 20.7000,                 loss: nan
env1_second_0:                 episode reward: -20.7000,                 loss: nan
Episode: 15021/30000 (50.0700%),                 avg. length: 728.0,                last time consumption/overall running time: 102.9802s / 143310.2204 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0144
env0_second_0:                 episode reward: -21.0000,                 loss: 0.4793
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 15041/30000 (50.1367%),                 avg. length: 728.0,                last time consumption/overall running time: 100.2113s / 143410.4317 s
env0_first_0:                 episode reward: 21.0000,                 loss: 0.0314
env0_second_0:                 episode reward: -21.0000,                 loss: 1.3323
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 15061/30000 (50.2033%),                 avg. length: 728.0,                last time consumption/overall running time: 98.4061s / 143508.8378 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0365
env0_second_0:                 episode reward: -21.0000,                 loss: 0.2661
env1_first_0:                 episode reward: 20.8500,                 loss: nan
env1_second_0:                 episode reward: -20.8500,                 loss: nan
Episode: 15081/30000 (50.2700%),                 avg. length: 728.0,                last time consumption/overall running time: 100.8993s / 143609.7371 s
env0_first_0:                 episode reward: 21.0000,                 loss: -0.0183
env0_second_0:                 episode reward: -21.0000,                 loss: 0.5670
env1_first_0:                 episode reward: 20.9000,                 loss: nan
env1_second_0:                 episode reward: -20.9000,                 loss: nan
Episode: 15101/30000 (50.3367%),                 avg. length: 728.0,                last time consumption/overall running time: 99.7833s / 143709.5205 s
env0_first_0:                 episode reward: 20.9500,                 loss: -0.0121
env0_second_0:                 episode reward: -20.9500,                 loss: 0.1893
env1_first_0:                 episode reward: 21.0000,                 loss: nan
env1_second_0:                 episode reward: -21.0000,                 loss: nan
Episode: 15121/30000 (50.4033%),                 avg. length: 822.75,                last time consumption/overall running time: 111.1471s / 143820.6676 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.3253
env0_second_0:                 episode reward: 1.1500,                 loss: 0.5940
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 15141/30000 (50.4700%),                 avg. length: 821.65,                last time consumption/overall running time: 108.5214s / 143929.1889 s
env0_first_0:                 episode reward: -8.6000,                 loss: 0.2013
env0_second_0:                 episode reward: 8.6000,                 loss: 0.7498
env1_first_0:                 episode reward: -8.3500,                 loss: nan
env1_second_0:                 episode reward: 8.3500,                 loss: nan
Episode: 15161/30000 (50.5367%),                 avg. length: 763.3,                last time consumption/overall running time: 105.0364s / 144034.2253 s
env0_first_0:                 episode reward: 4.1500,                 loss: 0.2093
env0_second_0:                 episode reward: -4.1500,                 loss: 0.4835
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 15181/30000 (50.6033%),                 avg. length: 776.4,                last time consumption/overall running time: 104.5837s / 144138.8090 s
env0_first_0:                 episode reward: -19.9000,                 loss: 0.1929
env0_second_0:                 episode reward: 19.9000,                 loss: 1.0507
env1_first_0:                 episode reward: -17.6500,                 loss: nan
env1_second_0:                 episode reward: 17.6500,                 loss: nan
Episode: 15201/30000 (50.6700%),                 avg. length: 818.85,                last time consumption/overall running time: 109.4024s / 144248.2114 s
env0_first_0:                 episode reward: -16.7500,                 loss: 0.2731
env0_second_0:                 episode reward: 16.7500,                 loss: 1.9698
env1_first_0:                 episode reward: -17.7000,                 loss: nan
env1_second_0:                 episode reward: 17.7000,                 loss: nan
Episode: 15221/30000 (50.7367%),                 avg. length: 818.55,                last time consumption/overall running time: 110.0270s / 144358.2384 s
env0_first_0:                 episode reward: -18.7000,                 loss: 0.1880
env0_second_0:                 episode reward: 18.7000,                 loss: 1.6938
env1_first_0:                 episode reward: -17.6000,                 loss: nan
env1_second_0:                 episode reward: 17.6000,                 loss: nan
Episode: 15241/30000 (50.8033%),                 avg. length: 930.4,                last time consumption/overall running time: 125.0659s / 144483.3042 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.3622
env0_second_0:                 episode reward: 12.6500,                 loss: 3.3792
env1_first_0:                 episode reward: -13.3500,                 loss: nan
env1_second_0:                 episode reward: 13.3500,                 loss: nan
Episode: 15261/30000 (50.8700%),                 avg. length: 926.6,                last time consumption/overall running time: 125.2513s / 144608.5555 s
env0_first_0:                 episode reward: -16.8000,                 loss: 0.3075
env0_second_0:                 episode reward: 16.8000,                 loss: 3.8890
env1_first_0:                 episode reward: -16.2000,                 loss: nan
env1_second_0:                 episode reward: 16.2000,                 loss: nan
Episode: 15281/30000 (50.9367%),                 avg. length: 1557.65,                last time consumption/overall running time: 208.0947s / 144816.6502 s
env0_first_0:                 episode reward: -11.9000,                 loss: 0.2342
env0_second_0:                 episode reward: 11.9000,                 loss: 4.5282
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 15301/30000 (51.0033%),                 avg. length: 1110.3,                last time consumption/overall running time: 143.1417s / 144959.7919 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.1619
env0_second_0:                 episode reward: 7.9500,                 loss: 3.5274
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
Episode: 15321/30000 (51.0700%),                 avg. length: 765.15,                last time consumption/overall running time: 108.7823s / 145068.5742 s
env0_first_0:                 episode reward: -6.5500,                 loss: 0.2381
env0_second_0:                 episode reward: 6.5500,                 loss: 1.8173
env1_first_0:                 episode reward: -6.7500,                 loss: nan
env1_second_0:                 episode reward: 6.7500,                 loss: nan
Episode: 15341/30000 (51.1367%),                 avg. length: 1322.8,                last time consumption/overall running time: 175.9400s / 145244.5142 s
env0_first_0:                 episode reward: -11.8000,                 loss: 0.4292
env0_second_0:                 episode reward: 11.8000,                 loss: 2.6215
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 15361/30000 (51.2033%),                 avg. length: 1353.7,                last time consumption/overall running time: 170.5548s / 145415.0691 s
env0_first_0:                 episode reward: -12.5500,                 loss: 0.4398
env0_second_0:                 episode reward: 12.5500,                 loss: 2.4952
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 15381/30000 (51.2700%),                 avg. length: 1326.6,                last time consumption/overall running time: 175.9157s / 145590.9848 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.3559
env0_second_0:                 episode reward: 10.7000,                 loss: 2.1827
env1_first_0:                 episode reward: -13.8000,                 loss: nan
env1_second_0:                 episode reward: 13.8000,                 loss: nan
Episode: 15401/30000 (51.3367%),                 avg. length: 1276.45,                last time consumption/overall running time: 170.9248s / 145761.9096 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.3351
env0_second_0:                 episode reward: 14.3500,                 loss: 2.1770
env1_first_0:                 episode reward: -11.6000,                 loss: nan
env1_second_0:                 episode reward: 11.6000,                 loss: nan
Episode: 15421/30000 (51.4033%),                 avg. length: 1295.65,                last time consumption/overall running time: 163.6850s / 145925.5946 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.3259
env0_second_0:                 episode reward: 13.7500,                 loss: 2.1618
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 15441/30000 (51.4700%),                 avg. length: 1484.5,                last time consumption/overall running time: 187.8037s / 146113.3983 s
env0_first_0:                 episode reward: -13.2000,                 loss: 0.2905
env0_second_0:                 episode reward: 13.2000,                 loss: 1.8131
env1_first_0:                 episode reward: -13.4000,                 loss: nan
env1_second_0:                 episode reward: 13.4000,                 loss: nan
Episode: 15461/30000 (51.5367%),                 avg. length: 1589.15,                last time consumption/overall running time: 205.0333s / 146318.4316 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.2765
env0_second_0:                 episode reward: 12.6000,                 loss: 2.2277
env1_first_0:                 episode reward: -12.7500,                 loss: nan
env1_second_0:                 episode reward: 12.7500,                 loss: nan
Episode: 15481/30000 (51.6033%),                 avg. length: 1650.1,                last time consumption/overall running time: 210.3377s / 146528.7693 s
env0_first_0:                 episode reward: -12.2500,                 loss: 0.2291
env0_second_0:                 episode reward: 12.2500,                 loss: 2.3107
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 15501/30000 (51.6700%),                 avg. length: 1582.0,                last time consumption/overall running time: 201.2345s / 146730.0038 s
env0_first_0:                 episode reward: -14.6000,                 loss: 0.2304
env0_second_0:                 episode reward: 14.6000,                 loss: 1.9471
env1_first_0:                 episode reward: -15.1500,                 loss: nan
env1_second_0:                 episode reward: 15.1500,                 loss: nan
Episode: 15521/30000 (51.7367%),                 avg. length: 1752.25,                last time consumption/overall running time: 220.7031s / 146950.7069 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.2209
env0_second_0:                 episode reward: 10.5500,                 loss: 1.5717
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 15541/30000 (51.8033%),                 avg. length: 1604.3,                last time consumption/overall running time: 203.3479s / 147154.0549 s
env0_first_0:                 episode reward: -15.1500,                 loss: 0.1733
env0_second_0:                 episode reward: 15.1500,                 loss: 0.8896
env1_first_0:                 episode reward: -16.1000,                 loss: nan
env1_second_0:                 episode reward: 16.1000,                 loss: nan
Episode: 15561/30000 (51.8700%),                 avg. length: 1671.5,                last time consumption/overall running time: 218.1032s / 147372.1581 s
env0_first_0:                 episode reward: -14.9000,                 loss: 0.1490
env0_second_0:                 episode reward: 14.9000,                 loss: 0.8224
env1_first_0:                 episode reward: -15.4000,                 loss: nan
env1_second_0:                 episode reward: 15.4000,                 loss: nan
Episode: 15581/30000 (51.9367%),                 avg. length: 1714.0,                last time consumption/overall running time: 214.5041s / 147586.6622 s
env0_first_0:                 episode reward: -16.0500,                 loss: 0.1575
env0_second_0:                 episode reward: 16.0500,                 loss: 0.8358
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 15601/30000 (52.0033%),                 avg. length: 1608.8,                last time consumption/overall running time: 203.1137s / 147789.7759 s
env0_first_0:                 episode reward: -14.3500,                 loss: 0.1734
env0_second_0:                 episode reward: 14.3500,                 loss: 0.7703
env1_first_0:                 episode reward: -15.2000,                 loss: nan
env1_second_0:                 episode reward: 15.2000,                 loss: nan
Episode: 15621/30000 (52.0700%),                 avg. length: 1839.65,                last time consumption/overall running time: 228.1316s / 148017.9076 s
env0_first_0:                 episode reward: -13.7500,                 loss: 0.1766
env0_second_0:                 episode reward: 13.7500,                 loss: 0.8347
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 15641/30000 (52.1367%),                 avg. length: 2138.65,                last time consumption/overall running time: 267.8707s / 148285.7783 s
env0_first_0:                 episode reward: -11.7000,                 loss: 0.1488
env0_second_0:                 episode reward: 11.7000,                 loss: 0.5897
env1_first_0:                 episode reward: -9.3500,                 loss: nan
env1_second_0:                 episode reward: 9.3500,                 loss: nan
Episode: 15661/30000 (52.2033%),                 avg. length: 1969.3,                last time consumption/overall running time: 248.9886s / 148534.7669 s
env0_first_0:                 episode reward: -12.6500,                 loss: 0.1608
env0_second_0:                 episode reward: 12.6500,                 loss: 0.5319
env1_first_0:                 episode reward: -12.5000,                 loss: nan
env1_second_0:                 episode reward: 12.5000,                 loss: nan
Episode: 15681/30000 (52.2700%),                 avg. length: 2001.35,                last time consumption/overall running time: 256.7643s / 148791.5312 s
env0_first_0:                 episode reward: -13.4000,                 loss: 0.1264
env0_second_0:                 episode reward: 13.4000,                 loss: 0.4628
env1_first_0:                 episode reward: -13.2000,                 loss: nan
env1_second_0:                 episode reward: 13.2000,                 loss: nan
Episode: 15701/30000 (52.3367%),                 avg. length: 2000.1,                last time consumption/overall running time: 248.8632s / 149040.3944 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.1486
env0_second_0:                 episode reward: 12.6000,                 loss: 0.7778
env1_first_0:                 episode reward: -14.6500,                 loss: nan
env1_second_0:                 episode reward: 14.6500,                 loss: nan
Episode: 15721/30000 (52.4033%),                 avg. length: 2211.3,                last time consumption/overall running time: 276.3089s / 149316.7033 s
env0_first_0:                 episode reward: -12.0500,                 loss: 0.1419
env0_second_0:                 episode reward: 12.0500,                 loss: 1.5093
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 15741/30000 (52.4700%),                 avg. length: 2184.65,                last time consumption/overall running time: 275.1496s / 149591.8529 s
env0_first_0:                 episode reward: -9.1500,                 loss: 0.1811
env0_second_0:                 episode reward: 9.1500,                 loss: 1.2809
env1_first_0:                 episode reward: -10.3500,                 loss: nan
env1_second_0:                 episode reward: 10.3500,                 loss: nan
Episode: 15761/30000 (52.5367%),                 avg. length: 2257.25,                last time consumption/overall running time: 287.1030s / 149878.9559 s
env0_first_0:                 episode reward: -11.8500,                 loss: 0.1380
env0_second_0:                 episode reward: 11.8500,                 loss: 0.8367
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 15781/30000 (52.6033%),                 avg. length: 2151.5,                last time consumption/overall running time: 274.7923s / 150153.7482 s
env0_first_0:                 episode reward: -13.0000,                 loss: 0.1363
env0_second_0:                 episode reward: 13.0000,                 loss: 0.5309
env1_first_0:                 episode reward: -12.8500,                 loss: nan
env1_second_0:                 episode reward: 12.8500,                 loss: nan
Episode: 15801/30000 (52.6700%),                 avg. length: 2355.5,                last time consumption/overall running time: 291.6577s / 150445.4059 s
env0_first_0:                 episode reward: -10.5500,                 loss: 0.1341
env0_second_0:                 episode reward: 10.5500,                 loss: 1.8888
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 15821/30000 (52.7367%),                 avg. length: 2330.8,                last time consumption/overall running time: 304.4778s / 150749.8837 s
env0_first_0:                 episode reward: -12.4500,                 loss: 0.1300
env0_second_0:                 episode reward: 12.4500,                 loss: 1.5722
env1_first_0:                 episode reward: -12.1500,                 loss: nan
env1_second_0:                 episode reward: 12.1500,                 loss: nan
Episode: 15841/30000 (52.8033%),                 avg. length: 2246.6,                last time consumption/overall running time: 299.5276s / 151049.4113 s
env0_first_0:                 episode reward: -13.2500,                 loss: 0.1166
env0_second_0:                 episode reward: 13.2500,                 loss: 1.4968
env1_first_0:                 episode reward: -14.2000,                 loss: nan
env1_second_0:                 episode reward: 14.2000,                 loss: nan
Episode: 15861/30000 (52.8700%),                 avg. length: 2070.45,                last time consumption/overall running time: 266.3668s / 151315.7781 s
env0_first_0:                 episode reward: 5.9000,                 loss: 0.3549
env0_second_0:                 episode reward: -5.9000,                 loss: 7.3390
env1_first_0:                 episode reward: 6.8000,                 loss: nan
env1_second_0:                 episode reward: -6.8000,                 loss: nan
Episode: 15881/30000 (52.9367%),                 avg. length: 2564.9,                last time consumption/overall running time: 331.2614s / 151647.0396 s
env0_first_0:                 episode reward: -9.4500,                 loss: 0.1572
env0_second_0:                 episode reward: 9.4500,                 loss: 1.6224
env1_first_0:                 episode reward: -10.8000,                 loss: nan
env1_second_0:                 episode reward: 10.8000,                 loss: nan
Episode: 15901/30000 (53.0033%),                 avg. length: 2587.6,                last time consumption/overall running time: 341.2578s / 151988.2974 s
env0_first_0:                 episode reward: -9.5000,                 loss: 0.1267
env0_second_0:                 episode reward: 9.5000,                 loss: 1.8095
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 15921/30000 (53.0700%),                 avg. length: 2778.35,                last time consumption/overall running time: 352.5103s / 152340.8077 s
env0_first_0:                 episode reward: -9.3500,                 loss: 0.1430
env0_second_0:                 episode reward: 9.3500,                 loss: 1.7990
env1_first_0:                 episode reward: -7.7500,                 loss: nan
env1_second_0:                 episode reward: 7.7500,                 loss: nan
Episode: 15941/30000 (53.1367%),                 avg. length: 2603.0,                last time consumption/overall running time: 332.5172s / 152673.3249 s
env0_first_0:                 episode reward: -12.9500,                 loss: 0.1226
env0_second_0:                 episode reward: 12.9500,                 loss: 1.6667
env1_first_0:                 episode reward: -9.9000,                 loss: nan
env1_second_0:                 episode reward: 9.9000,                 loss: nan
Episode: 15961/30000 (53.2033%),                 avg. length: 2569.25,                last time consumption/overall running time: 333.0435s / 153006.3684 s
env0_first_0:                 episode reward: -10.4500,                 loss: 0.1598
env0_second_0:                 episode reward: 10.4500,                 loss: 1.6770
env1_first_0:                 episode reward: -8.6500,                 loss: nan
env1_second_0:                 episode reward: 8.6500,                 loss: nan
Episode: 15981/30000 (53.2700%),                 avg. length: 2731.55,                last time consumption/overall running time: 352.2967s / 153358.6651 s
env0_first_0:                 episode reward: -7.9500,                 loss: 0.1451
env0_second_0:                 episode reward: 7.9500,                 loss: 2.2220
env1_first_0:                 episode reward: -9.4000,                 loss: nan
env1_second_0:                 episode reward: 9.4000,                 loss: nan
Episode: 16001/30000 (53.3367%),                 avg. length: 2650.25,                last time consumption/overall running time: 337.1136s / 153695.7786 s
env0_first_0:                 episode reward: -10.6000,                 loss: 0.1110
env0_second_0:                 episode reward: 10.6000,                 loss: 2.2184
env1_first_0:                 episode reward: -11.3500,                 loss: nan
env1_second_0:                 episode reward: 11.3500,                 loss: nan
Episode: 16021/30000 (53.4033%),                 avg. length: 2819.15,                last time consumption/overall running time: 366.7230s / 154062.5016 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.1169
env0_second_0:                 episode reward: 10.7000,                 loss: 1.9099
env1_first_0:                 episode reward: -11.0000,                 loss: nan
env1_second_0:                 episode reward: 11.0000,                 loss: nan
Episode: 16041/30000 (53.4700%),                 avg. length: 2098.8,                last time consumption/overall running time: 254.3168s / 154316.8184 s
env0_first_0:                 episode reward: 6.4000,                 loss: 0.3662
env0_second_0:                 episode reward: -6.4000,                 loss: 2.1022
env1_first_0:                 episode reward: 5.1500,                 loss: nan
env1_second_0:                 episode reward: -5.1500,                 loss: nan
Episode: 16061/30000 (53.5367%),                 avg. length: 2744.15,                last time consumption/overall running time: 345.4347s / 154662.2530 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.2258
env0_second_0:                 episode reward: 3.1500,                 loss: 1.9929
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 16081/30000 (53.6033%),                 avg. length: 2758.3,                last time consumption/overall running time: 340.3240s / 155002.5770 s
env0_first_0:                 episode reward: -8.5500,                 loss: 0.1854
env0_second_0:                 episode reward: 8.5500,                 loss: 1.9699
env1_first_0:                 episode reward: -7.1000,                 loss: nan
env1_second_0:                 episode reward: 7.1000,                 loss: nan
Episode: 16101/30000 (53.6700%),                 avg. length: 2670.75,                last time consumption/overall running time: 334.1710s / 155336.7480 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.3220
env0_second_0:                 episode reward: 5.7000,                 loss: 1.7647
env1_first_0:                 episode reward: -5.0500,                 loss: nan
env1_second_0:                 episode reward: 5.0500,                 loss: nan
Episode: 16121/30000 (53.7367%),                 avg. length: 871.7,                last time consumption/overall running time: 119.4627s / 155456.2107 s
env0_first_0:                 episode reward: 9.0500,                 loss: 0.6875
env0_second_0:                 episode reward: -9.0500,                 loss: 2.8782
env1_first_0:                 episode reward: 7.7000,                 loss: nan
env1_second_0:                 episode reward: -7.7000,                 loss: nan
Episode: 16141/30000 (53.8033%),                 avg. length: 931.3,                last time consumption/overall running time: 124.2952s / 155580.5059 s
env0_first_0:                 episode reward: 14.2500,                 loss: 0.6110
env0_second_0:                 episode reward: -14.2500,                 loss: 3.5344
env1_first_0:                 episode reward: 11.4500,                 loss: nan
env1_second_0:                 episode reward: -11.4500,                 loss: nan
Episode: 16161/30000 (53.8700%),                 avg. length: 1593.8,                last time consumption/overall running time: 206.7513s / 155787.2571 s
env0_first_0:                 episode reward: 4.1000,                 loss: 0.4624
env0_second_0:                 episode reward: -4.1000,                 loss: 3.2532
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 16181/30000 (53.9367%),                 avg. length: 1939.8,                last time consumption/overall running time: 243.8505s / 156031.1076 s
env0_first_0:                 episode reward: -5.7000,                 loss: 0.2956
env0_second_0:                 episode reward: 5.7000,                 loss: 3.3128
env1_first_0:                 episode reward: -8.3000,                 loss: nan
env1_second_0:                 episode reward: 8.3000,                 loss: nan
Episode: 16201/30000 (54.0033%),                 avg. length: 1906.15,                last time consumption/overall running time: 245.9202s / 156277.0279 s
env0_first_0:                 episode reward: -14.7500,                 loss: 0.1950
env0_second_0:                 episode reward: 14.7500,                 loss: 2.3560
env1_first_0:                 episode reward: -14.2000,                 loss: nan
env1_second_0:                 episode reward: 14.2000,                 loss: nan
Episode: 16221/30000 (54.0700%),                 avg. length: 1930.3,                last time consumption/overall running time: 246.0372s / 156523.0651 s
env0_first_0:                 episode reward: -14.1000,                 loss: 0.1284
env0_second_0:                 episode reward: 14.1000,                 loss: 1.9446
env1_first_0:                 episode reward: -16.1500,                 loss: nan
env1_second_0:                 episode reward: 16.1500,                 loss: nan
Episode: 16241/30000 (54.1367%),                 avg. length: 2084.55,                last time consumption/overall running time: 265.9392s / 156789.0043 s
env0_first_0:                 episode reward: -14.0000,                 loss: 0.1396
env0_second_0:                 episode reward: 14.0000,                 loss: 2.2244
env1_first_0:                 episode reward: -13.0000,                 loss: nan
env1_second_0:                 episode reward: 13.0000,                 loss: nan
Episode: 16261/30000 (54.2033%),                 avg. length: 2061.05,                last time consumption/overall running time: 262.4558s / 157051.4600 s
env0_first_0:                 episode reward: -11.5500,                 loss: 0.1803
env0_second_0:                 episode reward: 11.5500,                 loss: 3.4843
env1_first_0:                 episode reward: -11.2500,                 loss: nan
env1_second_0:                 episode reward: 11.2500,                 loss: nan
Episode: 16281/30000 (54.2700%),                 avg. length: 1972.5,                last time consumption/overall running time: 250.7863s / 157302.2464 s
env0_first_0:                 episode reward: -14.8000,                 loss: 0.1753
env0_second_0:                 episode reward: 14.8000,                 loss: 4.9105
env1_first_0:                 episode reward: -14.4000,                 loss: nan
env1_second_0:                 episode reward: 14.4000,                 loss: nan
Episode: 16301/30000 (54.3367%),                 avg. length: 1758.25,                last time consumption/overall running time: 219.9134s / 157522.1598 s
env0_first_0:                 episode reward: -13.8000,                 loss: 0.2174
env0_second_0:                 episode reward: 13.8000,                 loss: 6.7507
env1_first_0:                 episode reward: -13.9500,                 loss: nan
env1_second_0:                 episode reward: 13.9500,                 loss: nan
Episode: 16321/30000 (54.4033%),                 avg. length: 862.65,                last time consumption/overall running time: 113.4011s / 157635.5609 s
env0_first_0:                 episode reward: 12.4000,                 loss: 0.4632
env0_second_0:                 episode reward: -12.4000,                 loss: 3.2210
env1_first_0:                 episode reward: 12.7000,                 loss: nan
env1_second_0:                 episode reward: -12.7000,                 loss: nan
Episode: 16341/30000 (54.4700%),                 avg. length: 802.7,                last time consumption/overall running time: 105.9054s / 157741.4662 s
env0_first_0:                 episode reward: 10.0000,                 loss: 0.3814
env0_second_0:                 episode reward: -10.0000,                 loss: 1.7790
env1_first_0:                 episode reward: 9.2500,                 loss: nan
env1_second_0:                 episode reward: -9.2500,                 loss: nan
Episode: 16361/30000 (54.5367%),                 avg. length: 850.95,                last time consumption/overall running time: 110.8430s / 157852.3092 s
env0_first_0:                 episode reward: -15.0000,                 loss: 0.3584
env0_second_0:                 episode reward: 15.0000,                 loss: 1.7774
env1_first_0:                 episode reward: -8.9000,                 loss: nan
env1_second_0:                 episode reward: 8.9000,                 loss: nan
Episode: 16381/30000 (54.6033%),                 avg. length: 799.65,                last time consumption/overall running time: 111.1338s / 157963.4430 s
env0_first_0:                 episode reward: -17.1500,                 loss: 0.2640
env0_second_0:                 episode reward: 17.1500,                 loss: 1.5526
env1_first_0:                 episode reward: -17.5000,                 loss: nan
env1_second_0:                 episode reward: 17.5000,                 loss: nan
Episode: 16401/30000 (54.6700%),                 avg. length: 839.7,                last time consumption/overall running time: 113.9660s / 158077.4089 s
env0_first_0:                 episode reward: -14.5500,                 loss: 0.3032
env0_second_0:                 episode reward: 14.5500,                 loss: 1.8577
env1_first_0:                 episode reward: -13.5000,                 loss: nan
env1_second_0:                 episode reward: 13.5000,                 loss: nan
Episode: 16421/30000 (54.7367%),                 avg. length: 1016.2,                last time consumption/overall running time: 134.7124s / 158212.1213 s
env0_first_0:                 episode reward: -15.1000,                 loss: 0.3101
env0_second_0:                 episode reward: 15.1000,                 loss: 1.5755
env1_first_0:                 episode reward: -16.3500,                 loss: nan
env1_second_0:                 episode reward: 16.3500,                 loss: nan
Episode: 16441/30000 (54.8033%),                 avg. length: 1733.15,                last time consumption/overall running time: 223.5855s / 158435.7068 s
env0_first_0:                 episode reward: -8.1500,                 loss: 0.3852
env0_second_0:                 episode reward: 8.1500,                 loss: 1.7247
env1_first_0:                 episode reward: -8.4000,                 loss: nan
env1_second_0:                 episode reward: 8.4000,                 loss: nan
Episode: 16461/30000 (54.8700%),                 avg. length: 1304.75,                last time consumption/overall running time: 168.4183s / 158604.1251 s
env0_first_0:                 episode reward: -12.6000,                 loss: 0.5447
env0_second_0:                 episode reward: 12.6000,                 loss: 2.1857
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 16481/30000 (54.9367%),                 avg. length: 1387.8,                last time consumption/overall running time: 182.0352s / 158786.1603 s
env0_first_0:                 episode reward: -15.2500,                 loss: 0.3018
env0_second_0:                 episode reward: 15.2500,                 loss: 2.6272
env1_first_0:                 episode reward: -15.4500,                 loss: nan
env1_second_0:                 episode reward: 15.4500,                 loss: nan
Episode: 16501/30000 (55.0033%),                 avg. length: 1504.45,                last time consumption/overall running time: 191.4503s / 158977.6107 s
env0_first_0:                 episode reward: -9.5000,                 loss: 0.4440
env0_second_0:                 episode reward: 9.5000,                 loss: 8.4496
env1_first_0:                 episode reward: -10.1500,                 loss: nan
env1_second_0:                 episode reward: 10.1500,                 loss: nan
Episode: 16521/30000 (55.0700%),                 avg. length: 1953.3,                last time consumption/overall running time: 247.6210s / 159225.2317 s
env0_first_0:                 episode reward: -12.8500,                 loss: 0.2350
env0_second_0:                 episode reward: 12.8500,                 loss: 3.9854
env1_first_0:                 episode reward: -13.3000,                 loss: nan
env1_second_0:                 episode reward: 13.3000,                 loss: nan
Episode: 16541/30000 (55.1367%),                 avg. length: 2486.1,                last time consumption/overall running time: 318.6186s / 159543.8503 s
env0_first_0:                 episode reward: -6.2500,                 loss: 0.3147
env0_second_0:                 episode reward: 6.2500,                 loss: 3.3912
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 16561/30000 (55.2033%),                 avg. length: 2980.3,                last time consumption/overall running time: 384.7049s / 159928.5552 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.1363
env0_second_0:                 episode reward: 11.4500,                 loss: 2.4463
env1_first_0:                 episode reward: -11.1500,                 loss: nan
env1_second_0:                 episode reward: 11.1500,                 loss: nan
Episode: 16581/30000 (55.2700%),                 avg. length: 2829.7,                last time consumption/overall running time: 366.2361s / 160294.7913 s
env0_first_0:                 episode reward: -12.8000,                 loss: 0.0987
env0_second_0:                 episode reward: 12.8000,                 loss: 2.0721
env1_first_0:                 episode reward: -10.9000,                 loss: nan
env1_second_0:                 episode reward: 10.9000,                 loss: nan
Episode: 16601/30000 (55.3367%),                 avg. length: 3119.05,                last time consumption/overall running time: 402.2326s / 160697.0239 s
env0_first_0:                 episode reward: -9.5000,                 loss: 0.1152
env0_second_0:                 episode reward: 9.5000,                 loss: 11.0416
env1_first_0:                 episode reward: -8.2000,                 loss: nan
env1_second_0:                 episode reward: 8.2000,                 loss: nan
Episode: 16621/30000 (55.4033%),                 avg. length: 2824.7,                last time consumption/overall running time: 360.8546s / 161057.8786 s
env0_first_0:                 episode reward: -11.6500,                 loss: 0.1162
env0_second_0:                 episode reward: 11.6500,                 loss: 2.8909
env1_first_0:                 episode reward: -12.4500,                 loss: nan
env1_second_0:                 episode reward: 12.4500,                 loss: nan
Episode: 16641/30000 (55.4700%),                 avg. length: 2682.5,                last time consumption/overall running time: 332.9071s / 161390.7856 s
env0_first_0:                 episode reward: -10.3500,                 loss: 0.1168
env0_second_0:                 episode reward: 10.3500,                 loss: 2.4239
env1_first_0:                 episode reward: -12.1000,                 loss: nan
env1_second_0:                 episode reward: 12.1000,                 loss: nan
Episode: 16661/30000 (55.5367%),                 avg. length: 2817.85,                last time consumption/overall running time: 350.0593s / 161740.8449 s
env0_first_0:                 episode reward: -13.1000,                 loss: 0.0977
env0_second_0:                 episode reward: 13.1000,                 loss: 1.9712
env1_first_0:                 episode reward: -11.9000,                 loss: nan
env1_second_0:                 episode reward: 11.9000,                 loss: nan
Episode: 16681/30000 (55.6033%),                 avg. length: 2788.4,                last time consumption/overall running time: 343.6524s / 162084.4974 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.2855
env0_second_0:                 episode reward: 6.0500,                 loss: 2.8837
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 16701/30000 (55.6700%),                 avg. length: 2817.75,                last time consumption/overall running time: 353.3668s / 162437.8641 s
env0_first_0:                 episode reward: -12.0000,                 loss: 0.1019
env0_second_0:                 episode reward: 12.0000,                 loss: 2.9132
env1_first_0:                 episode reward: -9.9500,                 loss: nan
env1_second_0:                 episode reward: 9.9500,                 loss: nan
Episode: 16721/30000 (55.7367%),                 avg. length: 2714.3,                last time consumption/overall running time: 336.4030s / 162774.2672 s
env0_first_0:                 episode reward: -7.6000,                 loss: 0.1620
env0_second_0:                 episode reward: 7.6000,                 loss: 2.9062
env1_first_0:                 episode reward: -6.5000,                 loss: nan
env1_second_0:                 episode reward: 6.5000,                 loss: nan
Episode: 16741/30000 (55.8033%),                 avg. length: 2905.7,                last time consumption/overall running time: 364.9317s / 163139.1989 s
env0_first_0:                 episode reward: -10.6500,                 loss: 0.1209
env0_second_0:                 episode reward: 10.6500,                 loss: 2.5218
env1_first_0:                 episode reward: -10.1000,                 loss: nan
env1_second_0:                 episode reward: 10.1000,                 loss: nan
Episode: 16761/30000 (55.8700%),                 avg. length: 2879.1,                last time consumption/overall running time: 352.8573s / 163492.0562 s
env0_first_0:                 episode reward: -11.4500,                 loss: 0.1092
env0_second_0:                 episode reward: 11.4500,                 loss: 3.9929
env1_first_0:                 episode reward: -9.7000,                 loss: nan
env1_second_0:                 episode reward: 9.7000,                 loss: nan
Episode: 16781/30000 (55.9367%),                 avg. length: 2781.75,                last time consumption/overall running time: 349.3650s / 163841.4212 s
env0_first_0:                 episode reward: -8.9000,                 loss: 0.1085
env0_second_0:                 episode reward: 8.9000,                 loss: 2.3217
env1_first_0:                 episode reward: -11.8500,                 loss: nan
env1_second_0:                 episode reward: 11.8500,                 loss: nan
Episode: 16801/30000 (56.0033%),                 avg. length: 2515.25,                last time consumption/overall running time: 322.5105s / 164163.9317 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.2464
env0_second_0:                 episode reward: -3.1500,                 loss: 2.2337
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 16821/30000 (56.0700%),                 avg. length: 2390.15,                last time consumption/overall running time: 300.8079s / 164464.7396 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.2703
env0_second_0:                 episode reward: -0.5000,                 loss: 2.0991
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 16841/30000 (56.1367%),                 avg. length: 3053.15,                last time consumption/overall running time: 387.5878s / 164852.3274 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.1359
env0_second_0:                 episode reward: 7.2000,                 loss: 1.7678
env1_first_0:                 episode reward: -7.9500,                 loss: nan
env1_second_0:                 episode reward: 7.9500,                 loss: nan
Episode: 16861/30000 (56.2033%),                 avg. length: 2626.2,                last time consumption/overall running time: 335.1836s / 165187.5110 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.3472
env0_second_0:                 episode reward: 2.1500,                 loss: 2.1717
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 16881/30000 (56.2700%),                 avg. length: 2703.75,                last time consumption/overall running time: 336.5543s / 165524.0653 s
env0_first_0:                 episode reward: -11.1500,                 loss: 0.1537
env0_second_0:                 episode reward: 11.1500,                 loss: 2.5068
env1_first_0:                 episode reward: -12.5500,                 loss: nan
env1_second_0:                 episode reward: 12.5500,                 loss: nan
Episode: 16901/30000 (56.3367%),                 avg. length: 2895.2,                last time consumption/overall running time: 370.8391s / 165894.9044 s
env0_first_0:                 episode reward: -10.7000,                 loss: 0.1062
env0_second_0:                 episode reward: 10.7000,                 loss: 4.0403
env1_first_0:                 episode reward: -13.1000,                 loss: nan
env1_second_0:                 episode reward: 13.1000,                 loss: nan
Episode: 16921/30000 (56.4033%),                 avg. length: 2662.85,                last time consumption/overall running time: 333.4717s / 166228.3761 s
env0_first_0:                 episode reward: -12.9000,                 loss: 0.1112
env0_second_0:                 episode reward: 12.9000,                 loss: 3.6486
env1_first_0:                 episode reward: -11.8000,                 loss: nan
env1_second_0:                 episode reward: 11.8000,                 loss: nan
Episode: 16941/30000 (56.4700%),                 avg. length: 2883.75,                last time consumption/overall running time: 368.8981s / 166597.2742 s