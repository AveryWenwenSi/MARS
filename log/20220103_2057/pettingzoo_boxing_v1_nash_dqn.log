pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 84
<mars.env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f14dd217850>
No agent are not learnable.
{'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 3, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'multiprocess': True}
pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
<mars.rl.agents.multiagent.MultiAgent object at 0x7efddcb52090>
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 6
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 3, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'multiprocess': True}
Save models to : /home/zihan/research/MARS/data/model/0/pettingzoo_boxing_v1_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/0/pettingzoo_boxing_v1_nash_dqn.
Process ID: 0, episode: 20/30000 (0.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 337.0666s / 337.0666 s
first_0:                     episode reward: 1.1000
second_0:                     episode reward: -1.1000
Process ID: 0, episode: 40/30000 (0.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 493.5489s / 830.6155 s
first_0:                     episode reward: -5.1500
second_0:                     episode reward: 5.1500
Process ID: 0, episode: 60/30000 (0.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 549.7399s / 1380.3554 s
first_0:                     episode reward: -0.4500
second_0:                     episode reward: 0.4500
Process ID: 0, episode: 80/30000 (0.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 567.3443s / 1947.6997 s
first_0:                     episode reward: -2.2500
second_0:                     episode reward: 2.2500
Process ID: 0, episode: 100/30000 (0.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 572.0407s / 2519.7404 s
first_0:                     episode reward: -1.7000
second_0:                     episode reward: 1.7000
Process ID: 0, episode: 120/30000 (0.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 568.9747s / 3088.7150 s
first_0:                     episode reward: -2.0000
second_0:                     episode reward: 2.0000
Process ID: 0, episode: 140/30000 (0.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 567.4809s / 3656.1959 s
first_0:                     episode reward: -3.8000
second_0:                     episode reward: 3.8000
Process ID: 0, episode: 160/30000 (0.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 571.0537s / 4227.2497 s
first_0:                     episode reward: -2.5500
second_0:                     episode reward: 2.5500
Process ID: 0, episode: 180/30000 (0.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 549.7223s / 4776.9720 s
first_0:                     episode reward: 1.7000
second_0:                     episode reward: -1.7000
Process ID: 0, episode: 200/30000 (0.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.1343s / 5331.1063 s
first_0:                     episode reward: 0.3000
second_0:                     episode reward: -0.3000
Process ID: 0, episode: 220/30000 (0.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 549.8653s / 5880.9716 s
first_0:                     episode reward: -3.2000
second_0:                     episode reward: 3.2000
Process ID: 0, episode: 240/30000 (0.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 549.2198s / 6430.1914 s
first_0:                     episode reward: 0.5500
second_0:                     episode reward: -0.5500
Process ID: 0, episode: 260/30000 (0.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.9332s / 6983.1246 s
first_0:                     episode reward: -0.6500
second_0:                     episode reward: 0.6500
Process ID: 0, episode: 280/30000 (0.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.2682s / 7538.3928 s
first_0:                     episode reward: 0.0500
second_0:                     episode reward: -0.0500
Process ID: 0, episode: 300/30000 (1.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 550.1358s / 8088.5286 s
first_0:                     episode reward: -3.9500
second_0:                     episode reward: 3.9500
Process ID: 0, episode: 320/30000 (1.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 547.7553s / 8636.2839 s
first_0:                     episode reward: -0.5500
second_0:                     episode reward: 0.5500
Process ID: 0, episode: 340/30000 (1.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.3822s / 9187.6661 s
first_0:                     episode reward: 0.5500
second_0:                     episode reward: -0.5500
Process ID: 0, episode: 360/30000 (1.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.2520s / 9741.9181 s
first_0:                     episode reward: -0.7500
second_0:                     episode reward: 0.7500
Process ID: 0, episode: 380/30000 (1.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.8202s / 10293.7383 s
first_0:                     episode reward: -0.9500
second_0:                     episode reward: 0.9500
Process ID: 0, episode: 400/30000 (1.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.7255s / 10845.4639 s
first_0:                     episode reward: -2.5000
second_0:                     episode reward: 2.5000
Process ID: 0, episode: 420/30000 (1.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.1938s / 11398.6577 s
first_0:                     episode reward: -0.2500
second_0:                     episode reward: 0.2500
Process ID: 0, episode: 440/30000 (1.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.3570s / 11951.0147 s
first_0:                     episode reward: 0.8500
second_0:                     episode reward: -0.8500
Process ID: 0, episode: 460/30000 (1.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.7531s / 12504.7678 s
first_0:                     episode reward: -2.6000
second_0:                     episode reward: 2.6000
Process ID: 0, episode: 480/30000 (1.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.2616s / 13056.0295 s
first_0:                     episode reward: -1.6000
second_0:                     episode reward: 1.6000
Process ID: 0, episode: 500/30000 (1.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.7649s / 13609.7944 spygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
<mars.rl.agents.multiagent.MultiAgent object at 0x7efddcb52090>
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 89
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 3, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'multiprocess': True}
Save models to : /home/zihan/research/MARS/data/model/1/pettingzoo_boxing_v1_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/1/pettingzoo_boxing_v1_nash_dqn.
Process ID: 1, episode: 20/30000 (0.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 351.0799s / 351.0799 s
first_0:                     episode reward: -0.6000
second_0:                     episode reward: 0.6000
Process ID: 1, episode: 40/30000 (0.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 518.2429s / 869.3227 s
first_0:                     episode reward: -1.8000
second_0:                     episode reward: 1.8000
Process ID: 1, episode: 60/30000 (0.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 561.1911s / 1430.5139 s
first_0:                     episode reward: -0.6000
second_0:                     episode reward: 0.6000
Process ID: 1, episode: 80/30000 (0.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 563.4013s / 1993.9152 s
first_0:                     episode reward: -0.1000
second_0:                     episode reward: 0.1000
Process ID: 1, episode: 100/30000 (0.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 568.5314s / 2562.4466 s
first_0:                     episode reward: -2.7500
second_0:                     episode reward: 2.7500
Process ID: 1, episode: 120/30000 (0.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 570.3070s / 3132.7536 s
first_0:                     episode reward: 1.0500
second_0:                     episode reward: -1.0500
Process ID: 1, episode: 140/30000 (0.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 566.8865s / 3699.6401 s
first_0:                     episode reward: -0.4000
second_0:                     episode reward: 0.4000
Process ID: 1, episode: 160/30000 (0.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 567.4630s / 4267.1031 s
first_0:                     episode reward: -1.6000
second_0:                     episode reward: 1.6000
Process ID: 1, episode: 180/30000 (0.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 546.3740s / 4813.4771 s
first_0:                     episode reward: 0.3500
second_0:                     episode reward: -0.3500
Process ID: 1, episode: 200/30000 (0.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.1805s / 5370.6576 s
first_0:                     episode reward: -2.2000
second_0:                     episode reward: 2.2000
Process ID: 1, episode: 220/30000 (0.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 550.0627s / 5920.7203 s
first_0:                     episode reward: -0.8000
second_0:                     episode reward: 0.8000
Process ID: 1, episode: 240/30000 (0.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 550.6042s / 6471.3245 s
first_0:                     episode reward: -0.2000
second_0:                     episode reward: 0.2000
Process ID: 1, episode: 260/30000 (0.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.9603s / 7023.2848 s
first_0:                     episode reward: 0.7000
second_0:                     episode reward: -0.7000
Process ID: 1, episode: 280/30000 (0.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.5326s / 7574.8175 s
first_0:                     episode reward: 0.2000
second_0:                     episode reward: -0.2000
Process ID: 1, episode: 300/30000 (1.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 548.7432s / 8123.5607 s
first_0:                     episode reward: -1.0000
second_0:                     episode reward: 1.0000
Process ID: 1, episode: 320/30000 (1.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 548.9172s / 8672.4779 s
first_0:                     episode reward: 0.0500
second_0:                     episode reward: -0.0500
Process ID: 1, episode: 340/30000 (1.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.8468s / 9224.3247 s
first_0:                     episode reward: -0.6000
second_0:                     episode reward: 0.6000
Process ID: 1, episode: 360/30000 (1.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.4661s / 9778.7908 s
first_0:                     episode reward: 0.2000
second_0:                     episode reward: -0.2000
Process ID: 1, episode: 380/30000 (1.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.1893s / 10331.9802 s
first_0:                     episode reward: 0.8500
second_0:                     episode reward: -0.8500
Process ID: 1, episode: 400/30000 (1.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.4328s / 10884.4129 s
first_0:                     episode reward: -0.3500
second_0:                     episode reward: 0.3500
Process ID: 1, episode: 420/30000 (1.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.8158s / 11436.2287 s
first_0:                     episode reward: -1.1500
second_0:                     episode reward: 1.1500
Process ID: 1, episode: 440/30000 (1.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.3623s / 11989.5911 s
first_0:                     episode reward: -1.0500
second_0:                     episode reward: 1.0500
Process ID: 1, episode: 460/30000 (1.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.7065s / 12542.2976 s
first_0:                     episode reward: 0.3000
second_0:                     episode reward: -0.3000
Process ID: 1, episode: 480/30000 (1.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 550.0077s / 13092.3053 s
first_0:                     episode reward: -2.0500
second_0:                     episode reward: 2.0500
Process ID: 1, episode: 500/30000 (1.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.8125s / 13645.1178 spygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
<mars.rl.agents.multiagent.MultiAgent object at 0x7efddcb52090>
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 45
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 3, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'multiprocess': True}
Save models to : /home/zihan/research/MARS/data/model/2/pettingzoo_boxing_v1_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/2/pettingzoo_boxing_v1_nash_dqn.
Process ID: 2, episode: 20/30000 (0.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 348.2746s / 348.2746 s
first_0:                     episode reward: -2.6500
second_0:                     episode reward: 2.6500
Process ID: 2, episode: 40/30000 (0.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 518.3622s / 866.6369 s
first_0:                     episode reward: -1.5500
second_0:                     episode reward: 1.5500
Process ID: 2, episode: 60/30000 (0.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 561.5720s / 1428.2088 s
first_0:                     episode reward: -2.1500
second_0:                     episode reward: 2.1500
Process ID: 2, episode: 80/30000 (0.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 566.9711s / 1995.1799 s
first_0:                     episode reward: -4.0000
second_0:                     episode reward: 4.0000
Process ID: 2, episode: 100/30000 (0.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 571.0455s / 2566.2254 s
first_0:                     episode reward: 0.9500
second_0:                     episode reward: -0.9500
Process ID: 2, episode: 120/30000 (0.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 568.2805s / 3134.5059 s
first_0:                     episode reward: 0.5500
second_0:                     episode reward: -0.5500
Process ID: 2, episode: 140/30000 (0.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 569.0340s / 3703.5399 s
first_0:                     episode reward: -2.2000
second_0:                     episode reward: 2.2000
Process ID: 2, episode: 160/30000 (0.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 568.1315s / 4271.6714 s
first_0:                     episode reward: -2.3000
second_0:                     episode reward: 2.3000
Process ID: 2, episode: 180/30000 (0.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 547.2036s / 4818.8749 s
first_0:                     episode reward: 1.0000
second_0:                     episode reward: -1.0000
Process ID: 2, episode: 200/30000 (0.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.2430s / 5374.1180 s
first_0:                     episode reward: -0.2000
second_0:                     episode reward: 0.2000
Process ID: 2, episode: 220/30000 (0.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 550.8927s / 5925.0106 s
first_0:                     episode reward: -0.3000
second_0:                     episode reward: 0.3000
Process ID: 2, episode: 240/30000 (0.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 549.6093s / 6474.6199 s
first_0:                     episode reward: -1.5500
second_0:                     episode reward: 1.5500
Process ID: 2, episode: 260/30000 (0.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.1290s / 7030.7489 s
first_0:                     episode reward: -0.2500
second_0:                     episode reward: 0.2500
Process ID: 2, episode: 280/30000 (0.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.9804s / 7584.7293 s
first_0:                     episode reward: -1.6500
second_0:                     episode reward: 1.6500
Process ID: 2, episode: 300/30000 (1.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 549.2541s / 8133.9834 s
first_0:                     episode reward: -0.2000
second_0:                     episode reward: 0.2000
Process ID: 2, episode: 320/30000 (1.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 549.4454s / 8683.4288 s
first_0:                     episode reward: -1.1500
second_0:                     episode reward: 1.1500
Process ID: 2, episode: 340/30000 (1.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.7508s / 9235.1796 s
first_0:                     episode reward: -2.2000
second_0:                     episode reward: 2.2000
Process ID: 2, episode: 360/30000 (1.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.5922s / 9789.7719 s
first_0:                     episode reward: -1.9000
second_0:                     episode reward: 1.9000
Process ID: 2, episode: 380/30000 (1.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.0041s / 10341.7760 s
first_0:                     episode reward: -0.4000
second_0:                     episode reward: 0.4000
Process ID: 2, episode: 400/30000 (1.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.2392s / 10893.0152 s
first_0:                     episode reward: -2.0000
second_0:                     episode reward: 2.0000
Process ID: 2, episode: 420/30000 (1.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.8641s / 11444.8793 s
first_0:                     episode reward: 0.1000
second_0:                     episode reward: -0.1000
Process ID: 2, episode: 440/30000 (1.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.6212s / 12002.5005 s
first_0:                     episode reward: 0.4000
second_0:                     episode reward: -0.4000
Process ID: 2, episode: 460/30000 (1.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.5187s / 12556.0193 s
first_0:                     episode reward: -1.5000
second_0:                     episode reward: 1.5000
Process ID: 2, episode: 480/30000 (1.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.9996s / 13110.0189 s
first_0:                     episode reward: -2.0000
second_0:                     episode reward: 2.0000
Process ID: 2, episode: 500/30000 (1.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.2114s / 13665.2303 s
first_0:                     episode reward: -0.5500
second_0:                     episode reward: 0.5500
Process ID: 0, episode: 520/30000 (1.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.9254s / 14164.7197 s
first_0:                     episode reward: -2.4500
second_0:                     episode reward: 2.4500
Process ID: 0, episode: 540/30000 (1.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.1549s / 14718.8746 s
first_0:                     episode reward: 0.7500
second_0:                     episode reward: -0.7500
Process ID: 0, episode: 560/30000 (1.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.8303s / 15274.7050 s
first_0:                     episode reward: -2.9500
second_0:                     episode reward: 2.9500
Process ID: 0, episode: 580/30000 (1.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.7979s / 15831.5029 s
first_0:                     episode reward: -1.7500
second_0:                     episode reward: 1.7500
Process ID: 0, episode: 600/30000 (2.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.6778s / 16387.1807 s
first_0:                     episode reward: -0.6500
second_0:                     episode reward: 0.6500
Process ID: 0, episode: 620/30000 (2.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.3508s / 16943.5314 s
first_0:                     episode reward: -1.7000
second_0:                     episode reward: 1.7000
Process ID: 0, episode: 640/30000 (2.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.4662s / 17499.9976 s
first_0:                     episode reward: -2.0000
second_0:                     episode reward: 2.0000
Process ID: 0, episode: 660/30000 (2.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.6586s / 18057.6563 s
first_0:                     episode reward: -1.7000
second_0:                     episode reward: 1.7000
Process ID: 0, episode: 680/30000 (2.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.5368s / 18612.1930 s
first_0:                     episode reward: -3.1000
second_0:                     episode reward: 3.1000
Process ID: 0, episode: 700/30000 (2.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.7816s / 19165.9746 s
first_0:                     episode reward: -3.8500
second_0:                     episode reward: 3.8500
Process ID: 0, episode: 720/30000 (2.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.5968s / 19720.5714 s
first_0:                     episode reward: -1.4000
second_0:                     episode reward: 1.4000
Process ID: 0, episode: 740/30000 (2.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.9134s / 20274.4848 s
first_0:                     episode reward: -3.8000
second_0:                     episode reward: 3.8000
Process ID: 0, episode: 760/30000 (2.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 558.8998s / 20833.3846 s
first_0:                     episode reward: 0.2500
second_0:                     episode reward: -0.2500
Process ID: 0, episode: 780/30000 (2.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.7332s / 21387.1178 s
first_0:                     episode reward: -1.4000
second_0:                     episode reward: 1.4000
Process ID: 0, episode: 800/30000 (2.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.7809s / 21944.8987 s
first_0:                     episode reward: 0.8000
second_0:                     episode reward: -0.8000
Process ID: 0, episode: 820/30000 (2.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.7183s / 22501.6171 s
first_0:                     episode reward: 0.2500
second_0:                     episode reward: -0.2500
Process ID: 0, episode: 840/30000 (2.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 558.0670s / 23059.6840 s
first_0:                     episode reward: -1.2500
second_0:                     episode reward: 1.2500
Process ID: 0, episode: 860/30000 (2.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.4909s / 23616.1750 s
first_0:                     episode reward: -2.3500
second_0:                     episode reward: 2.3500
Process ID: 0, episode: 880/30000 (2.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.5495s / 24168.7245 s
first_0:                     episode reward: -2.1500
second_0:                     episode reward: 2.1500
Process ID: 0, episode: 900/30000 (3.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.0306s / 24722.7550 s
first_0:                     episode reward: -2.6000
second_0:                     episode reward: 2.6000
Process ID: 0, episode: 920/30000 (3.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.4982s / 25275.2533 s
first_0:                     episode reward: 0.4000
second_0:                     episode reward: -0.4000
Process ID: 0, episode: 940/30000 (3.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.9549s / 25828.2082 s
first_0:                     episode reward: 0.4000
second_0:                     episode reward: -0.4000
Process ID: 0, episode: 960/30000 (3.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 558.0527s / 26386.2609 s
first_0:                     episode reward: 0.1500
second_0:                     episode reward: -0.1500
Process ID: 0, episode: 980/30000 (3.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.8003s / 26940.0612 s
first_0:                     episode reward: -0.6500
second_0:                     episode reward: 0.6500
Process ID: 0, episode: 1000/30000 (3.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.8161s / 27495.8773 s
first_0:                     episode reward: -0.1000
second_0:                     episode reward: 0.1000
Process ID: 0, episode: 1020/30000 (3.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.3408s / 28049.2181 s
first_0:                     episode reward: -2.0500
second_0:                     episode reward: 2.0500
Process ID: 0, episode: 1040/30000 (3.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.8493s / 28602.0674 s
first_0:                     episode reward: -2.1500
second_0:                     episode reward: 2.1500
Process ID: 0, episode: 1060/30000 (3.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.7439s / 29157.8113 s
first_0:                     episode reward: -1.4000
second_0:                     episode reward: 1.4000
Process ID: 0, episode: 1080/30000 (3.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.8762s / 29709.6875 s
first_0:                     episode reward: -1.6500
second_0:                     episode reward: 1.6500
first_0:                     episode reward: -2.7000
second_0:                     episode reward: 2.7000
Process ID: 1, episode: 520/30000 (1.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.9120s / 14199.0298 s
first_0:                     episode reward: -0.2000
second_0:                     episode reward: 0.2000
Process ID: 1, episode: 540/30000 (1.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.9874s / 14753.0172 s
first_0:                     episode reward: -0.8000
second_0:                     episode reward: 0.8000
Process ID: 1, episode: 560/30000 (1.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.8678s / 15306.8851 s
first_0:                     episode reward: -3.4000
second_0:                     episode reward: 3.4000
Process ID: 1, episode: 580/30000 (1.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.4044s / 15863.2895 s
first_0:                     episode reward: -1.0500
second_0:                     episode reward: 1.0500
Process ID: 1, episode: 600/30000 (2.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.2576s / 16419.5471 s
first_0:                     episode reward: -1.7000
second_0:                     episode reward: 1.7000
Process ID: 1, episode: 620/30000 (2.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.7906s / 16972.3378 s
first_0:                     episode reward: -1.2000
second_0:                     episode reward: 1.2000
Process ID: 1, episode: 640/30000 (2.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.1765s / 17528.5143 s
first_0:                     episode reward: -1.3000
second_0:                     episode reward: 1.3000
Process ID: 1, episode: 660/30000 (2.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.1549s / 18083.6692 s
first_0:                     episode reward: -1.7000
second_0:                     episode reward: 1.7000
Process ID: 1, episode: 680/30000 (2.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.0590s / 18638.7282 s
first_0:                     episode reward: -3.1000
second_0:                     episode reward: 3.1000
Process ID: 1, episode: 700/30000 (2.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.0650s / 19193.7932 s
first_0:                     episode reward: 0.7500
second_0:                     episode reward: -0.7500
Process ID: 1, episode: 720/30000 (2.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.0630s / 19748.8562 s
first_0:                     episode reward: -0.6000
second_0:                     episode reward: 0.6000
Process ID: 1, episode: 740/30000 (2.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.3015s / 20302.1577 s
first_0:                     episode reward: -1.3500
second_0:                     episode reward: 1.3500
Process ID: 1, episode: 760/30000 (2.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.0902s / 20859.2479 s
first_0:                     episode reward: 0.8000
second_0:                     episode reward: -0.8000
Process ID: 1, episode: 780/30000 (2.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 550.6590s / 21409.9069 s
first_0:                     episode reward: -0.4500
second_0:                     episode reward: 0.4500
Process ID: 1, episode: 800/30000 (2.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.7787s / 21966.6856 s
first_0:                     episode reward: -0.2000
second_0:                     episode reward: 0.2000
Process ID: 1, episode: 820/30000 (2.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.6569s / 22522.3425 s
first_0:                     episode reward: -1.8000
second_0:                     episode reward: 1.8000
Process ID: 1, episode: 840/30000 (2.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.6930s / 23080.0356 s
first_0:                     episode reward: -1.7000
second_0:                     episode reward: 1.7000
Process ID: 1, episode: 860/30000 (2.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.9159s / 23633.9515 s
first_0:                     episode reward: -1.2500
second_0:                     episode reward: 1.2500
Process ID: 1, episode: 880/30000 (2.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.3885s / 24186.3400 s
first_0:                     episode reward: 0.8500
second_0:                     episode reward: -0.8500
Process ID: 1, episode: 900/30000 (3.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 549.6864s / 24736.0264 s
first_0:                     episode reward: 1.2000
second_0:                     episode reward: -1.2000
Process ID: 1, episode: 920/30000 (3.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.8325s / 25287.8588 s
first_0:                     episode reward: -1.4000
second_0:                     episode reward: 1.4000
Process ID: 1, episode: 940/30000 (3.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.2760s / 25839.1349 s
first_0:                     episode reward: -1.5000
second_0:                     episode reward: 1.5000
Process ID: 1, episode: 960/30000 (3.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.0159s / 26393.1508 s
first_0:                     episode reward: 0.0000
second_0:                     episode reward: 0.0000
Process ID: 1, episode: 980/30000 (3.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.1899s / 26950.3407 s
first_0:                     episode reward: 0.4500
second_0:                     episode reward: -0.4500
Process ID: 1, episode: 1000/30000 (3.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.3575s / 27505.6982 s
first_0:                     episode reward: -1.5000
second_0:                     episode reward: 1.5000
Process ID: 1, episode: 1020/30000 (3.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.4209s / 28061.1191 s
first_0:                     episode reward: 0.8500
second_0:                     episode reward: -0.8500
Process ID: 1, episode: 1040/30000 (3.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.2866s / 28614.4057 s
first_0:                     episode reward: -1.7000
second_0:                     episode reward: 1.7000
Process ID: 1, episode: 1060/30000 (3.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.8817s / 29171.2875 s
first_0:                     episode reward: -1.0000
second_0:                     episode reward: 1.0000
Process ID: 1, episode: 1080/30000 (3.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.2602s / 29724.5477 s
first_0:                     episode reward: 0.2500
second_0:                     episode reward: -0.2500
first_0:                     episode reward: -1.6500
second_0:                     episode reward: 1.6500
Process ID: 2, episode: 520/30000 (1.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 558.6500s / 14223.8803 s
first_0:                     episode reward: -0.6000
second_0:                     episode reward: 0.6000
Process ID: 2, episode: 540/30000 (1.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.9831s / 14779.8634 s
first_0:                     episode reward: -1.4000
second_0:                     episode reward: 1.4000
Process ID: 2, episode: 560/30000 (1.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.1873s / 15332.0507 s
first_0:                     episode reward: 0.8500
second_0:                     episode reward: -0.8500
Process ID: 2, episode: 580/30000 (1.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.5651s / 15887.6158 s
first_0:                     episode reward: -1.3500
second_0:                     episode reward: 1.3500
Process ID: 2, episode: 600/30000 (2.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 558.6906s / 16446.3064 s
first_0:                     episode reward: -1.3000
second_0:                     episode reward: 1.3000
Process ID: 2, episode: 620/30000 (2.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.3843s / 16999.6907 s
first_0:                     episode reward: -1.4500
second_0:                     episode reward: 1.4500
Process ID: 2, episode: 640/30000 (2.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 558.2443s / 17557.9350 s
first_0:                     episode reward: 1.0000
second_0:                     episode reward: -1.0000
Process ID: 2, episode: 660/30000 (2.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.2333s / 18115.1683 s
first_0:                     episode reward: -0.8000
second_0:                     episode reward: 0.8000
Process ID: 2, episode: 680/30000 (2.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.3966s / 18668.5649 s
first_0:                     episode reward: 1.2000
second_0:                     episode reward: -1.2000
Process ID: 2, episode: 700/30000 (2.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.8112s / 19223.3761 s
first_0:                     episode reward: -1.1000
second_0:                     episode reward: 1.1000
Process ID: 2, episode: 720/30000 (2.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.7467s / 19780.1228 s
first_0:                     episode reward: -0.6000
second_0:                     episode reward: 0.6000
Process ID: 2, episode: 740/30000 (2.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.7350s / 20333.8577 s
first_0:                     episode reward: -1.6500
second_0:                     episode reward: 1.6500
Process ID: 2, episode: 760/30000 (2.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 558.7003s / 20892.5580 s
first_0:                     episode reward: 0.7500
second_0:                     episode reward: -0.7500
Process ID: 2, episode: 780/30000 (2.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.2505s / 21443.8086 s
first_0:                     episode reward: 0.5000
second_0:                     episode reward: -0.5000
Process ID: 2, episode: 800/30000 (2.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.6758s / 22000.4844 s
first_0:                     episode reward: 0.1000
second_0:                     episode reward: -0.1000
Process ID: 2, episode: 820/30000 (2.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.4721s / 22556.9565 s
first_0:                     episode reward: 1.5000
second_0:                     episode reward: -1.5000
Process ID: 2, episode: 840/30000 (2.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.3710s / 23113.3275 s
first_0:                     episode reward: -2.6000
second_0:                     episode reward: 2.6000
Process ID: 2, episode: 860/30000 (2.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.6749s / 23667.0024 s
first_0:                     episode reward: -2.4000
second_0:                     episode reward: 2.4000
Process ID: 2, episode: 880/30000 (2.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.5668s / 24218.5691 s
first_0:                     episode reward: -0.8000
second_0:                     episode reward: 0.8000
Process ID: 2, episode: 900/30000 (3.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.4029s / 24769.9721 s
first_0:                     episode reward: -1.5000
second_0:                     episode reward: 1.5000
Process ID: 2, episode: 920/30000 (3.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.3114s / 25323.2834 s
first_0:                     episode reward: -0.1500
second_0:                     episode reward: 0.1500
Process ID: 2, episode: 940/30000 (3.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.3469s / 25876.6303 s
first_0:                     episode reward: 0.5000
second_0:                     episode reward: -0.5000
Process ID: 2, episode: 960/30000 (3.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.3900s / 26433.0203 s
first_0:                     episode reward: -1.5000
second_0:                     episode reward: 1.5000
Process ID: 2, episode: 980/30000 (3.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.1164s / 26989.1367 s
first_0:                     episode reward: -2.2000
second_0:                     episode reward: 2.2000
Process ID: 2, episode: 1000/30000 (3.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.3708s / 27545.5075 s
first_0:                     episode reward: -0.4000
second_0:                     episode reward: 0.4000
Process ID: 2, episode: 1020/30000 (3.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.4017s / 28096.9092 s
first_0:                     episode reward: 0.8000
second_0:                     episode reward: -0.8000
Process ID: 2, episode: 1040/30000 (3.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.2507s / 28653.1599 s
first_0:                     episode reward: -3.7000
second_0:                     episode reward: 3.7000
Process ID: 2, episode: 1060/30000 (3.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.8888s / 29207.0487 s
first_0:                     episode reward: 0.4500
second_0:                     episode reward: -0.4500
Process ID: 2, episode: 1080/30000 (3.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.0873s / 29760.1360 s
first_0:                     episode reward: -1.1500
second_0:                     episode reward: 1.1500
Process ID: 1, episode: 1100/30000 (3.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.2890s / 30279.8367 s
first_0:                     episode reward: -1.0500
second_0:                     episode reward: 1.0500
Process ID: 1, episode: 1120/30000 (3.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.2098s / 30835.0465 s
first_0:                     episode reward: -0.7500
second_0:                     episode reward: 0.7500
Process ID: 1, episode: 1140/30000 (3.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.3143s / 31389.3608 s
first_0:                     episode reward: -4.6000
second_0:                     episode reward: 4.6000
Process ID: 1, episode: 1160/30000 (3.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.7776s / 31946.1384 s
first_0:                     episode reward: -1.0000
second_0:                     episode reward: 1.0000
Process ID: 1, episode: 1180/30000 (3.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 558.5945s / 32504.7329 s
first_0:                     episode reward: 0.1000
second_0:                     episode reward: -0.1000
Process ID: 1, episode: 1200/30000 (4.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.8705s / 33058.6035 s
first_0:                     episode reward: 0.0500
second_0:                     episode reward: -0.0500
Process ID: 1, episode: 1220/30000 (4.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.3196s / 33614.9231 s
first_0:                     episode reward: -3.3000
second_0:                     episode reward: 3.3000
Process ID: 1, episode: 1240/30000 (4.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.5325s / 34168.4556 s
first_0:                     episode reward: -0.7500
second_0:                     episode reward: 0.7500
Process ID: 1, episode: 1260/30000 (4.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 558.4273s / 34726.8828 s
first_0:                     episode reward: 0.5500
second_0:                     episode reward: -0.5500
Process ID: 1, episode: 1280/30000 (4.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.0937s / 35279.9765 s
first_0:                     episode reward: 0.5000
second_0:                     episode reward: -0.5000
Process ID: 1, episode: 1300/30000 (4.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 558.3891s / 35838.3656 s
first_0:                     episode reward: -2.2000
second_0:                     episode reward: 2.2000
Process ID: 1, episode: 1320/30000 (4.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.2430s / 36393.6086 s
first_0:                     episode reward: -3.3500
second_0:                     episode reward: 3.3500
Process ID: 1, episode: 1340/30000 (4.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.5986s / 36947.2072 s
first_0:                     episode reward: 0.1000
second_0:                     episode reward: -0.1000
Process ID: 1, episode: 1360/30000 (4.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.3683s / 37500.5755 s
first_0:                     episode reward: -2.2000
second_0:                     episode reward: 2.2000
Process ID: 1, episode: 1380/30000 (4.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.1280s / 38057.7034 s
first_0:                     episode reward: -1.8500
second_0:                     episode reward: 1.8500
Process ID: 1, episode: 1400/30000 (4.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 559.1139s / 38616.8174 s
first_0:                     episode reward: -1.7000
second_0:                     episode reward: 1.7000
Process ID: 1, episode: 1420/30000 (4.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.2176s / 39174.0350 s
first_0:                     episode reward: -1.0500
second_0:                     episode reward: 1.0500
Process ID: 1, episode: 1440/30000 (4.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.6058s / 39725.6408 s
first_0:                     episode reward: -0.8000
second_0:                     episode reward: 0.8000
Process ID: 1, episode: 1460/30000 (4.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.1084s / 40279.7492 s
first_0:                     episode reward: -0.3500
second_0:                     episode reward: 0.3500
Process ID: 1, episode: 1480/30000 (4.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.5320s / 40834.2812 s
first_0:                     episode reward: -0.5500
second_0:                     episode reward: 0.5500
Process ID: 1, episode: 1500/30000 (5.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.4046s / 41389.6858 s
first_0:                     episode reward: -3.6000
second_0:                     episode reward: 3.6000
Process ID: 1, episode: 1520/30000 (5.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.2306s / 41943.9164 s
first_0:                     episode reward: -0.3500
second_0:                     episode reward: 0.3500
Process ID: 1, episode: 1540/30000 (5.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.1149s / 42495.0313 s
first_0:                     episode reward: -0.9500
second_0:                     episode reward: 0.9500
Process ID: 1, episode: 1560/30000 (5.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.5294s / 43049.5608 s
first_0:                     episode reward: 0.7500
second_0:                     episode reward: -0.7500
Process ID: 1, episode: 1580/30000 (5.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.0504s / 43601.6112 s
first_0:                     episode reward: -1.5500
second_0:                     episode reward: 1.5500
Process ID: 1, episode: 1600/30000 (5.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.2966s / 44152.9078 s
first_0:                     episode reward: -1.0500
second_0:                     episode reward: 1.0500
Process ID: 1, episode: 1620/30000 (5.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.1580s / 44704.0658 s
first_0:                     episode reward: -1.3000
second_0:                     episode reward: 1.3000
Process ID: 1, episode: 1640/30000 (5.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.3061s / 45257.3719 s
first_0:                     episode reward: 0.8500
second_0:                     episode reward: -0.8500
Process ID: 1, episode: 1660/30000 (5.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.2849s / 45814.6569 s
first_0:                     episode reward: -3.5000
second_0:                     episode reward: 3.5000
Process ID: 1, episode: 1680/30000 (5.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.3503s / 46370.0071 s
Process ID: 0, episode: 1100/30000 (3.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.0466s / 30266.7341 s
first_0:                     episode reward: -2.1000
second_0:                     episode reward: 2.1000
Process ID: 0, episode: 1120/30000 (3.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.5750s / 30824.3091 s
first_0:                     episode reward: -2.6500
second_0:                     episode reward: 2.6500
Process ID: 0, episode: 1140/30000 (3.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.1157s / 31379.4248 s
first_0:                     episode reward: -2.1500
second_0:                     episode reward: 2.1500
Process ID: 0, episode: 1160/30000 (3.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.8245s / 31937.2492 s
first_0:                     episode reward: -0.2500
second_0:                     episode reward: 0.2500
Process ID: 0, episode: 1180/30000 (3.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 561.4416s / 32498.6908 s
first_0:                     episode reward: -1.6500
second_0:                     episode reward: 1.6500
Process ID: 0, episode: 1200/30000 (4.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.9284s / 33056.6192 s
first_0:                     episode reward: 0.5000
second_0:                     episode reward: -0.5000
Process ID: 0, episode: 1220/30000 (4.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.6883s / 33614.3075 s
first_0:                     episode reward: -0.3000
second_0:                     episode reward: 0.3000
Process ID: 0, episode: 1240/30000 (4.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.9377s / 34172.2452 s
first_0:                     episode reward: -1.3000
second_0:                     episode reward: 1.3000
Process ID: 0, episode: 1260/30000 (4.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.4804s / 34729.7256 s
first_0:                     episode reward: -0.7000
second_0:                     episode reward: 0.7000
Process ID: 0, episode: 1280/30000 (4.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.0271s / 35284.7527 s
first_0:                     episode reward: -0.7000
second_0:                     episode reward: 0.7000
Process ID: 0, episode: 1300/30000 (4.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 558.6640s / 35843.4167 s
first_0:                     episode reward: -1.5500
second_0:                     episode reward: 1.5500
Process ID: 0, episode: 1320/30000 (4.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.8580s / 36398.2747 s
first_0:                     episode reward: 0.7000
second_0:                     episode reward: -0.7000
Process ID: 0, episode: 1340/30000 (4.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.5031s / 36952.7778 s
first_0:                     episode reward: -0.2000
second_0:                     episode reward: 0.2000
Process ID: 0, episode: 1360/30000 (4.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.1395s / 37508.9173 s
first_0:                     episode reward: -0.8500
second_0:                     episode reward: 0.8500
Process ID: 0, episode: 1380/30000 (4.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 558.9179s / 38067.8352 s
first_0:                     episode reward: -0.4500
second_0:                     episode reward: 0.4500
Process ID: 0, episode: 1400/30000 (4.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.2662s / 38625.1014 s
first_0:                     episode reward: 1.7000
second_0:                     episode reward: -1.7000
Process ID: 0, episode: 1420/30000 (4.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.3517s / 39182.4531 s
first_0:                     episode reward: -0.1000
second_0:                     episode reward: 0.1000
Process ID: 0, episode: 1440/30000 (4.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.3732s / 39736.8263 s
first_0:                     episode reward: -0.4500
second_0:                     episode reward: 0.4500
Process ID: 0, episode: 1460/30000 (4.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.8937s / 40292.7200 s
first_0:                     episode reward: 2.2000
second_0:                     episode reward: -2.2000
Process ID: 0, episode: 1480/30000 (4.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.3761s / 40849.0962 s
first_0:                     episode reward: -1.7000
second_0:                     episode reward: 1.7000
Process ID: 0, episode: 1500/30000 (5.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.0472s / 41406.1434 s
first_0:                     episode reward: -3.0500
second_0:                     episode reward: 3.0500
Process ID: 0, episode: 1520/30000 (5.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.4264s / 41963.5698 s
first_0:                     episode reward: 1.1000
second_0:                     episode reward: -1.1000
Process ID: 0, episode: 1540/30000 (5.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.9873s / 42516.5571 s
first_0:                     episode reward: -1.2500
second_0:                     episode reward: 1.2500
Process ID: 0, episode: 1560/30000 (5.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.0830s / 43071.6401 s
first_0:                     episode reward: -0.4500
second_0:                     episode reward: 0.4500
Process ID: 0, episode: 1580/30000 (5.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.6347s / 43626.2748 s
first_0:                     episode reward: 2.9500
second_0:                     episode reward: -2.9500
Process ID: 0, episode: 1600/30000 (5.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.5120s / 44178.7869 s
first_0:                     episode reward: -1.1000
second_0:                     episode reward: 1.1000
Process ID: 0, episode: 1620/30000 (5.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.0748s / 44731.8617 s
first_0:                     episode reward: -0.4500
second_0:                     episode reward: 0.4500
Process ID: 0, episode: 1640/30000 (5.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.7337s / 45284.5954 s
first_0:                     episode reward: -1.6500
second_0:                     episode reward: 1.6500
Process ID: 0, episode: 1660/30000 (5.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.9002s / 45840.4956 s
first_0:                     episode reward: -0.2000
second_0:                     episode reward: 0.2000
Process ID: 0, episode: 1680/30000 (5.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 558.3681s / 46398.8637 s
Process ID: 2, episode: 1100/30000 (3.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.0465s / 30313.1825 s
first_0:                     episode reward: -1.6500
second_0:                     episode reward: 1.6500
Process ID: 2, episode: 1120/30000 (3.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.7417s / 30869.9242 s
first_0:                     episode reward: -0.6000
second_0:                     episode reward: 0.6000
Process ID: 2, episode: 1140/30000 (3.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.3896s / 31424.3138 s
first_0:                     episode reward: -1.3000
second_0:                     episode reward: 1.3000
Process ID: 2, episode: 1160/30000 (3.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.4339s / 31981.7478 s
first_0:                     episode reward: -1.6000
second_0:                     episode reward: 1.6000
Process ID: 2, episode: 1180/30000 (3.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 559.6869s / 32541.4346 s
first_0:                     episode reward: 0.1000
second_0:                     episode reward: -0.1000
Process ID: 2, episode: 1200/30000 (4.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.7305s / 33095.1651 s
first_0:                     episode reward: -1.8000
second_0:                     episode reward: 1.8000
Process ID: 2, episode: 1220/30000 (4.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.8369s / 33651.0020 s
first_0:                     episode reward: 1.6000
second_0:                     episode reward: -1.6000
Process ID: 2, episode: 1240/30000 (4.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.2548s / 34204.2569 s
first_0:                     episode reward: 0.5500
second_0:                     episode reward: -0.5500
Process ID: 2, episode: 1260/30000 (4.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 558.6267s / 34762.8835 s
first_0:                     episode reward: -1.5500
second_0:                     episode reward: 1.5500
Process ID: 2, episode: 1280/30000 (4.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.0270s / 35314.9105 s
first_0:                     episode reward: 1.9500
second_0:                     episode reward: -1.9500
Process ID: 2, episode: 1300/30000 (4.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.9623s / 35871.8728 s
first_0:                     episode reward: -0.1000
second_0:                     episode reward: 0.1000
Process ID: 2, episode: 1320/30000 (4.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.5039s / 36424.3767 s
first_0:                     episode reward: 0.8500
second_0:                     episode reward: -0.8500
Process ID: 2, episode: 1340/30000 (4.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 549.9489s / 36974.3255 s
first_0:                     episode reward: -2.2500
second_0:                     episode reward: 2.2500
Process ID: 2, episode: 1360/30000 (4.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.5724s / 37527.8979 s
first_0:                     episode reward: -0.5000
second_0:                     episode reward: 0.5000
Process ID: 2, episode: 1380/30000 (4.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.9285s / 38085.8264 s
first_0:                     episode reward: -0.0500
second_0:                     episode reward: 0.0500
Process ID: 2, episode: 1400/30000 (4.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.3340s / 38642.1604 s
first_0:                     episode reward: -2.1000
second_0:                     episode reward: 2.1000
Process ID: 2, episode: 1420/30000 (4.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.8487s / 39199.0091 s
first_0:                     episode reward: -1.3500
second_0:                     episode reward: 1.3500
Process ID: 2, episode: 1440/30000 (4.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 550.3243s / 39749.3334 s
first_0:                     episode reward: -0.3500
second_0:                     episode reward: 0.3500
Process ID: 2, episode: 1460/30000 (4.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.9224s / 40306.2558 s
first_0:                     episode reward: -1.5000
second_0:                     episode reward: 1.5000
Process ID: 2, episode: 1480/30000 (4.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.1295s / 40859.3853 s
first_0:                     episode reward: -1.4000
second_0:                     episode reward: 1.4000
Process ID: 2, episode: 1500/30000 (5.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.5827s / 41413.9680 s
first_0:                     episode reward: -0.5500
second_0:                     episode reward: 0.5500
Process ID: 2, episode: 1520/30000 (5.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.4977s / 41969.4656 s
first_0:                     episode reward: -0.4000
second_0:                     episode reward: 0.4000
Process ID: 2, episode: 1540/30000 (5.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.0580s / 42525.5237 s
first_0:                     episode reward: -1.7000
second_0:                     episode reward: 1.7000
Process ID: 2, episode: 1560/30000 (5.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.6608s / 43079.1844 s
first_0:                     episode reward: -3.6500
second_0:                     episode reward: 3.6500
Process ID: 2, episode: 1580/30000 (5.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.6965s / 43630.8809 s
first_0:                     episode reward: -0.8000
second_0:                     episode reward: 0.8000
Process ID: 2, episode: 1600/30000 (5.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.5092s / 44184.3901 s
first_0:                     episode reward: 1.0000
second_0:                     episode reward: -1.0000
Process ID: 2, episode: 1620/30000 (5.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 550.0405s / 44734.4305 s
first_0:                     episode reward: -0.9500
second_0:                     episode reward: 0.9500
Process ID: 2, episode: 1640/30000 (5.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.8569s / 45291.2874 s
first_0:                     episode reward: 1.0500
second_0:                     episode reward: -1.0500
Process ID: 2, episode: 1660/30000 (5.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.2447s / 45848.5321 s
first_0:                     episode reward: -0.7000
second_0:                     episode reward: 0.7000
Process ID: 2, episode: 1680/30000 (5.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.9436s / 46402.4757 spygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(18)
random seed: 56
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 3, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}, 'multiprocess': True}
Save models to : /home/zihan/research/MARS/data/model/20220103_2057/pettingzoo_boxing_v1_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20220103_2057/pettingzoo_boxing_v1_nash_dqn.
Update itr: 20000/30000000 (0.0667%),                     last time consumption/overall running time: 4687.5377s / 4687.5377 s
first_0: loss: 0.0181
second_0: loss: 0.0183
Update itr: 40000/30000000 (0.1333%),                     last time consumption/overall running time: 4589.4452s / 9276.9829 s
first_0: loss: 0.0155
second_0: loss: 0.0095
Update itr: 60000/30000000 (0.2000%),                     last time consumption/overall running time: 4584.8562s / 13861.8391 s
first_0: loss: 0.0136
second_0: loss: 0.0111
Update itr: 80000/30000000 (0.2667%),                     last time consumption/overall running time: 4601.9027s / 18463.7418 s
first_0: loss: 0.0151
second_0: loss: 0.0120
Update itr: 100000/30000000 (0.3333%),                     last time consumption/overall running time: 4547.6058s / 23011.3476 s
first_0: loss: 0.0110
second_0: loss: 0.0178
Update itr: 120000/30000000 (0.4000%),                     last time consumption/overall running time: 4583.2893s / 27594.6369 s
first_0: loss: 0.0189
second_0: loss: 0.0121
Update itr: 140000/30000000 (0.4667%),                     last time consumption/overall running time: 4593.7137s / 32188.3506 s
first_0: loss: 0.0185
second_0: loss: 0.0180
Update itr: 160000/30000000 (0.5333%),                     last time consumption/overall running time: 4595.5717s / 36783.9223 s
first_0: loss: 0.0143
second_0: loss: 0.0116
Update itr: 180000/30000000 (0.6000%),                     last time consumption/overall running time: 4595.8804s / 41379.8027 s
first_0: loss: 0.0168
second_0: loss: 0.0140
Update itr: 200000/30000000 (0.6667%),                     last time consumption/overall running time: 4595.2698s / 45975.0725 s
first_0: loss: 0.0183
second_0: loss: 0.0127
Update itr: 220000/30000000 (0.7333%),                     last time consumption/overall running time: 4593.2400s / 50568.3125 s
first_0: loss: 0.0171
second_0: loss: 0.0134
Update itr: 240000/30000000 (0.8000%),                     last time consumption/overall running time: 4614.2299s / 55182.5424 s
first_0: loss: 0.0152
second_0: loss: 0.0129
Update itr: 260000/30000000 (0.8667%),                     last time consumption/overall running time: 4605.7078s / 59788.2502 s
first_0: loss: 0.0216
second_0: loss: 0.0151
Process Process-5:
Traceback (most recent call last):
  File "/home/zihan/research/MARS/mars/rl/agents/dqn.py", line 146, in save_model
    torch.save(self.model.state_dict(), path+'_model', _use_new_zipfile_serialization=False)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/serialization.py", line 369, in save
    with _open_file_like(f, 'wb') as opened_file:
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './/data/model/20220103_2057/pettingzoo_boxing_v1_nash_dqn/265999_0_model'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zihan/research/MARS/updateModel.py", line 24, in updateModel
    update_normal(env, model, save_id, args)
  File "/home/zihan/research/MARS/updateModel.py", line 59, in update_normal
    model.save_model(logger.model_dir+f'{itr}')
  File "/home/zihan/research/MARS/mars/rl/agents/multiagent.py", line 252, in save_model
    agent.save_model(path+f'_{str(idx)}')
  File "/home/zihan/research/MARS/mars/rl/agents/dqn.py", line 149, in save_model
    torch.save(self.model.state_dict(), path+'_model')
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/serialization.py", line 369, in save
    with _open_file_like(f, 'wb') as opened_file:
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/serialization.py", line 230, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/site-packages/torch/serialization.py", line 211, in __init__
    super(_open_file, self).__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: './/data/model/20220103_2057/pettingzoo_boxing_v1_nash_dqn/265999_0_model'
pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html

first_0:                     episode reward: -2.3500
second_0:                     episode reward: 2.3500
Process ID: 2, episode: 1700/30000 (5.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.1647s / 46954.6405 s
first_0:                     episode reward: 0.4000
second_0:                     episode reward: -0.4000
Process ID: 2, episode: 1720/30000 (5.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.6102s / 47508.2507 s
first_0:                     episode reward: -1.6000
second_0:                     episode reward: 1.6000
Process ID: 2, episode: 1740/30000 (5.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.3087s / 48063.5593 s
first_0:                     episode reward: 1.1000
second_0:                     episode reward: -1.1000
Process ID: 2, episode: 1760/30000 (5.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.7400s / 48616.2994 s
first_0:                     episode reward: -3.5000
second_0:                     episode reward: 3.5000
Process ID: 2, episode: 1780/30000 (5.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.5532s / 49171.8526 s
first_0:                     episode reward: 2.1000
second_0:                     episode reward: -2.1000
Process ID: 2, episode: 1800/30000 (6.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.8219s / 49723.6745 s
first_0:                     episode reward: -3.9500
second_0:                     episode reward: 3.9500
Process ID: 2, episode: 1820/30000 (6.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.4936s / 50279.1680 s
first_0:                     episode reward: 0.8000
second_0:                     episode reward: -0.8000
Process ID: 2, episode: 1840/30000 (6.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 559.1117s / 50838.2797 s
first_0:                     episode reward: -0.2000
second_0:                     episode reward: 0.2000
Process ID: 2, episode: 1860/30000 (6.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.6922s / 51393.9719 s
first_0:                     episode reward: 1.4500
second_0:                     episode reward: -1.4500
Process ID: 2, episode: 1880/30000 (6.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.8964s / 51946.8683 s
first_0:                     episode reward: -3.4500
second_0:                     episode reward: 3.4500
Process ID: 2, episode: 1900/30000 (6.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.3726s / 52504.2410 s
first_0:                     episode reward: 1.4500
second_0:                     episode reward: -1.4500
Process ID: 2, episode: 1920/30000 (6.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.5201s / 53059.7611 s
first_0:                     episode reward: 1.7500
second_0:                     episode reward: -1.7500
Process ID: 2, episode: 1940/30000 (6.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 558.8382s / 53618.5993 s
first_0:                     episode reward: 0.1500
second_0:                     episode reward: -0.1500
Process ID: 2, episode: 1960/30000 (6.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.2278s / 54175.8271 s
first_0:                     episode reward: -1.9500
second_0:                     episode reward: 1.9500
Process ID: 2, episode: 1980/30000 (6.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 573.8827s / 54749.7099 s
first_0:                     episode reward: -0.2000
second_0:                     episode reward: 0.2000
Process ID: 2, episode: 2000/30000 (6.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 574.3239s / 55324.0338 s
first_0:                     episode reward: 0.0000
second_0:                     episode reward: 0.0000
Process ID: 2, episode: 2020/30000 (6.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 563.4077s / 55887.4416 s
first_0:                     episode reward: -3.1000
second_0:                     episode reward: 3.1000
Process ID: 2, episode: 2040/30000 (6.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.2528s / 56443.6944 s
first_0:                     episode reward: -1.6500
second_0:                     episode reward: 1.6500
Process ID: 2, episode: 2060/30000 (6.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 558.8306s / 57002.5250 s
first_0:                     episode reward: -1.9000
second_0:                     episode reward: 1.9000
Process ID: 2, episode: 2080/30000 (6.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 559.0648s / 57561.5898 s
first_0:                     episode reward: -5.4500
second_0:                     episode reward: 5.4500
Process ID: 2, episode: 2100/30000 (7.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.8832s / 58118.4729 s
first_0:                     episode reward: -2.0500
second_0:                     episode reward: 2.0500
Process ID: 2, episode: 2120/30000 (7.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.1236s / 58672.5966 s
first_0:                     episode reward: -0.4000
second_0:                     episode reward: 0.4000
Process ID: 2, episode: 2140/30000 (7.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.7008s / 59230.2974 s
first_0:                     episode reward: -0.5000
second_0:                     episode reward: 0.5000
Process ID: 2, episode: 2160/30000 (7.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.9369s / 59785.2343 s
first_0:                     episode reward: 0.5000
second_0:                     episode reward: -0.5000
Process ID: 2, episode: 2180/30000 (7.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.9884s / 60343.2226 s
first_0:                     episode reward: -1.6000
second_0:                     episode reward: 1.6000
Process ID: 2, episode: 2200/30000 (7.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 558.6679s / 60901.8905 s
first_0:                     episode reward: -2.4500
second_0:                     episode reward: 2.4500
Process Process-4:
Traceback (most recent call last):
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zihan/research/MARS/rolloutExperience.py", line 26, in rolloutExperience
    rollout_normal(env, model, save_id, args)
  File "/home/zihan/research/MARS/rolloutExperience.py", line 107, in rollout_normal
    model.store(sample)
  File "/home/zihan/research/MARS/mars/rl/agents/multiagent.py", line 198, in store
    agent.store(samples)
  File "/home/zihan/research/MARS/mars/rl/agents/dqn.py", line 99, in store
    self.buffer.push(sample)
  File "<string>", line 2, in push
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/managers.py", line 819, in _callmethod
    kind, result = conn.recv()
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer

first_0:                     episode reward: 0.8500
second_0:                     episode reward: -0.8500
Process ID: 0, episode: 1700/30000 (5.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.4761s / 46952.3398 s
first_0:                     episode reward: -1.5000
second_0:                     episode reward: 1.5000
Process ID: 0, episode: 1720/30000 (5.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.8702s / 47506.2100 s
first_0:                     episode reward: -0.9500
second_0:                     episode reward: 0.9500
Process ID: 0, episode: 1740/30000 (5.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.7327s / 48059.9428 s
first_0:                     episode reward: -0.9500
second_0:                     episode reward: 0.9500
Process ID: 0, episode: 1760/30000 (5.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.5450s / 48613.4877 s
first_0:                     episode reward: -1.2000
second_0:                     episode reward: 1.2000
Process ID: 0, episode: 1780/30000 (5.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.1518s / 49168.6395 s
first_0:                     episode reward: -1.5000
second_0:                     episode reward: 1.5000
Process ID: 0, episode: 1800/30000 (6.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.0858s / 49722.7253 s
first_0:                     episode reward: -2.4000
second_0:                     episode reward: 2.4000
Process ID: 0, episode: 1820/30000 (6.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.8997s / 50280.6250 s
first_0:                     episode reward: 0.5500
second_0:                     episode reward: -0.5500
Process ID: 0, episode: 1840/30000 (6.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 560.4811s / 50841.1061 s
first_0:                     episode reward: -0.1000
second_0:                     episode reward: 0.1000
Process ID: 0, episode: 1860/30000 (6.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.4901s / 51396.5962 s
first_0:                     episode reward: -0.2000
second_0:                     episode reward: 0.2000
Process ID: 0, episode: 1880/30000 (6.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.9555s / 51948.5516 s
first_0:                     episode reward: -0.6500
second_0:                     episode reward: 0.6500
Process ID: 0, episode: 1900/30000 (6.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.0557s / 52505.6074 s
first_0:                     episode reward: -0.8500
second_0:                     episode reward: 0.8500
Process ID: 0, episode: 1920/30000 (6.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.9153s / 53059.5226 s
first_0:                     episode reward: -1.8500
second_0:                     episode reward: 1.8500
Process ID: 0, episode: 1940/30000 (6.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.7477s / 53614.2703 s
first_0:                     episode reward: -2.4000
second_0:                     episode reward: 2.4000
Process ID: 0, episode: 1960/30000 (6.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.5501s / 54169.8204 s
first_0:                     episode reward: -1.1500
second_0:                     episode reward: 1.1500
Process ID: 0, episode: 1980/30000 (6.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 573.8551s / 54743.6756 s
first_0:                     episode reward: 0.2500
second_0:                     episode reward: -0.2500
Process ID: 0, episode: 2000/30000 (6.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 575.9449s / 55319.6205 s
first_0:                     episode reward: -3.1000
second_0:                     episode reward: 3.1000
Process ID: 0, episode: 2020/30000 (6.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 567.0703s / 55886.6908 s
first_0:                     episode reward: 0.1500
second_0:                     episode reward: -0.1500
Process ID: 0, episode: 2040/30000 (6.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.6022s / 56443.2930 s
first_0:                     episode reward: -0.0500
second_0:                     episode reward: 0.0500
Process ID: 0, episode: 2060/30000 (6.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 559.2970s / 57002.5900 s
first_0:                     episode reward: -1.4500
second_0:                     episode reward: 1.4500
Process ID: 0, episode: 2080/30000 (6.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 559.3697s / 57561.9597 s
first_0:                     episode reward: 0.1500
second_0:                     episode reward: -0.1500
Process ID: 0, episode: 2100/30000 (7.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 559.3052s / 58121.2649 s
first_0:                     episode reward: -2.3000
second_0:                     episode reward: 2.3000
Process ID: 0, episode: 2120/30000 (7.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.7460s / 58677.0109 s
first_0:                     episode reward: -2.4000
second_0:                     episode reward: 2.4000
Process ID: 0, episode: 2140/30000 (7.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.6534s / 59233.6644 s
first_0:                     episode reward: 0.4000
second_0:                     episode reward: -0.4000
Process ID: 0, episode: 2160/30000 (7.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.0897s / 59790.7541 s
first_0:                     episode reward: -2.1500
second_0:                     episode reward: 2.1500
Process ID: 0, episode: 2180/30000 (7.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.5542s / 60346.3082 s
first_0:                     episode reward: -0.5500
second_0:                     episode reward: 0.5500
Process ID: 0, episode: 2200/30000 (7.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.5582s / 60903.8664 s
first_0:                     episode reward: -1.7000
second_0:                     episode reward: 1.7000
Process Process-2:
Traceback (most recent call last):
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zihan/research/MARS/rolloutExperience.py", line 26, in rolloutExperience
    rollout_normal(env, model, save_id, args)
  File "/home/zihan/research/MARS/rolloutExperience.py", line 107, in rollout_normal
    model.store(sample)
  File "/home/zihan/research/MARS/mars/rl/agents/multiagent.py", line 198, in store
    agent.store(samples)
  File "/home/zihan/research/MARS/mars/rl/agents/dqn.py", line 99, in store
    self.buffer.push(sample)
  File "<string>", line 2, in push
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/managers.py", line 819, in _callmethod
    kind, result = conn.recv()
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer

first_0:                     episode reward: 1.1000
second_0:                     episode reward: -1.1000
Process ID: 1, episode: 1700/30000 (5.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 551.8638s / 46921.8709 s
first_0:                     episode reward: -1.4000
second_0:                     episode reward: 1.4000
Process ID: 1, episode: 1720/30000 (5.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.1392s / 47475.0101 s
first_0:                     episode reward: 0.1000
second_0:                     episode reward: -0.1000
Process ID: 1, episode: 1740/30000 (5.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.4741s / 48027.4842 s
first_0:                     episode reward: -2.1000
second_0:                     episode reward: 2.1000
Process ID: 1, episode: 1760/30000 (5.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.5152s / 48581.9993 s
first_0:                     episode reward: -1.2000
second_0:                     episode reward: 1.2000
Process ID: 1, episode: 1780/30000 (5.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.8983s / 49136.8976 s
first_0:                     episode reward: -2.1500
second_0:                     episode reward: 2.1500
Process ID: 1, episode: 1800/30000 (6.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.8191s / 49689.7168 s
first_0:                     episode reward: 0.0000
second_0:                     episode reward: 0.0000
Process ID: 1, episode: 1820/30000 (6.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.8153s / 50246.5321 s
first_0:                     episode reward: 0.8500
second_0:                     episode reward: -0.8500
Process ID: 1, episode: 1840/30000 (6.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 556.9860s / 50803.5181 s
first_0:                     episode reward: -1.1500
second_0:                     episode reward: 1.1500
Process ID: 1, episode: 1860/30000 (6.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.2212s / 51357.7393 s
first_0:                     episode reward: 1.2500
second_0:                     episode reward: -1.2500
Process ID: 1, episode: 1880/30000 (6.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 550.4519s / 51908.1913 s
first_0:                     episode reward: 0.1500
second_0:                     episode reward: -0.1500
Process ID: 1, episode: 1900/30000 (6.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.8934s / 52464.0846 s
first_0:                     episode reward: 1.8000
second_0:                     episode reward: -1.8000
Process ID: 1, episode: 1920/30000 (6.4000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.2255s / 53019.3102 s
first_0:                     episode reward: -1.4000
second_0:                     episode reward: 1.4000
Process ID: 1, episode: 1940/30000 (6.4667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.8130s / 53574.1231 s
first_0:                     episode reward: -0.4500
second_0:                     episode reward: 0.4500
Process ID: 1, episode: 1960/30000 (6.5333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 554.2932s / 54128.4164 s
first_0:                     episode reward: -1.5000
second_0:                     episode reward: 1.5000
Process ID: 1, episode: 1980/30000 (6.6000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 572.8467s / 54701.2631 s
first_0:                     episode reward: -3.4000
second_0:                     episode reward: 3.4000
Process ID: 1, episode: 2000/30000 (6.6667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 575.8678s / 55277.1309 s
first_0:                     episode reward: -1.2500
second_0:                     episode reward: 1.2500
Process ID: 1, episode: 2020/30000 (6.7333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 564.1473s / 55841.2781 s
first_0:                     episode reward: -2.4500
second_0:                     episode reward: 2.4500
Process ID: 1, episode: 2040/30000 (6.8000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.1730s / 56393.4511 s
first_0:                     episode reward: -1.2500
second_0:                     episode reward: 1.2500
Process ID: 1, episode: 2060/30000 (6.8667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.8795s / 56951.3305 s
first_0:                     episode reward: -0.9000
second_0:                     episode reward: 0.9000
Process ID: 1, episode: 2080/30000 (6.9333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 557.7419s / 57509.0724 s
first_0:                     episode reward: -1.8500
second_0:                     episode reward: 1.8500
Process ID: 1, episode: 2100/30000 (7.0000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 559.7084s / 58068.7808 s
first_0:                     episode reward: 0.0000
second_0:                     episode reward: 0.0000
Process ID: 1, episode: 2120/30000 (7.0667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 552.7077s / 58621.4885 s
first_0:                     episode reward: -1.2500
second_0:                     episode reward: 1.2500
Process ID: 1, episode: 2140/30000 (7.1333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 553.5848s / 59175.0733 s
first_0:                     episode reward: 0.0500
second_0:                     episode reward: -0.0500
Process ID: 1, episode: 2160/30000 (7.2000%),                     avg. length: 1784.0,                    last time consumption/overall running time: 550.6512s / 59725.7245 s
first_0:                     episode reward: -2.3500
second_0:                     episode reward: 2.3500
Process ID: 1, episode: 2180/30000 (7.2667%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.3167s / 60281.0412 s
first_0:                     episode reward: -4.5500
second_0:                     episode reward: 4.5500
Process ID: 1, episode: 2200/30000 (7.3333%),                     avg. length: 1784.0,                    last time consumption/overall running time: 555.3928s / 60836.4340 s
first_0:                     episode reward: -0.6000
second_0:                     episode reward: 0.6000
Process Process-3:
Traceback (most recent call last):
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/home/zihan/research/MARS/rolloutExperience.py", line 26, in rolloutExperience
    rollout_normal(env, model, save_id, args)
  File "/home/zihan/research/MARS/rolloutExperience.py", line 107, in rollout_normal
    model.store(sample)
  File "/home/zihan/research/MARS/mars/rl/agents/multiagent.py", line 198, in store
    agent.store(samples)
  File "/home/zihan/research/MARS/mars/rl/agents/dqn.py", line 99, in store
    self.buffer.push(sample)
  File "<string>", line 2, in push
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/managers.py", line 819, in _callmethod
    kind, result = conn.recv()
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/zihan/anaconda3/envs/x/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
ConnectionResetError: [Errno 104] Connection reset by peer
