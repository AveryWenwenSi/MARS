{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "num_states = 3\n",
    "num_actions_per_player = 2\n",
    "num_actions = num_actions_per_player**2\n",
    "num_trans = 3\n",
    "reward_range = [-1,1]\n",
    "\n",
    "def generate_random_trans_and_rewards():\n",
    "    trans_prob_matrices = []\n",
    "    reward_matrices = []\n",
    "    for _ in range(num_trans):\n",
    "        trans_prob_matrix = []\n",
    "        reward_matrix = []\n",
    "        for s in range(num_states):\n",
    "            trans_prob_matrix_for_s = []\n",
    "            reward_matrix_for_s = []\n",
    "            for a in range(num_actions):\n",
    "                rands = np.random.uniform(0,1, num_states)\n",
    "                rand_probs = list(rands/sum(rands))\n",
    "                trans_prob_matrix_for_s.append(rand_probs)\n",
    "                rs = np.random.uniform(*reward_range, num_states)\n",
    "                reward_matrix_for_s.append(list(rs))\n",
    "            trans_prob_matrix.append(trans_prob_matrix_for_s)\n",
    "            reward_matrix.append(reward_matrix_for_s)\n",
    "        trans_prob_matrices.append(trans_prob_matrix)\n",
    "        reward_matrices.append(reward_matrix)\n",
    "    return trans_prob_matrices, reward_matrices\n",
    "\n",
    "tpmxs, rmxs =  generate_random_trans_and_rewards()  # shape: (trans, state, action, next_state)\n",
    "print(np.array(tpmxs).shape, np.array(rmxs).shape, rmxs) # shape: (trans, state, action, next_state)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3, 3, 4, 3) (3, 3, 4, 3) [[[[0.3467567654286501, -0.34091283442462816, -0.5789680111630586], [0.4835608572436221, 0.08290562160040937, 0.5025827055969319], [0.38146084179130724, -0.15388039953402854, 0.10246282709099175], [0.20623516832905553, -0.34476867760623575, 0.3794605769365267]], [[-0.5979937587756445, 0.43640003504477765, 0.2033118157104774], [0.6338579952749988, 0.35350868438074823, -0.9407164825729974], [-0.1315120446226501, -0.45244028123615143, -0.6979882926485159], [-0.3410059200264419, -0.9041320063903293, -0.8310812261136384]], [[-0.289745139773828, -0.6141492486106037, -0.09275754456588636], [-0.0065158426337410535, -0.5322776810312382, 0.5476167508939815], [-0.4227775166883523, 0.3381724281960061, 0.2401423898702051], [0.9242131831849734, -0.8896340899336708, 0.3982982530946184]]], [[[0.08763971914667645, -0.773980333283455, -0.8815137096112955], [0.4013720108808865, 0.4367411122368767, -0.9267067624759577], [-0.9501087549126122, 0.5995285838353452, 0.41739264509875595], [-0.4818805806118611, 0.35533052013337874, -0.27978560419688003]], [[-0.520411548204917, -0.6601483569977382, -0.5151162406770284], [0.9717292902207011, 0.6971720670771888, -0.30789560505767866], [0.2396435921525928, 0.9853749811401868, 0.022414050490219495], [0.23889050293962066, -0.2208126891908304, -0.6353899696535634]], [[-0.19203003521717665, -0.5649487420598487, 0.5991143324467585], [-0.7589363587559013, 0.18401975801278359, -0.7431072968183254], [0.4020940003478177, 0.5555359826190591, -0.09687839953782262], [-0.772420148312204, 0.554082863861254, 0.07628984420873874]]], [[[0.7569718516272126, 0.7288244027042097, 0.22264473977627364], [0.5845731260521587, 0.1898717261486076, -0.6561946828084242], [-0.21830418816640385, -0.10127248729135774, -0.9835955542549901], [0.2227660157487339, 0.2901803481188281, -0.726052341949621]], [[0.549716268683534, 0.10788982419546667, 0.9080892273973165], [-0.8859589303495405, 0.13399260847937677, -0.5245291177084257], [-0.6333942898243572, 0.27022412953254293, 0.18806437105637164], [0.9665975744466417, -0.28500566703471275, 0.3540838001930495]], [[-0.5015261616042379, -0.14525364778346916, 0.457458935046843], [-0.8791261226372553, 0.9436186829163502, 0.5901889457973575], [0.11005742419095421, -0.30159555745512234, -0.415502535642833], [0.7159368766927021, 0.1534414467267733, 0.9624436753503267]]]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "import ecos\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def NashEquilibriumECOSSolver(M):\n",
    "    \"\"\"\n",
    "    https://github.com/embotech/ecos-python\n",
    "    min  c*x\n",
    "    s.t. A*x = b\n",
    "         G*x <= h\n",
    "    https://github.com/embotech/ecos/wiki/Usage-from-MATLAB\n",
    "    args: \n",
    "        c,b,h: numpy.array\n",
    "        A, G: Scipy sparse matrix\n",
    "    \"\"\"\n",
    "    row, col = M.shape\n",
    "    c = np.zeros(row+1)\n",
    "    # max z\n",
    "    c[-1] = -1  \n",
    "    \n",
    "    # x1+x2+...+xn=1\n",
    "    A = np.ones(row+1)\n",
    "    A[-1] = 0.\n",
    "    A = csr_matrix([A])\n",
    "    b=np.array([1.])\n",
    "    \n",
    "    # M.T*x<=z\n",
    "    G1 = np.ones((col, row+1))\n",
    "    G1[:col, :row] = -1. * M.T\n",
    "    # x>=0\n",
    "    G2 = np.zeros((row, row+1))\n",
    "    for i in range(row):\n",
    "        G2[i, i]=-1. \n",
    "    # x<=1.\n",
    "    G3 = np.zeros((row, row+1))\n",
    "    for i in range(row):\n",
    "        G3[i, i]=1. \n",
    "    G = csr_matrix(np.concatenate((G1, G2, G3)))\n",
    "    h = np.concatenate((np.zeros(2*row), np.ones(row)))\n",
    "    \n",
    "    # specify number of variables\n",
    "    dims={'l': col+2*row, 'q': []}\n",
    "                       \n",
    "    solution = ecos.solve(c,G,h,dims,A,b, verbose=False)\n",
    "\n",
    "    p1_value = solution['x'][:row]\n",
    "    p2_value = solution['z'][:col] # z is the dual variable of x\n",
    "    # There are at least two bad cases with above constrained optimization,\n",
    "    # where the constraints are not fully satisfied (some numerical issue):\n",
    "    # 1. the sum of vars is larger than 1.\n",
    "    # 2. the value of var may be negative.\n",
    "    abs_p1_value = np.abs(p1_value)\n",
    "    abs_p2_value = np.abs(p2_value)\n",
    "    p1_value = abs_p1_value/np.sum(abs_p1_value)\n",
    "    p2_value = abs_p2_value/np.sum(abs_p2_value)\n",
    "\n",
    "    return (p1_value, p2_value)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "source": [
    "import copy\n",
    "import pandas\n",
    "\n",
    "class ArbitraryMDP():\n",
    "    def __init__(self, num_states=3, num_actions_per_player=2, num_trans=3):\n",
    "        self.num_states = num_states\n",
    "        self.num_actions_per_player = num_actions_per_player\n",
    "        self.num_actions = self.num_actions_per_player**2\n",
    "        self.num_trans = num_trans\n",
    "        self.reward_range = [-1,1]\n",
    "        self.state = None\n",
    "        self._construct_game()\n",
    "\n",
    "    def _construct_game(self, ):\n",
    "        self.trans_prob_matrices, self.reward_matrices = self.generate_random_trans_and_rewards()\n",
    "\n",
    "    def generate_random_trans_and_rewards(self,):\n",
    "        trans_prob_matrices = []\n",
    "        reward_matrices = []\n",
    "        for _ in range(self.num_trans):\n",
    "            trans_prob_matrix = []\n",
    "            reward_matrix = []\n",
    "            for s in range(self.num_states):\n",
    "                trans_prob_matrix_for_s = []\n",
    "                reward_matrix_for_s = []\n",
    "                for a in range(self.num_actions):\n",
    "                    rands = np.random.uniform(0,1, self.num_states)\n",
    "                    rand_probs = list(rands/sum(rands))\n",
    "                    trans_prob_matrix_for_s.append(rand_probs)\n",
    "                    rs = np.random.uniform(*self.reward_range, self.num_states)\n",
    "                    reward_matrix_for_s.append(list(rs))\n",
    "                trans_prob_matrix.append(trans_prob_matrix_for_s)\n",
    "                reward_matrix.append(reward_matrix_for_s)\n",
    "            trans_prob_matrices.append(trans_prob_matrix)\n",
    "            reward_matrices.append(reward_matrix)\n",
    "\n",
    "        return trans_prob_matrices, reward_matrices\n",
    "\n",
    "    def reset(self, ):\n",
    "        self.state = np.random.randint(0, self.num_states)  # randomly pick one state as initial\n",
    "        self.trans = 0\n",
    "        obs = self.state\n",
    "        return obs\n",
    "\n",
    "    def step(self, a):\n",
    "        trans_prob = self.trans_prob_matrices[self.trans][self.state][a]\n",
    "        next_state = np.random.choice([i for i in range(self.num_states)], p=trans_prob)\n",
    "        self.state = next_state\n",
    "        obs = self.state\n",
    "        reward = self.reward_matrices[self.trans][self.state][a][next_state]\n",
    "        self.trans += 1\n",
    "        done = False if self.trans < self.num_trans else True\n",
    "\n",
    "        return obs, reward, done, None\n",
    "\n",
    "    def NEsolver(self,):\n",
    "        self.Nash_v = []\n",
    "        for tm, rm in zip(self.trans_prob_matrices[::-1], self.reward_matrices[::-1]): # inverse enumerate \n",
    "            if len(self.Nash_v) > 0:\n",
    "                rm = np.array(rm)+np.array(self.Nash_v[-1])  # broadcast sum on rm's last dim, last one in Nash_v is for the next state\n",
    "            trm = np.einsum(\"ijk,ijk->ij\", tm, rm)  # transition prob * reward for the last dimension in (state, action, next_state)\n",
    "            trm = trm.reshape(-1, self.num_actions_per_player, self.num_actions_per_player) # action list to matrix\n",
    "            ne_values = []\n",
    "            for s_payoff in trm:\n",
    "                ne = NashEquilibriumECOSSolver(s_payoff)\n",
    "                ne_value = ne[0]@s_payoff@ne[1].T\n",
    "                ne_values.append(ne_value)  # each value is a Nash equilibrium value on one state\n",
    "            self.Nash_v.append(ne_values)  # (trans, state)\n",
    "        print('Nash values of all states: ', self.Nash_v)\n",
    "\n",
    "env = ArbitraryMDP()\n",
    "env.NEsolver()\n",
    "obs = env.reset()\n",
    "print(obs)    \n",
    "\n",
    "for _ in range(env.num_trans+1):\n",
    "    o,r,d,_ = env.step(1)\n",
    "    print(o,r,d)\n",
    "    if d:\n",
    "        break\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "                                                   0  \\\n",
      "0  [[0.9492277496511203, -0.7230850668264706, 0.4...   \n",
      "1  [[0.27079133106918807, -0.06955473452313932, 0...   \n",
      "2  [[-0.20057271773597818, -0.5008545145233938, 0...   \n",
      "\n",
      "                                                   1  \\\n",
      "0  [[0.017306001658161874, 0.7543340801951506, 0....   \n",
      "1  [[0.842845663847265, -0.9504237847419348, -0.7...   \n",
      "2  [[-0.5490177394287643, 0.7215394473492391, 0.8...   \n",
      "\n",
      "                                                   2  \n",
      "0  [[0.09268065392861335, -0.710504797377669, 0.9...  \n",
      "1  [[0.35157506192187826, -0.24766323322395367, 0...  \n",
      "2  [[0.06404206096902332, 0.49747060543367594, -0...  \n",
      "Nash values of all states:  [[0.6299419917107387, -0.09736993972611034, -0.30655330721599117], [0.3141539927602728, -0.36649219268142685, 0.2868228665333546], [-0.012930308050426989, 0.6033907736557464, 0.4710433901943522]]\n",
      "1\n",
      "0 0.36818102372533024 False\n",
      "2 0.9833582438622486 False\n",
      "2 0.4609506516912787 True\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:26: UserWarning: Converting G to a CSC matrix; may take a while.\n",
      "  warn(\"Converting G to a CSC matrix; may take a while.\")\n",
      "/home/quantumiracle/anaconda3/envs/res/lib/python3.6/site-packages/ecos/ecos.py:29: UserWarning: Converting A to a CSC matrix; may take a while.\n",
      "  warn(\"Converting A to a CSC matrix; may take a while.\")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "a=np.array([[1,2], [3,4]])\n",
    "b=np.array([1,1])\n",
    "a+b"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [4, 5]])"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "np.arange(2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('res': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "interpreter": {
   "hash": "230862b98d5539ea4f6edff4f834846d7aac25a9878478a73da403f7aa963d5d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}