{"episode_reward": {"env0_first_0": [-1.0, -2.0, -9.0, -1.0], "env0_second_0": [1.0, 2.0, 9.0, 1.0], "env1_first_0": [-6.0, -1.0, -4.0, 5.0], "env1_second_0": [6.0, 1.0, 4.0, -5.0]}, "loss": {"env0_first_0": [NaN, NaN, NaN, NaN], "env0_second_0": [NaN, NaN, NaN, NaN], "env1_first_0": [NaN, NaN, NaN, NaN], "env1_second_0": [NaN, NaN, NaN, NaN]}, "episode_length": [9370, 9234, 9482, 9144]}