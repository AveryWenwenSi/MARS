env_args:
    env_name: boxing_v1
    env_type: pettingzoo
    num_envs: 1
    ram: True
    seed: 1122

agent_args:
    algorithm: GA
    algorithm_spec:
        num_agents: 500
        mutation_power: 0.2  #hyper-parameter, set from https://arxiv.org/pdf/1712.06567.pdf
        max_generations: 1000

train_args:
    max_episodes: 10000
    max_steps_per_episode: 10000
    optimizer: adam
    learning_rate: 1e-4
    device: gpu
    update_itr: 1  # iterations of updates per frame, 0~inf; <1 means several steps are skipped per update
    log_avg_window: 5 # average window length in logging
    log_interval: 20  # log print interval 
    render: False
    net_architecture: 
        hidden_dim_list: [128, 128]  
        hidden_activation: ReLU
        output_activation: Softmax

    marl_method: selfplay
    marl_spec:  # configurations for specific MARL method
        selfplay_score_delta: 10  # the score that current learning agent must beat its opponent to update opponent's policy
        trainable_agent_idx: 0   # the index of trainable agent, with its opponent delayed updated
        opponent_idx: 1          # the one to be updated from trainable agent