pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (130,), float32) action space: Discrete(18)
<env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f236026b190>
boxing_v1 pettingzoo
Load boxing_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (130,), float32) action space: Discrete(18)
No agent are not learnable.
Arguments:  {'env_name': 'boxing_v1', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 1122, 'against_baseline': False, 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': True, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 32, 'max_episodes': 10000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [64, 64, 64], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nxdo', 'marl_spec': {'selfplay_score_delta': 50, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
Episode: 1, avg. length 1784.0
first_0:                 episode reward: -11.0000,                 loss: 0.0129
second_0:                 episode reward: 11.0000,                 loss: 0.0065
Episode: 21, avg. length 1784.0
first_0:                 episode reward: -2.6000,                 loss: 0.0366
second_0:                 episode reward: 2.6000,                 loss: 0.0112
Episode: 41, avg. length 1784.0
first_0:                 episode reward: 0.2500,                 loss: 0.0475
second_0:                 episode reward: -0.2500,                 loss: 0.0107
Episode: 61, avg. length 1784.0
first_0:                 episode reward: -1.3000,                 loss: 0.0480
second_0:                 episode reward: 1.3000,                 loss: 0.0112
Episode: 81, avg. length 1784.0
first_0:                 episode reward: 0.1500,                 loss: 0.0345
second_0:                 episode reward: -0.1500,                 loss: 0.0117
Episode: 101, avg. length 1784.0
first_0:                 episode reward: 2.1500,                 loss: 0.0211
second_0:                 episode reward: -2.1500,                 loss: 0.0122
Episode: 121, avg. length 1784.0
first_0:                 episode reward: 0.9000,                 loss: 0.0171
second_0:                 episode reward: -0.9000,                 loss: 0.0130
Episode: 141, avg. length 1784.0
first_0:                 episode reward: 3.1000,                 loss: 0.0164
second_0:                 episode reward: -3.1000,                 loss: 0.0143
Episode: 161, avg. length 1784.0
first_0:                 episode reward: 5.8500,                 loss: 0.0165
second_0:                 episode reward: -5.8500,                 loss: 0.0148
Episode: 181, avg. length 1784.0
first_0:                 episode reward: 7.3000,                 loss: 0.0174
second_0:                 episode reward: -7.3000,                 loss: 0.0156
Episode: 201, avg. length 1784.0
first_0:                 episode reward: 10.2000,                 loss: 0.0204
second_0:                 episode reward: -10.2000,                 loss: 0.0179
Episode: 221, avg. length 1784.0
first_0:                 episode reward: 15.8500,                 loss: 0.0258
second_0:                 episode reward: -15.8500,                 loss: 0.0230
Episode: 241, avg. length 1784.0
first_0:                 episode reward: 18.6500,                 loss: 0.0340
second_0:                 episode reward: -18.6500,                 loss: 0.0289
Episode: 261, avg. length 1784.0
first_0:                 episode reward: 16.1500,                 loss: 0.0420
second_0:                 episode reward: -16.1500,                 loss: 0.0364
Episode: 281, avg. length 1784.0
first_0:                 episode reward: 24.0000,                 loss: 0.0460
second_0:                 episode reward: -24.0000,                 loss: 0.4598
Score delta: 50.6, udpate the opponent.
Episode: 301, avg. length 1753.75
first_0:                 episode reward: 36.2500,                 loss: 0.0465
second_0:                 episode reward: -36.2500,                 loss: 0.5738
Score delta: 64.0, udpate the opponent.
Episode: 321, avg. length 1651.3
first_0:                 episode reward: 45.8500,                 loss: 0.0504
second_0:                 episode reward: -45.8500,                 loss: 0.3709
Score delta: 104.4, udpate the opponent.
Episode: 341, avg. length 1461.55
first_0:                 episode reward: 68.8500,                 loss: 0.0604
second_0:                 episode reward: -68.8500,                 loss: 0.1585
Score delta: 128.2, udpate the opponent.
Episode: 361, avg. length 1392.25
first_0:                 episode reward: 67.5500,                 loss: 0.0716
second_0:                 episode reward: -67.5500,                 loss: 0.0830
Score delta: 142.4, udpate the opponent.
Episode: 381, avg. length 1170.15
first_0:                 episode reward: 79.7500,                 loss: 0.0832
second_0:                 episode reward: -79.7500,                 loss: 0.0836
Score delta: 141.2, udpate the opponent.
Episode: 401, avg. length 1143.3
first_0:                 episode reward: 89.5500,                 loss: 0.0921
second_0:                 episode reward: -89.5500,                 loss: 0.0892
Score delta: 182.2, udpate the opponent.
Episode: 421, avg. length 921.1
first_0:                 episode reward: 92.5500,                 loss: 0.0939
second_0:                 episode reward: -92.5500,                 loss: 0.0868
Score delta: 187.4, udpate the opponent.
Episode: 441, avg. length 736.45
first_0:                 episode reward: 94.9500,                 loss: 0.0926
second_0:                 episode reward: -94.9500,                 loss: 0.0898
Score delta: 180.6, udpate the opponent.
Episode: 461, avg. length 823.7
first_0:                 episode reward: 93.9500,                 loss: 0.0981
second_0:                 episode reward: -93.9500,                 loss: 0.0902
Score delta: 194.6, udpate the opponent.
Episode: 481, avg. length 716.95
first_0:                 episode reward: 85.1000,                 loss: 0.1051
second_0:                 episode reward: -85.1000,                 loss: 0.0996
Score delta: 156.0, udpate the opponent.
Episode: 501, avg. length 392.65
first_0:                 episode reward: 98.6500,                 loss: 0.1137
second_0:                 episode reward: -98.6500,                 loss: 0.1268
Score delta: 197.2, udpate the opponent.
Episode: 521, avg. length 370.8
first_0:                 episode reward: 98.5500,                 loss: 0.1267
second_0:                 episode reward: -98.5500,                 loss: 0.1217
Score delta: 196.0, udpate the opponent.
Episode: 541, avg. length 355.25
first_0:                 episode reward: 99.4000,                 loss: 0.1333
second_0:                 episode reward: -99.4000,                 loss: 0.1738
Score delta: 199.8, udpate the opponent.
Episode: 561, avg. length 378.05
first_0:                 episode reward: 97.9000,                 loss: 0.1376
second_0:                 episode reward: -97.9000,                 loss: 0.1477
Episode: 581, avg. length 366.85
first_0:                 episode reward: 99.1000,                 loss: 0.1458
second_0:                 episode reward: -99.1000,                 loss: 0.2000
Score delta: 197.6, udpate the opponent.
Episode: 601, avg. length 354.5
first_0:                 episode reward: 99.3500,                 loss: 0.1590
second_0:                 episode reward: -99.3500,                 loss: 0.2369
Score delta: 199.2, udpate the opponent.
Episode: 621, avg. length 763.35
first_0:                 episode reward: 88.7000,                 loss: 0.1653
second_0:                 episode reward: -88.7000,                 loss: 0.1769