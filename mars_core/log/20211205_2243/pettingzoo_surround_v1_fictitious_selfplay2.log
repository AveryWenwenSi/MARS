pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
surround_v1 pettingzoo
Load surround_v1 environment in type pettingzoo.
Env observation space: Box(0.0, 1.0, (128,), float32) action space: Discrete(5)
random seed: 84
<env.wrappers.mars_wrappers.Dict2TupleWrapper object at 0x7f8b69529050>
Agents No. [1] (index starting from 0) are not learnable.
Arguments:  {'env_name': 'surround_v1', 'env_type': 'pettingzoo', 'num_envs': 1, 'ram': True, 'seed': 'random', 'algorithm': 'DQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'fictitious_selfplay2', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'selfplay_score_delta': 16, 'trainable_agent_idx': 0, 'opponent_idx': 1}}
Save models to : /home/zihan/research/MARS/data/model/20211205_2243/pettingzoo_surround_v1_fictitious_selfplay2. 
 Save logs to: /home/zihan/research/MARS/data/log/20211205_2243/pettingzoo_surround_v1_fictitious_selfplay2.
Episode: 1, avg. length 1413.0
first_0:                 episode reward: 6.0000,                 loss: 0.1610
second_0:                 episode reward: -6.0000,                 loss: nan
Episode: 21, avg. length 1495.9
first_0:                 episode reward: -2.8000,                 loss: 0.0658
second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 41, avg. length 1386.35
first_0:                 episode reward: 5.0500,                 loss: 0.0538
second_0:                 episode reward: -5.0500,                 loss: nan
Episode: 61, avg. length 1457.35
first_0:                 episode reward: 7.3500,                 loss: nan
second_0:                 episode reward: -7.3500,                 loss: nan
Score delta: 16.8, save the model to ..//data/model/20211205_2243/pettingzoo_surround_v1_fictitious_selfplay2/51_0.
Episode: 81, avg. length 1618.95
first_0:                 episode reward: 6.5000,                 loss: nan
second_0:                 episode reward: -6.5000,                 loss: 0.0401
Episode: 101, avg. length 1865.3
first_0:                 episode reward: 3.4500,                 loss: nan
second_0:                 episode reward: -3.4500,                 loss: 0.0354
Episode: 121, avg. length 2065.35
first_0:                 episode reward: -4.3000,                 loss: nan
second_0:                 episode reward: 4.3000,                 loss: 0.0335
Episode: 141, avg. length 2054.95
first_0:                 episode reward: -6.1000,                 loss: nan
second_0:                 episode reward: 6.1000,                 loss: 0.0384
Episode: 161, avg. length 2059.2
first_0:                 episode reward: -3.5000,                 loss: nan
second_0:                 episode reward: 3.5000,                 loss: 0.0317
Episode: 181, avg. length 1778.35
first_0:                 episode reward: -6.2500,                 loss: nan
second_0:                 episode reward: 6.2500,                 loss: 0.0336
Episode: 201, avg. length 1597.75
first_0:                 episode reward: -2.5500,                 loss: nan
second_0:                 episode reward: 2.5500,                 loss: nan
Score delta: 16.2, save the model to ..//data/model/20211205_2243/pettingzoo_surround_v1_fictitious_selfplay2/193_1.
Episode: 221, avg. length 1453.75
first_0:                 episode reward: 6.8500,                 loss: nan
second_0:                 episode reward: -6.8500,                 loss: nan
Score delta: 16.8, save the model to ..//data/model/20211205_2243/pettingzoo_surround_v1_fictitious_selfplay2/214_0.
Episode: 241, avg. length 1922.85
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.0407
Episode: 261, avg. length 1949.65
first_0:                 episode reward: 0.3000,                 loss: nan
second_0:                 episode reward: -0.3000,                 loss: 0.0472
Episode: 281, avg. length 1953.1
first_0:                 episode reward: -1.3500,                 loss: nan
second_0:                 episode reward: 1.3500,                 loss: 0.0478
Episode: 301, avg. length 1904.35
first_0:                 episode reward: 3.6000,                 loss: nan
second_0:                 episode reward: -3.6000,                 loss: 0.0451
Episode: 321, avg. length 2324.8
first_0:                 episode reward: -0.8500,                 loss: nan
second_0:                 episode reward: 0.8500,                 loss: 0.0440
Episode: 341, avg. length 1956.5
first_0:                 episode reward: 1.7500,                 loss: nan
second_0:                 episode reward: -1.7500,                 loss: 0.0381
Episode: 361, avg. length 2021.6
first_0:                 episode reward: 3.7500,                 loss: nan
second_0:                 episode reward: -3.7500,                 loss: 0.0372
Episode: 381, avg. length 2231.4
first_0:                 episode reward: -1.2000,                 loss: nan
second_0:                 episode reward: 1.2000,                 loss: 0.0360
Episode: 401, avg. length 2159.75
first_0:                 episode reward: -1.6500,                 loss: nan
second_0:                 episode reward: 1.6500,                 loss: 0.0365
Episode: 421, avg. length 1962.85
first_0:                 episode reward: -1.5500,                 loss: nan
second_0:                 episode reward: 1.5500,                 loss: 0.0353
Episode: 441, avg. length 1720.8
first_0:                 episode reward: -5.4000,                 loss: nan
second_0:                 episode reward: 5.4000,                 loss: 0.0364
Episode: 461, avg. length 1598.0
first_0:                 episode reward: -6.4500,                 loss: nan
second_0:                 episode reward: 6.4500,                 loss: 0.0355
Episode: 481, avg. length 1731.55
first_0:                 episode reward: -4.8000,                 loss: nan
second_0:                 episode reward: 4.8000,                 loss: 0.0370
Episode: 501, avg. length 2123.3
first_0:                 episode reward: 1.3000,                 loss: nan
second_0:                 episode reward: -1.3000,                 loss: 0.0401
Episode: 521, avg. length 2120.5
first_0:                 episode reward: -1.5000,                 loss: nan
second_0:                 episode reward: 1.5000,                 loss: 0.0393
Episode: 541, avg. length 2114.4
first_0:                 episode reward: -3.8000,                 loss: nan
second_0:                 episode reward: 3.8000,                 loss: 0.0373
Episode: 561, avg. length 1659.75
first_0:                 episode reward: -6.6500,                 loss: nan
second_0:                 episode reward: 6.6500,                 loss: 0.0360
Episode: 581, avg. length 2010.45
first_0:                 episode reward: -3.5500,                 loss: nan
second_0:                 episode reward: 3.5500,                 loss: 0.0386
Episode: 601, avg. length 1924.2
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0401
Episode: 621, avg. length 2045.9
first_0:                 episode reward: -3.4500,                 loss: nan
second_0:                 episode reward: 3.4500,                 loss: 0.0402
Episode: 641, avg. length 1771.7
first_0:                 episode reward: -4.3500,                 loss: nan
second_0:                 episode reward: 4.3500,                 loss: 0.0410