pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
surround_v1 pettingzoo
random seed: [59, 44, 15]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'surround_v1', 'env_type': 'pettingzoo', 'num_envs': 3, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'exploiter_update_itr': 1}, 'batch_size': 128, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20211227_1021/pettingzoo_surround_v1_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/20211227_1021/pettingzoo_surround_v1_nash_dqn_exploiter.
Episode: 1/30000 (0.0033%),                 avg. length: 1422.0,                last time consumption/overall running time: 52.7165s / 52.7165 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.0122
env0_second_0:                 episode reward: -3.0000,                 loss: 0.0111
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 1374.5,                last time consumption/overall running time: 916.4473s / 969.1638 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0094
env0_second_0:                 episode reward: 2.4500,                 loss: 0.0097
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: -1.3500,                 loss: nan
env2_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 1414.6,                last time consumption/overall running time: 1001.6371s / 1970.8010 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.0091
env0_second_0:                 episode reward: 2.1000,                 loss: 0.0088
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
env2_first_0:                 episode reward: -2.9000,                 loss: nan
env2_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 1570.9,                last time consumption/overall running time: 1140.8714s / 3111.6724 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0078
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0078
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 1584.15,                last time consumption/overall running time: 1170.4285s / 4282.1009 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0070
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0071
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -1.9500,                 loss: nan
env2_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 1602.7,                last time consumption/overall running time: 1184.0505s / 5466.1514 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0070
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0071
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -3.0500,                 loss: nan
env2_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 1704.05,                last time consumption/overall running time: 1258.3483s / 6724.4997 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0072
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0070
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 1772.7,                last time consumption/overall running time: 1295.8412s / 8020.3409 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0066
env0_second_0:                 episode reward: 2.4500,                 loss: 0.0063
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -2.5000,                 loss: nan
env2_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 1943.8,                last time consumption/overall running time: 1427.1709s / 9447.5118 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0063
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0063
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 1812.05,                last time consumption/overall running time: 1331.1518s / 10778.6636 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0061
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0060
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
env2_first_0:                 episode reward: -3.2000,                 loss: nan
env2_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 1806.6,                last time consumption/overall running time: 1334.4845s / 12113.1481 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0063
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0064
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2043.5,                last time consumption/overall running time: 1497.3389s / 13610.4870 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0063
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0064
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 1835.9,                last time consumption/overall running time: 1355.5498s / 14966.0368 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0059
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0058
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
env2_first_0:                 episode reward: -3.5000,                 loss: nan
env2_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 1897.15,                last time consumption/overall running time: 1394.1124s / 16360.1492 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0058
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0059
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 1744.85,                last time consumption/overall running time: 1282.3186s / 17642.4678 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0059
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0059
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -2.2000,                 loss: nan
env2_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2285.95,                last time consumption/overall running time: 1669.7934s / 19312.2612 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0056
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0056
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2231.45,                last time consumption/overall running time: 1662.2427s / 20974.5038 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0051
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0052
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2332.6,                last time consumption/overall running time: 1734.9840s / 22709.4878 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0048
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0049
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2271.95,                last time consumption/overall running time: 1677.5319s / 24387.0197 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0047
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0047
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2293.25,                last time consumption/overall running time: 1668.7744s / 26055.7941 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0052
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0051
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2078.7,                last time consumption/overall running time: 1520.8579s / 27576.6520 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0056
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0056
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 1924.2,                last time consumption/overall running time: 1438.7694s / 29015.4213 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0057
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0058
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -2.8500,                 loss: nan
env2_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 1877.75,                last time consumption/overall running time: 1382.3103s / 30397.7316 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0064
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0065
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -2.4500,                 loss: nan
env2_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 1997.6,                last time consumption/overall running time: 1476.7651s / 31874.4967 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0065
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0065
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2066.25,                last time consumption/overall running time: 1515.6430s / 33390.1397 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0057
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0057
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -2.2500,                 loss: nan
env2_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2129.65,                last time consumption/overall running time: 1567.4061s / 34957.5457 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0055
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0054
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 1862.0,                last time consumption/overall running time: 1354.2940s / 36311.8397 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0056
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0056
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2004.05,                last time consumption/overall running time: 1476.3586s / 37788.1984 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0057
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0058
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 1832.7,                last time consumption/overall running time: 1351.1009s / 39139.2993 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0054
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0053
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
env2_first_0:                 episode reward: -3.6500,                 loss: nan
env2_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2024.3,                last time consumption/overall running time: 1500.0014s / 40639.3006 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0055
env0_second_0:                 episode reward: 1.7500,                 loss: 0.0054
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2035.5,                last time consumption/overall running time: 1498.6406s / 42137.9412 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0058
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0058
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: 0.5500,                 loss: nan
env2_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2027.75,                last time consumption/overall running time: 1509.6895s / 43647.6308 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0052
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0053
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
env2_first_0:                 episode reward: -3.2500,                 loss: nan
env2_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2233.0,                last time consumption/overall running time: 1642.9556s / 45290.5863 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0054
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0053
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
env2_first_0:                 episode reward: -3.7000,                 loss: nan
env2_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2102.55,                last time consumption/overall running time: 1556.2981s / 46846.8845 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0051
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0051
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
env2_first_0:                 episode reward: -1.5500,                 loss: nan
env2_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2101.05,                last time consumption/overall running time: 1546.8774s / 48393.7619 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0052
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0053
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 1789.35,                last time consumption/overall running time: 1315.5517s / 49709.3136 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0053
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0055
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
env2_first_0:                 episode reward: -2.5000,                 loss: nan
env2_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 1732.55,                last time consumption/overall running time: 1272.7163s / 50982.0299 s
env0_first_0:                 episode reward: -5.3500,                 loss: 0.0051
env0_second_0:                 episode reward: 5.3500,                 loss: 0.0055
env1_first_0:                 episode reward: -4.9500,                 loss: nan
env1_second_0:                 episode reward: 4.9500,                 loss: nan
env2_first_0:                 episode reward: -4.3500,                 loss: nan
env2_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 1818.0,                last time consumption/overall running time: 1338.5613s / 52320.5912 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.0049
env0_second_0:                 episode reward: 2.6000,                 loss: 0.0051
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: -4.1000,                 loss: nan
env2_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2079.65,                last time consumption/overall running time: 1551.2353s / 53871.8265 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0047
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0048
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
env2_first_0:                 episode reward: -3.9500,                 loss: nan
env2_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2086.55,                last time consumption/overall running time: 1534.6729s / 55406.4994 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0051
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0052
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -3.2500,                 loss: nan
env2_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2175.25,                last time consumption/overall running time: 1602.1189s / 57008.6183 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0052
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0051
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: -1.2000,                 loss: nan
env2_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2116.55,                last time consumption/overall running time: 1559.0903s / 58567.7086 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0053
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0053
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2049.75,                last time consumption/overall running time: 1513.0246s / 60080.7332 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0053
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0053
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.8000,                 loss: nan
env2_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2068.95,                last time consumption/overall running time: 1531.4636s / 61612.1968 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0053
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0051
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
env2_first_0:                 episode reward: -1.3500,                 loss: nan
env2_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2282.0,                last time consumption/overall running time: 1689.0332s / 63301.2300 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0051
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0052
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2563.9,                last time consumption/overall running time: 1885.7046s / 65186.9346 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0047
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0048
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -1.2500,                 loss: nan
env2_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2407.9,                last time consumption/overall running time: 1786.2332s / 66973.1678 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0045
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0044
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
env2_first_0:                 episode reward: -2.4500,                 loss: nan
env2_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2478.2,                last time consumption/overall running time: 1829.4033s / 68802.5711 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0044
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0044
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -1.2500,                 loss: nan
env2_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2528.25,                last time consumption/overall running time: 1867.6719s / 70670.2431 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0044
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0043
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
env2_first_0:                 episode reward: -2.5500,                 loss: nan
env2_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2514.2,                last time consumption/overall running time: 1856.9424s / 72527.1855 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0044
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0046
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2361.1,                last time consumption/overall running time: 1746.4041s / 74273.5896 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0050
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0049
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2364.6,                last time consumption/overall running time: 1728.7853s / 76002.3750 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0047
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0048
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2456.4,                last time consumption/overall running time: 1817.3513s / 77819.7263 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0047
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0048
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2251.95,                last time consumption/overall running time: 1664.7382s / 79484.4645 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0046
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0045
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2387.15,                last time consumption/overall running time: 1789.6779s / 81274.1424 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0048
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0047
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 1.2000,                 loss: nan
env2_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2297.3,                last time consumption/overall running time: 1694.7312s / 82968.8736 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0046
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0045
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2361.5,                last time consumption/overall running time: 1720.4633s / 84689.3369 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0043
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0047
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
env2_first_0:                 episode reward: -1.8000,                 loss: nan
env2_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2619.9,                last time consumption/overall running time: 1918.7261s / 86608.0630 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0040
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0041
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
env2_first_0:                 episode reward: -3.1000,                 loss: nan
env2_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2283.9,                last time consumption/overall running time: 1670.4706s / 88278.5336 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0041
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0041
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: -3.5500,                 loss: nan
env2_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2157.7,                last time consumption/overall running time: 1583.5564s / 89862.0899 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0045
env0_second_0:                 episode reward: 1.7000,                 loss: 0.0046
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2382.55,                last time consumption/overall running time: 1750.5956s / 91612.6856 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0046
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0047
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2175.2,                last time consumption/overall running time: 1604.5051s / 93217.1907 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0045
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0046
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
env2_first_0:                 episode reward: -3.2000,                 loss: nan
env2_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2676.9,                last time consumption/overall running time: 1982.5369s / 95199.7276 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0044
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0045
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2485.6,                last time consumption/overall running time: 1819.6314s / 97019.3590 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0044
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0046
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -1.7500,                 loss: nan
env2_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2046.05,                last time consumption/overall running time: 1521.5358s / 98540.8948 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0047
env0_second_0:                 episode reward: 1.7000,                 loss: 0.0052
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2081.85,                last time consumption/overall running time: 1537.3672s / 100078.2620 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0049
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0052
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 1912.85,                last time consumption/overall running time: 1422.5427s / 101500.8047 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0048
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0050
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
env2_first_0:                 episode reward: -4.3500,                 loss: nan
env2_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 1956.55,                last time consumption/overall running time: 1435.3830s / 102936.1877 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.0038
env0_second_0:                 episode reward: 6.0500,                 loss: 0.0039
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
env2_first_0:                 episode reward: -5.8500,                 loss: nan
env2_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2246.25,                last time consumption/overall running time: 1652.7446s / 104588.9323 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0034
env0_second_0:                 episode reward: 4.4500,                 loss: 0.0036
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
env2_first_0:                 episode reward: -4.6000,                 loss: nan
env2_second_0:                 episode reward: 4.6000,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2367.3,                last time consumption/overall running time: 1752.3618s / 106341.2941 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0038
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0038
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
env2_first_0:                 episode reward: -3.6500,                 loss: nan
env2_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2350.5,                last time consumption/overall running time: 1761.1669s / 108102.4610 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0035
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0038
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
env2_first_0:                 episode reward: -4.0000,                 loss: nan
env2_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2569.55,                last time consumption/overall running time: 1901.0995s / 110003.5604 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0039
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0040
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
env2_first_0:                 episode reward: -2.4500,                 loss: nan
env2_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2525.15,                last time consumption/overall running time: 1872.3732s / 111875.9337 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0037
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0038
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2452.8,                last time consumption/overall running time: 1806.6673s / 113682.6009 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0035
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0036
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2412.1,                last time consumption/overall running time: 1773.3481s / 115455.9491 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0037
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0039
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
env2_first_0:                 episode reward: -3.5000,                 loss: nan
env2_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2297.3,                last time consumption/overall running time: 1710.7313s / 117166.6803 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0039
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0040
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
env2_first_0:                 episode reward: -3.4500,                 loss: nan
env2_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2443.55,                last time consumption/overall running time: 1803.6566s / 118970.3370 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0046
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0045
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2525.65,                last time consumption/overall running time: 1862.8650s / 120833.2020 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.0039
env0_second_0:                 episode reward: 2.3000,                 loss: 0.0041
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -3.9000,                 loss: nan
env2_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2330.1,                last time consumption/overall running time: 1722.9653s / 122556.1673 s
env0_first_0:                 episode reward: -4.9000,                 loss: 0.0039
env0_second_0:                 episode reward: 4.9000,                 loss: 0.0040
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
env2_first_0:                 episode reward: -2.7000,                 loss: nan
env2_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2010.9,                last time consumption/overall running time: 1481.3945s / 124037.5618 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0045
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0046
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
env2_first_0:                 episode reward: -2.8000,                 loss: nan
env2_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2407.65,                last time consumption/overall running time: 1769.9226s / 125807.4844 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0048
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0049
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2376.7,                last time consumption/overall running time: 1740.7220s / 127548.2064 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0041
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0044
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
env2_first_0:                 episode reward: 0.5500,                 loss: nan
env2_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2217.7,                last time consumption/overall running time: 1634.6546s / 129182.8611 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.0043
env0_second_0:                 episode reward: 2.8000,                 loss: 0.0044
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
env2_first_0:                 episode reward: -1.2000,                 loss: nan
env2_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2278.45,                last time consumption/overall running time: 1680.9352s / 130863.7963 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0044
env0_second_0:                 episode reward: 2.4500,                 loss: 0.0043
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -1.2000,                 loss: nan
env2_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2152.85,                last time consumption/overall running time: 1595.6926s / 132459.4889 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0049
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0052
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2260.65,                last time consumption/overall running time: 1673.1518s / 134132.6407 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0049
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0050
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
env2_first_0:                 episode reward: -2.7500,                 loss: nan
env2_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2390.05,                last time consumption/overall running time: 1770.1427s / 135902.7834 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0044
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0046
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2266.55,                last time consumption/overall running time: 1674.4833s / 137577.2667 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0048
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0050
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -3.2000,                 loss: nan
env2_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2159.65,                last time consumption/overall running time: 1592.5821s / 139169.8488 s
env0_first_0:                 episode reward: -4.4000,                 loss: 0.0045
env0_second_0:                 episode reward: 4.4000,                 loss: 0.0045
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
env2_first_0:                 episode reward: -2.2000,                 loss: nan
env2_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2115.55,                last time consumption/overall running time: 1567.3278s / 140737.1766 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0047
env0_second_0:                 episode reward: 2.0000,                 loss: 0.0050
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2515.9,                last time consumption/overall running time: 1855.5627s / 142592.7393 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0044
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0045
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2017.45,                last time consumption/overall running time: 1490.7590s / 144083.4983 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0046
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0048
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 1994.05,                last time consumption/overall running time: 1460.1054s / 145543.6037 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0051
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0051
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2006.9,                last time consumption/overall running time: 1462.3939s / 147005.9976 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0052
env0_second_0:                 episode reward: -2.5000,                 loss: 0.0054
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 1601.7,                last time consumption/overall running time: 1192.8621s / 148198.8597 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0062
env0_second_0:                 episode reward: -2.3500,                 loss: 0.0066
env1_first_0:                 episode reward: 4.9000,                 loss: nan
env1_second_0:                 episode reward: -4.9000,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2077.85,                last time consumption/overall running time: 1536.7216s / 149735.5814 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.0047
env0_second_0:                 episode reward: -2.9500,                 loss: 0.0053
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
env2_first_0:                 episode reward: 3.0000,                 loss: nan
env2_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2306.55,                last time consumption/overall running time: 1702.4441s / 151438.0255 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0042
env0_second_0:                 episode reward: -1.6000,                 loss: 0.0046
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
env2_first_0:                 episode reward: 2.7500,                 loss: nan
env2_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2028.35,                last time consumption/overall running time: 1498.7427s / 152936.7681 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.0048
env0_second_0:                 episode reward: -3.0500,                 loss: 0.0047
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
env2_first_0:                 episode reward: 3.0500,                 loss: nan
env2_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2198.4,                last time consumption/overall running time: 1611.6654s / 154548.4335 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0045
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0050
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2556.9,                last time consumption/overall running time: 1889.9231s / 156438.3566 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0044
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0046
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2895.45,                last time consumption/overall running time: 2115.7953s / 158554.1519 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0038
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0039
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -1.4000,                 loss: nan
env2_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2702.75,                last time consumption/overall running time: 1999.3197s / 160553.4716 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0037
env0_second_0:                 episode reward: 1.9500,                 loss: 0.0038
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -1.7500,                 loss: nan
env2_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2640.95,                last time consumption/overall running time: 1962.3996s / 162515.8712 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0036
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0036
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
env2_first_0:                 episode reward: -3.1500,                 loss: nan
env2_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2657.8,                last time consumption/overall running time: 1961.0917s / 164476.9629 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0038
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0039
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -2.2500,                 loss: nan
env2_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2573.65,                last time consumption/overall running time: 1883.9220s / 166360.8849 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0041
env0_second_0:                 episode reward: 2.2500,                 loss: 0.0040
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2639.15,                last time consumption/overall running time: 1934.9559s / 168295.8408 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0042
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0041
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2742.5,                last time consumption/overall running time: 2031.0440s / 170326.8848 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0039
env0_second_0:                 episode reward: -1.6000,                 loss: 0.0044
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: 0.9500,                 loss: nan
env2_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2946.0,                last time consumption/overall running time: 2149.0323s / 172475.9172 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0036
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0036
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
env2_first_0:                 episode reward: -2.9500,                 loss: nan
env2_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2639.85,                last time consumption/overall running time: 1942.4334s / 174418.3506 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0038
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0040
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2466.9,                last time consumption/overall running time: 1825.1436s / 176243.4942 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0041
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0044
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 3028.6,                last time consumption/overall running time: 2222.6998s / 178466.1940 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0040
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0044
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 3057.25,                last time consumption/overall running time: 2237.9195s / 180704.1135 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0036
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0037
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2890.1,                last time consumption/overall running time: 2123.7721s / 182827.8856 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0035
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0037
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: -2.0500,                 loss: nan
env2_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2522.35,                last time consumption/overall running time: 1848.3376s / 184676.2232 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0035
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0037
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -4.0500,                 loss: nan
env2_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2540.55,                last time consumption/overall running time: 1871.3139s / 186547.5371 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0036
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0037
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2504.95,                last time consumption/overall running time: 1851.4809s / 188399.0180 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0039
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0041
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2481.25,                last time consumption/overall running time: 1855.1943s / 190254.2124 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.0041
env0_second_0:                 episode reward: 2.2000,                 loss: 0.0043
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
env2_first_0:                 episode reward: -1.8000,                 loss: nan
env2_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2808.55,                last time consumption/overall running time: 2091.7329s / 192345.9453 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0038
env0_second_0:                 episode reward: 2.4500,                 loss: 0.0039
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
env2_first_0:                 episode reward: -2.3000,                 loss: nan
env2_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2437.25,                last time consumption/overall running time: 1816.4101s / 194162.3554 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0041
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0040
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -3.3500,                 loss: nan
env2_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2337.15,                last time consumption/overall running time: 1704.1197s / 195866.4751 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0042
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0041
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2368.6,                last time consumption/overall running time: 1752.0082s / 197618.4832 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0042
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0044
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2459.2,                last time consumption/overall running time: 1804.5986s / 199423.0819 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0043
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0044
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2558.7,                last time consumption/overall running time: 1878.6934s / 201301.7753 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0046
env0_second_0:                 episode reward: 2.2500,                 loss: 0.0049
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2401.55,                last time consumption/overall running time: 1769.9654s / 203071.7407 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0038
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0038
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
env2_first_0:                 episode reward: -3.3500,                 loss: nan
env2_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2673.45,                last time consumption/overall running time: 1943.4999s / 205015.2406 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0039
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0041
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2478.3,                last time consumption/overall running time: 1825.7308s / 206840.9714 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0039
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0039
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: -3.5500,                 loss: nan
env2_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2394.05,                last time consumption/overall running time: 1770.2902s / 208611.2616 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0042
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0041
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -3.5000,                 loss: nan
env2_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2437.95,                last time consumption/overall running time: 1787.6000s / 210398.8616 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.0042
env0_second_0:                 episode reward: 2.6000,                 loss: 0.0041
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2216.3,                last time consumption/overall running time: 1609.7605s / 212008.6221 s
env0_first_0:                 episode reward: -4.7000,                 loss: 0.0039
env0_second_0:                 episode reward: 4.7000,                 loss: 0.0040
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: -2.2000,                 loss: nan
env2_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2194.05,                last time consumption/overall running time: 1621.5664s / 213630.1885 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0042
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0043
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -1.3500,                 loss: nan
env2_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 1719.5,                last time consumption/overall running time: 1265.1326s / 214895.3210 s
env0_first_0:                 episode reward: -5.5500,                 loss: 0.0055
env0_second_0:                 episode reward: 5.5500,                 loss: 0.0053
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
env2_first_0:                 episode reward: -3.8000,                 loss: nan
env2_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2245.55,                last time consumption/overall running time: 1663.5261s / 216558.8472 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0054
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0055
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
env2_first_0:                 episode reward: -3.3000,                 loss: nan
env2_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2418.25,                last time consumption/overall running time: 1776.6759s / 218335.5231 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0039
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0039
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
env2_first_0:                 episode reward: -3.1500,                 loss: nan
env2_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2745.65,                last time consumption/overall running time: 2012.2666s / 220347.7897 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0033
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0035
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2506.75,                last time consumption/overall running time: 1842.1565s / 222189.9462 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0039
env0_second_0:                 episode reward: 2.0000,                 loss: 0.0041
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2696.8,                last time consumption/overall running time: 1986.9090s / 224176.8552 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0041
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0043
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -3.1000,                 loss: nan
env2_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2387.8,                last time consumption/overall running time: 1749.9345s / 225926.7897 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0040
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0040
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -2.3000,                 loss: nan
env2_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2446.15,                last time consumption/overall running time: 1807.9990s / 227734.7887 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0046
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0045
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
env2_first_0:                 episode reward: -0.8000,                 loss: nan
env2_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2376.6,                last time consumption/overall running time: 1756.4148s / 229491.2035 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0045
env0_second_0:                 episode reward: -2.0000,                 loss: 0.0046
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2738.15,                last time consumption/overall running time: 1998.0504s / 231489.2539 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0044
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0046
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2450.3,                last time consumption/overall running time: 1789.8727s / 233279.1266 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0043
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0047
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2500.1,                last time consumption/overall running time: 1835.2270s / 235114.3536 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0038
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0040
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -3.3000,                 loss: nan
env2_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2516.95,                last time consumption/overall running time: 1858.8673s / 236973.2209 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0037
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0039
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
env2_first_0:                 episode reward: -3.6000,                 loss: nan
env2_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2389.6,                last time consumption/overall running time: 1755.7966s / 238729.0175 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0030
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0033
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
env2_first_0:                 episode reward: -5.6500,                 loss: nan
env2_second_0:                 episode reward: 5.6500,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2779.9,                last time consumption/overall running time: 2056.4777s / 240785.4951 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0032
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0035
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -3.3000,                 loss: nan
env2_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2601.45,                last time consumption/overall running time: 1931.5941s / 242717.0892 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.0035
env0_second_0:                 episode reward: 2.1000,                 loss: 0.0036
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
env2_first_0:                 episode reward: -3.6000,                 loss: nan
env2_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2786.5,                last time consumption/overall running time: 2037.9840s / 244755.0732 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0039
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0043
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2665.9,                last time consumption/overall running time: 1958.7093s / 246713.7826 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0038
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0041
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2301.8,                last time consumption/overall running time: 1695.3377s / 248409.1203 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0045
env0_second_0:                 episode reward: -1.6500,                 loss: 0.0049
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 2.3000,                 loss: nan
env2_second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2429.1,                last time consumption/overall running time: 1783.8317s / 250192.9520 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.0042
env0_second_0:                 episode reward: -2.2000,                 loss: 0.0046
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
env2_first_0:                 episode reward: 2.6000,                 loss: nan
env2_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2480.75,                last time consumption/overall running time: 1812.0978s / 252005.0498 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0039
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0043
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 2593.35,                last time consumption/overall running time: 1910.4141s / 253915.4639 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0040
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0041
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 2594.7,                last time consumption/overall running time: 1898.2223s / 255813.6863 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0039
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0040
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
env2_first_0:                 episode reward: -2.0000,                 loss: nan
env2_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 2736.6,                last time consumption/overall running time: 2008.3081s / 257821.9944 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0031
env0_second_0:                 episode reward: 2.2500,                 loss: 0.0034
env1_first_0:                 episode reward: -4.1500,                 loss: nan
env1_second_0:                 episode reward: 4.1500,                 loss: nan
env2_first_0:                 episode reward: -3.7500,                 loss: nan
env2_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 2745.85,                last time consumption/overall running time: 2023.9470s / 259845.9413 s
env0_first_0:                 episode reward: -4.5000,                 loss: 0.0029
env0_second_0:                 episode reward: 4.5000,                 loss: 0.0031
env1_first_0:                 episode reward: -4.8500,                 loss: nan
env1_second_0:                 episode reward: 4.8500,                 loss: nan
env2_first_0:                 episode reward: -5.8000,                 loss: nan
env2_second_0:                 episode reward: 5.8000,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 2498.1,                last time consumption/overall running time: 1833.4713s / 261679.4126 s
env0_first_0:                 episode reward: -3.8500,                 loss: 0.0028
env0_second_0:                 episode reward: 3.8500,                 loss: 0.0031
env1_first_0:                 episode reward: -4.6000,                 loss: nan
env1_second_0:                 episode reward: 4.6000,                 loss: nan
env2_first_0:                 episode reward: -4.8500,                 loss: nan
env2_second_0:                 episode reward: 4.8500,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 2763.75,                last time consumption/overall running time: 2027.7469s / 263707.1595 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0031
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0035
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 2321.65,                last time consumption/overall running time: 1718.9627s / 265426.1222 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0038
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0041
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 2667.35,                last time consumption/overall running time: 1956.9975s / 267383.1197 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0041
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0042
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 2418.1,                last time consumption/overall running time: 1790.0070s / 269173.1267 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0043
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0049
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
env2_first_0:                 episode reward: 2.6000,                 loss: nan
env2_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 2032.65,                last time consumption/overall running time: 1490.1001s / 270663.2268 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0045
env0_second_0:                 episode reward: -1.9500,                 loss: 0.0048
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
env2_first_0:                 episode reward: 1.1500,                 loss: nan
env2_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 1825.3,                last time consumption/overall running time: 1331.4465s / 271994.6733 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.0050
env0_second_0:                 episode reward: -3.6500,                 loss: 0.0054
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
env2_first_0:                 episode reward: 3.0000,                 loss: nan
env2_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 2228.1,                last time consumption/overall running time: 1625.0272s / 273619.7005 s
env0_first_0:                 episode reward: 4.0000,                 loss: 0.0047
env0_second_0:                 episode reward: -4.0000,                 loss: 0.0049
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
env2_first_0:                 episode reward: 4.7500,                 loss: nan
env2_second_0:                 episode reward: -4.7500,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 2135.1,                last time consumption/overall running time: 1564.1419s / 275183.8424 s
env0_first_0:                 episode reward: 3.4000,                 loss: 0.0041
env0_second_0:                 episode reward: -3.4000,                 loss: 0.0044
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
env2_first_0:                 episode reward: 3.5500,                 loss: nan
env2_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 1972.3,                last time consumption/overall running time: 1462.3574s / 276646.1998 s
env0_first_0:                 episode reward: 3.8500,                 loss: 0.0039
env0_second_0:                 episode reward: -3.8500,                 loss: 0.0042
env1_first_0:                 episode reward: 4.2500,                 loss: nan
env1_second_0:                 episode reward: -4.2500,                 loss: nan
env2_first_0:                 episode reward: 5.0500,                 loss: nan
env2_second_0:                 episode reward: -5.0500,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 2229.2,                last time consumption/overall running time: 1641.1453s / 278287.3451 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.0043
env0_second_0:                 episode reward: -2.9000,                 loss: 0.0045
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 2152.55,                last time consumption/overall running time: 1601.9810s / 279889.3262 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0042
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0043
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
env2_first_0:                 episode reward: 3.8500,                 loss: nan
env2_second_0:                 episode reward: -3.8500,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 2069.35,                last time consumption/overall running time: 1528.3117s / 281417.6378 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0047
env0_second_0:                 episode reward: -1.3500,                 loss: 0.0047
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 2.9000,                 loss: nan
env2_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 3361/30000 (11.2033%),                 avg. length: 2273.0,                last time consumption/overall running time: 1666.4160s / 283084.0538 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0045
env0_second_0:                 episode reward: -2.7000,                 loss: 0.0048
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 1.5000,                 loss: nan
env2_second_0:                 episode reward: -1.5000,                 loss: nan
Episode: 3381/30000 (11.2700%),                 avg. length: 1943.75,                last time consumption/overall running time: 1448.5329s / 284532.5867 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.0047
env0_second_0:                 episode reward: -2.8000,                 loss: 0.0048
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
env2_first_0:                 episode reward: 2.3500,                 loss: nan
env2_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 3401/30000 (11.3367%),                 avg. length: 2104.25,                last time consumption/overall running time: 1551.3428s / 286083.9294 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0047
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0049
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 3421/30000 (11.4033%),                 avg. length: 2118.9,                last time consumption/overall running time: 1563.0858s / 287647.0152 s
env0_first_0:                 episode reward: 4.0000,                 loss: 0.0044
env0_second_0:                 episode reward: -4.0000,                 loss: 0.0049
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 3441/30000 (11.4700%),                 avg. length: 2131.4,                last time consumption/overall running time: 1566.3031s / 289213.3184 s
env0_first_0:                 episode reward: 4.0500,                 loss: 0.0043
env0_second_0:                 episode reward: -4.0500,                 loss: 0.0047
env1_first_0:                 episode reward: 2.2500,                 loss: nan
env1_second_0:                 episode reward: -2.2500,                 loss: nan
env2_first_0:                 episode reward: 3.1000,                 loss: nan
env2_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 3461/30000 (11.5367%),                 avg. length: 2047.8,                last time consumption/overall running time: 1506.0502s / 290719.3686 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.0044
env0_second_0:                 episode reward: -3.0500,                 loss: 0.0048
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
env2_first_0:                 episode reward: 2.1500,                 loss: nan
env2_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 3481/30000 (11.6033%),                 avg. length: 2043.4,                last time consumption/overall running time: 1496.5805s / 292215.9491 s
env0_first_0:                 episode reward: 4.2500,                 loss: 0.0047
env0_second_0:                 episode reward: -4.2500,                 loss: 0.0049
env1_first_0:                 episode reward: 4.7000,                 loss: nan
env1_second_0:                 episode reward: -4.7000,                 loss: nan
env2_first_0:                 episode reward: 3.7000,                 loss: nan
env2_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 3501/30000 (11.6700%),                 avg. length: 2050.7,                last time consumption/overall running time: 1517.2979s / 293733.2470 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0054
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0055
env1_first_0:                 episode reward: 0.9500,                 loss: nan
env1_second_0:                 episode reward: -0.9500,                 loss: nan
env2_first_0:                 episode reward: 2.6000,                 loss: nan
env2_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 3521/30000 (11.7367%),                 avg. length: 1684.15,                last time consumption/overall running time: 1233.9842s / 294967.2313 s
env0_first_0:                 episode reward: 4.3000,                 loss: 0.0058
env0_second_0:                 episode reward: -4.3000,                 loss: 0.0058
env1_first_0:                 episode reward: 4.1500,                 loss: nan
env1_second_0:                 episode reward: -4.1500,                 loss: nan
env2_first_0:                 episode reward: 4.1000,                 loss: nan
env2_second_0:                 episode reward: -4.1000,                 loss: nan
Episode: 3541/30000 (11.8033%),                 avg. length: 1988.5,                last time consumption/overall running time: 1464.3813s / 296431.6126 s
env0_first_0:                 episode reward: 2.0500,                 loss: 0.0049
env0_second_0:                 episode reward: -2.0500,                 loss: 0.0052
env1_first_0:                 episode reward: 4.8500,                 loss: nan
env1_second_0:                 episode reward: -4.8500,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 3561/30000 (11.8700%),                 avg. length: 2017.5,                last time consumption/overall running time: 1474.4797s / 297906.0922 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0052
env0_second_0:                 episode reward: -1.3500,                 loss: 0.0052
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 3581/30000 (11.9367%),                 avg. length: 1992.35,                last time consumption/overall running time: 1469.0962s / 299375.1884 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.0046
env0_second_0:                 episode reward: -3.1500,                 loss: 0.0047
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
env2_first_0:                 episode reward: 4.3000,                 loss: nan
env2_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 3601/30000 (12.0033%),                 avg. length: 2348.7,                last time consumption/overall running time: 1727.6063s / 301102.7947 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.0045
env0_second_0:                 episode reward: -2.6500,                 loss: 0.0047
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 2.1500,                 loss: nan
env2_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 3621/30000 (12.0700%),                 avg. length: 2410.85,                last time consumption/overall running time: 1776.4334s / 302879.2281 s
env0_first_0:                 episode reward: 3.4000,                 loss: 0.0041
env0_second_0:                 episode reward: -3.4000,                 loss: 0.0044
env1_first_0:                 episode reward: 3.0000,                 loss: nan
env1_second_0:                 episode reward: -3.0000,                 loss: nan
env2_first_0:                 episode reward: 3.4000,                 loss: nan
env2_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 3641/30000 (12.1367%),                 avg. length: 2454.1,                last time consumption/overall running time: 1800.2602s / 304679.4883 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0045
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0045
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 3661/30000 (12.2033%),                 avg. length: 2332.75,                last time consumption/overall running time: 1709.7600s / 306389.2483 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0047
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0047
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 3681/30000 (12.2700%),                 avg. length: 2297.85,                last time consumption/overall running time: 1690.9765s / 308080.2249 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.0045
env0_second_0:                 episode reward: -3.5500,                 loss: 0.0048
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
env2_first_0:                 episode reward: 2.6500,                 loss: nan
env2_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 3701/30000 (12.3367%),                 avg. length: 2241.75,                last time consumption/overall running time: 1647.1378s / 309727.3626 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0047
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0049
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
env2_first_0:                 episode reward: 2.3000,                 loss: nan
env2_second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 3721/30000 (12.4033%),                 avg. length: 2367.15,                last time consumption/overall running time: 1746.9165s / 311474.2791 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0049
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0047
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 3741/30000 (12.4700%),                 avg. length: 2337.65,                last time consumption/overall running time: 1710.8588s / 313185.1380 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0047
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0046
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 3761/30000 (12.5367%),                 avg. length: 1997.75,                last time consumption/overall running time: 1456.7249s / 314641.8629 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0047
env0_second_0:                 episode reward: -1.9000,                 loss: 0.0048
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 2.4000,                 loss: nan
env2_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 3781/30000 (12.6033%),                 avg. length: 2305.05,                last time consumption/overall running time: 1680.5918s / 316322.4548 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0047
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0046
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 3801/30000 (12.6700%),                 avg. length: 2040.95,                last time consumption/overall running time: 1502.5503s / 317825.0051 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0046
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0047
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 2.8000,                 loss: nan
env2_second_0:                 episode reward: -2.8000,                 loss: nan
Episode: 3821/30000 (12.7367%),                 avg. length: 2384.1,                last time consumption/overall running time: 1750.7732s / 319575.7783 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0040
env0_second_0:                 episode reward: -1.8500,                 loss: 0.0041
env1_first_0:                 episode reward: 3.3000,                 loss: nan
env1_second_0:                 episode reward: -3.3000,                 loss: nan
env2_first_0:                 episode reward: 3.2500,                 loss: nan
env2_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 3841/30000 (12.8033%),                 avg. length: 2171.5,                last time consumption/overall running time: 1586.5959s / 321162.3742 s
env0_first_0:                 episode reward: 5.4000,                 loss: 0.0039
env0_second_0:                 episode reward: -5.4000,                 loss: 0.0041
env1_first_0:                 episode reward: 4.9000,                 loss: nan
env1_second_0:                 episode reward: -4.9000,                 loss: nan
env2_first_0:                 episode reward: 3.8500,                 loss: nan
env2_second_0:                 episode reward: -3.8500,                 loss: nan
Episode: 3861/30000 (12.8700%),                 avg. length: 2248.85,                last time consumption/overall running time: 1660.7536s / 322823.1278 s
env0_first_0:                 episode reward: 4.9000,                 loss: 0.0038
env0_second_0:                 episode reward: -4.9000,                 loss: 0.0041
env1_first_0:                 episode reward: 4.5000,                 loss: nan
env1_second_0:                 episode reward: -4.5000,                 loss: nan
env2_first_0:                 episode reward: 5.5000,                 loss: nan
env2_second_0:                 episode reward: -5.5000,                 loss: nan
Episode: 3881/30000 (12.9367%),                 avg. length: 2379.55,                last time consumption/overall running time: 1746.9771s / 324570.1048 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.0033
env0_second_0:                 episode reward: -3.8000,                 loss: 0.0038
env1_first_0:                 episode reward: 4.3500,                 loss: nan
env1_second_0:                 episode reward: -4.3500,                 loss: nan
env2_first_0:                 episode reward: 4.0500,                 loss: nan
env2_second_0:                 episode reward: -4.0500,                 loss: nan
Episode: 3901/30000 (13.0033%),                 avg. length: 2573.35,                last time consumption/overall running time: 1907.0975s / 326477.2023 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.0037
env0_second_0:                 episode reward: -3.5000,                 loss: 0.0041
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
env2_first_0:                 episode reward: 2.0500,                 loss: nan
env2_second_0:                 episode reward: -2.0500,                 loss: nan
Episode: 3921/30000 (13.0700%),                 avg. length: 2224.1,                last time consumption/overall running time: 1631.1938s / 328108.3961 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.0040
env0_second_0:                 episode reward: -3.5500,                 loss: 0.0043
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
env2_first_0:                 episode reward: 2.1500,                 loss: nan
env2_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 3941/30000 (13.1367%),                 avg. length: 1978.15,                last time consumption/overall running time: 1457.3309s / 329565.7271 s
env0_first_0:                 episode reward: 4.1500,                 loss: 0.0049
env0_second_0:                 episode reward: -4.1500,                 loss: 0.0052
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 3.8000,                 loss: nan
env2_second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 3961/30000 (13.2033%),                 avg. length: 1856.75,                last time consumption/overall running time: 1356.8719s / 330922.5990 s
env0_first_0:                 episode reward: 3.3500,                 loss: 0.0051
env0_second_0:                 episode reward: -3.3500,                 loss: 0.0051
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
env2_first_0:                 episode reward: 4.3000,                 loss: nan
env2_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 3981/30000 (13.2700%),                 avg. length: 2198.0,                last time consumption/overall running time: 1619.5857s / 332542.1846 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0050
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0049
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4001/30000 (13.3367%),                 avg. length: 2041.8,                last time consumption/overall running time: 1484.3145s / 334026.4992 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.0050
env0_second_0:                 episode reward: -3.5000,                 loss: 0.0054
env1_first_0:                 episode reward: 2.9500,                 loss: nan
env1_second_0:                 episode reward: -2.9500,                 loss: nan
env2_first_0:                 episode reward: 3.2500,                 loss: nan
env2_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 4021/30000 (13.4033%),                 avg. length: 1789.55,                last time consumption/overall running time: 1300.5472s / 335327.0464 s
env0_first_0:                 episode reward: 5.4500,                 loss: 0.0050
env0_second_0:                 episode reward: -5.4500,                 loss: 0.0049
env1_first_0:                 episode reward: 4.4000,                 loss: nan
env1_second_0:                 episode reward: -4.4000,                 loss: nan
env2_first_0:                 episode reward: 5.6000,                 loss: nan
env2_second_0:                 episode reward: -5.6000,                 loss: nan
Episode: 4041/30000 (13.4700%),                 avg. length: 1903.4,                last time consumption/overall running time: 1397.6541s / 336724.7005 s
env0_first_0:                 episode reward: 4.2500,                 loss: 0.0046
env0_second_0:                 episode reward: -4.2500,                 loss: 0.0047
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
env2_first_0:                 episode reward: 3.3500,                 loss: nan
env2_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 4061/30000 (13.5367%),                 avg. length: 2313.55,                last time consumption/overall running time: 1683.4939s / 338408.1944 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0045
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0047
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 4081/30000 (13.6033%),                 avg. length: 2475.1,                last time consumption/overall running time: 1826.9265s / 340235.1210 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0045
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0049
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 4101/30000 (13.6700%),                 avg. length: 2663.6,                last time consumption/overall running time: 1946.3734s / 342181.4944 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0039
env0_second_0:                 episode reward: -1.8000,                 loss: 0.0043
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 2.4500,                 loss: nan
env2_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 4121/30000 (13.7367%),                 avg. length: 2489.95,                last time consumption/overall running time: 1826.7640s / 344008.2584 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.0041
env0_second_0:                 episode reward: -2.8500,                 loss: 0.0043
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 4141/30000 (13.8033%),                 avg. length: 2409.15,                last time consumption/overall running time: 1769.9628s / 345778.2212 s
env0_first_0:                 episode reward: 4.7500,                 loss: 0.0036
env0_second_0:                 episode reward: -4.7500,                 loss: 0.0040
env1_first_0:                 episode reward: 4.1500,                 loss: nan
env1_second_0:                 episode reward: -4.1500,                 loss: nan
env2_first_0:                 episode reward: 5.1500,                 loss: nan
env2_second_0:                 episode reward: -5.1500,                 loss: nan
Episode: 4161/30000 (13.8700%),                 avg. length: 2298.5,                last time consumption/overall running time: 1692.3628s / 347470.5840 s
env0_first_0:                 episode reward: 5.6000,                 loss: 0.0039
env0_second_0:                 episode reward: -5.6000,                 loss: 0.0043
env1_first_0:                 episode reward: 3.9000,                 loss: nan
env1_second_0:                 episode reward: -3.9000,                 loss: nan
env2_first_0:                 episode reward: 4.9000,                 loss: nan
env2_second_0:                 episode reward: -4.9000,                 loss: nan
Episode: 4181/30000 (13.9367%),                 avg. length: 2366.4,                last time consumption/overall running time: 1762.5344s / 349233.1184 s
env0_first_0:                 episode reward: 3.8500,                 loss: 0.0036
env0_second_0:                 episode reward: -3.8500,                 loss: 0.0039
env1_first_0:                 episode reward: 4.3500,                 loss: nan
env1_second_0:                 episode reward: -4.3500,                 loss: nan
env2_first_0:                 episode reward: 3.6500,                 loss: nan
env2_second_0:                 episode reward: -3.6500,                 loss: nan
Episode: 4201/30000 (14.0033%),                 avg. length: 2217.5,                last time consumption/overall running time: 1619.6041s / 350852.7225 s
env0_first_0:                 episode reward: 3.8500,                 loss: 0.0041
env0_second_0:                 episode reward: -3.8500,                 loss: 0.0044
env1_first_0:                 episode reward: 5.3500,                 loss: nan
env1_second_0:                 episode reward: -5.3500,                 loss: nan
env2_first_0:                 episode reward: 4.5500,                 loss: nan
env2_second_0:                 episode reward: -4.5500,                 loss: nan
Episode: 4221/30000 (14.0700%),                 avg. length: 2020.45,                last time consumption/overall running time: 1473.9685s / 352326.6910 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.0048
env0_second_0:                 episode reward: -3.3000,                 loss: 0.0050
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
env2_first_0:                 episode reward: 3.3500,                 loss: nan
env2_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 4241/30000 (14.1367%),                 avg. length: 2134.4,                last time consumption/overall running time: 1556.8132s / 353883.5042 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0053
env0_second_0:                 episode reward: -1.7000,                 loss: 0.0056
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
env2_first_0:                 episode reward: 2.9500,                 loss: nan
env2_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 4261/30000 (14.2033%),                 avg. length: 2684.65,                last time consumption/overall running time: 1958.1059s / 355841.6101 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.0045
env0_second_0:                 episode reward: -2.7500,                 loss: 0.0045
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 1.3500,                 loss: nan
env2_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 4281/30000 (14.2700%),                 avg. length: 2716.85,                last time consumption/overall running time: 1980.1024s / 357821.7125 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0038
env0_second_0:                 episode reward: -1.8500,                 loss: 0.0037
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 2.7500,                 loss: nan
env2_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 4301/30000 (14.3367%),                 avg. length: 2695.9,                last time consumption/overall running time: 1968.1814s / 359789.8939 s
env0_first_0:                 episode reward: 3.1500,                 loss: 0.0037
env0_second_0:                 episode reward: -3.1500,                 loss: 0.0039
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 2.9500,                 loss: nan
env2_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 4321/30000 (14.4033%),                 avg. length: 2549.9,                last time consumption/overall running time: 1864.7635s / 361654.6574 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0044
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0045
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 4341/30000 (14.4700%),                 avg. length: 2646.45,                last time consumption/overall running time: 1923.8575s / 363578.5149 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.0038
env0_second_0:                 episode reward: -2.9000,                 loss: 0.0041
env1_first_0:                 episode reward: 3.9000,                 loss: nan
env1_second_0:                 episode reward: -3.9000,                 loss: nan
env2_first_0:                 episode reward: 3.3500,                 loss: nan
env2_second_0:                 episode reward: -3.3500,                 loss: nan
Episode: 4361/30000 (14.5367%),                 avg. length: 2407.5,                last time consumption/overall running time: 1774.3396s / 365352.8546 s
env0_first_0:                 episode reward: 4.5000,                 loss: 0.0037
env0_second_0:                 episode reward: -4.5000,                 loss: 0.0041
env1_first_0:                 episode reward: 4.4000,                 loss: nan
env1_second_0:                 episode reward: -4.4000,                 loss: nan
env2_first_0:                 episode reward: 4.3000,                 loss: nan
env2_second_0:                 episode reward: -4.3000,                 loss: nan
Episode: 4381/30000 (14.6033%),                 avg. length: 2232.25,                last time consumption/overall running time: 1632.8654s / 366985.7199 s
env0_first_0:                 episode reward: 4.4500,                 loss: 0.0041
env0_second_0:                 episode reward: -4.4500,                 loss: 0.0045
env1_first_0:                 episode reward: 5.2500,                 loss: nan
env1_second_0:                 episode reward: -5.2500,                 loss: nan
env2_first_0:                 episode reward: 5.3000,                 loss: nan
env2_second_0:                 episode reward: -5.3000,                 loss: nan
Episode: 4401/30000 (14.6700%),                 avg. length: 2357.95,                last time consumption/overall running time: 1721.8770s / 368707.5969 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.0039
env0_second_0:                 episode reward: -3.0000,                 loss: 0.0042
env1_first_0:                 episode reward: 3.5500,                 loss: nan
env1_second_0:                 episode reward: -3.5500,                 loss: nan
env2_first_0:                 episode reward: 2.9500,                 loss: nan
env2_second_0:                 episode reward: -2.9500,                 loss: nan
Episode: 4421/30000 (14.7367%),                 avg. length: 2357.3,                last time consumption/overall running time: 1732.6359s / 370440.2327 s
env0_first_0:                 episode reward: 5.1000,                 loss: 0.0035
env0_second_0:                 episode reward: -5.1000,                 loss: 0.0038
env1_first_0:                 episode reward: 5.3000,                 loss: nan
env1_second_0:                 episode reward: -5.3000,                 loss: nan
env2_first_0:                 episode reward: 5.0000,                 loss: nan
env2_second_0:                 episode reward: -5.0000,                 loss: nan
Episode: 4441/30000 (14.8033%),                 avg. length: 1817.05,                last time consumption/overall running time: 1322.0184s / 371762.2511 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0038
env0_second_0:                 episode reward: -2.7000,                 loss: 0.0041
env1_first_0:                 episode reward: 4.0000,                 loss: nan
env1_second_0:                 episode reward: -4.0000,                 loss: nan
env2_first_0:                 episode reward: 4.0000,                 loss: nan
env2_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 4461/30000 (14.8700%),                 avg. length: 1701.0,                last time consumption/overall running time: 1257.1527s / 373019.4038 s
env0_first_0:                 episode reward: 2.8500,                 loss: 0.0049
env0_second_0:                 episode reward: -2.8500,                 loss: 0.0052
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
env2_first_0:                 episode reward: 4.0000,                 loss: nan
env2_second_0:                 episode reward: -4.0000,                 loss: nan
Episode: 4481/30000 (14.9367%),                 avg. length: 2294.85,                last time consumption/overall running time: 1680.9232s / 374700.3269 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.0044
env0_second_0:                 episode reward: -3.0500,                 loss: 0.0046
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 2.0000,                 loss: nan
env2_second_0:                 episode reward: -2.0000,                 loss: nan
Episode: 4501/30000 (15.0033%),                 avg. length: 2046.05,                last time consumption/overall running time: 1494.7591s / 376195.0860 s
env0_first_0:                 episode reward: 6.3000,                 loss: 0.0037
env0_second_0:                 episode reward: -6.3000,                 loss: 0.0039
env1_first_0:                 episode reward: 4.6500,                 loss: nan
env1_second_0:                 episode reward: -4.6500,                 loss: nan
env2_first_0:                 episode reward: 5.2500,                 loss: nan
env2_second_0:                 episode reward: -5.2500,                 loss: nan
Episode: 4521/30000 (15.0700%),                 avg. length: 2030.55,                last time consumption/overall running time: 1488.9147s / 377684.0007 s
env0_first_0:                 episode reward: 6.3500,                 loss: 0.0034
env0_second_0:                 episode reward: -6.3500,                 loss: 0.0037
env1_first_0:                 episode reward: 5.2500,                 loss: nan
env1_second_0:                 episode reward: -5.2500,                 loss: nan
env2_first_0:                 episode reward: 5.3000,                 loss: nan
env2_second_0:                 episode reward: -5.3000,                 loss: nan
Episode: 4541/30000 (15.1367%),                 avg. length: 2161.0,                last time consumption/overall running time: 1600.1154s / 379284.1161 s
env0_first_0:                 episode reward: 4.0000,                 loss: 0.0039
env0_second_0:                 episode reward: -4.0000,                 loss: 0.0042
env1_first_0:                 episode reward: 4.3000,                 loss: nan
env1_second_0:                 episode reward: -4.3000,                 loss: nan
env2_first_0:                 episode reward: 2.3500,                 loss: nan
env2_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 4561/30000 (15.2033%),                 avg. length: 2554.6,                last time consumption/overall running time: 1874.4529s / 381158.5690 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.0040
env0_second_0:                 episode reward: -2.9500,                 loss: 0.0042
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 2.6500,                 loss: nan
env2_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 4581/30000 (15.2700%),                 avg. length: 2477.95,                last time consumption/overall running time: 1820.7720s / 382979.3410 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0037
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0040
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4601/30000 (15.3367%),                 avg. length: 2353.65,                last time consumption/overall running time: 1729.1098s / 384708.4508 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.0041
env0_second_0:                 episode reward: -2.6500,                 loss: 0.0043
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 1.4000,                 loss: nan
env2_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 4621/30000 (15.4033%),                 avg. length: 2537.25,                last time consumption/overall running time: 1850.6468s / 386559.0976 s
env0_first_0:                 episode reward: 2.4500,                 loss: 0.0032
env0_second_0:                 episode reward: -2.4500,                 loss: 0.0035
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
env2_first_0:                 episode reward: 3.0500,                 loss: nan
env2_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 4641/30000 (15.4700%),                 avg. length: 2472.5,                last time consumption/overall running time: 1814.7535s / 388373.8510 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0042
env0_second_0:                 episode reward: -1.8000,                 loss: 0.0043
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
env2_first_0:                 episode reward: 3.0000,                 loss: nan
env2_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 4661/30000 (15.5367%),                 avg. length: 2652.65,                last time consumption/overall running time: 1960.9712s / 390334.8222 s
env0_first_0:                 episode reward: 2.6000,                 loss: 0.0037
env0_second_0:                 episode reward: -2.6000,                 loss: 0.0040
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
env2_first_0:                 episode reward: 3.4000,                 loss: nan
env2_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 4681/30000 (15.6033%),                 avg. length: 2519.6,                last time consumption/overall running time: 1862.1687s / 392196.9909 s
env0_first_0:                 episode reward: 4.6500,                 loss: 0.0031
env0_second_0:                 episode reward: -4.6500,                 loss: 0.0034
env1_first_0:                 episode reward: 4.9000,                 loss: nan
env1_second_0:                 episode reward: -4.9000,                 loss: nan
env2_first_0:                 episode reward: 5.1500,                 loss: nan
env2_second_0:                 episode reward: -5.1500,                 loss: nan
Episode: 4701/30000 (15.6700%),                 avg. length: 3051.0,                last time consumption/overall running time: 2233.7822s / 394430.7730 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0037
env0_second_0:                 episode reward: -1.6500,                 loss: 0.0039
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 4721/30000 (15.7367%),                 avg. length: 2893.85,                last time consumption/overall running time: 2120.4740s / 396551.2470 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0036
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0038
env1_first_0:                 episode reward: 3.8500,                 loss: nan
env1_second_0:                 episode reward: -3.8500,                 loss: nan
env2_first_0:                 episode reward: 2.3500,                 loss: nan
env2_second_0:                 episode reward: -2.3500,                 loss: nan
Episode: 4741/30000 (15.8033%),                 avg. length: 2483.0,                last time consumption/overall running time: 1804.5536s / 398355.8006 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0041
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0043
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 4761/30000 (15.8700%),                 avg. length: 2503.65,                last time consumption/overall running time: 1895.5224s / 400251.3230 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0041
env0_second_0:                 episode reward: -1.9000,                 loss: 0.0042
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
env2_first_0:                 episode reward: 3.2500,                 loss: nan
env2_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 4781/30000 (15.9367%),                 avg. length: 2541.9,                last time consumption/overall running time: 1855.5528s / 402106.8758 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0040
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0042
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 4801/30000 (16.0033%),                 avg. length: 2555.95,                last time consumption/overall running time: 1869.6592s / 403976.5350 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0039
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0042
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 4821/30000 (16.0700%),                 avg. length: 2576.0,                last time consumption/overall running time: 1880.8962s / 405857.4313 s
env0_first_0:                 episode reward: 1.2000,                 loss: 0.0044
env0_second_0:                 episode reward: -1.2000,                 loss: 0.0042
env1_first_0:                 episode reward: 1.9500,                 loss: nan
env1_second_0:                 episode reward: -1.9500,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 4841/30000 (16.1367%),                 avg. length: 2588.2,                last time consumption/overall running time: 1897.9725s / 407755.4038 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0048
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0048
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 4861/30000 (16.2033%),                 avg. length: 2622.0,                last time consumption/overall running time: 1920.7083s / 409676.1121 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0045
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0045
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 4881/30000 (16.2700%),                 avg. length: 2773.25,                last time consumption/overall running time: 2030.6450s / 411706.7571 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0039
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0040
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 4901/30000 (16.3367%),                 avg. length: 2479.8,                last time consumption/overall running time: 1814.8685s / 413521.6256 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0042
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0045
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
env2_first_0:                 episode reward: -1.2500,                 loss: nan
env2_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 4921/30000 (16.4033%),                 avg. length: 2225.4,                last time consumption/overall running time: 1643.8181s / 415165.4437 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0051
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0051
env1_first_0:                 episode reward: 2.3000,                 loss: nan
env1_second_0:                 episode reward: -2.3000,                 loss: nan
env2_first_0:                 episode reward: 0.5500,                 loss: nan
env2_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 4941/30000 (16.4700%),                 avg. length: 2240.45,                last time consumption/overall running time: 1641.2647s / 416806.7084 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.0046
env0_second_0:                 episode reward: -2.7500,                 loss: 0.0047
env1_first_0:                 episode reward: 2.4500,                 loss: nan
env1_second_0:                 episode reward: -2.4500,                 loss: nan
env2_first_0:                 episode reward: 3.3000,                 loss: nan
env2_second_0:                 episode reward: -3.3000,                 loss: nan
Episode: 4961/30000 (16.5367%),                 avg. length: 2787.2,                last time consumption/overall running time: 2034.5966s / 418841.3051 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0040
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0043
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 4981/30000 (16.6033%),                 avg. length: 2415.1,                last time consumption/overall running time: 1773.1351s / 420614.4401 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0040
env0_second_0:                 episode reward: -1.8500,                 loss: 0.0042
env1_first_0:                 episode reward: 3.4500,                 loss: nan
env1_second_0:                 episode reward: -3.4500,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 5001/30000 (16.6700%),                 avg. length: 2237.15,                last time consumption/overall running time: 1641.4335s / 422255.8736 s
env0_first_0:                 episode reward: 3.4000,                 loss: 0.0042
env0_second_0:                 episode reward: -3.4000,                 loss: 0.0044
env1_first_0:                 episode reward: 3.6000,                 loss: nan
env1_second_0:                 episode reward: -3.6000,                 loss: nan
env2_first_0:                 episode reward: 4.0500,                 loss: nan
env2_second_0:                 episode reward: -4.0500,                 loss: nan
Episode: 5021/30000 (16.7367%),                 avg. length: 2374.85,                last time consumption/overall running time: 1719.2786s / 423975.1522 s
env0_first_0:                 episode reward: 4.0000,                 loss: 0.0042
env0_second_0:                 episode reward: -4.0000,                 loss: 0.0048
env1_first_0:                 episode reward: 4.8500,                 loss: nan
env1_second_0:                 episode reward: -4.8500,                 loss: nan
env2_first_0:                 episode reward: 4.7000,                 loss: nan
env2_second_0:                 episode reward: -4.7000,                 loss: nan
Episode: 5041/30000 (16.8033%),                 avg. length: 2510.85,                last time consumption/overall running time: 1837.3014s / 425812.4537 s
env0_first_0:                 episode reward: 3.7500,                 loss: 0.0035
env0_second_0:                 episode reward: -3.7500,                 loss: 0.0037
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 3.4000,                 loss: nan
env2_second_0:                 episode reward: -3.4000,                 loss: nan
Episode: 5061/30000 (16.8700%),                 avg. length: 2472.25,                last time consumption/overall running time: 1801.4529s / 427613.9066 s
env0_first_0:                 episode reward: 4.3000,                 loss: 0.0037
env0_second_0:                 episode reward: -4.3000,                 loss: 0.0040
env1_first_0:                 episode reward: 4.4000,                 loss: nan
env1_second_0:                 episode reward: -4.4000,                 loss: nan
env2_first_0:                 episode reward: 4.7000,                 loss: nan
env2_second_0:                 episode reward: -4.7000,                 loss: nan
Episode: 5081/30000 (16.9367%),                 avg. length: 2653.4,                last time consumption/overall running time: 1935.9092s / 429549.8158 s
env0_first_0:                 episode reward: 3.3500,                 loss: 0.0031
env0_second_0:                 episode reward: -3.3500,                 loss: 0.0033
env1_first_0:                 episode reward: 3.5000,                 loss: nan
env1_second_0:                 episode reward: -3.5000,                 loss: nan
env2_first_0:                 episode reward: 3.5500,                 loss: nan
env2_second_0:                 episode reward: -3.5500,                 loss: nan
Episode: 5101/30000 (17.0033%),                 avg. length: 2694.05,                last time consumption/overall running time: 1982.5879s / 431532.4037 s
env0_first_0:                 episode reward: 2.8000,                 loss: 0.0038
env0_second_0:                 episode reward: -2.8000,                 loss: 0.0039
env1_first_0:                 episode reward: 3.0500,                 loss: nan
env1_second_0:                 episode reward: -3.0500,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 5121/30000 (17.0700%),                 avg. length: 2418.45,                last time consumption/overall running time: 1761.9389s / 433294.3426 s
env0_first_0:                 episode reward: 5.0500,                 loss: 0.0035
env0_second_0:                 episode reward: -5.0500,                 loss: 0.0036
env1_first_0:                 episode reward: 4.5500,                 loss: nan
env1_second_0:                 episode reward: -4.5500,                 loss: nan
env2_first_0:                 episode reward: 3.6500,                 loss: nan
env2_second_0:                 episode reward: -3.6500,                 loss: nan
Episode: 5141/30000 (17.1367%),                 avg. length: 2034.65,                last time consumption/overall running time: 1497.3624s / 434791.7050 s
env0_first_0:                 episode reward: 4.5500,                 loss: 0.0043
env0_second_0:                 episode reward: -4.5500,                 loss: 0.0044
env1_first_0:                 episode reward: 4.3000,                 loss: nan
env1_second_0:                 episode reward: -4.3000,                 loss: nan
env2_first_0:                 episode reward: 4.2500,                 loss: nan
env2_second_0:                 episode reward: -4.2500,                 loss: nan
Episode: 5161/30000 (17.2033%),                 avg. length: 2121.6,                last time consumption/overall running time: 1569.6781s / 436361.3831 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.0047
env0_second_0:                 episode reward: -2.4000,                 loss: 0.0051
env1_first_0:                 episode reward: 2.0500,                 loss: nan
env1_second_0:                 episode reward: -2.0500,                 loss: nan
env2_first_0:                 episode reward: 2.5000,                 loss: nan
env2_second_0:                 episode reward: -2.5000,                 loss: nan
Episode: 5181/30000 (17.2700%),                 avg. length: 2514.85,                last time consumption/overall running time: 1854.7285s / 438216.1117 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0040
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0045
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 1.4000,                 loss: nan
env2_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 5201/30000 (17.3367%),                 avg. length: 2786.0,                last time consumption/overall running time: 2039.0547s / 440255.1664 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0037
env0_second_0:                 episode reward: -2.0000,                 loss: 0.0038
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.2500,                 loss: nan
env2_second_0:                 episode reward: -1.2500,                 loss: nan
Episode: 5221/30000 (17.4033%),                 avg. length: 2681.05,                last time consumption/overall running time: 1958.9644s / 442214.1307 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0035
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0038
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
env2_first_0:                 episode reward: 3.1000,                 loss: nan
env2_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 5241/30000 (17.4700%),                 avg. length: 2946.05,                last time consumption/overall running time: 2155.7694s / 444369.9001 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0036
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0037
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 2.7000,                 loss: nan
env2_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 5261/30000 (17.5367%),                 avg. length: 2843.4,                last time consumption/overall running time: 2064.5068s / 446434.4069 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0036
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0036
env1_first_0:                 episode reward: 2.3500,                 loss: nan
env1_second_0:                 episode reward: -2.3500,                 loss: nan
env2_first_0:                 episode reward: 3.0500,                 loss: nan
env2_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 5281/30000 (17.6033%),                 avg. length: 2679.2,                last time consumption/overall running time: 1963.8590s / 448398.2660 s
env0_first_0:                 episode reward: 3.6000,                 loss: 0.0037
env0_second_0:                 episode reward: -3.6000,                 loss: 0.0035
env1_first_0:                 episode reward: 2.7500,                 loss: nan
env1_second_0:                 episode reward: -2.7500,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 5301/30000 (17.6700%),                 avg. length: 2147.25,                last time consumption/overall running time: 1575.7397s / 449974.0057 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0042
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0041
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
env2_first_0:                 episode reward: -2.7500,                 loss: nan
env2_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 5321/30000 (17.7367%),                 avg. length: 1974.2,                last time consumption/overall running time: 1450.6726s / 451424.6783 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0053
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0045
env1_first_0:                 episode reward: -6.0500,                 loss: nan
env1_second_0:                 episode reward: 6.0500,                 loss: nan
env2_first_0:                 episode reward: -4.2000,                 loss: nan
env2_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 5341/30000 (17.8033%),                 avg. length: 2005.65,                last time consumption/overall running time: 1455.6536s / 452880.3320 s
env0_first_0:                 episode reward: -5.5500,                 loss: 0.0045
env0_second_0:                 episode reward: 5.5500,                 loss: 0.0045
env1_first_0:                 episode reward: -5.9500,                 loss: nan
env1_second_0:                 episode reward: 5.9500,                 loss: nan
env2_first_0:                 episode reward: -4.2000,                 loss: nan
env2_second_0:                 episode reward: 4.2000,                 loss: nan
Episode: 5361/30000 (17.8700%),                 avg. length: 1904.0,                last time consumption/overall running time: 1392.8962s / 454273.2282 s
env0_first_0:                 episode reward: -5.0000,                 loss: 0.0042
env0_second_0:                 episode reward: 5.0000,                 loss: 0.0043
env1_first_0:                 episode reward: -6.1500,                 loss: nan
env1_second_0:                 episode reward: 6.1500,                 loss: nan
env2_first_0:                 episode reward: -4.9500,                 loss: nan
env2_second_0:                 episode reward: 4.9500,                 loss: nan
Episode: 5381/30000 (17.9367%),                 avg. length: 1970.35,                last time consumption/overall running time: 1450.2815s / 455723.5096 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.0037
env0_second_0:                 episode reward: 4.2500,                 loss: 0.0044
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
env2_first_0:                 episode reward: -3.6000,                 loss: nan
env2_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 5401/30000 (18.0033%),                 avg. length: 1788.45,                last time consumption/overall running time: 1305.7251s / 457029.2347 s
env0_first_0:                 episode reward: -4.8500,                 loss: 0.0038
env0_second_0:                 episode reward: 4.8500,                 loss: 0.0040
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
env2_first_0:                 episode reward: -5.7500,                 loss: nan
env2_second_0:                 episode reward: 5.7500,                 loss: nan
Episode: 5421/30000 (18.0700%),                 avg. length: 1667.4,                last time consumption/overall running time: 1216.4396s / 458245.6742 s
env0_first_0:                 episode reward: -6.0000,                 loss: 0.0035
env0_second_0:                 episode reward: 6.0000,                 loss: 0.0036
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
env2_first_0:                 episode reward: -6.3000,                 loss: nan
env2_second_0:                 episode reward: 6.3000,                 loss: nan
Episode: 5441/30000 (18.1367%),                 avg. length: 1763.9,                last time consumption/overall running time: 1297.0760s / 459542.7503 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0048
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0049
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 5461/30000 (18.2033%),                 avg. length: 2088.9,                last time consumption/overall running time: 1539.7015s / 461082.4518 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0057
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0054
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 5481/30000 (18.2700%),                 avg. length: 2011.35,                last time consumption/overall running time: 1469.5908s / 462552.0426 s
env0_first_0:                 episode reward: 2.3000,                 loss: 0.0045
env0_second_0:                 episode reward: -2.3000,                 loss: 0.0044
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
env2_first_0:                 episode reward: 3.1000,                 loss: nan
env2_second_0:                 episode reward: -3.1000,                 loss: nan
Episode: 5501/30000 (18.3367%),                 avg. length: 2373.7,                last time consumption/overall running time: 1740.9591s / 464293.0017 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0040
env0_second_0:                 episode reward: -1.9500,                 loss: 0.0039
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 5521/30000 (18.4033%),                 avg. length: 2956.8,                last time consumption/overall running time: 2154.4601s / 466447.4618 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0039
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0037
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 5541/30000 (18.4700%),                 avg. length: 2704.15,                last time consumption/overall running time: 1977.1440s / 468424.6058 s
env0_first_0:                 episode reward: 4.5500,                 loss: 0.0028
env0_second_0:                 episode reward: -4.5500,                 loss: 0.0026
env1_first_0:                 episode reward: 4.2000,                 loss: nan
env1_second_0:                 episode reward: -4.2000,                 loss: nan
env2_first_0:                 episode reward: 4.0500,                 loss: nan
env2_second_0:                 episode reward: -4.0500,                 loss: nan
Episode: 5561/30000 (18.5367%),                 avg. length: 2601.6,                last time consumption/overall running time: 1907.9093s / 470332.5150 s
env0_first_0:                 episode reward: 4.1000,                 loss: 0.0028
env0_second_0:                 episode reward: -4.1000,                 loss: 0.0031
env1_first_0:                 episode reward: 4.8500,                 loss: nan
env1_second_0:                 episode reward: -4.8500,                 loss: nan
env2_first_0:                 episode reward: 5.1500,                 loss: nan
env2_second_0:                 episode reward: -5.1500,                 loss: nan
Episode: 5581/30000 (18.6033%),                 avg. length: 3102.2,                last time consumption/overall running time: 2280.4351s / 472612.9501 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0038
env0_second_0:                 episode reward: -1.8500,                 loss: 0.0038
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 5601/30000 (18.6700%),                 avg. length: 2865.45,                last time consumption/overall running time: 2078.1524s / 474691.1025 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0040
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0039
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 5621/30000 (18.7367%),                 avg. length: 2066.5,                last time consumption/overall running time: 1510.4850s / 476201.5875 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0047
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0046
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
env2_first_0:                 episode reward: -3.4500,                 loss: nan
env2_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 5641/30000 (18.8033%),                 avg. length: 2093.35,                last time consumption/overall running time: 1528.7820s / 477730.3695 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0052
env0_second_0:                 episode reward: -1.7000,                 loss: 0.0051
env1_first_0:                 episode reward: 1.1500,                 loss: nan
env1_second_0:                 episode reward: -1.1500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 5661/30000 (18.8700%),                 avg. length: 1764.75,                last time consumption/overall running time: 1284.3706s / 479014.7402 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0056
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0057
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 5681/30000 (18.9367%),                 avg. length: 1401.85,                last time consumption/overall running time: 1026.4389s / 480041.1791 s
env0_first_0:                 episode reward: -4.6000,                 loss: 0.0060
env0_second_0:                 episode reward: 4.6000,                 loss: 0.0055
env1_first_0:                 episode reward: -6.4000,                 loss: nan
env1_second_0:                 episode reward: 6.4000,                 loss: nan
env2_first_0:                 episode reward: -5.6000,                 loss: nan
env2_second_0:                 episode reward: 5.6000,                 loss: nan
Episode: 5701/30000 (19.0033%),                 avg. length: 1960.95,                last time consumption/overall running time: 1439.9202s / 481481.0993 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0059
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0063
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 5721/30000 (19.0700%),                 avg. length: 2308.0,                last time consumption/overall running time: 1689.0852s / 483170.1845 s
env0_first_0:                 episode reward: -3.5000,                 loss: 0.0053
env0_second_0:                 episode reward: 3.5000,                 loss: 0.0053
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 5741/30000 (19.1367%),                 avg. length: 2193.55,                last time consumption/overall running time: 1604.8929s / 484775.0774 s
env0_first_0:                 episode reward: -4.2500,                 loss: 0.0050
env0_second_0:                 episode reward: 4.2500,                 loss: 0.0049
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
env2_first_0:                 episode reward: -2.0000,                 loss: nan
env2_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 5761/30000 (19.2033%),                 avg. length: 2416.55,                last time consumption/overall running time: 1790.7128s / 486565.7902 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0047
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0047
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 5781/30000 (19.2700%),                 avg. length: 2541.55,                last time consumption/overall running time: 1866.5511s / 488432.3413 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0049
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0053
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 2.4000,                 loss: nan
env2_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 5801/30000 (19.3367%),                 avg. length: 2691.45,                last time consumption/overall running time: 1984.8577s / 490417.1990 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0045
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0044
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 5821/30000 (19.4033%),                 avg. length: 2597.8,                last time consumption/overall running time: 1938.3628s / 492355.5618 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0044
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0043
env1_first_0:                 episode reward: 0.0000,                 loss: nan
env1_second_0:                 episode reward: 0.0000,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 5841/30000 (19.4700%),                 avg. length: 2718.2,                last time consumption/overall running time: 1978.9751s / 494334.5368 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0044
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0046
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 5861/30000 (19.5367%),                 avg. length: 2627.35,                last time consumption/overall running time: 1937.8972s / 496272.4341 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0044
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0043
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 5881/30000 (19.6033%),                 avg. length: 2518.8,                last time consumption/overall running time: 1863.4806s / 498135.9147 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0045
env0_second_0:                 episode reward: -1.4500,                 loss: 0.0046
env1_first_0:                 episode reward: 2.5500,                 loss: nan
env1_second_0:                 episode reward: -2.5500,                 loss: nan
env2_first_0:                 episode reward: 2.2500,                 loss: nan
env2_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 5901/30000 (19.6700%),                 avg. length: 2424.05,                last time consumption/overall running time: 1783.7221s / 499919.6367 s
env0_first_0:                 episode reward: 2.5500,                 loss: 0.0041
env0_second_0:                 episode reward: -2.5500,                 loss: 0.0042
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
env2_first_0:                 episode reward: 2.9000,                 loss: nan
env2_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 5921/30000 (19.7367%),                 avg. length: 2272.05,                last time consumption/overall running time: 1698.7464s / 501618.3831 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0044
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0047
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 5941/30000 (19.8033%),                 avg. length: 2654.85,                last time consumption/overall running time: 1938.4085s / 503556.7916 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0042
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0044
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 5961/30000 (19.8700%),                 avg. length: 3092.3,                last time consumption/overall running time: 2250.7112s / 505807.5029 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.0036
env0_second_0:                 episode reward: -2.4000,                 loss: 0.0038
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 5981/30000 (19.9367%),                 avg. length: 2500.45,                last time consumption/overall running time: 1847.9717s / 507655.4745 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0036
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0039
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 6001/30000 (20.0033%),                 avg. length: 2139.55,                last time consumption/overall running time: 1564.5348s / 509220.0094 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0055
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0055
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 6021/30000 (20.0700%),                 avg. length: 1879.05,                last time consumption/overall running time: 1369.8725s / 510589.8818 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0049
env0_second_0:                 episode reward: 1.7500,                 loss: 0.0052
env1_first_0:                 episode reward: -4.0000,                 loss: nan
env1_second_0:                 episode reward: 4.0000,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 6041/30000 (20.1367%),                 avg. length: 1938.7,                last time consumption/overall running time: 1419.3532s / 512009.2350 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0053
env0_second_0:                 episode reward: -1.8000,                 loss: 0.0057
env1_first_0:                 episode reward: 1.8000,                 loss: nan
env1_second_0:                 episode reward: -1.8000,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 6061/30000 (20.2033%),                 avg. length: 1782.2,                last time consumption/overall running time: 1296.2562s / 513305.4911 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0065
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0061
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.8000,                 loss: nan
env2_second_0:                 episode reward: -0.8000,                 loss: nan
Episode: 6081/30000 (20.2700%),                 avg. length: 2063.05,                last time consumption/overall running time: 1514.2395s / 514819.7307 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0062
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0063
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: -0.1500,                 loss: nan
env2_second_0:                 episode reward: 0.1500,                 loss: nan
Episode: 6101/30000 (20.3367%),                 avg. length: 2072.1,                last time consumption/overall running time: 1546.5620s / 516366.2926 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0055
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0057
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 6121/30000 (20.4033%),                 avg. length: 2184.65,                last time consumption/overall running time: 1599.1985s / 517965.4912 s
env0_first_0:                 episode reward: 4.4000,                 loss: 0.0047
env0_second_0:                 episode reward: -4.4000,                 loss: 0.0048
env1_first_0:                 episode reward: 1.7500,                 loss: nan
env1_second_0:                 episode reward: -1.7500,                 loss: nan
env2_first_0:                 episode reward: 2.7000,                 loss: nan
env2_second_0:                 episode reward: -2.7000,                 loss: nan
Episode: 6141/30000 (20.4700%),                 avg. length: 2503.3,                last time consumption/overall running time: 1822.8373s / 519788.3285 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0045
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0048
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.8000,                 loss: nan
env2_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6161/30000 (20.5367%),                 avg. length: 2510.65,                last time consumption/overall running time: 1848.6998s / 521637.0283 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0047
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0049
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 6181/30000 (20.6033%),                 avg. length: 2622.2,                last time consumption/overall running time: 1912.9180s / 523549.9463 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0043
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0043
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 6201/30000 (20.6700%),                 avg. length: 2322.25,                last time consumption/overall running time: 1697.7554s / 525247.7017 s
env0_first_0:                 episode reward: -4.3000,                 loss: 0.0037
env0_second_0:                 episode reward: 4.3000,                 loss: 0.0037
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
env2_first_0:                 episode reward: -5.7000,                 loss: nan
env2_second_0:                 episode reward: 5.7000,                 loss: nan
Episode: 6221/30000 (20.7367%),                 avg. length: 2132.25,                last time consumption/overall running time: 1561.5801s / 526809.2818 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0042
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0043
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
env2_first_0:                 episode reward: -3.4000,                 loss: nan
env2_second_0:                 episode reward: 3.4000,                 loss: nan
Episode: 6241/30000 (20.8033%),                 avg. length: 2218.65,                last time consumption/overall running time: 1630.8116s / 528440.0934 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0045
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0046
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 6261/30000 (20.8700%),                 avg. length: 2626.15,                last time consumption/overall running time: 1924.6347s / 530364.7281 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0044
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0045
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
env2_first_0:                 episode reward: 0.5500,                 loss: nan
env2_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 6281/30000 (20.9367%),                 avg. length: 2678.8,                last time consumption/overall running time: 1978.3468s / 532343.0748 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0043
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0044
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6301/30000 (21.0033%),                 avg. length: 2641.45,                last time consumption/overall running time: 1945.5191s / 534288.5940 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0041
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0043
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 6321/30000 (21.0700%),                 avg. length: 2731.65,                last time consumption/overall running time: 2012.0560s / 536300.6500 s
env0_first_0:                 episode reward: -4.1000,                 loss: 0.0036
env0_second_0:                 episode reward: 4.1000,                 loss: 0.0038
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
env2_first_0:                 episode reward: -3.7000,                 loss: nan
env2_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 6341/30000 (21.1367%),                 avg. length: 2745.25,                last time consumption/overall running time: 2012.7107s / 538313.3608 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0031
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0031
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
env2_first_0:                 episode reward: -1.8000,                 loss: nan
env2_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 6361/30000 (21.2033%),                 avg. length: 2866.8,                last time consumption/overall running time: 2098.9810s / 540412.3418 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0034
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0035
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 6381/30000 (21.2700%),                 avg. length: 2857.95,                last time consumption/overall running time: 2091.2476s / 542503.5894 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0033
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0035
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 6401/30000 (21.3367%),                 avg. length: 2831.75,                last time consumption/overall running time: 2071.4861s / 544575.0755 s
env0_first_0:                 episode reward: -0.7000,                 loss: 0.0036
env0_second_0:                 episode reward: 0.7000,                 loss: 0.0037
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 6421/30000 (21.4033%),                 avg. length: 2839.75,                last time consumption/overall running time: 2092.4584s / 546667.5339 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0034
env0_second_0:                 episode reward: 1.7500,                 loss: 0.0035
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
env2_first_0:                 episode reward: -3.1000,                 loss: nan
env2_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 6441/30000 (21.4700%),                 avg. length: 2430.85,                last time consumption/overall running time: 1778.7620s / 548446.2960 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0040
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0042
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 6461/30000 (21.5367%),                 avg. length: 2591.3,                last time consumption/overall running time: 1906.3285s / 550352.6244 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0042
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0043
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 6481/30000 (21.6033%),                 avg. length: 2544.35,                last time consumption/overall running time: 1837.6871s / 552190.3115 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0044
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0049
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 6501/30000 (21.6700%),                 avg. length: 2608.2,                last time consumption/overall running time: 1903.9667s / 554094.2782 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0043
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0044
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 6521/30000 (21.7367%),                 avg. length: 2619.25,                last time consumption/overall running time: 1910.6782s / 556004.9564 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0043
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0044
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
env2_first_0:                 episode reward: -0.8000,                 loss: nan
env2_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6541/30000 (21.8033%),                 avg. length: 2221.7,                last time consumption/overall running time: 1612.7081s / 557617.6645 s
env0_first_0:                 episode reward: 1.8500,                 loss: 0.0048
env0_second_0:                 episode reward: -1.8500,                 loss: 0.0049
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 6561/30000 (21.8700%),                 avg. length: 1889.2,                last time consumption/overall running time: 1372.8120s / 558990.4766 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0053
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0052
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.8000,                 loss: nan
env2_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6581/30000 (21.9367%),                 avg. length: 2369.55,                last time consumption/overall running time: 1747.6010s / 560738.0776 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0046
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0046
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 6601/30000 (22.0033%),                 avg. length: 2514.3,                last time consumption/overall running time: 1838.2976s / 562576.3752 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0037
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0038
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: 1.4500,                 loss: nan
env2_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 6621/30000 (22.0700%),                 avg. length: 2244.75,                last time consumption/overall running time: 1636.6390s / 564213.0142 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0046
env0_second_0:                 episode reward: 1.6500,                 loss: 0.0050
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 6641/30000 (22.1367%),                 avg. length: 2293.2,                last time consumption/overall running time: 1676.0697s / 565889.0839 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.0046
env0_second_0:                 episode reward: 2.8000,                 loss: 0.0049
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 6661/30000 (22.2033%),                 avg. length: 2531.05,                last time consumption/overall running time: 1848.3466s / 567737.4305 s
env0_first_0:                 episode reward: -3.9500,                 loss: 0.0040
env0_second_0:                 episode reward: 3.9500,                 loss: 0.0041
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: -2.7000,                 loss: nan
env2_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 6681/30000 (22.2700%),                 avg. length: 2380.55,                last time consumption/overall running time: 1735.9579s / 569473.3884 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0044
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0046
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 6701/30000 (22.3367%),                 avg. length: 2560.25,                last time consumption/overall running time: 1873.7945s / 571347.1829 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0043
env0_second_0:                 episode reward: 1.9500,                 loss: 0.0044
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
env2_first_0:                 episode reward: -1.2500,                 loss: nan
env2_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 6721/30000 (22.4033%),                 avg. length: 2449.45,                last time consumption/overall running time: 1790.9348s / 573138.1177 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.0042
env0_second_0:                 episode reward: 2.1000,                 loss: 0.0044
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 6741/30000 (22.4700%),                 avg. length: 2445.05,                last time consumption/overall running time: 1783.1124s / 574921.2300 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0040
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0041
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 6761/30000 (22.5367%),                 avg. length: 2371.2,                last time consumption/overall running time: 1742.6103s / 576663.8403 s
env0_first_0:                 episode reward: -1.6500,                 loss: 0.0038
env0_second_0:                 episode reward: 1.6500,                 loss: 0.0039
env1_first_0:                 episode reward: -2.9500,                 loss: nan
env1_second_0:                 episode reward: 2.9500,                 loss: nan
env2_first_0:                 episode reward: -2.7000,                 loss: nan
env2_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 6781/30000 (22.6033%),                 avg. length: 2847.8,                last time consumption/overall running time: 2103.0272s / 578766.8675 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0033
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0037
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.8000,                 loss: nan
env2_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 6801/30000 (22.6700%),                 avg. length: 2618.95,                last time consumption/overall running time: 1918.2340s / 580685.1015 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0034
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0035
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 6821/30000 (22.7367%),                 avg. length: 2564.75,                last time consumption/overall running time: 1882.0463s / 582567.1478 s
env0_first_0:                 episode reward: 0.6500,                 loss: 0.0041
env0_second_0:                 episode reward: -0.6500,                 loss: 0.0040
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 6841/30000 (22.8033%),                 avg. length: 2596.05,                last time consumption/overall running time: 1910.3584s / 584477.5062 s
env0_first_0:                 episode reward: -3.3000,                 loss: 0.0034
env0_second_0:                 episode reward: 3.3000,                 loss: 0.0036
env1_first_0:                 episode reward: -2.7500,                 loss: nan
env1_second_0:                 episode reward: 2.7500,                 loss: nan
env2_first_0:                 episode reward: -3.7000,                 loss: nan
env2_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 6861/30000 (22.8700%),                 avg. length: 2625.4,                last time consumption/overall running time: 1927.6826s / 586405.1889 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.0031
env0_second_0:                 episode reward: 2.3000,                 loss: 0.0033
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
env2_first_0:                 episode reward: -3.2500,                 loss: nan
env2_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 6881/30000 (22.9367%),                 avg. length: 2733.65,                last time consumption/overall running time: 1998.6543s / 588403.8432 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0036
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0038
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6901/30000 (23.0033%),                 avg. length: 2572.0,                last time consumption/overall running time: 1874.5534s / 590278.3967 s
env0_first_0:                 episode reward: 0.5000,                 loss: 0.0038
env0_second_0:                 episode reward: -0.5000,                 loss: 0.0038
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 6921/30000 (23.0700%),                 avg. length: 2279.25,                last time consumption/overall running time: 1677.3660s / 591955.7627 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0046
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0045
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 6941/30000 (23.1367%),                 avg. length: 2716.05,                last time consumption/overall running time: 2003.3223s / 593959.0850 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0040
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0041
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -2.0500,                 loss: nan
env2_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 6961/30000 (23.2033%),                 avg. length: 2598.05,                last time consumption/overall running time: 1909.5743s / 595868.6593 s
env0_first_0:                 episode reward: -3.1500,                 loss: 0.0038
env0_second_0:                 episode reward: 3.1500,                 loss: 0.0036
env1_first_0:                 episode reward: -3.3000,                 loss: nan
env1_second_0:                 episode reward: 3.3000,                 loss: nan
env2_first_0:                 episode reward: -2.7000,                 loss: nan
env2_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 6981/30000 (23.2700%),                 avg. length: 2853.25,                last time consumption/overall running time: 2090.8787s / 597959.5380 s
env0_first_0:                 episode reward: -0.4500,                 loss: 0.0036
env0_second_0:                 episode reward: 0.4500,                 loss: 0.0038
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 7001/30000 (23.3367%),                 avg. length: 2738.05,                last time consumption/overall running time: 2004.3173s / 599963.8553 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0037
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0041
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 7021/30000 (23.4033%),                 avg. length: 2801.5,                last time consumption/overall running time: 2049.5483s / 602013.4035 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0039
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0041
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
env2_first_0:                 episode reward: 1.0000,                 loss: nan
env2_second_0:                 episode reward: -1.0000,                 loss: nan
Episode: 7041/30000 (23.4700%),                 avg. length: 2701.3,                last time consumption/overall running time: 1986.0247s / 603999.4282 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0042
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0043
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 7061/30000 (23.5367%),                 avg. length: 2842.05,                last time consumption/overall running time: 2080.8744s / 606080.3026 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0038
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0041
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 7081/30000 (23.6033%),                 avg. length: 2068.3,                last time consumption/overall running time: 1537.5562s / 607617.8588 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0046
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0048
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan