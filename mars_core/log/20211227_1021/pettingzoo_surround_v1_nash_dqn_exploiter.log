pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
surround_v1 pettingzoo
random seed: [59, 44, 15]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'surround_v1', 'env_type': 'pettingzoo', 'num_envs': 3, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQNExploiter', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000, 'exploiter_update_itr': 1}, 'batch_size': 128, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn_exploiter', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20211227_1021/pettingzoo_surround_v1_nash_dqn_exploiter. 
 Save logs to: /home/zihan/research/MARS/data/log/20211227_1021/pettingzoo_surround_v1_nash_dqn_exploiter.
Episode: 1/30000 (0.0033%),                 avg. length: 1422.0,                last time consumption/overall running time: 52.7165s / 52.7165 s
env0_first_0:                 episode reward: 3.0000,                 loss: 0.0122
env0_second_0:                 episode reward: -3.0000,                 loss: 0.0111
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 1374.5,                last time consumption/overall running time: 916.4473s / 969.1638 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0094
env0_second_0:                 episode reward: 2.4500,                 loss: 0.0097
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: -1.3500,                 loss: nan
env2_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 1414.6,                last time consumption/overall running time: 1001.6371s / 1970.8010 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.0091
env0_second_0:                 episode reward: 2.1000,                 loss: 0.0088
env1_first_0:                 episode reward: -2.1500,                 loss: nan
env1_second_0:                 episode reward: 2.1500,                 loss: nan
env2_first_0:                 episode reward: -2.9000,                 loss: nan
env2_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 1570.9,                last time consumption/overall running time: 1140.8714s / 3111.6724 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0078
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0078
env1_first_0:                 episode reward: 1.3500,                 loss: nan
env1_second_0:                 episode reward: -1.3500,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 1584.15,                last time consumption/overall running time: 1170.4285s / 4282.1009 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0070
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0071
env1_first_0:                 episode reward: -1.2500,                 loss: nan
env1_second_0:                 episode reward: 1.2500,                 loss: nan
env2_first_0:                 episode reward: -1.9500,                 loss: nan
env2_second_0:                 episode reward: 1.9500,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 1602.7,                last time consumption/overall running time: 1184.0505s / 5466.1514 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0070
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0071
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -3.0500,                 loss: nan
env2_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 1704.05,                last time consumption/overall running time: 1258.3483s / 6724.4997 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0072
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0070
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 1772.7,                last time consumption/overall running time: 1295.8412s / 8020.3409 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0066
env0_second_0:                 episode reward: 2.4500,                 loss: 0.0063
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -2.5000,                 loss: nan
env2_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 1943.8,                last time consumption/overall running time: 1427.1709s / 9447.5118 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0063
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0063
env1_first_0:                 episode reward: -1.7000,                 loss: nan
env1_second_0:                 episode reward: 1.7000,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 1812.05,                last time consumption/overall running time: 1331.1518s / 10778.6636 s
env0_first_0:                 episode reward: -3.4500,                 loss: 0.0061
env0_second_0:                 episode reward: 3.4500,                 loss: 0.0060
env1_first_0:                 episode reward: -2.7000,                 loss: nan
env1_second_0:                 episode reward: 2.7000,                 loss: nan
env2_first_0:                 episode reward: -3.2000,                 loss: nan
env2_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 1806.6,                last time consumption/overall running time: 1334.4845s / 12113.1481 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0063
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0064
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2043.5,                last time consumption/overall running time: 1497.3389s / 13610.4870 s
env0_first_0:                 episode reward: -0.9500,                 loss: 0.0063
env0_second_0:                 episode reward: 0.9500,                 loss: 0.0064
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 1835.9,                last time consumption/overall running time: 1355.5498s / 14966.0368 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0059
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0058
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
env2_first_0:                 episode reward: -3.5000,                 loss: nan
env2_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 1897.15,                last time consumption/overall running time: 1394.1124s / 16360.1492 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0058
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0059
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 1744.85,                last time consumption/overall running time: 1282.3186s / 17642.4678 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0059
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0059
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -2.2000,                 loss: nan
env2_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2285.95,                last time consumption/overall running time: 1669.7934s / 19312.2612 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0056
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0056
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2231.45,                last time consumption/overall running time: 1662.2427s / 20974.5038 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0051
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0052
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2332.6,                last time consumption/overall running time: 1734.9840s / 22709.4878 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0048
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0049
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2271.95,                last time consumption/overall running time: 1677.5319s / 24387.0197 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0047
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0047
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2293.25,                last time consumption/overall running time: 1668.7744s / 26055.7941 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0052
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0051
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2078.7,                last time consumption/overall running time: 1520.8579s / 27576.6520 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0056
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0056
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 1924.2,                last time consumption/overall running time: 1438.7694s / 29015.4213 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0057
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0058
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -2.8500,                 loss: nan
env2_second_0:                 episode reward: 2.8500,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 1877.75,                last time consumption/overall running time: 1382.3103s / 30397.7316 s
env0_first_0:                 episode reward: -0.5500,                 loss: 0.0064
env0_second_0:                 episode reward: 0.5500,                 loss: 0.0065
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -2.4500,                 loss: nan
env2_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 1997.6,                last time consumption/overall running time: 1476.7651s / 31874.4967 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0065
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0065
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2066.25,                last time consumption/overall running time: 1515.6430s / 33390.1397 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0057
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0057
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -2.2500,                 loss: nan
env2_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2129.65,                last time consumption/overall running time: 1567.4061s / 34957.5457 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0055
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0054
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 1862.0,                last time consumption/overall running time: 1354.2940s / 36311.8397 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0056
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0056
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2004.05,                last time consumption/overall running time: 1476.3586s / 37788.1984 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0057
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0058
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 1832.7,                last time consumption/overall running time: 1351.1009s / 39139.2993 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0054
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0053
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
env2_first_0:                 episode reward: -3.6500,                 loss: nan
env2_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2024.3,                last time consumption/overall running time: 1500.0014s / 40639.3006 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0055
env0_second_0:                 episode reward: 1.7500,                 loss: 0.0054
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2035.5,                last time consumption/overall running time: 1498.6406s / 42137.9412 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0058
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0058
env1_first_0:                 episode reward: -1.1000,                 loss: nan
env1_second_0:                 episode reward: 1.1000,                 loss: nan
env2_first_0:                 episode reward: 0.5500,                 loss: nan
env2_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2027.75,                last time consumption/overall running time: 1509.6895s / 43647.6308 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0052
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0053
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
env2_first_0:                 episode reward: -3.2500,                 loss: nan
env2_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2233.0,                last time consumption/overall running time: 1642.9556s / 45290.5863 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0054
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0053
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
env2_first_0:                 episode reward: -3.7000,                 loss: nan
env2_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2102.55,                last time consumption/overall running time: 1556.2981s / 46846.8845 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0051
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0051
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
env2_first_0:                 episode reward: -1.5500,                 loss: nan
env2_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2101.05,                last time consumption/overall running time: 1546.8774s / 48393.7619 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0052
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0053
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 1789.35,                last time consumption/overall running time: 1315.5517s / 49709.3136 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0053
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0055
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
env2_first_0:                 episode reward: -2.5000,                 loss: nan
env2_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 1732.55,                last time consumption/overall running time: 1272.7163s / 50982.0299 s
env0_first_0:                 episode reward: -5.3500,                 loss: 0.0051
env0_second_0:                 episode reward: 5.3500,                 loss: 0.0055
env1_first_0:                 episode reward: -4.9500,                 loss: nan
env1_second_0:                 episode reward: 4.9500,                 loss: nan
env2_first_0:                 episode reward: -4.3500,                 loss: nan
env2_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 1818.0,                last time consumption/overall running time: 1338.5613s / 52320.5912 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.0049
env0_second_0:                 episode reward: 2.6000,                 loss: 0.0051
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: -4.1000,                 loss: nan
env2_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2079.65,                last time consumption/overall running time: 1551.2353s / 53871.8265 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0047
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0048
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
env2_first_0:                 episode reward: -3.9500,                 loss: nan
env2_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2086.55,                last time consumption/overall running time: 1534.6729s / 55406.4994 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0051
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0052
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -3.2500,                 loss: nan
env2_second_0:                 episode reward: 3.2500,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2175.25,                last time consumption/overall running time: 1602.1189s / 57008.6183 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0052
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0051
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: -1.2000,                 loss: nan
env2_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2116.55,                last time consumption/overall running time: 1559.0903s / 58567.7086 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0053
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0053
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2049.75,                last time consumption/overall running time: 1513.0246s / 60080.7332 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0053
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0053
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.8000,                 loss: nan
env2_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2068.95,                last time consumption/overall running time: 1531.4636s / 61612.1968 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0053
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0051
env1_first_0:                 episode reward: -1.7500,                 loss: nan
env1_second_0:                 episode reward: 1.7500,                 loss: nan
env2_first_0:                 episode reward: -1.3500,                 loss: nan
env2_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2282.0,                last time consumption/overall running time: 1689.0332s / 63301.2300 s
env0_first_0:                 episode reward: -0.2500,                 loss: 0.0051
env0_second_0:                 episode reward: 0.2500,                 loss: 0.0052
env1_first_0:                 episode reward: -0.8500,                 loss: nan
env1_second_0:                 episode reward: 0.8500,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2563.9,                last time consumption/overall running time: 1885.7046s / 65186.9346 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0047
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0048
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -1.2500,                 loss: nan
env2_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2407.9,                last time consumption/overall running time: 1786.2332s / 66973.1678 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0045
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0044
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
env2_first_0:                 episode reward: -2.4500,                 loss: nan
env2_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2478.2,                last time consumption/overall running time: 1829.4033s / 68802.5711 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0044
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0044
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -1.2500,                 loss: nan
env2_second_0:                 episode reward: 1.2500,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2528.25,                last time consumption/overall running time: 1867.6719s / 70670.2431 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0044
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0043
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
env2_first_0:                 episode reward: -2.5500,                 loss: nan
env2_second_0:                 episode reward: 2.5500,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2514.2,                last time consumption/overall running time: 1856.9424s / 72527.1855 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0044
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0046
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2361.1,                last time consumption/overall running time: 1746.4041s / 74273.5896 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0050
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0049
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2364.6,                last time consumption/overall running time: 1728.7853s / 76002.3750 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0047
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0048
env1_first_0:                 episode reward: -2.5500,                 loss: nan
env1_second_0:                 episode reward: 2.5500,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2456.4,                last time consumption/overall running time: 1817.3513s / 77819.7263 s
env0_first_0:                 episode reward: -1.3000,                 loss: 0.0047
env0_second_0:                 episode reward: 1.3000,                 loss: 0.0048
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2251.95,                last time consumption/overall running time: 1664.7382s / 79484.4645 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0046
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0045
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2387.15,                last time consumption/overall running time: 1789.6779s / 81274.1424 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0048
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0047
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 1.2000,                 loss: nan
env2_second_0:                 episode reward: -1.2000,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2297.3,                last time consumption/overall running time: 1694.7312s / 82968.8736 s
env0_first_0:                 episode reward: -1.2000,                 loss: 0.0046
env0_second_0:                 episode reward: 1.2000,                 loss: 0.0045
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2361.5,                last time consumption/overall running time: 1720.4633s / 84689.3369 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0043
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0047
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
env2_first_0:                 episode reward: -1.8000,                 loss: nan
env2_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2619.9,                last time consumption/overall running time: 1918.7261s / 86608.0630 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0040
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0041
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
env2_first_0:                 episode reward: -3.1000,                 loss: nan
env2_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2283.9,                last time consumption/overall running time: 1670.4706s / 88278.5336 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0041
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0041
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: -3.5500,                 loss: nan
env2_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2157.7,                last time consumption/overall running time: 1583.5564s / 89862.0899 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0045
env0_second_0:                 episode reward: 1.7000,                 loss: 0.0046
env1_first_0:                 episode reward: -3.1500,                 loss: nan
env1_second_0:                 episode reward: 3.1500,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2382.55,                last time consumption/overall running time: 1750.5956s / 91612.6856 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0046
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0047
env1_first_0:                 episode reward: -1.1500,                 loss: nan
env1_second_0:                 episode reward: 1.1500,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2175.2,                last time consumption/overall running time: 1604.5051s / 93217.1907 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0045
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0046
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
env2_first_0:                 episode reward: -3.2000,                 loss: nan
env2_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2676.9,                last time consumption/overall running time: 1982.5369s / 95199.7276 s
env0_first_0:                 episode reward: -1.4000,                 loss: 0.0044
env0_second_0:                 episode reward: 1.4000,                 loss: 0.0045
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2485.6,                last time consumption/overall running time: 1819.6314s / 97019.3590 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0044
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0046
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -1.7500,                 loss: nan
env2_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2046.05,                last time consumption/overall running time: 1521.5358s / 98540.8948 s
env0_first_0:                 episode reward: -1.7000,                 loss: 0.0047
env0_second_0:                 episode reward: 1.7000,                 loss: 0.0052
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2081.85,                last time consumption/overall running time: 1537.3672s / 100078.2620 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0049
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0052
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 1912.85,                last time consumption/overall running time: 1422.5427s / 101500.8047 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0048
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0050
env1_first_0:                 episode reward: -5.1500,                 loss: nan
env1_second_0:                 episode reward: 5.1500,                 loss: nan
env2_first_0:                 episode reward: -4.3500,                 loss: nan
env2_second_0:                 episode reward: 4.3500,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 1956.55,                last time consumption/overall running time: 1435.3830s / 102936.1877 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.0038
env0_second_0:                 episode reward: 6.0500,                 loss: 0.0039
env1_first_0:                 episode reward: -6.1000,                 loss: nan
env1_second_0:                 episode reward: 6.1000,                 loss: nan
env2_first_0:                 episode reward: -5.8500,                 loss: nan
env2_second_0:                 episode reward: 5.8500,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2246.25,                last time consumption/overall running time: 1652.7446s / 104588.9323 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0034
env0_second_0:                 episode reward: 4.4500,                 loss: 0.0036
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
env2_first_0:                 episode reward: -4.6000,                 loss: nan
env2_second_0:                 episode reward: 4.6000,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2367.3,                last time consumption/overall running time: 1752.3618s / 106341.2941 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0038
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0038
env1_first_0:                 episode reward: -3.9000,                 loss: nan
env1_second_0:                 episode reward: 3.9000,                 loss: nan
env2_first_0:                 episode reward: -3.6500,                 loss: nan
env2_second_0:                 episode reward: 3.6500,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2350.5,                last time consumption/overall running time: 1761.1669s / 108102.4610 s
env0_first_0:                 episode reward: -3.1000,                 loss: 0.0035
env0_second_0:                 episode reward: 3.1000,                 loss: 0.0038
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
env2_first_0:                 episode reward: -4.0000,                 loss: nan
env2_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2569.55,                last time consumption/overall running time: 1901.0995s / 110003.5604 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0039
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0040
env1_first_0:                 episode reward: -3.6000,                 loss: nan
env1_second_0:                 episode reward: 3.6000,                 loss: nan
env2_first_0:                 episode reward: -2.4500,                 loss: nan
env2_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2525.15,                last time consumption/overall running time: 1872.3732s / 111875.9337 s
env0_first_0:                 episode reward: -1.5500,                 loss: 0.0037
env0_second_0:                 episode reward: 1.5500,                 loss: 0.0038
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2452.8,                last time consumption/overall running time: 1806.6673s / 113682.6009 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0035
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0036
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2412.1,                last time consumption/overall running time: 1773.3481s / 115455.9491 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0037
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0039
env1_first_0:                 episode reward: -4.1000,                 loss: nan
env1_second_0:                 episode reward: 4.1000,                 loss: nan
env2_first_0:                 episode reward: -3.5000,                 loss: nan
env2_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2297.3,                last time consumption/overall running time: 1710.7313s / 117166.6803 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0039
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0040
env1_first_0:                 episode reward: -2.2000,                 loss: nan
env1_second_0:                 episode reward: 2.2000,                 loss: nan
env2_first_0:                 episode reward: -3.4500,                 loss: nan
env2_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2443.55,                last time consumption/overall running time: 1803.6566s / 118970.3370 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0046
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0045
env1_first_0:                 episode reward: -2.0500,                 loss: nan
env1_second_0:                 episode reward: 2.0500,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2525.65,                last time consumption/overall running time: 1862.8650s / 120833.2020 s
env0_first_0:                 episode reward: -2.3000,                 loss: 0.0039
env0_second_0:                 episode reward: 2.3000,                 loss: 0.0041
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -3.9000,                 loss: nan
env2_second_0:                 episode reward: 3.9000,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2330.1,                last time consumption/overall running time: 1722.9653s / 122556.1673 s
env0_first_0:                 episode reward: -4.9000,                 loss: 0.0039
env0_second_0:                 episode reward: 4.9000,                 loss: 0.0040
env1_first_0:                 episode reward: -3.4500,                 loss: nan
env1_second_0:                 episode reward: 3.4500,                 loss: nan
env2_first_0:                 episode reward: -2.7000,                 loss: nan
env2_second_0:                 episode reward: 2.7000,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2010.9,                last time consumption/overall running time: 1481.3945s / 124037.5618 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0045
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0046
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
env2_first_0:                 episode reward: -2.8000,                 loss: nan
env2_second_0:                 episode reward: 2.8000,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2407.65,                last time consumption/overall running time: 1769.9226s / 125807.4844 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0048
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0049
env1_first_0:                 episode reward: -0.6000,                 loss: nan
env1_second_0:                 episode reward: 0.6000,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2376.7,                last time consumption/overall running time: 1740.7220s / 127548.2064 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0041
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0044
env1_first_0:                 episode reward: -2.4500,                 loss: nan
env1_second_0:                 episode reward: 2.4500,                 loss: nan
env2_first_0:                 episode reward: 0.5500,                 loss: nan
env2_second_0:                 episode reward: -0.5500,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2217.7,                last time consumption/overall running time: 1634.6546s / 129182.8611 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.0043
env0_second_0:                 episode reward: 2.8000,                 loss: 0.0044
env1_first_0:                 episode reward: -3.5500,                 loss: nan
env1_second_0:                 episode reward: 3.5500,                 loss: nan
env2_first_0:                 episode reward: -1.2000,                 loss: nan
env2_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2278.45,                last time consumption/overall running time: 1680.9352s / 130863.7963 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0044
env0_second_0:                 episode reward: 2.4500,                 loss: 0.0043
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -1.2000,                 loss: nan
env2_second_0:                 episode reward: 1.2000,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2152.85,                last time consumption/overall running time: 1595.6926s / 132459.4889 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0049
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0052
env1_first_0:                 episode reward: -1.2000,                 loss: nan
env1_second_0:                 episode reward: 1.2000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2260.65,                last time consumption/overall running time: 1673.1518s / 134132.6407 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0049
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0050
env1_first_0:                 episode reward: -2.9000,                 loss: nan
env1_second_0:                 episode reward: 2.9000,                 loss: nan
env2_first_0:                 episode reward: -2.7500,                 loss: nan
env2_second_0:                 episode reward: 2.7500,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2390.05,                last time consumption/overall running time: 1770.1427s / 135902.7834 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0044
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0046
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2266.55,                last time consumption/overall running time: 1674.4833s / 137577.2667 s
env0_first_0:                 episode reward: -1.1000,                 loss: 0.0048
env0_second_0:                 episode reward: 1.1000,                 loss: 0.0050
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -3.2000,                 loss: nan
env2_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2159.65,                last time consumption/overall running time: 1592.5821s / 139169.8488 s
env0_first_0:                 episode reward: -4.4000,                 loss: 0.0045
env0_second_0:                 episode reward: 4.4000,                 loss: 0.0045
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
env2_first_0:                 episode reward: -2.2000,                 loss: nan
env2_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2115.55,                last time consumption/overall running time: 1567.3278s / 140737.1766 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0047
env0_second_0:                 episode reward: 2.0000,                 loss: 0.0050
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2515.9,                last time consumption/overall running time: 1855.5627s / 142592.7393 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0044
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0045
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2017.45,                last time consumption/overall running time: 1490.7590s / 144083.4983 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0046
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0048
env1_first_0:                 episode reward: -1.9000,                 loss: nan
env1_second_0:                 episode reward: 1.9000,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 1994.05,                last time consumption/overall running time: 1460.1054s / 145543.6037 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0051
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0051
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 2006.9,                last time consumption/overall running time: 1462.3939s / 147005.9976 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0052
env0_second_0:                 episode reward: -2.5000,                 loss: 0.0054
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 1601.7,                last time consumption/overall running time: 1192.8621s / 148198.8597 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0062
env0_second_0:                 episode reward: -2.3500,                 loss: 0.0066
env1_first_0:                 episode reward: 4.9000,                 loss: nan
env1_second_0:                 episode reward: -4.9000,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 2077.85,                last time consumption/overall running time: 1536.7216s / 149735.5814 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.0047
env0_second_0:                 episode reward: -2.9500,                 loss: 0.0053
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
env2_first_0:                 episode reward: 3.0000,                 loss: nan
env2_second_0:                 episode reward: -3.0000,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 2306.55,                last time consumption/overall running time: 1702.4441s / 151438.0255 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0042
env0_second_0:                 episode reward: -1.6000,                 loss: 0.0046
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
env2_first_0:                 episode reward: 2.7500,                 loss: nan
env2_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 2028.35,                last time consumption/overall running time: 1498.7427s / 152936.7681 s
env0_first_0:                 episode reward: 3.0500,                 loss: 0.0048
env0_second_0:                 episode reward: -3.0500,                 loss: 0.0047
env1_first_0:                 episode reward: 3.1500,                 loss: nan
env1_second_0:                 episode reward: -3.1500,                 loss: nan
env2_first_0:                 episode reward: 3.0500,                 loss: nan
env2_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2198.4,                last time consumption/overall running time: 1611.6654s / 154548.4335 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0045
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0050
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 2556.9,                last time consumption/overall running time: 1889.9231s / 156438.3566 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0044
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0046
env1_first_0:                 episode reward: 1.0500,                 loss: nan
env1_second_0:                 episode reward: -1.0500,                 loss: nan
env2_first_0:                 episode reward: -0.6000,                 loss: nan
env2_second_0:                 episode reward: 0.6000,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 2895.45,                last time consumption/overall running time: 2115.7953s / 158554.1519 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0038
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0039
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -1.4000,                 loss: nan
env2_second_0:                 episode reward: 1.4000,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 2702.75,                last time consumption/overall running time: 1999.3197s / 160553.4716 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0037
env0_second_0:                 episode reward: 1.9500,                 loss: 0.0038
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -1.7500,                 loss: nan
env2_second_0:                 episode reward: 1.7500,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 2640.95,                last time consumption/overall running time: 1962.3996s / 162515.8712 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0036
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0036
env1_first_0:                 episode reward: -2.8000,                 loss: nan
env1_second_0:                 episode reward: 2.8000,                 loss: nan
env2_first_0:                 episode reward: -3.1500,                 loss: nan
env2_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 2657.8,                last time consumption/overall running time: 1961.0917s / 164476.9629 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0038
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0039
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -2.2500,                 loss: nan
env2_second_0:                 episode reward: 2.2500,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 2573.65,                last time consumption/overall running time: 1883.9220s / 166360.8849 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0041
env0_second_0:                 episode reward: 2.2500,                 loss: 0.0040
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 2639.15,                last time consumption/overall running time: 1934.9559s / 168295.8408 s
env0_first_0:                 episode reward: -0.6000,                 loss: 0.0042
env0_second_0:                 episode reward: 0.6000,                 loss: 0.0041
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 2742.5,                last time consumption/overall running time: 2031.0440s / 170326.8848 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0039
env0_second_0:                 episode reward: -1.6000,                 loss: 0.0044
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: 0.9500,                 loss: nan
env2_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 2946.0,                last time consumption/overall running time: 2149.0323s / 172475.9172 s
env0_first_0:                 episode reward: -2.6500,                 loss: 0.0036
env0_second_0:                 episode reward: 2.6500,                 loss: 0.0036
env1_first_0:                 episode reward: -1.5000,                 loss: nan
env1_second_0:                 episode reward: 1.5000,                 loss: nan
env2_first_0:                 episode reward: -2.9500,                 loss: nan
env2_second_0:                 episode reward: 2.9500,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 2639.85,                last time consumption/overall running time: 1942.4334s / 174418.3506 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0038
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0040
env1_first_0:                 episode reward: -0.5500,                 loss: nan
env1_second_0:                 episode reward: 0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 2466.9,                last time consumption/overall running time: 1825.1436s / 176243.4942 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0041
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0044
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 3028.6,                last time consumption/overall running time: 2222.6998s / 178466.1940 s
env0_first_0:                 episode reward: 1.1000,                 loss: 0.0040
env0_second_0:                 episode reward: -1.1000,                 loss: 0.0044
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 3057.25,                last time consumption/overall running time: 2237.9195s / 180704.1135 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0036
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0037
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 2890.1,                last time consumption/overall running time: 2123.7721s / 182827.8856 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0035
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0037
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: -2.0500,                 loss: nan
env2_second_0:                 episode reward: 2.0500,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 2522.35,                last time consumption/overall running time: 1848.3376s / 184676.2232 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0035
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0037
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -4.0500,                 loss: nan
env2_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 2540.55,                last time consumption/overall running time: 1871.3139s / 186547.5371 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0036
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0037
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -1.5000,                 loss: nan
env2_second_0:                 episode reward: 1.5000,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 2504.95,                last time consumption/overall running time: 1851.4809s / 188399.0180 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0039
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0041
env1_first_0:                 episode reward: -1.6500,                 loss: nan
env1_second_0:                 episode reward: 1.6500,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 2481.25,                last time consumption/overall running time: 1855.1943s / 190254.2124 s
env0_first_0:                 episode reward: -2.2000,                 loss: 0.0041
env0_second_0:                 episode reward: 2.2000,                 loss: 0.0043
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
env2_first_0:                 episode reward: -1.8000,                 loss: nan
env2_second_0:                 episode reward: 1.8000,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 2808.55,                last time consumption/overall running time: 2091.7329s / 192345.9453 s
env0_first_0:                 episode reward: -2.4500,                 loss: 0.0038
env0_second_0:                 episode reward: 2.4500,                 loss: 0.0039
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
env2_first_0:                 episode reward: -2.3000,                 loss: nan
env2_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 2437.25,                last time consumption/overall running time: 1816.4101s / 194162.3554 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0041
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0040
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -3.3500,                 loss: nan
env2_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 2337.15,                last time consumption/overall running time: 1704.1197s / 195866.4751 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0042
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0041
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 2368.6,                last time consumption/overall running time: 1752.0082s / 197618.4832 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0042
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0044
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 2459.2,                last time consumption/overall running time: 1804.5986s / 199423.0819 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0043
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0044
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 2558.7,                last time consumption/overall running time: 1878.6934s / 201301.7753 s
env0_first_0:                 episode reward: -2.2500,                 loss: 0.0046
env0_second_0:                 episode reward: 2.2500,                 loss: 0.0049
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -2.3500,                 loss: nan
env2_second_0:                 episode reward: 2.3500,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 2401.55,                last time consumption/overall running time: 1769.9654s / 203071.7407 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0038
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0038
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
env2_first_0:                 episode reward: -3.3500,                 loss: nan
env2_second_0:                 episode reward: 3.3500,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 2673.45,                last time consumption/overall running time: 1943.4999s / 205015.2406 s
env0_first_0:                 episode reward: -1.5000,                 loss: 0.0039
env0_second_0:                 episode reward: 1.5000,                 loss: 0.0041
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 2478.3,                last time consumption/overall running time: 1825.7308s / 206840.9714 s
env0_first_0:                 episode reward: -2.8500,                 loss: 0.0039
env0_second_0:                 episode reward: 2.8500,                 loss: 0.0039
env1_first_0:                 episode reward: -1.3500,                 loss: nan
env1_second_0:                 episode reward: 1.3500,                 loss: nan
env2_first_0:                 episode reward: -3.5500,                 loss: nan
env2_second_0:                 episode reward: 3.5500,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 2394.05,                last time consumption/overall running time: 1770.2902s / 208611.2616 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0042
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0041
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -3.5000,                 loss: nan
env2_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 2437.95,                last time consumption/overall running time: 1787.6000s / 210398.8616 s
env0_first_0:                 episode reward: -2.6000,                 loss: 0.0042
env0_second_0:                 episode reward: 2.6000,                 loss: 0.0041
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
env2_first_0:                 episode reward: -1.9000,                 loss: nan
env2_second_0:                 episode reward: 1.9000,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 2216.3,                last time consumption/overall running time: 1609.7605s / 212008.6221 s
env0_first_0:                 episode reward: -4.7000,                 loss: 0.0039
env0_second_0:                 episode reward: 4.7000,                 loss: 0.0040
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: -2.2000,                 loss: nan
env2_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 2194.05,                last time consumption/overall running time: 1621.5664s / 213630.1885 s
env0_first_0:                 episode reward: -1.2500,                 loss: 0.0042
env0_second_0:                 episode reward: 1.2500,                 loss: 0.0043
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -1.3500,                 loss: nan
env2_second_0:                 episode reward: 1.3500,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 1719.5,                last time consumption/overall running time: 1265.1326s / 214895.3210 s
env0_first_0:                 episode reward: -5.5500,                 loss: 0.0055
env0_second_0:                 episode reward: 5.5500,                 loss: 0.0053
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
env2_first_0:                 episode reward: -3.8000,                 loss: nan
env2_second_0:                 episode reward: 3.8000,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 2245.55,                last time consumption/overall running time: 1663.5261s / 216558.8472 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0054
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0055
env1_first_0:                 episode reward: -2.2500,                 loss: nan
env1_second_0:                 episode reward: 2.2500,                 loss: nan
env2_first_0:                 episode reward: -3.3000,                 loss: nan
env2_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 2418.25,                last time consumption/overall running time: 1776.6759s / 218335.5231 s
env0_first_0:                 episode reward: -3.2500,                 loss: 0.0039
env0_second_0:                 episode reward: 3.2500,                 loss: 0.0039
env1_first_0:                 episode reward: -4.4500,                 loss: nan
env1_second_0:                 episode reward: 4.4500,                 loss: nan
env2_first_0:                 episode reward: -3.1500,                 loss: nan
env2_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 2745.65,                last time consumption/overall running time: 2012.2666s / 220347.7897 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0033
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0035
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 2506.75,                last time consumption/overall running time: 1842.1565s / 222189.9462 s
env0_first_0:                 episode reward: -2.0000,                 loss: 0.0039
env0_second_0:                 episode reward: 2.0000,                 loss: 0.0041
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 2696.8,                last time consumption/overall running time: 1986.9090s / 224176.8552 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0041
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0043
env1_first_0:                 episode reward: -2.6500,                 loss: nan
env1_second_0:                 episode reward: 2.6500,                 loss: nan
env2_first_0:                 episode reward: -3.1000,                 loss: nan
env2_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 2387.8,                last time consumption/overall running time: 1749.9345s / 225926.7897 s
env0_first_0:                 episode reward: -3.3500,                 loss: 0.0040
env0_second_0:                 episode reward: 3.3500,                 loss: 0.0040
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -2.3000,                 loss: nan
env2_second_0:                 episode reward: 2.3000,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 2446.15,                last time consumption/overall running time: 1807.9990s / 227734.7887 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0046
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0045
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
env2_first_0:                 episode reward: -0.8000,                 loss: nan
env2_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 2376.6,                last time consumption/overall running time: 1756.4148s / 229491.2035 s
env0_first_0:                 episode reward: 2.0000,                 loss: 0.0045
env0_second_0:                 episode reward: -2.0000,                 loss: 0.0046
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.1000,                 loss: nan
env2_second_0:                 episode reward: 0.1000,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 2738.15,                last time consumption/overall running time: 1998.0504s / 231489.2539 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0044
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0046
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 2450.3,                last time consumption/overall running time: 1789.8727s / 233279.1266 s
env0_first_0:                 episode reward: 1.4000,                 loss: 0.0043
env0_second_0:                 episode reward: -1.4000,                 loss: 0.0047
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 2500.1,                last time consumption/overall running time: 1835.2270s / 235114.3536 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0038
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0040
env1_first_0:                 episode reward: -2.0000,                 loss: nan
env1_second_0:                 episode reward: 2.0000,                 loss: nan
env2_first_0:                 episode reward: -3.3000,                 loss: nan
env2_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 2516.95,                last time consumption/overall running time: 1858.8673s / 236973.2209 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0037
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0039
env1_first_0:                 episode reward: -3.9500,                 loss: nan
env1_second_0:                 episode reward: 3.9500,                 loss: nan
env2_first_0:                 episode reward: -3.6000,                 loss: nan
env2_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 2389.6,                last time consumption/overall running time: 1755.7966s / 238729.0175 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0030
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0033
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
env2_first_0:                 episode reward: -5.6500,                 loss: nan
env2_second_0:                 episode reward: 5.6500,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 2779.9,                last time consumption/overall running time: 2056.4777s / 240785.4951 s
env0_first_0:                 episode reward: -2.0500,                 loss: 0.0032
env0_second_0:                 episode reward: 2.0500,                 loss: 0.0035
env1_first_0:                 episode reward: -2.6000,                 loss: nan
env1_second_0:                 episode reward: 2.6000,                 loss: nan
env2_first_0:                 episode reward: -3.3000,                 loss: nan
env2_second_0:                 episode reward: 3.3000,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 2601.45,                last time consumption/overall running time: 1931.5941s / 242717.0892 s
env0_first_0:                 episode reward: -2.1000,                 loss: 0.0035
env0_second_0:                 episode reward: 2.1000,                 loss: 0.0036
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
env2_first_0:                 episode reward: -3.6000,                 loss: nan
env2_second_0:                 episode reward: 3.6000,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 2786.5,                last time consumption/overall running time: 2037.9840s / 244755.0732 s
env0_first_0:                 episode reward: -0.8000,                 loss: 0.0039
env0_second_0:                 episode reward: 0.8000,                 loss: 0.0043
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 2665.9,                last time consumption/overall running time: 1958.7093s / 246713.7826 s
env0_first_0:                 episode reward: -1.1500,                 loss: 0.0038
env0_second_0:                 episode reward: 1.1500,                 loss: 0.0041
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 2301.8,                last time consumption/overall running time: 1695.3377s / 248409.1203 s
env0_first_0:                 episode reward: 1.6500,                 loss: 0.0045
env0_second_0:                 episode reward: -1.6500,                 loss: 0.0049
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 2.3000,                 loss: nan
env2_second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 2429.1,                last time consumption/overall running time: 1783.8317s / 250192.9520 s
env0_first_0:                 episode reward: 2.2000,                 loss: 0.0042
env0_second_0:                 episode reward: -2.2000,                 loss: 0.0046
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
env2_first_0:                 episode reward: 2.6000,                 loss: nan
env2_second_0:                 episode reward: -2.6000,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 2480.75,                last time consumption/overall running time: 1812.0978s / 252005.0498 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0039
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0043
env1_first_0:                 episode reward: -1.9500,                 loss: nan
env1_second_0:                 episode reward: 1.9500,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan