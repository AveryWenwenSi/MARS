pygame 2.0.0 (SDL 2.0.12, python 3.7.10)
Hello from the pygame community. https://www.pygame.org/contribute.html
ice_hockey_v1 pettingzoo
random seed: [89, 79, 44]
<SubprocVectorEnv instance>
No agent are not learnable.
Arguments:  {'env_name': 'ice_hockey_v1', 'env_type': 'pettingzoo', 'num_envs': 3, 'ram': True, 'seed': 'random', 'algorithm': 'NashDQN', 'algorithm_spec': {'episodic_update': False, 'dueling': False, 'replay_buffer_size': '1e5', 'gamma': 0.99, 'multi_step': 1, 'target_update_interval': 1000, 'eps_start': 1.0, 'eps_final': 0.01, 'eps_decay': 30000}, 'batch_size': 128, 'max_episodes': 30000, 'max_steps_per_episode': 10000, 'train_start_frame': 0, 'optimizer': 'adam', 'learning_rate': '1e-4', 'device': 'gpu', 'update_itr': 0.1, 'log_avg_window': 20, 'log_interval': 20, 'render': False, 'test': False, 'exploit': False, 'load_model_idx': False, 'load_model_full_path': False, 'save_path': '', 'save_interval': 2000, 'net_architecture': {'hidden_dim_list': [256, 256, 256, 256], 'hidden_activation': 'ReLU', 'output_activation': False}, 'marl_method': 'nash_dqn', 'marl_spec': {'min_update_interval': 20, 'score_avg_window': 10, 'global_state': False}}
Save models to : /home/zihan/research/MARS/data/model/20211227_1021/pettingzoo_ice_hockey_v1_nash_dqn. 
 Save logs to: /home/zihan/research/MARS/data/log/20211227_1021/pettingzoo_ice_hockey_v1_nash_dqn.
Episode: 1/30000 (0.0033%),                 avg. length: 2760.0,                last time consumption/overall running time: 139.1744s / 139.1744 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0014
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0017
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 21/30000 (0.0700%),                 avg. length: 2811.9,                last time consumption/overall running time: 3012.5370s / 3151.7115 s
env0_first_0:                 episode reward: -0.5000,                 loss: 0.0012
env0_second_0:                 episode reward: 0.5000,                 loss: 0.0012
env1_first_0:                 episode reward: -1.0000,                 loss: nan
env1_second_0:                 episode reward: 1.0000,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 41/30000 (0.1367%),                 avg. length: 2839.4,                last time consumption/overall running time: 3196.7785s / 6348.4899 s
env0_first_0:                 episode reward: 0.5500,                 loss: 0.0015
env0_second_0:                 episode reward: -0.5500,                 loss: 0.0014
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 61/30000 (0.2033%),                 avg. length: 2846.15,                last time consumption/overall running time: 3278.5807s / 9627.0706 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0015
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0015
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 81/30000 (0.2700%),                 avg. length: 2847.7,                last time consumption/overall running time: 3274.1643s / 12901.2349 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0016
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0016
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: -0.4000,                 loss: nan
env2_second_0:                 episode reward: 0.4000,                 loss: nan
Episode: 101/30000 (0.3367%),                 avg. length: 2832.5,                last time consumption/overall running time: 3270.6798s / 16171.9147 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0014
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0015
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -0.7000,                 loss: nan
env2_second_0:                 episode reward: 0.7000,                 loss: nan
Episode: 121/30000 (0.4033%),                 avg. length: 2856.9,                last time consumption/overall running time: 3234.9265s / 19406.8412 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0015
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0015
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 141/30000 (0.4700%),                 avg. length: 2841.65,                last time consumption/overall running time: 3230.5547s / 22637.3959 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0013
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0014
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.4500,                 loss: nan
env2_second_0:                 episode reward: -0.4500,                 loss: nan
Episode: 161/30000 (0.5367%),                 avg. length: 2827.55,                last time consumption/overall running time: 3219.2012s / 25856.5971 s
env0_first_0:                 episode reward: -0.9000,                 loss: 0.0013
env0_second_0:                 episode reward: 0.9000,                 loss: 0.0013
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.0500,                 loss: nan
env2_second_0:                 episode reward: 0.0500,                 loss: nan
Episode: 181/30000 (0.6033%),                 avg. length: 2832.55,                last time consumption/overall running time: 3216.2037s / 29072.8008 s
env0_first_0:                 episode reward: -0.4000,                 loss: 0.0015
env0_second_0:                 episode reward: 0.4000,                 loss: 0.0014
env1_first_0:                 episode reward: 0.8500,                 loss: nan
env1_second_0:                 episode reward: -0.8500,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 201/30000 (0.6700%),                 avg. length: 2851.05,                last time consumption/overall running time: 3222.6335s / 32295.4344 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0013
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0014
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 221/30000 (0.7367%),                 avg. length: 2839.6,                last time consumption/overall running time: 3218.3249s / 35513.7593 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0015
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0014
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 241/30000 (0.8033%),                 avg. length: 2833.35,                last time consumption/overall running time: 3213.2827s / 38727.0419 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0014
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0014
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 261/30000 (0.8700%),                 avg. length: 2840.05,                last time consumption/overall running time: 3251.4305s / 41978.4724 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0013
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0013
env1_first_0:                 episode reward: 0.9000,                 loss: nan
env1_second_0:                 episode reward: -0.9000,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 281/30000 (0.9367%),                 avg. length: 2828.5,                last time consumption/overall running time: 3225.1710s / 45203.6434 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0012
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0012
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 301/30000 (1.0033%),                 avg. length: 2831.65,                last time consumption/overall running time: 3203.4041s / 48407.0475 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0013
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0013
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 321/30000 (1.0700%),                 avg. length: 2833.5,                last time consumption/overall running time: 3279.6116s / 51686.6591 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0012
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0012
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 341/30000 (1.1367%),                 avg. length: 2829.1,                last time consumption/overall running time: 3195.0688s / 54881.7279 s
env0_first_0:                 episode reward: -0.1500,                 loss: 0.0013
env0_second_0:                 episode reward: 0.1500,                 loss: 0.0012
env1_first_0:                 episode reward: 0.3500,                 loss: nan
env1_second_0:                 episode reward: -0.3500,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 361/30000 (1.2033%),                 avg. length: 2837.7,                last time consumption/overall running time: 3209.4737s / 58091.2016 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0013
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0012
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 381/30000 (1.2700%),                 avg. length: 2832.55,                last time consumption/overall running time: 3206.8087s / 61298.0103 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0012
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0012
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 401/30000 (1.3367%),                 avg. length: 2843.95,                last time consumption/overall running time: 3280.6348s / 64578.6451 s
env0_first_0:                 episode reward: -0.6500,                 loss: 0.0012
env0_second_0:                 episode reward: 0.6500,                 loss: 0.0012
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 421/30000 (1.4033%),                 avg. length: 2836.55,                last time consumption/overall running time: 3270.7903s / 67849.4354 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0013
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0013
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 441/30000 (1.4700%),                 avg. length: 2839.75,                last time consumption/overall running time: 3293.0588s / 71142.4943 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0013
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0013
env1_first_0:                 episode reward: -0.2500,                 loss: nan
env1_second_0:                 episode reward: 0.2500,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 461/30000 (1.5367%),                 avg. length: 2826.85,                last time consumption/overall running time: 3252.9762s / 74395.4705 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0011
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0012
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 481/30000 (1.6033%),                 avg. length: 2859.85,                last time consumption/overall running time: 3234.2866s / 77629.7571 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0014
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0013
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.5500,                 loss: nan
env2_second_0:                 episode reward: 0.5500,                 loss: nan
Episode: 501/30000 (1.6700%),                 avg. length: 2838.3,                last time consumption/overall running time: 3200.8110s / 80830.5681 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0013
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0012
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 521/30000 (1.7367%),                 avg. length: 2846.0,                last time consumption/overall running time: 3221.7657s / 84052.3338 s
env0_first_0:                 episode reward: 0.2000,                 loss: 0.0012
env0_second_0:                 episode reward: -0.2000,                 loss: 0.0012
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
env2_first_0:                 episode reward: 0.7500,                 loss: nan
env2_second_0:                 episode reward: -0.7500,                 loss: nan
Episode: 541/30000 (1.8033%),                 avg. length: 2849.9,                last time consumption/overall running time: 3284.5162s / 87336.8500 s
env0_first_0:                 episode reward: 0.0500,                 loss: 0.0012
env0_second_0:                 episode reward: -0.0500,                 loss: 0.0012
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 561/30000 (1.8700%),                 avg. length: 2830.9,                last time consumption/overall running time: 3270.9178s / 90607.7678 s
env0_first_0:                 episode reward: 0.1500,                 loss: 0.0012
env0_second_0:                 episode reward: -0.1500,                 loss: 0.0012
env1_first_0:                 episode reward: 0.5000,                 loss: nan
env1_second_0:                 episode reward: -0.5000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 581/30000 (1.9367%),                 avg. length: 2823.75,                last time consumption/overall running time: 3262.1816s / 93869.9494 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0011
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0012
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.6500,                 loss: nan
env2_second_0:                 episode reward: -0.6500,                 loss: nan
Episode: 601/30000 (2.0033%),                 avg. length: 2848.1,                last time consumption/overall running time: 3262.7703s / 97132.7197 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0012
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0011
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 621/30000 (2.0700%),                 avg. length: 2852.7,                last time consumption/overall running time: 3228.9441s / 100361.6638 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0012
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0011
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
env2_first_0:                 episode reward: 0.9500,                 loss: nan
env2_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 641/30000 (2.1367%),                 avg. length: 2852.15,                last time consumption/overall running time: 3229.3421s / 103591.0060 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0013
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0011
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: -0.2000,                 loss: nan
env2_second_0:                 episode reward: 0.2000,                 loss: nan
Episode: 661/30000 (2.2033%),                 avg. length: 2829.25,                last time consumption/overall running time: 3212.6817s / 106803.6877 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0012
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0011
env1_first_0:                 episode reward: 0.7000,                 loss: nan
env1_second_0:                 episode reward: -0.7000,                 loss: nan
env2_first_0:                 episode reward: 1.1500,                 loss: nan
env2_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 681/30000 (2.2700%),                 avg. length: 2827.7,                last time consumption/overall running time: 3207.1315s / 110010.8192 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0010
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0010
env1_first_0:                 episode reward: -0.6500,                 loss: nan
env1_second_0:                 episode reward: 0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 701/30000 (2.3367%),                 avg. length: 2852.3,                last time consumption/overall running time: 3242.0266s / 113252.8458 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0012
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0011
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 721/30000 (2.4033%),                 avg. length: 2855.7,                last time consumption/overall running time: 3224.3578s / 116477.2036 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0012
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0010
env1_first_0:                 episode reward: 0.8000,                 loss: nan
env1_second_0:                 episode reward: -0.8000,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 741/30000 (2.4700%),                 avg. length: 2859.15,                last time consumption/overall running time: 3257.0035s / 119734.2071 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0011
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0010
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 761/30000 (2.5367%),                 avg. length: 2823.2,                last time consumption/overall running time: 3182.0185s / 122916.2256 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0012
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0010
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 1.3500,                 loss: nan
env2_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 781/30000 (2.6033%),                 avg. length: 2835.85,                last time consumption/overall running time: 3234.7035s / 126150.9291 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0011
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0009
env1_first_0:                 episode reward: -0.4000,                 loss: nan
env1_second_0:                 episode reward: 0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 801/30000 (2.6700%),                 avg. length: 2824.45,                last time consumption/overall running time: 3204.8009s / 129355.7301 s
env0_first_0:                 episode reward: 1.1500,                 loss: 0.0011
env0_second_0:                 episode reward: -1.1500,                 loss: 0.0009
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.4000,                 loss: nan
env2_second_0:                 episode reward: -0.4000,                 loss: nan
Episode: 821/30000 (2.7367%),                 avg. length: 2854.35,                last time consumption/overall running time: 3235.8651s / 132591.5952 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0010
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0009
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 841/30000 (2.8033%),                 avg. length: 2854.25,                last time consumption/overall running time: 3273.5890s / 135865.1842 s
env0_first_0:                 episode reward: 1.4500,                 loss: 0.0010
env0_second_0:                 episode reward: -1.4500,                 loss: 0.0010
env1_first_0:                 episode reward: 1.0000,                 loss: nan
env1_second_0:                 episode reward: -1.0000,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 861/30000 (2.8700%),                 avg. length: 2838.25,                last time consumption/overall running time: 3276.1398s / 139141.3240 s
env0_first_0:                 episode reward: -0.2000,                 loss: 0.0009
env0_second_0:                 episode reward: 0.2000,                 loss: 0.0009
env1_first_0:                 episode reward: 1.1000,                 loss: nan
env1_second_0:                 episode reward: -1.1000,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 881/30000 (2.9367%),                 avg. length: 2834.2,                last time consumption/overall running time: 3204.6355s / 142345.9595 s
env0_first_0:                 episode reward: -0.3000,                 loss: 0.0009
env0_second_0:                 episode reward: 0.3000,                 loss: 0.0009
env1_first_0:                 episode reward: -0.4500,                 loss: nan
env1_second_0:                 episode reward: 0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 901/30000 (3.0033%),                 avg. length: 2850.4,                last time consumption/overall running time: 3249.4571s / 145595.4166 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0009
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0009
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: 1.4500,                 loss: nan
env2_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 921/30000 (3.0700%),                 avg. length: 2827.2,                last time consumption/overall running time: 3227.9455s / 148823.3621 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0009
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0008
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.0000,                 loss: nan
env2_second_0:                 episode reward: 0.0000,                 loss: nan
Episode: 941/30000 (3.1367%),                 avg. length: 2853.3,                last time consumption/overall running time: 3229.4165s / 152052.7786 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0009
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0008
env1_first_0:                 episode reward: 0.6000,                 loss: nan
env1_second_0:                 episode reward: -0.6000,                 loss: nan
env2_first_0:                 episode reward: -0.6500,                 loss: nan
env2_second_0:                 episode reward: 0.6500,                 loss: nan
Episode: 961/30000 (3.2033%),                 avg. length: 2841.7,                last time consumption/overall running time: 3219.2290s / 155272.0076 s
env0_first_0:                 episode reward: 2.1000,                 loss: 0.0008
env0_second_0:                 episode reward: -2.1000,                 loss: 0.0007
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: 1.1000,                 loss: nan
env2_second_0:                 episode reward: -1.1000,                 loss: nan
Episode: 981/30000 (3.2700%),                 avg. length: 2825.75,                last time consumption/overall running time: 3209.5589s / 158481.5665 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0009
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0009
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 1001/30000 (3.3367%),                 avg. length: 2814.7,                last time consumption/overall running time: 3196.8339s / 161678.4004 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0008
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0008
env1_first_0:                 episode reward: 0.5500,                 loss: nan
env1_second_0:                 episode reward: -0.5500,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 1021/30000 (3.4033%),                 avg. length: 2844.55,                last time consumption/overall running time: 3210.2497s / 164888.6501 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0008
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0008
env1_first_0:                 episode reward: 1.2000,                 loss: nan
env1_second_0:                 episode reward: -1.2000,                 loss: nan
env2_first_0:                 episode reward: 0.9500,                 loss: nan
env2_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 1041/30000 (3.4700%),                 avg. length: 2822.15,                last time consumption/overall running time: 3212.5938s / 168101.2439 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0009
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0009
env1_first_0:                 episode reward: 0.4500,                 loss: nan
env1_second_0:                 episode reward: -0.4500,                 loss: nan
env2_first_0:                 episode reward: 0.2000,                 loss: nan
env2_second_0:                 episode reward: -0.2000,                 loss: nan
Episode: 1061/30000 (3.5367%),                 avg. length: 2831.95,                last time consumption/overall running time: 3234.4175s / 171335.6614 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0009
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0008
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.2500,                 loss: nan
env2_second_0:                 episode reward: 0.2500,                 loss: nan
Episode: 1081/30000 (3.6033%),                 avg. length: 2812.8,                last time consumption/overall running time: 3254.4071s / 174590.0684 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0008
env0_second_0:                 episode reward: -1.6000,                 loss: 0.0007
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.1500,                 loss: nan
env2_second_0:                 episode reward: -0.1500,                 loss: nan
Episode: 1101/30000 (3.6700%),                 avg. length: 2831.55,                last time consumption/overall running time: 3256.6189s / 177846.6873 s
env0_first_0:                 episode reward: -0.7500,                 loss: 0.0008
env0_second_0:                 episode reward: 0.7500,                 loss: 0.0007
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.1000,                 loss: nan
env2_second_0:                 episode reward: -0.1000,                 loss: nan
Episode: 1121/30000 (3.7367%),                 avg. length: 2837.7,                last time consumption/overall running time: 3255.0415s / 181101.7288 s
env0_first_0:                 episode reward: 0.6000,                 loss: 0.0008
env0_second_0:                 episode reward: -0.6000,                 loss: 0.0007
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.2500,                 loss: nan
env2_second_0:                 episode reward: -0.2500,                 loss: nan
Episode: 1141/30000 (3.8033%),                 avg. length: 2837.9,                last time consumption/overall running time: 3272.5663s / 184374.2951 s
env0_first_0:                 episode reward: 0.7000,                 loss: 0.0009
env0_second_0:                 episode reward: -0.7000,                 loss: 0.0007
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 1161/30000 (3.8700%),                 avg. length: 2810.7,                last time consumption/overall running time: 3228.8448s / 187603.1399 s
env0_first_0:                 episode reward: 0.4500,                 loss: 0.0009
env0_second_0:                 episode reward: -0.4500,                 loss: 0.0008
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 1181/30000 (3.9367%),                 avg. length: 2811.15,                last time consumption/overall running time: 3245.2610s / 190848.4009 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0008
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0008
env1_first_0:                 episode reward: 0.6500,                 loss: nan
env1_second_0:                 episode reward: -0.6500,                 loss: nan
env2_first_0:                 episode reward: 0.9500,                 loss: nan
env2_second_0:                 episode reward: -0.9500,                 loss: nan
Episode: 1201/30000 (4.0033%),                 avg. length: 2865.2,                last time consumption/overall running time: 3316.4968s / 194164.8977 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0009
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0008
env1_first_0:                 episode reward: 0.2000,                 loss: nan
env1_second_0:                 episode reward: -0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1221/30000 (4.0700%),                 avg. length: 2851.4,                last time consumption/overall running time: 3282.6426s / 197447.5403 s
env0_first_0:                 episode reward: 0.8500,                 loss: 0.0009
env0_second_0:                 episode reward: -0.8500,                 loss: 0.0009
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 1241/30000 (4.1367%),                 avg. length: 2826.1,                last time consumption/overall running time: 3247.9466s / 200695.4869 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0007
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0007
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 1261/30000 (4.2033%),                 avg. length: 2830.85,                last time consumption/overall running time: 3264.9224s / 203960.4093 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0008
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0007
env1_first_0:                 episode reward: 0.2500,                 loss: nan
env1_second_0:                 episode reward: -0.2500,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 1281/30000 (4.2700%),                 avg. length: 2849.35,                last time consumption/overall running time: 3286.4237s / 207246.8330 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0008
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0007
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 1301/30000 (4.3367%),                 avg. length: 2847.2,                last time consumption/overall running time: 3294.6561s / 210541.4891 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0009
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0008
env1_first_0:                 episode reward: -0.3500,                 loss: nan
env1_second_0:                 episode reward: 0.3500,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 1321/30000 (4.4033%),                 avg. length: 2840.0,                last time consumption/overall running time: 3278.9016s / 213820.3907 s
env0_first_0:                 episode reward: 1.6000,                 loss: 0.0008
env0_second_0:                 episode reward: -1.6000,                 loss: 0.0007
env1_first_0:                 episode reward: 0.1500,                 loss: nan
env1_second_0:                 episode reward: -0.1500,                 loss: nan
env2_first_0:                 episode reward: 1.4000,                 loss: nan
env2_second_0:                 episode reward: -1.4000,                 loss: nan
Episode: 1341/30000 (4.4700%),                 avg. length: 2837.65,                last time consumption/overall running time: 3278.8270s / 217099.2178 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0008
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0007
env1_first_0:                 episode reward: 1.4000,                 loss: nan
env1_second_0:                 episode reward: -1.4000,                 loss: nan
env2_first_0:                 episode reward: 0.7000,                 loss: nan
env2_second_0:                 episode reward: -0.7000,                 loss: nan
Episode: 1361/30000 (4.5367%),                 avg. length: 2855.45,                last time consumption/overall running time: 3298.3647s / 220397.5824 s
env0_first_0:                 episode reward: 1.2500,                 loss: 0.0008
env0_second_0:                 episode reward: -1.2500,                 loss: 0.0007
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 1381/30000 (4.6033%),                 avg. length: 2846.4,                last time consumption/overall running time: 3278.1589s / 223675.7414 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0008
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0008
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 1401/30000 (4.6700%),                 avg. length: 2861.9,                last time consumption/overall running time: 3290.3099s / 226966.0512 s
env0_first_0:                 episode reward: 1.0000,                 loss: 0.0010
env0_second_0:                 episode reward: -1.0000,                 loss: 0.0009
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 1421/30000 (4.7367%),                 avg. length: 2853.85,                last time consumption/overall running time: 3270.4723s / 230236.5236 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0009
env0_second_0:                 episode reward: -1.8000,                 loss: 0.0009
env1_first_0:                 episode reward: 2.0000,                 loss: nan
env1_second_0:                 episode reward: -2.0000,                 loss: nan
env2_first_0:                 episode reward: 2.3000,                 loss: nan
env2_second_0:                 episode reward: -2.3000,                 loss: nan
Episode: 1441/30000 (4.8033%),                 avg. length: 2890.75,                last time consumption/overall running time: 3333.0166s / 233569.5402 s
env0_first_0:                 episode reward: 1.8000,                 loss: 0.0011
env0_second_0:                 episode reward: -1.8000,                 loss: 0.0011
env1_first_0:                 episode reward: 2.1000,                 loss: nan
env1_second_0:                 episode reward: -2.1000,                 loss: nan
env2_first_0:                 episode reward: 1.9500,                 loss: nan
env2_second_0:                 episode reward: -1.9500,                 loss: nan
Episode: 1461/30000 (4.8700%),                 avg. length: 2912.75,                last time consumption/overall running time: 3361.0165s / 236930.5566 s
env0_first_0:                 episode reward: 2.9500,                 loss: 0.0011
env0_second_0:                 episode reward: -2.9500,                 loss: 0.0011
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 1.9000,                 loss: nan
env2_second_0:                 episode reward: -1.9000,                 loss: nan
Episode: 1481/30000 (4.9367%),                 avg. length: 2887.65,                last time consumption/overall running time: 3340.9368s / 240271.4934 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0011
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0012
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 1501/30000 (5.0033%),                 avg. length: 2887.7,                last time consumption/overall running time: 3328.9747s / 243600.4681 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0012
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0011
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 1521/30000 (5.0700%),                 avg. length: 2912.6,                last time consumption/overall running time: 3358.2020s / 246958.6701 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.0012
env0_second_0:                 episode reward: -2.7500,                 loss: 0.0011
env1_first_0:                 episode reward: 1.4500,                 loss: nan
env1_second_0:                 episode reward: -1.4500,                 loss: nan
env2_first_0:                 episode reward: 2.4000,                 loss: nan
env2_second_0:                 episode reward: -2.4000,                 loss: nan
Episode: 1541/30000 (5.1367%),                 avg. length: 2860.7,                last time consumption/overall running time: 3316.8720s / 250275.5421 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0011
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0010
env1_first_0:                 episode reward: 1.7000,                 loss: nan
env1_second_0:                 episode reward: -1.7000,                 loss: nan
env2_first_0:                 episode reward: 1.1500,                 loss: nan
env2_second_0:                 episode reward: -1.1500,                 loss: nan
Episode: 1561/30000 (5.2033%),                 avg. length: 2882.25,                last time consumption/overall running time: 3343.2177s / 253618.7598 s
env0_first_0:                 episode reward: 1.9500,                 loss: 0.0010
env0_second_0:                 episode reward: -1.9500,                 loss: 0.0009
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 1.3000,                 loss: nan
env2_second_0:                 episode reward: -1.3000,                 loss: nan
Episode: 1581/30000 (5.2700%),                 avg. length: 2867.55,                last time consumption/overall running time: 3316.1263s / 256934.8862 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0009
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0008
env1_first_0:                 episode reward: 1.6500,                 loss: nan
env1_second_0:                 episode reward: -1.6500,                 loss: nan
env2_first_0:                 episode reward: 1.6500,                 loss: nan
env2_second_0:                 episode reward: -1.6500,                 loss: nan
Episode: 1601/30000 (5.3367%),                 avg. length: 2903.2,                last time consumption/overall running time: 3332.2252s / 260267.1113 s
env0_first_0:                 episode reward: 0.3500,                 loss: 0.0010
env0_second_0:                 episode reward: -0.3500,                 loss: 0.0009
env1_first_0:                 episode reward: 1.3000,                 loss: nan
env1_second_0:                 episode reward: -1.3000,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 1621/30000 (5.4033%),                 avg. length: 2953.0,                last time consumption/overall running time: 3415.4120s / 263682.5233 s
env0_first_0:                 episode reward: 4.1500,                 loss: 0.0011
env0_second_0:                 episode reward: -4.1500,                 loss: 0.0010
env1_first_0:                 episode reward: 2.6000,                 loss: nan
env1_second_0:                 episode reward: -2.6000,                 loss: nan
env2_first_0:                 episode reward: 3.7000,                 loss: nan
env2_second_0:                 episode reward: -3.7000,                 loss: nan
Episode: 1641/30000 (5.4700%),                 avg. length: 2942.75,                last time consumption/overall running time: 3381.9800s / 267064.5033 s
env0_first_0:                 episode reward: 3.3500,                 loss: 0.0013
env0_second_0:                 episode reward: -3.3500,                 loss: 0.0012
env1_first_0:                 episode reward: 4.1500,                 loss: nan
env1_second_0:                 episode reward: -4.1500,                 loss: nan
env2_first_0:                 episode reward: 4.2500,                 loss: nan
env2_second_0:                 episode reward: -4.2500,                 loss: nan
Episode: 1661/30000 (5.5367%),                 avg. length: 2961.45,                last time consumption/overall running time: 3413.7520s / 270478.2553 s
env0_first_0:                 episode reward: 3.6500,                 loss: 0.0013
env0_second_0:                 episode reward: -3.6500,                 loss: 0.0012
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
env2_first_0:                 episode reward: 3.2000,                 loss: nan
env2_second_0:                 episode reward: -3.2000,                 loss: nan
Episode: 1681/30000 (5.6033%),                 avg. length: 2909.4,                last time consumption/overall running time: 3359.7966s / 273838.0520 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0013
env0_second_0:                 episode reward: -1.9000,                 loss: 0.0011
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 1.8000,                 loss: nan
env2_second_0:                 episode reward: -1.8000,                 loss: nan
Episode: 1701/30000 (5.6700%),                 avg. length: 2860.35,                last time consumption/overall running time: 3296.6774s / 277134.7293 s
env0_first_0:                 episode reward: 1.3500,                 loss: 0.0012
env0_second_0:                 episode reward: -1.3500,                 loss: 0.0010
env1_first_0:                 episode reward: 3.2000,                 loss: nan
env1_second_0:                 episode reward: -3.2000,                 loss: nan
env2_first_0:                 episode reward: 1.8500,                 loss: nan
env2_second_0:                 episode reward: -1.8500,                 loss: nan
Episode: 1721/30000 (5.7367%),                 avg. length: 2986.0,                last time consumption/overall running time: 3445.4142s / 280580.1435 s
env0_first_0:                 episode reward: 4.2500,                 loss: 0.0014
env0_second_0:                 episode reward: -4.2500,                 loss: 0.0012
env1_first_0:                 episode reward: 4.0500,                 loss: nan
env1_second_0:                 episode reward: -4.0500,                 loss: nan
env2_first_0:                 episode reward: 4.6500,                 loss: nan
env2_second_0:                 episode reward: -4.6500,                 loss: nan
Episode: 1741/30000 (5.8033%),                 avg. length: 2968.85,                last time consumption/overall running time: 3415.9312s / 283996.0747 s
env0_first_0:                 episode reward: 4.0500,                 loss: 0.0014
env0_second_0:                 episode reward: -4.0500,                 loss: 0.0013
env1_first_0:                 episode reward: 2.5000,                 loss: nan
env1_second_0:                 episode reward: -2.5000,                 loss: nan
env2_first_0:                 episode reward: 4.2500,                 loss: nan
env2_second_0:                 episode reward: -4.2500,                 loss: nan
Episode: 1761/30000 (5.8700%),                 avg. length: 2910.4,                last time consumption/overall running time: 3347.3265s / 287343.4012 s
env0_first_0:                 episode reward: 1.5000,                 loss: 0.0013
env0_second_0:                 episode reward: -1.5000,                 loss: 0.0013
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
env2_first_0:                 episode reward: 2.4500,                 loss: nan
env2_second_0:                 episode reward: -2.4500,                 loss: nan
Episode: 1781/30000 (5.9367%),                 avg. length: 2931.55,                last time consumption/overall running time: 3389.3782s / 290732.7794 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0013
env0_second_0:                 episode reward: -1.7000,                 loss: 0.0013
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
env2_first_0:                 episode reward: 2.2500,                 loss: nan
env2_second_0:                 episode reward: -2.2500,                 loss: nan
Episode: 1801/30000 (6.0033%),                 avg. length: 2958.2,                last time consumption/overall running time: 3418.4617s / 294151.2410 s
env0_first_0:                 episode reward: 2.7500,                 loss: 0.0015
env0_second_0:                 episode reward: -2.7500,                 loss: 0.0013
env1_first_0:                 episode reward: 4.4000,                 loss: nan
env1_second_0:                 episode reward: -4.4000,                 loss: nan
env2_first_0:                 episode reward: 1.7500,                 loss: nan
env2_second_0:                 episode reward: -1.7500,                 loss: nan
Episode: 1821/30000 (6.0700%),                 avg. length: 2938.25,                last time consumption/overall running time: 3350.2594s / 297501.5005 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.0016
env0_second_0:                 episode reward: -2.9000,                 loss: 0.0013
env1_first_0:                 episode reward: 3.7500,                 loss: nan
env1_second_0:                 episode reward: -3.7500,                 loss: nan
env2_first_0:                 episode reward: 2.7500,                 loss: nan
env2_second_0:                 episode reward: -2.7500,                 loss: nan
Episode: 1841/30000 (6.1367%),                 avg. length: 3035.95,                last time consumption/overall running time: 3518.0011s / 301019.5016 s
env0_first_0:                 episode reward: 1.9000,                 loss: 0.0016
env0_second_0:                 episode reward: -1.9000,                 loss: 0.0015
env1_first_0:                 episode reward: 2.7000,                 loss: nan
env1_second_0:                 episode reward: -2.7000,                 loss: nan
env2_first_0:                 episode reward: 1.3500,                 loss: nan
env2_second_0:                 episode reward: -1.3500,                 loss: nan
Episode: 1861/30000 (6.2033%),                 avg. length: 3028.4,                last time consumption/overall running time: 3496.3393s / 304515.8409 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.0016
env0_second_0:                 episode reward: -2.6500,                 loss: 0.0017
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
env2_first_0:                 episode reward: 2.1500,                 loss: nan
env2_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 1881/30000 (6.2700%),                 avg. length: 3016.25,                last time consumption/overall running time: 3474.2528s / 307990.0937 s
env0_first_0:                 episode reward: 1.0500,                 loss: 0.0016
env0_second_0:                 episode reward: -1.0500,                 loss: 0.0016
env1_first_0:                 episode reward: 2.8500,                 loss: nan
env1_second_0:                 episode reward: -2.8500,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 1901/30000 (6.3367%),                 avg. length: 3079.8,                last time consumption/overall running time: 3564.1873s / 311554.2810 s
env0_first_0:                 episode reward: 5.3500,                 loss: 0.0019
env0_second_0:                 episode reward: -5.3500,                 loss: 0.0016
env1_first_0:                 episode reward: 3.8500,                 loss: nan
env1_second_0:                 episode reward: -3.8500,                 loss: nan
env2_first_0:                 episode reward: 4.7000,                 loss: nan
env2_second_0:                 episode reward: -4.7000,                 loss: nan
Episode: 1921/30000 (6.4033%),                 avg. length: 3014.3,                last time consumption/overall running time: 3482.5117s / 315036.7927 s
env0_first_0:                 episode reward: 3.5000,                 loss: 0.0017
env0_second_0:                 episode reward: -3.5000,                 loss: 0.0015
env1_first_0:                 episode reward: 4.2000,                 loss: nan
env1_second_0:                 episode reward: -4.2000,                 loss: nan
env2_first_0:                 episode reward: 4.1000,                 loss: nan
env2_second_0:                 episode reward: -4.1000,                 loss: nan
Episode: 1941/30000 (6.4700%),                 avg. length: 3094.1,                last time consumption/overall running time: 3568.7995s / 318605.5922 s
env0_first_0:                 episode reward: 2.2500,                 loss: 0.0021
env0_second_0:                 episode reward: -2.2500,                 loss: 0.0019
env1_first_0:                 episode reward: 2.6500,                 loss: nan
env1_second_0:                 episode reward: -2.6500,                 loss: nan
env2_first_0:                 episode reward: 2.5500,                 loss: nan
env2_second_0:                 episode reward: -2.5500,                 loss: nan
Episode: 1961/30000 (6.5367%),                 avg. length: 2960.3,                last time consumption/overall running time: 3427.2224s / 322032.8146 s
env0_first_0:                 episode reward: 0.8000,                 loss: 0.0018
env0_second_0:                 episode reward: -0.8000,                 loss: 0.0017
env1_first_0:                 episode reward: 2.1500,                 loss: nan
env1_second_0:                 episode reward: -2.1500,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 1981/30000 (6.6033%),                 avg. length: 3164.8,                last time consumption/overall running time: 3657.4022s / 325690.2168 s
env0_first_0:                 episode reward: 4.2500,                 loss: 0.0022
env0_second_0:                 episode reward: -4.2500,                 loss: 0.0019
env1_first_0:                 episode reward: 3.9500,                 loss: nan
env1_second_0:                 episode reward: -3.9500,                 loss: nan
env2_first_0:                 episode reward: 4.4500,                 loss: nan
env2_second_0:                 episode reward: -4.4500,                 loss: nan
Episode: 2001/30000 (6.6700%),                 avg. length: 3144.75,                last time consumption/overall running time: 3635.3404s / 329325.5572 s
env0_first_0:                 episode reward: 4.9000,                 loss: 0.0023
env0_second_0:                 episode reward: -4.9000,                 loss: 0.0022
env1_first_0:                 episode reward: 3.2500,                 loss: nan
env1_second_0:                 episode reward: -3.2500,                 loss: nan
env2_first_0:                 episode reward: 4.7500,                 loss: nan
env2_second_0:                 episode reward: -4.7500,                 loss: nan
Episode: 2021/30000 (6.7367%),                 avg. length: 3165.25,                last time consumption/overall running time: 3656.6655s / 332982.2227 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0024
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0021
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
env2_first_0:                 episode reward: 3.0500,                 loss: nan
env2_second_0:                 episode reward: -3.0500,                 loss: nan
Episode: 2041/30000 (6.8033%),                 avg. length: 3187.6,                last time consumption/overall running time: 3680.4848s / 336662.7075 s
env0_first_0:                 episode reward: 4.3500,                 loss: 0.0023
env0_second_0:                 episode reward: -4.3500,                 loss: 0.0020
env1_first_0:                 episode reward: 2.9000,                 loss: nan
env1_second_0:                 episode reward: -2.9000,                 loss: nan
env2_first_0:                 episode reward: 2.1500,                 loss: nan
env2_second_0:                 episode reward: -2.1500,                 loss: nan
Episode: 2061/30000 (6.8700%),                 avg. length: 3150.4,                last time consumption/overall running time: 3625.0938s / 340287.8014 s
env0_first_0:                 episode reward: 3.5500,                 loss: 0.0024
env0_second_0:                 episode reward: -3.5500,                 loss: 0.0021
env1_first_0:                 episode reward: 4.4000,                 loss: nan
env1_second_0:                 episode reward: -4.4000,                 loss: nan
env2_first_0:                 episode reward: 3.2500,                 loss: nan
env2_second_0:                 episode reward: -3.2500,                 loss: nan
Episode: 2081/30000 (6.9367%),                 avg. length: 3031.05,                last time consumption/overall running time: 3490.1635s / 343777.9649 s
env0_first_0:                 episode reward: 3.9000,                 loss: 0.0021
env0_second_0:                 episode reward: -3.9000,                 loss: 0.0018
env1_first_0:                 episode reward: 4.7500,                 loss: nan
env1_second_0:                 episode reward: -4.7500,                 loss: nan
env2_first_0:                 episode reward: 4.7500,                 loss: nan
env2_second_0:                 episode reward: -4.7500,                 loss: nan
Episode: 2101/30000 (7.0033%),                 avg. length: 3066.6,                last time consumption/overall running time: 3541.8339s / 347319.7987 s
env0_first_0:                 episode reward: 2.6500,                 loss: 0.0020
env0_second_0:                 episode reward: -2.6500,                 loss: 0.0015
env1_first_0:                 episode reward: 2.4000,                 loss: nan
env1_second_0:                 episode reward: -2.4000,                 loss: nan
env2_first_0:                 episode reward: 4.5000,                 loss: nan
env2_second_0:                 episode reward: -4.5000,                 loss: nan
Episode: 2121/30000 (7.0700%),                 avg. length: 3108.0,                last time consumption/overall running time: 3585.5755s / 350905.3742 s
env0_first_0:                 episode reward: 2.9000,                 loss: 0.0025
env0_second_0:                 episode reward: -2.9000,                 loss: 0.0019
env1_first_0:                 episode reward: 2.8000,                 loss: nan
env1_second_0:                 episode reward: -2.8000,                 loss: nan
env2_first_0:                 episode reward: 2.9000,                 loss: nan
env2_second_0:                 episode reward: -2.9000,                 loss: nan
Episode: 2141/30000 (7.1367%),                 avg. length: 3039.1,                last time consumption/overall running time: 3502.4693s / 354407.8435 s
env0_first_0:                 episode reward: 3.8000,                 loss: 0.0022
env0_second_0:                 episode reward: -3.8000,                 loss: 0.0021
env1_first_0:                 episode reward: 4.6000,                 loss: nan
env1_second_0:                 episode reward: -4.6000,                 loss: nan
env2_first_0:                 episode reward: 2.6500,                 loss: nan
env2_second_0:                 episode reward: -2.6500,                 loss: nan
Episode: 2161/30000 (7.2033%),                 avg. length: 3024.9,                last time consumption/overall running time: 3485.4859s / 357893.3295 s
env0_first_0:                 episode reward: 3.3000,                 loss: 0.0018
env0_second_0:                 episode reward: -3.3000,                 loss: 0.0016
env1_first_0:                 episode reward: 4.8000,                 loss: nan
env1_second_0:                 episode reward: -4.8000,                 loss: nan
env2_first_0:                 episode reward: 3.8000,                 loss: nan
env2_second_0:                 episode reward: -3.8000,                 loss: nan
Episode: 2181/30000 (7.2700%),                 avg. length: 3026.6,                last time consumption/overall running time: 3485.2163s / 361378.5458 s
env0_first_0:                 episode reward: 2.4000,                 loss: 0.0018
env0_second_0:                 episode reward: -2.4000,                 loss: 0.0016
env1_first_0:                 episode reward: 3.8000,                 loss: nan
env1_second_0:                 episode reward: -3.8000,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 2201/30000 (7.3367%),                 avg. length: 3100.6,                last time consumption/overall running time: 3575.6420s / 364954.1878 s
env0_first_0:                 episode reward: 2.5000,                 loss: 0.0024
env0_second_0:                 episode reward: -2.5000,                 loss: 0.0019
env1_first_0:                 episode reward: 3.4000,                 loss: nan
env1_second_0:                 episode reward: -3.4000,                 loss: nan
env2_first_0:                 episode reward: 1.4500,                 loss: nan
env2_second_0:                 episode reward: -1.4500,                 loss: nan
Episode: 2221/30000 (7.4033%),                 avg. length: 3145.95,                last time consumption/overall running time: 3620.9839s / 368575.1717 s
env0_first_0:                 episode reward: 2.7000,                 loss: 0.0022
env0_second_0:                 episode reward: -2.7000,                 loss: 0.0020
env1_first_0:                 episode reward: 0.7500,                 loss: nan
env1_second_0:                 episode reward: -0.7500,                 loss: nan
env2_first_0:                 episode reward: 0.8500,                 loss: nan
env2_second_0:                 episode reward: -0.8500,                 loss: nan
Episode: 2241/30000 (7.4700%),                 avg. length: 3185.6,                last time consumption/overall running time: 3648.0968s / 372223.2685 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0025
env0_second_0:                 episode reward: -1.7000,                 loss: 0.0022
env1_first_0:                 episode reward: 1.5500,                 loss: nan
env1_second_0:                 episode reward: -1.5500,                 loss: nan
env2_first_0:                 episode reward: 1.5500,                 loss: nan
env2_second_0:                 episode reward: -1.5500,                 loss: nan
Episode: 2261/30000 (7.5367%),                 avg. length: 3148.05,                last time consumption/overall running time: 3635.0553s / 375858.3238 s
env0_first_0:                 episode reward: 1.5500,                 loss: 0.0028
env0_second_0:                 episode reward: -1.5500,                 loss: 0.0022
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: 2.1000,                 loss: nan
env2_second_0:                 episode reward: -2.1000,                 loss: nan
Episode: 2281/30000 (7.6033%),                 avg. length: 3078.65,                last time consumption/overall running time: 3553.8206s / 379412.1445 s
env0_first_0:                 episode reward: -0.0500,                 loss: 0.0023
env0_second_0:                 episode reward: 0.0500,                 loss: 0.0022
env1_first_0:                 episode reward: 0.4000,                 loss: nan
env1_second_0:                 episode reward: -0.4000,                 loss: nan
env2_first_0:                 episode reward: -0.3500,                 loss: nan
env2_second_0:                 episode reward: 0.3500,                 loss: nan
Episode: 2301/30000 (7.6700%),                 avg. length: 3107.05,                last time consumption/overall running time: 3595.7383s / 383007.8828 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0024
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0021
env1_first_0:                 episode reward: -0.1500,                 loss: nan
env1_second_0:                 episode reward: 0.1500,                 loss: nan
env2_first_0:                 episode reward: 0.9000,                 loss: nan
env2_second_0:                 episode reward: -0.9000,                 loss: nan
Episode: 2321/30000 (7.7367%),                 avg. length: 3139.35,                last time consumption/overall running time: 3625.8560s / 386633.7388 s
env0_first_0:                 episode reward: 2.3500,                 loss: 0.0027
env0_second_0:                 episode reward: -2.3500,                 loss: 0.0025
env1_first_0:                 episode reward: 2.2000,                 loss: nan
env1_second_0:                 episode reward: -2.2000,                 loss: nan
env2_first_0:                 episode reward: 1.0500,                 loss: nan
env2_second_0:                 episode reward: -1.0500,                 loss: nan
Episode: 2341/30000 (7.8033%),                 avg. length: 3003.6,                last time consumption/overall running time: 3472.1204s / 390105.8592 s
env0_first_0:                 episode reward: 1.7000,                 loss: 0.0021
env0_second_0:                 episode reward: -1.7000,                 loss: 0.0022
env1_first_0:                 episode reward: 3.1000,                 loss: nan
env1_second_0:                 episode reward: -3.1000,                 loss: nan
env2_first_0:                 episode reward: 1.7000,                 loss: nan
env2_second_0:                 episode reward: -1.7000,                 loss: nan
Episode: 2361/30000 (7.8700%),                 avg. length: 3120.95,                last time consumption/overall running time: 3577.8652s / 393683.7244 s
env0_first_0:                 episode reward: 0.0000,                 loss: 0.0022
env0_second_0:                 episode reward: 0.0000,                 loss: 0.0021
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: 0.3000,                 loss: nan
env2_second_0:                 episode reward: -0.3000,                 loss: nan
Episode: 2381/30000 (7.9367%),                 avg. length: 3225.45,                last time consumption/overall running time: 3712.0251s / 397395.7495 s
env0_first_0:                 episode reward: 0.9000,                 loss: 0.0026
env0_second_0:                 episode reward: -0.9000,                 loss: 0.0026
env1_first_0:                 episode reward: -0.2000,                 loss: nan
env1_second_0:                 episode reward: 0.2000,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2401/30000 (8.0033%),                 avg. length: 3172.9,                last time consumption/overall running time: 3654.1590s / 401049.9084 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0026
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0025
env1_first_0:                 episode reward: -0.0500,                 loss: nan
env1_second_0:                 episode reward: 0.0500,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2421/30000 (8.0700%),                 avg. length: 3188.25,                last time consumption/overall running time: 3667.3338s / 404717.2422 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0027
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0023
env1_first_0:                 episode reward: -0.7000,                 loss: nan
env1_second_0:                 episode reward: 0.7000,                 loss: nan
env2_first_0:                 episode reward: 0.3500,                 loss: nan
env2_second_0:                 episode reward: -0.3500,                 loss: nan
Episode: 2441/30000 (8.1367%),                 avg. length: 3129.1,                last time consumption/overall running time: 3602.1164s / 408319.3585 s
env0_first_0:                 episode reward: -0.8500,                 loss: 0.0024
env0_second_0:                 episode reward: 0.8500,                 loss: 0.0023
env1_first_0:                 episode reward: 0.1000,                 loss: nan
env1_second_0:                 episode reward: -0.1000,                 loss: nan
env2_first_0:                 episode reward: -0.8000,                 loss: nan
env2_second_0:                 episode reward: 0.8000,                 loss: nan
Episode: 2461/30000 (8.2033%),                 avg. length: 3098.0,                last time consumption/overall running time: 3569.1549s / 411888.5135 s
env0_first_0:                 episode reward: 1.3000,                 loss: 0.0023
env0_second_0:                 episode reward: -1.3000,                 loss: 0.0021
env1_first_0:                 episode reward: -0.1000,                 loss: nan
env1_second_0:                 episode reward: 0.1000,                 loss: nan
env2_first_0:                 episode reward: -1.5500,                 loss: nan
env2_second_0:                 episode reward: 1.5500,                 loss: nan
Episode: 2481/30000 (8.2700%),                 avg. length: 3211.05,                last time consumption/overall running time: 3697.6834s / 415586.1969 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0026
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0022
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -2.0000,                 loss: nan
env2_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 2501/30000 (8.3367%),                 avg. length: 3244.8,                last time consumption/overall running time: 3743.7262s / 419329.9230 s
env0_first_0:                 episode reward: -1.6000,                 loss: 0.0027
env0_second_0:                 episode reward: 1.6000,                 loss: 0.0026
env1_first_0:                 episode reward: -0.9500,                 loss: nan
env1_second_0:                 episode reward: 0.9500,                 loss: nan
env2_first_0:                 episode reward: -1.7000,                 loss: nan
env2_second_0:                 episode reward: 1.7000,                 loss: nan
Episode: 2521/30000 (8.4033%),                 avg. length: 3200.5,                last time consumption/overall running time: 3670.0381s / 422999.9611 s
env0_first_0:                 episode reward: 0.1000,                 loss: 0.0028
env0_second_0:                 episode reward: -0.1000,                 loss: 0.0026
env1_first_0:                 episode reward: -0.8000,                 loss: nan
env1_second_0:                 episode reward: 0.8000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2541/30000 (8.4700%),                 avg. length: 3170.7,                last time consumption/overall running time: 3663.8094s / 426663.7705 s
env0_first_0:                 episode reward: -3.0500,                 loss: 0.0028
env0_second_0:                 episode reward: 3.0500,                 loss: 0.0021
env1_first_0:                 episode reward: -0.5000,                 loss: nan
env1_second_0:                 episode reward: 0.5000,                 loss: nan
env2_first_0:                 episode reward: -1.0000,                 loss: nan
env2_second_0:                 episode reward: 1.0000,                 loss: nan
Episode: 2561/30000 (8.5367%),                 avg. length: 3147.6,                last time consumption/overall running time: 3620.7898s / 430284.5602 s
env0_first_0:                 episode reward: 0.3000,                 loss: 0.0022
env0_second_0:                 episode reward: -0.3000,                 loss: 0.0022
env1_first_0:                 episode reward: -2.3000,                 loss: nan
env1_second_0:                 episode reward: 2.3000,                 loss: nan
env2_first_0:                 episode reward: 0.0500,                 loss: nan
env2_second_0:                 episode reward: -0.0500,                 loss: nan
Episode: 2581/30000 (8.6033%),                 avg. length: 3218.4,                last time consumption/overall running time: 3700.0607s / 433984.6209 s
env0_first_0:                 episode reward: -1.3500,                 loss: 0.0028
env0_second_0:                 episode reward: 1.3500,                 loss: 0.0022
env1_first_0:                 episode reward: -1.4000,                 loss: nan
env1_second_0:                 episode reward: 1.4000,                 loss: nan
env2_first_0:                 episode reward: -1.0500,                 loss: nan
env2_second_0:                 episode reward: 1.0500,                 loss: nan
Episode: 2601/30000 (8.6700%),                 avg. length: 3227.25,                last time consumption/overall running time: 3712.5774s / 437697.1984 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0028
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0022
env1_first_0:                 episode reward: 0.3000,                 loss: nan
env1_second_0:                 episode reward: -0.3000,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2621/30000 (8.7367%),                 avg. length: 3279.4,                last time consumption/overall running time: 3776.9798s / 441474.1781 s
env0_first_0:                 episode reward: -2.3500,                 loss: 0.0028
env0_second_0:                 episode reward: 2.3500,                 loss: 0.0024
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
env2_first_0:                 episode reward: -1.1000,                 loss: nan
env2_second_0:                 episode reward: 1.1000,                 loss: nan
Episode: 2641/30000 (8.8033%),                 avg. length: 3216.6,                last time consumption/overall running time: 3688.9245s / 445163.1027 s
env0_first_0:                 episode reward: -1.8000,                 loss: 0.0029
env0_second_0:                 episode reward: 1.8000,                 loss: 0.0025
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
env2_first_0:                 episode reward: -0.5000,                 loss: nan
env2_second_0:                 episode reward: 0.5000,                 loss: nan
Episode: 2661/30000 (8.8700%),                 avg. length: 3166.15,                last time consumption/overall running time: 3630.4042s / 448793.5069 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0027
env0_second_0:                 episode reward: 1.7500,                 loss: 0.0022
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -0.4500,                 loss: nan
env2_second_0:                 episode reward: 0.4500,                 loss: nan
Episode: 2681/30000 (8.9367%),                 avg. length: 3172.75,                last time consumption/overall running time: 3649.2224s / 452442.7293 s
env0_first_0:                 episode reward: -0.3500,                 loss: 0.0029
env0_second_0:                 episode reward: 0.3500,                 loss: 0.0023
env1_first_0:                 episode reward: 1.5000,                 loss: nan
env1_second_0:                 episode reward: -1.5000,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2701/30000 (9.0033%),                 avg. length: 3200.45,                last time consumption/overall running time: 3656.4560s / 456099.1853 s
env0_first_0:                 episode reward: -2.1500,                 loss: 0.0026
env0_second_0:                 episode reward: 2.1500,                 loss: 0.0022
env1_first_0:                 episode reward: -1.3000,                 loss: nan
env1_second_0:                 episode reward: 1.3000,                 loss: nan
env2_first_0:                 episode reward: -1.6000,                 loss: nan
env2_second_0:                 episode reward: 1.6000,                 loss: nan
Episode: 2721/30000 (9.0700%),                 avg. length: 3137.65,                last time consumption/overall running time: 3588.1553s / 459687.3406 s
env0_first_0:                 episode reward: 0.2500,                 loss: 0.0026
env0_second_0:                 episode reward: -0.2500,                 loss: 0.0023
env1_first_0:                 episode reward: 0.0500,                 loss: nan
env1_second_0:                 episode reward: -0.0500,                 loss: nan
env2_first_0:                 episode reward: -0.3000,                 loss: nan
env2_second_0:                 episode reward: 0.3000,                 loss: nan
Episode: 2741/30000 (9.1367%),                 avg. length: 3185.35,                last time consumption/overall running time: 3671.0849s / 463358.4255 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0026
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0023
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 2761/30000 (9.2033%),                 avg. length: 3179.55,                last time consumption/overall running time: 3664.4245s / 467022.8500 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0027
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0024
env1_first_0:                 episode reward: -1.5500,                 loss: nan
env1_second_0:                 episode reward: 1.5500,                 loss: nan
env2_first_0:                 episode reward: -0.8500,                 loss: nan
env2_second_0:                 episode reward: 0.8500,                 loss: nan
Episode: 2781/30000 (9.2700%),                 avg. length: 3272.5,                last time consumption/overall running time: 3767.0787s / 470789.9286 s
env0_first_0:                 episode reward: -0.1000,                 loss: 0.0029
env0_second_0:                 episode reward: 0.1000,                 loss: 0.0024
env1_first_0:                 episode reward: -2.3500,                 loss: nan
env1_second_0:                 episode reward: 2.3500,                 loss: nan
env2_first_0:                 episode reward: -1.8500,                 loss: nan
env2_second_0:                 episode reward: 1.8500,                 loss: nan
Episode: 2801/30000 (9.3367%),                 avg. length: 3212.7,                last time consumption/overall running time: 3690.3630s / 474480.2916 s
env0_first_0:                 episode reward: -1.9500,                 loss: 0.0028
env0_second_0:                 episode reward: 1.9500,                 loss: 0.0025
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -2.4500,                 loss: nan
env2_second_0:                 episode reward: 2.4500,                 loss: nan
Episode: 2821/30000 (9.4033%),                 avg. length: 3172.15,                last time consumption/overall running time: 3626.9284s / 478107.2200 s
env0_first_0:                 episode reward: -1.0000,                 loss: 0.0028
env0_second_0:                 episode reward: 1.0000,                 loss: 0.0027
env1_first_0:                 episode reward: -0.9000,                 loss: nan
env1_second_0:                 episode reward: 0.9000,                 loss: nan
env2_first_0:                 episode reward: -2.0000,                 loss: nan
env2_second_0:                 episode reward: 2.0000,                 loss: nan
Episode: 2841/30000 (9.4700%),                 avg. length: 3264.55,                last time consumption/overall running time: 3749.1244s / 481856.3444 s
env0_first_0:                 episode reward: -1.9000,                 loss: 0.0027
env0_second_0:                 episode reward: 1.9000,                 loss: 0.0025
env1_first_0:                 episode reward: -0.7500,                 loss: nan
env1_second_0:                 episode reward: 0.7500,                 loss: nan
env2_first_0:                 episode reward: -1.4500,                 loss: nan
env2_second_0:                 episode reward: 1.4500,                 loss: nan
Episode: 2861/30000 (9.5367%),                 avg. length: 3198.85,                last time consumption/overall running time: 3670.1964s / 485526.5408 s
env0_first_0:                 episode reward: -1.8500,                 loss: 0.0031
env0_second_0:                 episode reward: 1.8500,                 loss: 0.0026
env1_first_0:                 episode reward: -1.8500,                 loss: nan
env1_second_0:                 episode reward: 1.8500,                 loss: nan
env2_first_0:                 episode reward: -3.2000,                 loss: nan
env2_second_0:                 episode reward: 3.2000,                 loss: nan
Episode: 2881/30000 (9.6033%),                 avg. length: 3189.7,                last time consumption/overall running time: 3659.7664s / 489186.3072 s
env0_first_0:                 episode reward: -1.7500,                 loss: 0.0027
env0_second_0:                 episode reward: 1.7500,                 loss: 0.0022
env1_first_0:                 episode reward: -1.0500,                 loss: nan
env1_second_0:                 episode reward: 1.0500,                 loss: nan
env2_first_0:                 episode reward: 0.6000,                 loss: nan
env2_second_0:                 episode reward: -0.6000,                 loss: nan
Episode: 2901/30000 (9.6700%),                 avg. length: 3250.0,                last time consumption/overall running time: 3745.6835s / 492931.9907 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0026
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0021
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
env2_first_0:                 episode reward: -0.9000,                 loss: nan
env2_second_0:                 episode reward: 0.9000,                 loss: nan
Episode: 2921/30000 (9.7367%),                 avg. length: 3171.45,                last time consumption/overall running time: 3630.4352s / 496562.4259 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0030
env0_second_0:                 episode reward: 4.1500,                 loss: 0.0024
env1_first_0:                 episode reward: -5.2500,                 loss: nan
env1_second_0:                 episode reward: 5.2500,                 loss: nan
env2_first_0:                 episode reward: -4.0500,                 loss: nan
env2_second_0:                 episode reward: 4.0500,                 loss: nan
Episode: 2941/30000 (9.8033%),                 avg. length: 3139.15,                last time consumption/overall running time: 3593.3112s / 500155.7371 s
env0_first_0:                 episode reward: -1.4500,                 loss: 0.0026
env0_second_0:                 episode reward: 1.4500,                 loss: 0.0023
env1_first_0:                 episode reward: -0.3000,                 loss: nan
env1_second_0:                 episode reward: 0.3000,                 loss: nan
env2_first_0:                 episode reward: -1.3000,                 loss: nan
env2_second_0:                 episode reward: 1.3000,                 loss: nan
Episode: 2961/30000 (9.8700%),                 avg. length: 3192.7,                last time consumption/overall running time: 3662.3488s / 503818.0860 s
env0_first_0:                 episode reward: -3.7000,                 loss: 0.0027
env0_second_0:                 episode reward: 3.7000,                 loss: 0.0024
env1_first_0:                 episode reward: -1.8000,                 loss: nan
env1_second_0:                 episode reward: 1.8000,                 loss: nan
env2_first_0:                 episode reward: -2.5000,                 loss: nan
env2_second_0:                 episode reward: 2.5000,                 loss: nan
Episode: 2981/30000 (9.9367%),                 avg. length: 3197.6,                last time consumption/overall running time: 3669.2474s / 507487.3334 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.0029
env0_second_0:                 episode reward: 2.8000,                 loss: 0.0026
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
env2_first_0:                 episode reward: -3.1000,                 loss: nan
env2_second_0:                 episode reward: 3.1000,                 loss: nan
Episode: 3001/30000 (10.0033%),                 avg. length: 3181.9,                last time consumption/overall running time: 3642.9008s / 511130.2342 s
env0_first_0:                 episode reward: -2.8000,                 loss: 0.0029
env0_second_0:                 episode reward: 2.8000,                 loss: 0.0026
env1_first_0:                 episode reward: -4.2000,                 loss: nan
env1_second_0:                 episode reward: 4.2000,                 loss: nan
env2_first_0:                 episode reward: -3.7000,                 loss: nan
env2_second_0:                 episode reward: 3.7000,                 loss: nan
Episode: 3021/30000 (10.0700%),                 avg. length: 3145.75,                last time consumption/overall running time: 3602.0437s / 514732.2779 s
env0_first_0:                 episode reward: -4.0000,                 loss: 0.0027
env0_second_0:                 episode reward: 4.0000,                 loss: 0.0023
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
env2_first_0:                 episode reward: -4.8000,                 loss: nan
env2_second_0:                 episode reward: 4.8000,                 loss: nan
Episode: 3041/30000 (10.1367%),                 avg. length: 3177.85,                last time consumption/overall running time: 3641.6387s / 518373.9166 s
env0_first_0:                 episode reward: -3.5500,                 loss: 0.0027
env0_second_0:                 episode reward: 3.5500,                 loss: 0.0024
env1_first_0:                 episode reward: -2.8500,                 loss: nan
env1_second_0:                 episode reward: 2.8500,                 loss: nan
env2_first_0:                 episode reward: -2.9000,                 loss: nan
env2_second_0:                 episode reward: 2.9000,                 loss: nan
Episode: 3061/30000 (10.2033%),                 avg. length: 3182.85,                last time consumption/overall running time: 3655.5097s / 522029.4263 s
env0_first_0:                 episode reward: -2.9500,                 loss: 0.0027
env0_second_0:                 episode reward: 2.9500,                 loss: 0.0025
env1_first_0:                 episode reward: -3.8000,                 loss: nan
env1_second_0:                 episode reward: 3.8000,                 loss: nan
env2_first_0:                 episode reward: -4.6500,                 loss: nan
env2_second_0:                 episode reward: 4.6500,                 loss: nan
Episode: 3081/30000 (10.2700%),                 avg. length: 3204.25,                last time consumption/overall running time: 3683.1518s / 525712.5781 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0024
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0022
env1_first_0:                 episode reward: -4.3000,                 loss: nan
env1_second_0:                 episode reward: 4.3000,                 loss: nan
env2_first_0:                 episode reward: -3.7500,                 loss: nan
env2_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 3101/30000 (10.3367%),                 avg. length: 3228.95,                last time consumption/overall running time: 3708.7498s / 529421.3279 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0030
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0023
env1_first_0:                 episode reward: -3.8500,                 loss: nan
env1_second_0:                 episode reward: 3.8500,                 loss: nan
env2_first_0:                 episode reward: -4.9500,                 loss: nan
env2_second_0:                 episode reward: 4.9500,                 loss: nan
Episode: 3121/30000 (10.4033%),                 avg. length: 3201.5,                last time consumption/overall running time: 3655.1847s / 533076.5126 s
env0_first_0:                 episode reward: -6.0500,                 loss: 0.0027
env0_second_0:                 episode reward: 6.0500,                 loss: 0.0024
env1_first_0:                 episode reward: -4.3500,                 loss: nan
env1_second_0:                 episode reward: 4.3500,                 loss: nan
env2_first_0:                 episode reward: -4.0000,                 loss: nan
env2_second_0:                 episode reward: 4.0000,                 loss: nan
Episode: 3141/30000 (10.4700%),                 avg. length: 3148.9,                last time consumption/overall running time: 3609.2435s / 536685.7561 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0027
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0024
env1_first_0:                 episode reward: -3.0000,                 loss: nan
env1_second_0:                 episode reward: 3.0000,                 loss: nan
env2_first_0:                 episode reward: -3.0500,                 loss: nan
env2_second_0:                 episode reward: 3.0500,                 loss: nan
Episode: 3161/30000 (10.5367%),                 avg. length: 3125.45,                last time consumption/overall running time: 3596.0496s / 540281.8057 s
env0_first_0:                 episode reward: -1.0500,                 loss: 0.0024
env0_second_0:                 episode reward: 1.0500,                 loss: 0.0021
env1_first_0:                 episode reward: -1.6000,                 loss: nan
env1_second_0:                 episode reward: 1.6000,                 loss: nan
env2_first_0:                 episode reward: -1.1500,                 loss: nan
env2_second_0:                 episode reward: 1.1500,                 loss: nan
Episode: 3181/30000 (10.6033%),                 avg. length: 3231.8,                last time consumption/overall running time: 3710.8708s / 543992.6766 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0027
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0025
env1_first_0:                 episode reward: -5.0000,                 loss: nan
env1_second_0:                 episode reward: 5.0000,                 loss: nan
env2_first_0:                 episode reward: -4.1000,                 loss: nan
env2_second_0:                 episode reward: 4.1000,                 loss: nan
Episode: 3201/30000 (10.6700%),                 avg. length: 3196.15,                last time consumption/overall running time: 3669.3816s / 547662.0581 s
env0_first_0:                 episode reward: -3.7500,                 loss: 0.0026
env0_second_0:                 episode reward: 3.7500,                 loss: 0.0024
env1_first_0:                 episode reward: -3.1000,                 loss: nan
env1_second_0:                 episode reward: 3.1000,                 loss: nan
env2_first_0:                 episode reward: -3.4500,                 loss: nan
env2_second_0:                 episode reward: 3.4500,                 loss: nan
Episode: 3221/30000 (10.7367%),                 avg. length: 3266.15,                last time consumption/overall running time: 3743.0873s / 551405.1454 s
env0_first_0:                 episode reward: -7.2000,                 loss: 0.0027
env0_second_0:                 episode reward: 7.2000,                 loss: 0.0023
env1_first_0:                 episode reward: -6.8500,                 loss: nan
env1_second_0:                 episode reward: 6.8500,                 loss: nan
env2_first_0:                 episode reward: -6.0000,                 loss: nan
env2_second_0:                 episode reward: 6.0000,                 loss: nan
Episode: 3241/30000 (10.8033%),                 avg. length: 3141.2,                last time consumption/overall running time: 3599.8469s / 555004.9923 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.0026
env0_second_0:                 episode reward: 4.5500,                 loss: 0.0023
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
env2_first_0:                 episode reward: -3.7500,                 loss: nan
env2_second_0:                 episode reward: 3.7500,                 loss: nan
Episode: 3261/30000 (10.8700%),                 avg. length: 3172.15,                last time consumption/overall running time: 3640.5200s / 558645.5123 s
env0_first_0:                 episode reward: -4.2000,                 loss: 0.0026
env0_second_0:                 episode reward: 4.2000,                 loss: 0.0022
env1_first_0:                 episode reward: -3.3500,                 loss: nan
env1_second_0:                 episode reward: 3.3500,                 loss: nan
env2_first_0:                 episode reward: -3.8500,                 loss: nan
env2_second_0:                 episode reward: 3.8500,                 loss: nan
Episode: 3281/30000 (10.9367%),                 avg. length: 3164.8,                last time consumption/overall running time: 3619.0439s / 562264.5562 s
env0_first_0:                 episode reward: -5.4000,                 loss: 0.0026
env0_second_0:                 episode reward: 5.4000,                 loss: 0.0022
env1_first_0:                 episode reward: -4.0500,                 loss: nan
env1_second_0:                 episode reward: 4.0500,                 loss: nan
env2_first_0:                 episode reward: -4.6000,                 loss: nan
env2_second_0:                 episode reward: 4.6000,                 loss: nan
Episode: 3301/30000 (11.0033%),                 avg. length: 3164.15,                last time consumption/overall running time: 3628.0825s / 565892.6386 s
env0_first_0:                 episode reward: -2.4000,                 loss: 0.0023
env0_second_0:                 episode reward: 2.4000,                 loss: 0.0020
env1_first_0:                 episode reward: -2.5000,                 loss: nan
env1_second_0:                 episode reward: 2.5000,                 loss: nan
env2_first_0:                 episode reward: 0.5000,                 loss: nan
env2_second_0:                 episode reward: -0.5000,                 loss: nan
Episode: 3321/30000 (11.0700%),                 avg. length: 3178.1,                last time consumption/overall running time: 3649.1259s / 569541.7646 s
env0_first_0:                 episode reward: -4.1500,                 loss: 0.0027
env0_second_0:                 episode reward: 4.1500,                 loss: 0.0023
env1_first_0:                 episode reward: -1.4500,                 loss: nan
env1_second_0:                 episode reward: 1.4500,                 loss: nan
env2_first_0:                 episode reward: -3.5000,                 loss: nan
env2_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 3341/30000 (11.1367%),                 avg. length: 3104.2,                last time consumption/overall running time: 3553.3097s / 573095.0743 s
env0_first_0:                 episode reward: -2.5000,                 loss: 0.0025
env0_second_0:                 episode reward: 2.5000,                 loss: 0.0022
env1_first_0:                 episode reward: -3.7500,                 loss: nan
env1_second_0:                 episode reward: 3.7500,                 loss: nan
env2_first_0:                 episode reward: -0.9500,                 loss: nan
env2_second_0:                 episode reward: 0.9500,                 loss: nan
Episode: 3361/30000 (11.2033%),                 avg. length: 3161.6,                last time consumption/overall running time: 3626.4916s / 576721.5659 s
env0_first_0:                 episode reward: -3.6500,                 loss: 0.0024
env0_second_0:                 episode reward: 3.6500,                 loss: 0.0021
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: -4.6500,                 loss: nan
env2_second_0:                 episode reward: 4.6500,                 loss: nan
Episode: 3381/30000 (11.2700%),                 avg. length: 3199.75,                last time consumption/overall running time: 3685.2120s / 580406.7779 s
env0_first_0:                 episode reward: -3.4000,                 loss: 0.0026
env0_second_0:                 episode reward: 3.4000,                 loss: 0.0024
env1_first_0:                 episode reward: -4.6500,                 loss: nan
env1_second_0:                 episode reward: 4.6500,                 loss: nan
env2_first_0:                 episode reward: -2.6500,                 loss: nan
env2_second_0:                 episode reward: 2.6500,                 loss: nan
Episode: 3401/30000 (11.3367%),                 avg. length: 3110.3,                last time consumption/overall running time: 3580.9516s / 583987.7295 s
env0_first_0:                 episode reward: -2.5500,                 loss: 0.0027
env0_second_0:                 episode reward: 2.5500,                 loss: 0.0022
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan
env2_first_0:                 episode reward: -1.6500,                 loss: nan
env2_second_0:                 episode reward: 1.6500,                 loss: nan
Episode: 3421/30000 (11.4033%),                 avg. length: 3106.75,                last time consumption/overall running time: 3599.4803s / 587587.2098 s
env0_first_0:                 episode reward: -4.5500,                 loss: 0.0025
env0_second_0:                 episode reward: 4.5500,                 loss: 0.0018
env1_first_0:                 episode reward: -3.2000,                 loss: nan
env1_second_0:                 episode reward: 3.2000,                 loss: nan
env2_first_0:                 episode reward: -3.9500,                 loss: nan
env2_second_0:                 episode reward: 3.9500,                 loss: nan
Episode: 3441/30000 (11.4700%),                 avg. length: 3108.55,                last time consumption/overall running time: 3573.1588s / 591160.3686 s
env0_first_0:                 episode reward: -3.0000,                 loss: 0.0025
env0_second_0:                 episode reward: 3.0000,                 loss: 0.0019
env1_first_0:                 episode reward: -2.4000,                 loss: nan
env1_second_0:                 episode reward: 2.4000,                 loss: nan
env2_first_0:                 episode reward: -2.2000,                 loss: nan
env2_second_0:                 episode reward: 2.2000,                 loss: nan
Episode: 3461/30000 (11.5367%),                 avg. length: 3149.3,                last time consumption/overall running time: 3617.9860s / 594778.3546 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0026
env0_second_0:                 episode reward: 4.4500,                 loss: 0.0019
env1_first_0:                 episode reward: -3.4000,                 loss: nan
env1_second_0:                 episode reward: 3.4000,                 loss: nan
env2_first_0:                 episode reward: -3.5000,                 loss: nan
env2_second_0:                 episode reward: 3.5000,                 loss: nan
Episode: 3481/30000 (11.6033%),                 avg. length: 3153.7,                last time consumption/overall running time: 3625.3203s / 598403.6749 s
env0_first_0:                 episode reward: -2.7000,                 loss: 0.0028
env0_second_0:                 episode reward: 2.7000,                 loss: 0.0022
env1_first_0:                 episode reward: -2.1000,                 loss: nan
env1_second_0:                 episode reward: 2.1000,                 loss: nan
env2_first_0:                 episode reward: -3.0000,                 loss: nan
env2_second_0:                 episode reward: 3.0000,                 loss: nan
Episode: 3501/30000 (11.6700%),                 avg. length: 3146.35,                last time consumption/overall running time: 3618.4536s / 602022.1285 s
env0_first_0:                 episode reward: -4.4500,                 loss: 0.0029
env0_second_0:                 episode reward: 4.4500,                 loss: 0.0023
env1_first_0:                 episode reward: -3.5000,                 loss: nan
env1_second_0:                 episode reward: 3.5000,                 loss: nan
env2_first_0:                 episode reward: -3.1500,                 loss: nan
env2_second_0:                 episode reward: 3.1500,                 loss: nan
Episode: 3521/30000 (11.7367%),                 avg. length: 3163.25,                last time consumption/overall running time: 3629.7735s / 605651.9020 s
env0_first_0:                 episode reward: -3.2000,                 loss: 0.0026
env0_second_0:                 episode reward: 3.2000,                 loss: 0.0020
env1_first_0:                 episode reward: -3.2500,                 loss: nan
env1_second_0:                 episode reward: 3.2500,                 loss: nan