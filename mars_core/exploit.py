from utils.func import LoadYAML2Dict
from env.import_env import make_env
from rollout import rollout
from rl.algorithm import *
from general_train import get_general_args
from general_exploit import get_latest_file_in_folder
from utils.common import SelfplayBasedMethods

### Load configurations
game_type = 'pettingzoo'
game = ['boxing_v1', 'surround_v1', 'combat_plane_v1'][0]
method = ['selfplay', 'nash_dqn', 'nash_dqn_exploiter'][2]

args = get_general_args(game_type+'_'+game, method)
print(args)

## Change/specify some arguments if necessary
args.against_baseline = False
args.test = False
args.exploit = True
# args.render = True
folder = f'../data/model/20211109_1530/{game_type}_{game}_{method}/'
if method in SelfplayBasedMethods:
    file_path = get_latest_file_in_folder(folder)
else:
    file_path = get_latest_file_in_folder(folder, id=0)  # load from the first agent model of the two
args.load_model_full_path = file_path

### Create env
env = make_env(args)
print(env)

### Specify models for each agent
# args.net_architecture['hidden_dim_list'] = [1024, 1024, 1024, 1024]  
trained_model = eval(args.algorithm)(env, args)
args.net_architecture['hidden_dim_list'] = [64, 64, 64]
exploiter = DQN(env, args)
exploiter.reinit()
trained_model.fix()

model = MultiAgent(env, [trained_model, exploiter], args)
# model = MultiAgent(env, [exploiter, trained_model], args)

### Rollout
rollout(env, model, args)